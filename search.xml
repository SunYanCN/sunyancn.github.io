<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>2019 面试</title>
    <url>/post/55675.html</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><div class="table-container">
<table>
<thead>
<tr>
<th>面试公司</th>
<th>投递时间</th>
<th>投递方式</th>
<th>面试情况</th>
</tr>
</thead>
<tbody>
<tr>
<td>云从科技</td>
<td> 2019 年 8 月 2 日</td>
<td> moka</td>
<td> 等待面试</td>
</tr>
<tr>
<td> B 站</td>
<td> 2019 年 8 月 2 日</td>
<td> moka</td>
<td> 等待面试</td>
</tr>
<tr>
<td>快手</td>
<td> 2019 年 8 月 2 日</td>
<td>官网内推</td>
<td>等待面试</td>
</tr>
<tr>
<td>斗鱼校招提前批</td>
<td> 2019 年 8 月 4 日</td>
<td>官网内推</td>
<td>等待面试</td>
</tr>
<tr>
<td>字节跳动秋招</td>
<td> 2019 年 8 月 5 日</td>
<td>官网内推</td>
<td>等待面试</td>
</tr>
<tr>
<td>顺丰</td>
<td> 2019 年 8 月 5 日</td>
<td>官网内推</td>
<td>等待面试</td>
</tr>
<tr>
<td>百度提前批</td>
<td> 2019 年 8 月 5 日</td>
<td>邮箱投递</td>
<td>等待面试 </td>
</tr>
</tbody>
</table>
</div>
<ul>
<li><a href="https://app.mokahr.com/campus_apply/transwarp/3196#/candidateHome/applications?_k=5fww6j">MoKa 简历状态查询</a></li>
<li>超级简历一个月会员激活码：guluvlogs</li>
</ul>
]]></content>
  </entry>
  <entry>
    <title>20200224210643</title>
    <url>/post/6222.html</url>
    <content><![CDATA[<html><head><link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script></head><body><h3 id="nodejs更新" class="heading-control"><a href="#nodejs更新" class="headerlink" title="nodejs更新"></a>nodejs 更新<a class="heading-anchor" href="#nodejs更新" aria-hidden="true"></a></h3><ol>
<li><p>`npm install -g n 对 n 模块进行全局安装</p>
</li>
<li><p>使用 n 命令进行更新<br>n stable // 更新到稳定版<br>n latest // 更新到最新版</p>
</li>
<li><p>使用 node -v 看是否已经更新完成了</p>
</li>
</ol>
<h3 id="查看文件的状态" class="heading-control"><a href="#查看文件的状态" class="headerlink" title="查看文件的状态"></a>查看文件的状态<a class="heading-anchor" href="#查看文件的状态" aria-hidden="true"></a></h3><p>在 Linux 下，一个文件有三种时间，分别是访问时间（Access）、修改时间（Modify）、状态改变时间（Change）。可以通过 stat 命令查看文件的状态<br>stat file<br>example: stat A.py</p>
<h3 id="模型性能通常会随着时间而下降" class="heading-control"><a href="#模型性能通常会随着时间而下降" class="headerlink" title="模型性能通常会随着时间而下降"></a>模型性能通常会随着时间而下降<a class="heading-anchor" href="#模型性能通常会随着时间而下降" aria-hidden="true"></a></h3><p>观点：模型性能通常会随着时间而下降<br>因为新的数据在不断产生，俗话说学如逆水行舟，不进则退</p>
<h3 id="两个github库" class="heading-control"><a href="#两个github库" class="headerlink" title="两个github库"></a>两个 github 库<a class="heading-anchor" href="#两个github库" aria-hidden="true"></a></h3><ul>
<li>streamlit：可视化构建应用<br><a href="https://mlwhiz.com/blog/2019/12/07/streamlit/">https://mlwhiz.com/blog/2019/12/07/streamlit/</a></li>
<li>ELI5：模型解释性</li>
</ul>
<h3 id="对象检测和实例分割" class="heading-control"><a href="#对象检测和实例分割" class="headerlink" title="对象检测和实例分割"></a>对象检测和实例分割<a class="heading-anchor" href="#对象检测和实例分割" aria-hidden="true"></a></h3><ul>
<li><a href="https://mlwhiz.com/blog/2019/12/06/weapons/">https://mlwhiz.com/blog/2019/12/06/weapons/</a></li>
<li><a href="https://mlwhiz.com/blog/2019/12/05/od/">https://mlwhiz.com/blog/2019/12/05/od/</a><br>-<a href="https://mlwhiz.com/blog/2019/11/08/interpret_models/">https://mlwhiz.com/blog/2019/11/08/interpret_models/</a></li>
</ul>
</body></html>]]></content>
  </entry>
  <entry>
    <title>20200203123847</title>
    <url>/post/30365.html</url>
    <content><![CDATA[<html><head><link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script></head><body><h2 id="0x01-Python好用的格式化" class="heading-control"><a href="#0x01-Python好用的格式化" class="headerlink" title="0x01 Python好用的格式化"></a>0x01 Python 好用的格式化<a class="heading-anchor" href="#0x01-Python好用的格式化" aria-hidden="true"></a></h2><p>来自文章<a href>《Write Better Python Code Today》</a>，从 Python 3.6 开始，f-string 是格式化字符串的一种很好的新方法。与其他格式化方式相比，它们不仅更易读，更简洁，不易出错，而且速度更快。<br>下面是一个简单例子 (注意大写的 F 也是有效的)：<br></p><figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line">name = <span class="string">"Eric"</span></span><br><span class="line">age = <span class="number">74</span></span><br><span class="line"><span class="string">f"Hello, <span class="subst">{name}</span>. You are <span class="subst">{age}</span>."</span></span><br><span class="line"><span class="comment">#or F"Hello, {name}. You are {age}."</span></span><br><span class="line"><span class="comment"># 输出</span></span><br><span class="line"><span class="string">'Hello, Eric. You are 74.'</span></span><br></pre></td></tr></tbody></table></figure><p></p>
</body></html>]]></content>
  </entry>
  <entry>
    <title>2020 苹果发布会</title>
    <url>/post/f07c7ecf.html</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p><img src="https://i.loli.net/2020/10/16/NehVWL9DGaYbBny.png" alt="20201016010552186"><br><a id="more"></a><br><img src="https://i.loli.net/2020/10/16/l1H6wBTS7Jctmo8.png" alt="20201016010623017"><br><img src="https://i.loli.net/2020/10/16/ANiRnkdbZoTK98B.png" alt="20201016010710900"></p>
]]></content>
      <tags>
        <tag>苹果</tag>
      </tags>
  </entry>
  <entry>
    <title>ACL2020 paper 相关论文</title>
    <url>/post/58505.html</url>
    <content><![CDATA[<html><head><link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script></head><body><h3 id="数据集" class="heading-control"><a href="#数据集" class="headerlink" title="数据集"></a>数据集<a class="heading-anchor" href="#数据集" aria-hidden="true"></a></h3><p><a href="https://arxiv.xilesou.top/pdf/1810.07366.pdf">CMRC2018</a><br><a href="https://arxiv.xilesou.top/ftp/arxiv/papers/1806/1806.00920.pdf">DRCD</a></p>
<h3 id="Rank" class="heading-control"><a href="#Rank" class="headerlink" title="Rank"></a>Rank<a class="heading-anchor" href="#Rank" aria-hidden="true"></a></h3><p><a href="https://arxiv.xilesou.top/pdf/1901.04085.pdf">Passage Re-ranking with BERT</a></p>
</body></html>]]></content>
      <tags>
        <tag>论文</tag>
      </tags>
  </entry>
  <entry>
    <title>Attention,BiLSTM 以及 Transform</title>
    <url>/post/50119.html</url>
    <content><![CDATA[<html><head><link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script></head><body><h2 id="Attention" class="heading-control"><a href="#Attention" class="headerlink" title="Attention"></a>Attention<a class="heading-anchor" href="#Attention" aria-hidden="true"></a></h2><div id="dplayer0" class="dplayer hexo-tag-dplayer-mark" style="margin-bottom: 20px;"></div><script>(function(){var player = new DPlayer({"container":document.getElementById("dplayer0"),"theme":"#FADFA3","loop":true,"video":{"url":"https://jalammar.github.io/images/attention_process.mp4"},"danmaku":{"api":"https://api.prprpr.me/dplayer/","token":"tokendemo"}});window.dplayers||(window.dplayers=[]);window.dplayers.push(player);})()</script>
<a id="more"></a>
<p>上面这个视频很好的总结了 Attention 的各个步骤：</p>
<ol>
<li>首先收集 (储存) Encoder 的每一步的隐藏状态的输出向量。</li>
<li>对每个隐藏状态进行评分（先不考虑如何评分）。</li>
<li>对评分进行 Softmax 概率化。</li>
<li>把得到的概率与对应的输出向量相乘，放大具有高分数的隐藏状态，淹没低分数的隐藏状态。</li>
<li>对加权后的向量求和，得到输出。</li>
</ol>
<div id="dplayer1" class="dplayer hexo-tag-dplayer-mark" style="margin-bottom: 20px;"></div><script>(function(){var player = new DPlayer({"container":document.getElementById("dplayer1"),"theme":"#FADFA3","loop":true,"video":{"url":"https://jalammar.github.io/images/attention_tensor_dance.mp4"},"danmaku":{"api":"https://api.prprpr.me/dplayer/","token":"tokendemo"}});window.dplayers||(window.dplayers=[]);window.dplayers.push(player);})()</script>
<p>在具体的每一个时间单元步里面执行过程如下：</p>
<ol>
<li>Decoder RNN 接受’<end>‘的词向量和 Decoder 的初始向量。</end></li>
<li>经过 RNN 处理，产生输出和隐藏向量 (h4), 丢掉输出。</li>
<li>Attention: 使用储存的 Encoder 词向量和 h4 向量来计算时间步的上下文向量 (C4)。</li>
<li>h4 和 C4 进行拼接得到这一个 RNN 的输出。</li>
<li>通过 Dense+softmax 来得到字典中每个字的概率，从而最大化输出字标签。</li>
<li>这一时间步执行完毕，把 h4 传递到下一个 RNN, 下一个 RNN 的输入为上一个 RNN 的输出。</li>
</ol>
<p>把每一个时间步骤汇总起来就得到了最后的输入输出的 Attention 矩阵：<br><img src="https://i.loli.net/2018/11/06/5be102811cbdf.png" alt><br>上面的过程搞明白后，现在的问题就是怎么对几个向量进行评分。</p>
<h2 id="Transformer-（Attention-Is-All-You-Need）" class="heading-control"><a href="#Transformer-（Attention-Is-All-You-Need）" class="headerlink" title="Transformer （Attention Is All You Need）"></a>Transformer （Attention Is All You Need）<a class="heading-anchor" href="#Transformer-（Attention-Is-All-You-Need）" aria-hidden="true"></a></h2><p>正如论文的题目所说的，Transformer 中抛弃了传统的 CNN 和 RNN，整个网络结构完全是由 Attention 机制组成。更准确地讲，Transformer 由且仅由 self-Attenion 和 Feed Forward Neural Network 组成。一个基于 Transformer 的可训练的神经网络可以通过堆叠 Transformer 的形式进行搭建，作者的实验是通过搭建编码器和解码器各 6 层，总共 12 层的 Encoder-Decoder，并在机器翻译中取得了 BLEU 值得新高。<br><img src="/Attention,BiLSTM以及Transform/20181106111716656.png" alt><br>作者采用 Attention 机制的原因是考虑到 RNN（或者 LSTM，GRU 等）的计算限制为是顺序的，也就是说 RNN 相关算法只能从左向右依次计算或者从右向左依次计算，这种机制带来了两个问题：</p>
<ol>
<li>时间片 t 的计算依赖 t-1 时刻的计算结果，这样限制了模型的并行能力；</li>
<li>顺序计算的过程中信息会丢失，尽管 LSTM 等门机制的结构一定程度上缓解了长期依赖的问题，但是对于特别长期的依赖现象，LSTM 依旧无能为力。</li>
</ol>
</body></html>]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>NLP</tag>
      </tags>
  </entry>
  <entry>
    <title>CNN+BLSTM+CTC 的验证码识别从训练到部署</title>
    <url>/post/45705.html</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>这个项目很偏实战，有非常多的细节值得学习。我主要关注作者的项目部署过程。</p>
<ul>
<li><a href="https://github.com/kerlomz/captcha_trainer">项目地址</a></li>
<li><a href="https://www.jianshu.com/p/80ef04b16efc">简书项目介绍</a></li>
</ul>
<p>在简书的项目介绍中，作者介绍了 CUDA 和 cuDNN 版本的问题，目前我都是通过 conda 安装 Tensorflow-GPU 版本，没有出现什么问题，但是还是在这里列一下，以防万一。</p>
<a id="more"></a>
<p><img src="https://i.loli.net/2018/12/06/5c0919fd3275c.png" alt=""><br><img src="https://i.loli.net/2018/12/06/5c0919fd6faef.png" alt=""></p>
]]></content>
      <categories>
        <category>项目</category>
      </categories>
      <tags>
        <tag>验证码</tag>
      </tags>
  </entry>
  <entry>
    <title>CS231N 学习笔记</title>
    <url>/post/24704.html</url>
    <content><![CDATA[<html><head><link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script></head><body><h2 id="CS231N课程描述和资源" class="heading-control"><a href="#CS231N课程描述和资源" class="headerlink" title="CS231N课程描述和资源"></a>CS231N 课程描述和资源<a class="heading-anchor" href="#CS231N课程描述和资源" aria-hidden="true"></a></h2><p>CS231n 的全称是 CS231n: Convolutional Neural Networks for Visual Recognition，即面向视觉识别的卷积神经网络。该课程是斯坦福大学计算机视觉实验室推出的课程。<br>课程官网：<a href="http://cs231n.stanford.edu/">http://cs231n.stanford.edu/</a><br>官方笔记：<a href="http://cs231n.github.io/">http://cs231n.github.io/</a><br>B 站视频：<a href="https://www.bilibili.com/video/av58778425">https://www.bilibili.com/video/av58778425</a><br>课程作业：<a href="https://github.com/Burton2000/CS231n-2017">https://github.com/Burton2000/CS231n-2017</a></p>
<a id="more"></a>
<h2 id="Lecture-1：引言" class="heading-control"><a href="#Lecture-1：引言" class="headerlink" title="Lecture 1：引言"></a>Lecture 1：引言<a class="heading-anchor" href="#Lecture-1：引言" aria-hidden="true"></a></h2><p>主要是计算机视觉概述和背景。</p>
<ul>
<li>从 1960 年代末到 2017 年的计算机视觉简史。</li>
<li>计算机视觉问题包括图像分类，目标定位，目标检测和场景理解。</li>
<li>Imagenet 是目前可用的图像分类中最大的数据集之一。</li>
<li>从 2012 年在 Imagenet 竞赛中开始，CNN（卷积神经网络）一直是赢家。</li>
<li>CNN 实际上是由 Yann Lecun 于 1997 年发明的。</li>
<li>近年来深度学习的成功主要来源于数据和算力的增长</li>
</ul>
<h2 id="Lecture-2：图像分类" class="heading-control"><a href="#Lecture-2：图像分类" class="headerlink" title="Lecture 2：图像分类"></a>Lecture 2：图像分类<a class="heading-anchor" href="#Lecture-2：图像分类" aria-hidden="true"></a></h2><h3 id="数据驱动" class="heading-control"><a href="#数据驱动" class="headerlink" title="数据驱动"></a>数据驱动<a class="heading-anchor" href="#数据驱动" aria-hidden="true"></a></h3><p>数据驱动的分类方法是指:</p>
<ul>
<li>收集具有标注的图片数据集 (CIFAR10).</li>
<li> 使用机器学习来训练分类器.</li>
<li> 使用模型来预测新的图片.</li>
</ul>
<h3 id="KNN" class="heading-control"><a href="#KNN" class="headerlink" title="KNN"></a>KNN<a class="heading-anchor" href="#KNN" aria-hidden="true"></a></h3><p>KNN 用于图片分类：将两张图片先转化为两个向量（向量的维度为像素数量）$I_1$ 和 $I_2$，再计算两者的距离 $L_1$ 或者 $L_2$（距离的选择是一个超参数），找距离最近的 k 个图片的标签，让他们针对测试图片进行投票，把票数最高的标签作为对测试图片的预测。</p>
<h4 id="距离函数" class="heading-control"><a href="#距离函数" class="headerlink" title="距离函数"></a>距离函数<a class="heading-anchor" href="#距离函数" aria-hidden="true"></a></h4><p>距离函数是 K 近邻算法的关键。常用的有 L1 距离，L2 距离等。通过不同的距离函数还可以将 K 近邻算法泛化到任何类型的数据上.<br><img src="https://i.loli.net/2019/09/24/Mv4KWftwbTCBlgu.png" alt></p>
<h4 id="K值" class="heading-control"><a href="#K值" class="headerlink" title="K值"></a>K 值<a class="heading-anchor" href="#K值" aria-hidden="true"></a></h4><p>K 指的是邻居的个数，可以使用交叉验证调优。</p>
<h4 id="超参数选择" class="heading-control"><a href="#超参数选择" class="headerlink" title="超参数选择"></a>超参数选择<a class="heading-anchor" href="#超参数选择" aria-hidden="true"></a></h4><p>K 近邻算法中的 K 值和距离函数就是典型的超参数：需要人为设置，而不能由算法学习得到。选择超参数的常见作法就是将数据集分为训练集，验证集，测试集。使用验证集来选择超参数，并在测试集得到结果。如果数据集较小，还可以采用交叉验证的方法进行选择.<br><strong>划分数据集</strong><br><img src="https://i.loli.net/2019/09/24/nm9aGqfFD3Q4KgV.png" alt><br><strong>交叉验证</strong><br><img src="https://i.loli.net/2019/09/24/nybgcoX8Vsi3fUE.png" alt><br><strong>交叉验证选择 K 值</strong><br><img src="https://i.loli.net/2019/09/24/zZ7PIpEK8xCwS9k.png" alt></p>
<h4 id="缺点" class="heading-control"><a href="#缺点" class="headerlink" title="缺点"></a>缺点<a class="heading-anchor" href="#缺点" aria-hidden="true"></a></h4><ul>
<li>测试要花费大量时间计算，因为每个测试图像需要和所有存储的训练图像进行比较（Train <script type="math/tex">O(1)</script> , Test <script type="math/tex">O(n)</script>）</li>
<li>图像的分类是基于背景的，而不是图片的语义主体。</li>
</ul>
<h2 id="Lecture-3：损失函数和优化" class="heading-control"><a href="#Lecture-3：损失函数和优化" class="headerlink" title="Lecture 3：损失函数和优化"></a>Lecture 3：损失函数和优化<a class="heading-anchor" href="#Lecture-3：损失函数和优化" aria-hidden="true"></a></h2><h2 id="Lecture-4：反向传播与神经网络" class="heading-control"><a href="#Lecture-4：反向传播与神经网络" class="headerlink" title="Lecture 4：反向传播与神经网络"></a>Lecture 4：反向传播与神经网络<a class="heading-anchor" href="#Lecture-4：反向传播与神经网络" aria-hidden="true"></a></h2><h2 id="Lecture-5：卷积神经网络" class="heading-control"><a href="#Lecture-5：卷积神经网络" class="headerlink" title="Lecture 5：卷积神经网络"></a>Lecture 5：卷积神经网络<a class="heading-anchor" href="#Lecture-5：卷积神经网络" aria-hidden="true"></a></h2><h2 id="Lecture-6：如何训练神经网络-I" class="heading-control"><a href="#Lecture-6：如何训练神经网络-I" class="headerlink" title="Lecture 6：如何训练神经网络 I"></a>Lecture 6：如何训练神经网络 I<a class="heading-anchor" href="#Lecture-6：如何训练神经网络-I" aria-hidden="true"></a></h2><h2 id="Lecture-7：如何训练神经网络-II" class="heading-control"><a href="#Lecture-7：如何训练神经网络-II" class="headerlink" title="Lecture 7：如何训练神经网络 II"></a>Lecture 7：如何训练神经网络 II<a class="heading-anchor" href="#Lecture-7：如何训练神经网络-II" aria-hidden="true"></a></h2><h2 id="Lecture-8-深度学习软件" class="heading-control"><a href="#Lecture-8-深度学习软件" class="headerlink" title="Lecture 8: 深度学习软件"></a>Lecture 8: 深度学习软件<a class="heading-anchor" href="#Lecture-8-深度学习软件" aria-hidden="true"></a></h2><h2 id="Lecture-9：卷积神经网络架构" class="heading-control"><a href="#Lecture-9：卷积神经网络架构" class="headerlink" title="Lecture 9：卷积神经网络架构"></a>Lecture 9：卷积神经网络架构<a class="heading-anchor" href="#Lecture-9：卷积神经网络架构" aria-hidden="true"></a></h2><h2 id="Lecture-10：循环神经网络" class="heading-control"><a href="#Lecture-10：循环神经网络" class="headerlink" title="Lecture 10：循环神经网络"></a>Lecture 10：循环神经网络<a class="heading-anchor" href="#Lecture-10：循环神经网络" aria-hidden="true"></a></h2><h2 id="Lecture-11：检测与分割" class="heading-control"><a href="#Lecture-11：检测与分割" class="headerlink" title="Lecture 11：检测与分割"></a>Lecture 11：检测与分割<a class="heading-anchor" href="#Lecture-11：检测与分割" aria-hidden="true"></a></h2><h2 id="Lecture-12：可视化和理解" class="heading-control"><a href="#Lecture-12：可视化和理解" class="headerlink" title="Lecture 12：可视化和理解"></a>Lecture 12：可视化和理解<a class="heading-anchor" href="#Lecture-12：可视化和理解" aria-hidden="true"></a></h2><h2 id="Lecture-13：生成模型" class="heading-control"><a href="#Lecture-13：生成模型" class="headerlink" title="Lecture 13：生成模型"></a>Lecture 13：生成模型<a class="heading-anchor" href="#Lecture-13：生成模型" aria-hidden="true"></a></h2><h2 id="Lecture-14：强化学习" class="heading-control"><a href="#Lecture-14：强化学习" class="headerlink" title="Lecture 14：强化学习"></a>Lecture 14：强化学习<a class="heading-anchor" href="#Lecture-14：强化学习" aria-hidden="true"></a></h2><h2 id="Lecture-15：深度学习高效的方法和硬件" class="heading-control"><a href="#Lecture-15：深度学习高效的方法和硬件" class="headerlink" title="Lecture 15：深度学习高效的方法和硬件"></a>Lecture 15：深度学习高效的方法和硬件<a class="heading-anchor" href="#Lecture-15：深度学习高效的方法和硬件" aria-hidden="true"></a></h2><h2 id="Lecture-16：对抗性样本和对抗性训练" class="heading-control"><a href="#Lecture-16：对抗性样本和对抗性训练" class="headerlink" title="Lecture 16：对抗性样本和对抗性训练"></a>Lecture 16：对抗性样本和对抗性训练<a class="heading-anchor" href="#Lecture-16：对抗性样本和对抗性训练" aria-hidden="true"></a></h2></body></html>]]></content>
      <tags>
        <tag>CS231N</tag>
      </tags>
  </entry>
  <entry>
    <title>Deepin 配置 TF GPU 环境</title>
    <url>/post/32924.html</url>
    <content><![CDATA[<html><head><link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script></head><body><h2 id="更新" class="heading-control"><a href="#更新" class="headerlink" title="更新"></a>更新<a class="heading-anchor" href="#更新" aria-hidden="true"></a></h2><p>2018 年 10 月 29 日更新。</p>
<p>使用 conda 安装 GPU 加速版本的 TensorFlow 时，将自动安装 GPU 支持所需的 CUDA 和 CuDNN 库。不需要再额外安装这些库了。而且与 pip 安装相比，conda 安装可以带来超过 8 倍的 CPU 速度提升。因此推荐通过 conda 安装 TensorFlow。</p>
<h2 id="前言" class="heading-control"><a href="#前言" class="headerlink" title="前言"></a>前言<a class="heading-anchor" href="#前言" aria-hidden="true"></a></h2><p>服务器在升级维护，打算先在本机上做 Mask RCNN，之前一直懒得去折腾这些，这次一次搞清楚了，记录一下。<br>总体参照的是下面这篇博客：<br><a href="https://blog.csdn.net/aaronjny/article/details/79330727">https://blog.csdn.net/aaronjny/article/details/79330727</a></p>
<h2 id="第一步：检查" class="heading-control"><a href="#第一步：检查" class="headerlink" title="第一步：检查"></a>第一步：检查<a class="heading-anchor" href="#第一步：检查" aria-hidden="true"></a></h2><p>我自己电脑上是有 GPU 的，查看方式是安装 nvidia-smi</p>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line">sudo apt-get install nvidia-smi</span><br></pre></td></tr></tbody></table></figure>
<p>直接在终端运行 nvidia-smi 输出 GPU 信息。<br><img src="https://i.loli.net/2018/10/26/5bd2b390e7141.png" alt></p>
<p>然后检查有没有 gcc，gcc —version, 输出 gcc 版本<br><img src="https://i.loli.net/2018/10/26/5bd2b3efa0247.png" alt><br><a id="more"></a></p>
<h2 id="安装cuda" class="heading-control"><a href="#安装cuda" class="headerlink" title="安装cuda"></a>安装 cuda<a class="heading-anchor" href="#安装cuda" aria-hidden="true"></a></h2><p>一句话完成：<br></p><figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line">sudo apt install nvidia-cuda-dev nvidia-cuda-toolkit nvidia-nsight nvidia-visual-profiler </span><br></pre></td></tr></tbody></table></figure><p></p>
<p>安装的时候能看到安装的是什么版本，比如我这里是 9.1。<br><img src="https://i.loli.net/2018/10/26/5bd2b49c8e34e.png" alt><br>安装完有一个警告，再安装一下这个：<br>sudo apt-get install console-setup</p>
<h2 id="安装cudnn" class="heading-control"><a href="#安装cudnn" class="headerlink" title="安装cudnn"></a>安装 cudnn<a class="heading-anchor" href="#安装cudnn" aria-hidden="true"></a></h2><p>首先下载 cudnn,<a href="https://developer.nvidia.com/cudnn">https://developer.nvidia.com/cudnn</a><br>对压缩包进行解压，得到一个名为 cuda 的文件夹。<br>然后执行下面的步骤：</p>
<ul>
<li>第一，将解压出来的 cuda/include/ 下的 cudnn.h 文件复制到 /usr/local/include/ 目录下。</li>
<li>第二，将 cuda/lib64 / 目录下的所有文件复制到 python 环境的 tensorflow 包的 tensorflow/python/ 目录下。</li>
</ul>
<h2 id="安装Tf-GPU版本" class="heading-control"><a href="#安装Tf-GPU版本" class="headerlink" title="安装Tf GPU版本"></a>安装 Tf GPU 版本<a class="heading-anchor" href="#安装Tf-GPU版本" aria-hidden="true"></a></h2><figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line">conda install tensorflow-gpu</span><br></pre></td></tr></tbody></table></figure>
<h2 id="测试" class="heading-control"><a href="#测试" class="headerlink" title="测试"></a>测试<a class="heading-anchor" href="#测试" aria-hidden="true"></a></h2><p><img src="https://i.loli.net/2018/10/26/5bd2b58ec9c6c.png" alt><br>正常输出显卡信息则安装完成。</p>
</body></html>]]></content>
      <categories>
        <category>工具</category>
      </categories>
      <tags>
        <tag>GPU</tag>
      </tags>
  </entry>
  <entry>
    <title>Docker 入手</title>
    <url>/post/20925.html</url>
    <content><![CDATA[<html><head><link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script></head><body><p><img src="https://i.loli.net/2018/11/30/5c013a3895a19.png" alt="下载.png"></p>
<h2 id="Docker-简介" class="heading-control"><a href="#Docker-简介" class="headerlink" title="Docker 简介"></a>Docker 简介<a class="heading-anchor" href="#Docker-简介" aria-hidden="true"></a></h2><p>Docker 是一个开源的引擎，可以轻松的为任何应用创建一个轻量级的、可移植的、自给自足的容器。开发者在笔记本上编译测试通过的容器可以批量地在生产环境中部署，包括 VMs（虚拟机）、 bare metal、OpenStack 集群和其他的基础应用平台。<br>Docker 通常用于如下场景：</p>
<ul>
<li>web 应用的自动化打包和发布；</li>
<li>自动化测试和持续集成、发布；</li>
<li>在服务型环境中部署和调整数据库或其他的后台应用；</li>
<li>从头编译或者扩展现有的 OpenShift 或 Cloud Foundry 平台来搭建自己的 PaaS 环境。</li>
</ul>
<a id="more"></a>
<h3 id="安装Curl" class="heading-control"><a href="#安装Curl" class="headerlink" title="安装Curl"></a>安装 Curl<a class="heading-anchor" href="#安装Curl" aria-hidden="true"></a></h3><p>使用 APT 包管理工具安装 cURL：<code>sudo apt install -y curl</code></p>
<h3 id="安装-Docker" class="heading-control"><a href="#安装-Docker" class="headerlink" title="安装 Docker"></a>安装 Docker<a class="heading-anchor" href="#安装-Docker" aria-hidden="true"></a></h3><p>官方已经给出了适合 Linux 平台的自动安装脚本。因此想要安装 Docker，只需要运行下面的命令：<br></p><figure class="highlight shell"><table><tbody><tr><td class="code"><pre><span class="line">curl -fsSL https://get.docker.com | bash -s docker --mirror Aliyun</span><br></pre></td></tr></tbody></table></figure><br>在上面的命令中，我们添加了参数—mirror 以使用国内的安装包镜像。<p></p>
<h2 id="添加Docker-Hub镜像加速" class="heading-control"><a href="#添加Docker-Hub镜像加速" class="headerlink" title="添加Docker Hub镜像加速"></a>添加 Docker Hub 镜像加速<a class="heading-anchor" href="#添加Docker-Hub镜像加速" aria-hidden="true"></a></h2><h3 id="创建daemon-json文件" class="heading-control"><a href="#创建daemon-json文件" class="headerlink" title="创建daemon.json文件"></a>创建 daemon.json 文件<a class="heading-anchor" href="#创建daemon-json文件" aria-hidden="true"></a></h3><p>创建配置文件，<code>sudo vi /etc/docker/daemon.json</code>，添加镜像服务地址。腾讯云镜像的配置如下：<br></p><figure class="highlight json"><table><tbody><tr><td class="code"><pre><span class="line">{</span><br><span class="line">    <span class="attr">"registry-mirrors"</span>: [<span class="string">"https://mirror.ccs.tencentyun.com"</span>]</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><p></p>
<h3 id="重新启动Docker" class="heading-control"><a href="#重新启动Docker" class="headerlink" title="重新启动Docker"></a>重新启动 Docker<a class="heading-anchor" href="#重新启动Docker" aria-hidden="true"></a></h3><figure class="highlight shell"><table><tbody><tr><td class="code"><pre><span class="line">sudo systemctl daemon-reload</span><br><span class="line">suod systemctl restart docker</span><br></pre></td></tr></tbody></table></figure>
<h2 id="测试" class="heading-control"><a href="#测试" class="headerlink" title="测试"></a>测试<a class="heading-anchor" href="#测试" aria-hidden="true"></a></h2><p><code>docker version</code></p>
<h2 id="Hello-World" class="heading-control"><a href="#Hello-World" class="headerlink" title="Hello World"></a>Hello World<a class="heading-anchor" href="#Hello-World" aria-hidden="true"></a></h2><p>运行下面的命令，将 image 文件从仓库抓取到本地。<br><code>docker pull library/hello-world</code><br>上面代码中，docker image pull 是抓取 image 文件的命令。library/hello-world 是 image 文件在仓库里面的位置，其中 library 是 image 文件所在的组，hello-world 是 image 文件的名字。抓取成功以后，就可以在本机看到这个 image 文件了。<br></p><figure class="highlight shell"><table><tbody><tr><td class="code"><pre><span class="line">docker images</span><br><span class="line"><span class="meta">#</span><span class="bash">显示结果</span></span><br><span class="line">REPOSITORY                      TAG                 IMAGE ID            CREATED             SIZE</span><br><span class="line">docker.io/hello-world           latest              f2a91732366c        3 months ago        1.848 kB</span><br></pre></td></tr></tbody></table></figure><br>现在，运行这个 image 文件。<br><figure class="highlight shell"><table><tbody><tr><td class="code"><pre><span class="line">docker run hello-world</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">显示结果</span></span><br><span class="line">Hello from Docker!</span><br><span class="line">This message shows that your installation appears to be working correctly.</span><br><span class="line">...</span><br></pre></td></tr></tbody></table></figure><br>输出这段提示以后，hello world就会停止运行，容器自动终止。有些容器不会自动终止，因为提供的是服务，比如Mysql镜像等。<p></p>
<h2 id="常用命令" class="heading-control"><a href="#常用命令" class="headerlink" title="常用命令"></a>常用命令<a class="heading-anchor" href="#常用命令" aria-hidden="true"></a></h2><p>除过以上我们使用的 Docker 命令外，Docker 还有一些其它常用的命令</p>
<ol>
<li>拉取 docker 镜像 <code>docker pull image_name</code></li>
<li>查看宿主机上的镜像，Docker 镜像保存在 /var/lib/docker 目录下:<code>docker images</code></li>
<li>删除镜像:<code>docker rmi  docker.io/tomcat:7.0.77-jre7   或者  docker rmi b39c68b7af30</code></li>
<li>查看当前有哪些容器正在运行:<code>docker ps</code></li>
<li>查看所有容器 <code>docker ps -a</code></li>
<li>启动、停止、重启容器命令：<figure class="highlight shell"><table><tbody><tr><td class="code"><pre><span class="line">docker start container_name/container_id</span><br><span class="line">docker stop container_name/container_id</span><br><span class="line">docker restart container_name/container_id</span><br></pre></td></tr></tbody></table></figure></li>
<li>动一个容器后，如果想进入到这个容器，可以使用 attach 命令：<code>docker attach container_name/container_id</code></li>
<li>删除容器的命令：<code>docker rm container_name/container_id</code></li>
<li>查看当前系统 Docker 信息:<code>docker info</code></li>
<li>从 Docker hub 上下载某个镜像:<figure class="highlight shell"><table><tbody><tr><td class="code"><pre><span class="line">docker pull centos:latest</span><br></pre></td></tr></tbody></table></figure>
执行 docker pull centos 会将 Centos 这个仓库下面的所有镜像下载到本地 repository。</li>
</ol>
</body></html>]]></content>
      <categories>
        <category>项目</category>
      </categories>
      <tags>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title>Docker 部署深度学习模型</title>
    <url>/post/1488.html</url>
    <content><![CDATA[<html><head><link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script></head><body><h2 id="Docker安装" class="heading-control"><a href="#Docker安装" class="headerlink" title="Docker安装"></a>Docker 安装<a class="heading-anchor" href="#Docker安装" aria-hidden="true"></a></h2><p>参考链接：<a href="https://docs.docker.com/install/linux/docker-ce/centos/">https://docs.docker.com/install/linux/docker-ce/centos/</a><br>运行到 <code>sudo docker run hello-world</code> 正常输出即可<br><a id="more"></a></p>
<h2 id="Docker国内加速" class="heading-control"><a href="#Docker国内加速" class="headerlink" title="Docker国内加速"></a>Docker 国内加速<a class="heading-anchor" href="#Docker国内加速" aria-hidden="true"></a></h2><p><strong>操作步骤</strong></p>
<ul>
<li>编辑文件 <code>/etc/docker/daemon.json</code>，没有就新建。加入以下项目：<figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">{</span><br><span class="line">    <span class="string">"registry-mirrors"</span>: [<span class="string">"https://registry.docker-cn.com"</span>,<span class="string">"http://hub-mirror.c.163.com"</span>]</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure></li>
<li>重启 docker daemon : <code>systemctl restart docker</code></li>
</ul>
<p>也可以写一个脚本<br></p><figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line">cat>/etc/docker/daemon.json<<EOF</span><br><span class="line">{</span><br><span class="line">  <span class="string">"registry-mirrors"</span>: [<span class="string">"https://registry.docker-cn.com"</span>,<span class="string">"http://hub-mirror.c.163.com"</span>]</span><br><span class="line">}</span><br><span class="line">EOF</span><br><span class="line">systemctl restart docker</span><br></pre></td></tr></tbody></table></figure><p></p>
<h2 id="拉取tensorflow-serving" class="heading-control"><a href="#拉取tensorflow-serving" class="headerlink" title="拉取tensorflow serving"></a>拉取 tensorflow serving<a class="heading-anchor" href="#拉取tensorflow-serving" aria-hidden="true"></a></h2></body></html>]]></content>
      <tags>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title>DuReader，a Chinese Machine Reading Comprehension Dataset from Real-world Applications</title>
    <url>/post/850.html</url>
    <content><![CDATA[<html><head><link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script></head><body><h2 id="数据总体概述" class="heading-control"><a href="#数据总体概述" class="headerlink" title="数据总体概述"></a>数据总体概述<a class="heading-anchor" href="#数据总体概述" aria-hidden="true"></a></h2><p>百度在 2017 年发布了大规模的中文 MRC 数据集：DuReader。相比以前的 MRC 数据集，DuReader 有以下特点：</p>
<ul>
<li>所有的问题、原文都来源于实际数据（百度搜索引擎数据和百度知道问答社区），答案是由人类回答的。</li>
<li>数据集中包含大量的之前很少研究的是非和观点类的样本。</li>
<li>每个问题都对应多个答案，数据集包含 200k 问题、1000k 原文和 420k 答案，是目前最大的中文 MRC 数据集。<br>图 1 展示了 Reader 数据集与其他数据集的比较情况。<br><img src="https://i.loli.net/2019/01/05/5c30363d9ba96.png" alt><br><center>图 1 Reader 数据集与其他数据集的比较</center><a id="more"></a>
DuReader 数据集的样本可用一个四维数组表示：{q, t, D, A}，其中 q 表示问题，t 表示问题类型，D 表示文档集合，A 表示答案集合。一半的样本来源于百度搜索引擎，一半来源于百度知道。图 2 展示了 DuReader 数据集的一些样本。<br><img src="https://i.loli.net/2019/01/05/5c30363da7bdc.png" alt><br><center>图 2 DuReader 数据集的一些样本</center><br>根据答案类型，DuReader 将问题分为：Entity（实体）、Description（描述）和 YesNo（是非）。对于实体类问题，其答案一般是单一确定的回答，比如：iPhone 是哪天发布？对于描述类问题，其答案一般较长，是多个句子的总结，典型的 how/why 类型的问题，比如：消防车为什么是红的？对于是非类问题，其答案往往较简单，是或者否，比如：39.5 度算高烧吗？同时，无论将问题分类以上哪种类型都可以进一步细分为是事实（Fact）类还是观点（Opinion）类。如图 3 展示了这两大类维度的划分方式。<br><img src="https://i.loli.net/2019/01/05/5c30363d7d758.png" alt><br><center>图 3 DuReader 数据集问题划分方法</center><br>通过这两个维度的划分方法，DuReader 的问题类别共有 6 类。图 4 展示了 DuReader 数据集的问题类型分布情况。<br><img src="https://i.loli.net/2019/01/05/5c30363d74f92.png" alt><br><center>图 4 DuReader 数据集的问题类型分布情况</center><br>基于问题和文档来对答案进行标注，由于一个问题可能对应多个文档，所以一个问题可能有多个答案，但对于及其相似的答案则归为一个。其数据分布情况如图 5 所示。<br><img src="https://i.loli.net/2019/01/05/5c303fb675f68.png" alt><br><center>图 5 答案种类分布情况</center><br>由图 5 可知，百度知道中含有多个答案的问题占比高于百度搜索引擎，而含有一个答案的问题占比却低于百度搜索引擎，说明在问答社区中用户生成内容的主观性和多样性。DuReader 数据集问题的平均字数长度为 4.8，答案的平均字数长度为 69.6，文档的平均字数长度为 396.0，是 MS-MARCO 的 5 倍。由于规模大且问题类型复杂，基于 DuReader 数据集的分析工作相比以往数据集都要难得多。百度通过计算人工答案和文档的最小编辑距离来判断回答问题的困难度。编辑距离越大，对文档的编辑修改就更多，回答问题的复杂度也就越高。对于答案直接来源于原文的数据集（如 SQuAD），它们的编辑距离应该是 0。图 6 展示了 MS-MARCO 和 DuReader 两个数据集答案与文档编辑距离分布情况。<br><img src="https://i.loli.net/2019/01/05/5c303fb673298.png" alt><br><center>图 6 MS-MARCO 和 DuReader 两个数据集答案与文档编辑距离分布情况</center><br>从图 6 可以看出，在同为人工标注的数据集 MS-MARCO 中，77.1% 的样本的编辑距离低于 3，而在 DuReader 中 51.3% 的样本的编辑距离高于 10，这说明 DuReader 更为复杂。<h2 id="数据集实例" class="heading-control"><a href="#数据集实例" class="headerlink" title="数据集实例"></a>数据集实例<a class="heading-anchor" href="#数据集实例" aria-hidden="true"></a></h2>问题：昆特牌什么时候公测<br>人工标注答案：[‘时间为 6 月 6 日，暂定为期两周，即 6 月 6 日 - 6 月 19 日。’]<br>Naturali 答案: [‘巫师之昆特牌国服山丘试炼开启时间为 6 月 6 日，暂定为期两周，即 6 月 6 日 - 6 月 19 日。’]<br>参考文档<br>[‘文章 阅读’，’巫师之昆特牌山丘试炼马上开启了，帅编来告诉大家开启时间。’，’巫师之昆特牌国服山丘试炼开启时间为 6 月 6 日，暂定为期两周，即 6 月 6 日 - 6 月 19 日。’，’参与过 “青草试炼” 的玩家将直接获得本次测试的资格，无需激活码。’，’国服公测时间暂未公布。’，’声明：本文由入驻搜狐公众平台的作者撰写，除搜狐官方账号外，观点仅代表作者本人，不代表搜狐立场。’，’一款专为游戏动漫爱好者打造的 app 全面的资讯福利，热门资讯图鉴攻略应有尽有。国内外热门手游推荐，精彩不容错过。’，’itmo 爱萌游戏 - 二次元游戏第一门户 itmo 爱萌游戏是国内第一二次元游戏门户网站，致力于打造全新型的手机游戏网站。’]<br>[‘南方公园游戏在 U2 上放出了新的宣传片昆特牌公测日期发布南方公园游戏这都从去年 4 月延到今年 10 月不过动画 21 季今年 9 月开始播刚好可以衔接到游戏发售日期’，’反正昆特牌打了一下午电脑一盘没赢我就放弃了’，’我巫师 3 二周目开始玩昆特牌，毕竟一周目没钱，二周目也不继承。现在走到哪打到哪。’，’下周就公测？好突然，这么快’，’昆特盘看测试录像，氪金也是厉害啊。。。这南方公园竟然跳票到这个时候。。’，’昆特牌国际服已经激活就是看不懂挺期待南方公园的’，’期待 spOktoberfest! 另外希望昆特正式服早日上线’，’南方公园一听就是垃圾游戏，大家千万别买’，’应用吧活动，去领取’，’活动截止：2100-01-01’，’要不是川普赢了，也不至于这么跳票’，’昆特牌还没公测啊，我都以为大家已经玩了好久了’，’打牌才是正事 打牌打到十一月玩高清二战 美滋滋’]<br>解析说明：参考文档是从搜索引擎得到的排名靠前结果的网页全文，一个问题会对应多篇长文档；标注答案是人工根据文档总结撰写而成，一个问题可能对应多个答案，特别是对意见性的问题来说，有多个答案是很常见的。从以上案例可见，Naturali 阅读理解系统给出的答案比人工答案甚至还要全面。<h2 id="基线模型" class="heading-control"><a href="#基线模型" class="headerlink" title="基线模型"></a>基线模型<a class="heading-anchor" href="#基线模型" aria-hidden="true"></a></h2>百度基于 DuReader 构建了两个基线模型：Match-LSTM 和 BiDAF。<br>Match-LSTM 是广泛应用的 MRC 模型，Match-LSTM 为了在文章中找到答案，依次遍历文章，动态地将注意力权重与文章的每个标记进行匹配。最后，使用一个应答指针层来查找文章中的答案跨度。<br>BiDAF 既使用了语境对问题的注意，又使用了问题对上下文的注意，从而突出了问题和上下文中的重要部分。然后，利用注意流层融合所有有用的信息，从而得到每个位置的向量表示。<br>模型的相关参数：</li>
<li>词向量维度：300</li>
<li> 隐藏层节点大小：150</li>
<li> 优化算法：Adam</li>
<li> 初始学习率：0.001</li>
<li>batch size：32<br>一个问题可能对应了多个文档，为了训练和测试的效率，在每个文档中选择具有代表意义的段落。在训练时，选择与答案相比较时可达到最高查全率的段落；在测试时，由于没有答案，则使用问题来计算查全率。<br>评价方法为：BLEU-4 和 Rouge-L。基于 DuReader 数据集模型实验结果如图 7 所示。基于不同问题类型模型实验结果如图 8 所示。<br><img src="https://i.loli.net/2019/01/05/5c303fb676d2a.png" alt><br><center>图 7 基于 DuReader 数据集模型实验结果对比</center><br>由图 7 可知，构建的模型在百度搜索引擎的数据集的表现比百度知道的数据集要差。<br><img src="https://i.loli.net/2019/01/05/5c303fb675f51.png" alt><br><center>图 8 基于不同问题类型模型实验结果对比</center><br>由图 8 可知，模型在描述类问题普遍表现良好，但在是非问题上表现较差。分析可能是因为描述类问题答案往往是同一主题下的长文本，而是非问题的答案则较短（有时候只有 Yes 或 No），且是非类问题的答案主观性强，答案之间往往是矛盾的。<br>BLEU 和 Rouge 这两种评价指标对是非类问题并不友好，因为这两种评价指标不能很好的反应答案之间的一致性，比如两个完全相反的两个答案：“你可以做到” 和 “你不可以做到”，在 BLEU 和 Rouge 评价指标上，这两种矛盾的答案具有高一致性。<br>为了解决以上出现在是非类问题的问题，建议模型不仅输出答案，同时还给出答案的标签（Yes、No 或 Depend），最终只使用相同标签的答案来计算 BLEU 和 Rouge 评价指标。图 9 表示对 YesNo 类型问题添加和不添加标签模型的表现。<h2 id="资源" class="heading-control"><a href="#资源" class="headerlink" title="资源"></a>资源<a class="heading-anchor" href="#资源" aria-hidden="true"></a></h2></li>
<li> Paper: <a href="https://arxiv.org/abs/1711.05073">https://arxiv.org/abs/1711.05073</a></li>
<li>Page: <a href="http://ai.baidu.com/broad/subordinate?dataset=dureader">http://ai.baidu.com/broad/subordinate?dataset=dureader</a></li>
<li>Code: <a href="https://github.com/baidu/DuReader/">https://github.com/baidu/DuReader/</a></li>
<li>Bidirectional Attention Flow for Machine Comprehension:<a href="https://arxiv.org/abs/1611.01603">https://arxiv.org/abs/1611.01603</a></li>
<li>Machine Comprehension Using Match-LSTM and Answer Pointer:<a href="https://arxiv.org/abs/1608.07905">https://arxiv.org/abs/1608.07905</a></li>
</ul>
</body></html>]]></content>
      <categories>
        <category>DuReader</category>
      </categories>
      <tags>
        <tag>DuReader</tag>
      </tags>
  </entry>
  <entry>
    <title>Github 集锦</title>
    <url>/post/43849.html</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><ol>
<li><a href="https://github.com/chinese-poetry/chinese-poetry">chinese-poetry</a>: 中华古诗词数据库<br>唐宋两朝近一万四千古诗人，接近 5.5 万首唐诗加 26 万宋诗。两宋时期 1564 位词人，21050 首词。<a href="http://shici.store">网站</a><br><img src="https://i.loli.net/2018/11/13/5beae0fb0e23a.png" alt=""></li>
</ol>
<a id="more"></a>
<ol>
<li><p><a href="https://github.com/farzaa/DeepLeague">DeepLeague</a><br>leveraging computer vision and deep learning on the League of Legends mini map。<br><img src="https://i.loli.net/2018/11/13/5beac610c04e1.gif" alt="1.gif"></p>
</li>
<li><p><a href="https://github.com/apachecn/AiLearning">AiLearning</a> 机器学习、深度学习、自然语言处理资料</p>
</li>
<li><p><a href="https://github.com/chenyuntc/pytorch-book">pytorch-book</a><br>书籍《深度学习框架 PyTorch：入门与实践》的对应代码，也可以作为一个独立的 PyTorch 入门指南和教程。</p>
</li>
<li><p><a href="https://github.com/huyingxi/Synonyms">Synonyms</a>: 最好的中文近义词工具包<br><img src="https://i.loli.net/2018/11/13/5beac7cf7dbaf.gif" alt="3.gif"></p>
</li>
<li><p><a href="https://tools.yimo.link/#/home">YiMo</a> 提供 MD 和 HTML 互转，加解密，二维码生成等小工具<br>类似的一个:<a href="https://www.toolfk.com/">ToolFK</a></p>
</li>
<li><p><a href="https://github.com/frank-lam/2019_campus_apply">Full Stack Developer Tutorial</a> 后台技术栈 / 全栈开发 / 架构师之路，秋招 / 春招 / 校招 / 面试</p>
</li>
<li><p><a href="https://github.com/Snailclimb/JavaGuide">JavaGuide</a>Java 学习 + 面试指南</p>
</li>
<li><a href="https://github.com/SnakeHacker/QA-Snake">QA-Snake</a> 基于多搜索引擎和深度学习技术的自动问答 </li>
<li><a href="https://www.hellogithub.com/">HelloGitHub</a> 分享 GitHub 上有趣、入门级的开源项目 </li>
<li><a href="https://eastlakeside.gitbooks.io/interpy-zh/content/">Python 进阶</a></li>
<li><a href="https://github.com/observerss/textfilter">textfilter</a> 敏感词过滤的几种实现 + 某 1w 词敏感词库 </li>
<li><a href="https://github.com/PyMySQL/PyMySQL">PyMySQL</a>Pure Python MySQL Client <a href="https://pymysql.readthedocs.io/">https://pymysql.readthedocs.io/</a></li>
<li><a href="https://github.com/yeasy/docker_practice">Docker — 从入门到实践</a></li>
<li><a href="https://github.com/julycoding/The-Art-Of-Programming-By-July/blob/master/ebook/zh/Readme.md">编程之法：面试和算法心得</a></li>
<li><a href="http://redisdoc.com/">Redis 命令参考</a></li>
<li><a href="https://newspaper.readthedocs.io/en/latest/">Newspaper</a> 解析新闻文章内容 </li>
<li><a href="https://flaggo.github.io/pydu/#/?id=pydu">pydu</a>Python 的一些数据结构的扩展，部分内容非常有用。这个库会另外写一一篇文章介绍。</li>
<li><a href="https://houshanren.gitbooks.io/hangzhou_house_knowledge/content/">杭州买房指南</a> 2017 年买房经历总结出来的买房购房知识</li>
<li><a href="https://github.com/warmheartli/ChatBotCourse/blob/master/README.md">自己动手做聊天机器人教程</a></li>
<li><a href="https://github.com/exacity/simplified-deeplearning/blob/master/README.md">DeepLearningBook 读书笔记</a></li>
<li><a href="https://github.com/pwxcoo/chinese-xinhua">chinese-xinhua</a> 中华新华字典数据库。包括歇后语，成语，词语，汉字。提供新华字典 API。</li>
<li><a href="https://github.com/yandexdataschool/nlp_course">NLP 课程</a></li>
</ol>
]]></content>
      <categories>
        <category>工具</category>
      </categories>
      <tags>
        <tag>Github</tag>
      </tags>
  </entry>
  <entry>
    <title>Google Colab 免费 GPU 服务器使用教程</title>
    <url>/post/529.html</url>
    <content><![CDATA[<html><head><link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script></head><body><p><img src="https://i.loli.net/2018/10/29/5bd707070a49e.png" alt></p>
<h2 id="地址" class="heading-control"><a href="#地址" class="headerlink" title="地址"></a>地址<a class="heading-anchor" href="#地址" aria-hidden="true"></a></h2><a class="btn" href="https://colab.research.google.com/notebooks/welcome.ipynb ">
            <i class="fa fa-share fa-lg fa-fw"></i>跳转至 Colab
          </a>（需要梯子，谷歌访问助手即可访问）
<a id="more"></a>
<h2 id="使用方法" class="heading-control"><a href="#使用方法" class="headerlink" title="使用方法"></a>使用方法<a class="heading-anchor" href="#使用方法" aria-hidden="true"></a></h2><p>参见下面博客的链接，经过测试没有问题。<a class="btn" href="https://blog.csdn.net/cocoaqin/article/details/79184540">
            <i class="fa fa-share fa-lg fa-fw"></i>跳转至博客
          </a></p>
<h2 id="数据的上传下载" class="heading-control"><a href="#数据的上传下载" class="headerlink" title="数据的上传下载"></a>数据的上传下载<a class="heading-anchor" href="#数据的上传下载" aria-hidden="true"></a></h2><p>参见下面博客的链接，经过测试也没有问题。<a class="btn" href="https://blog.csdn.net/ssssdbucdbod/article/details/80397808?utm_source=blogxgwz0">
            <i class="fa fa-share fa-lg fa-fw"></i>跳转至博客
          </a></p>
<h2 id="TPU的使用方法" class="heading-control"><a href="#TPU的使用方法" class="headerlink" title="TPU的使用方法"></a>TPU 的使用方法<a class="heading-anchor" href="#TPU的使用方法" aria-hidden="true"></a></h2><p><a href="https://zhuanlan.zhihu.com/p/46903363">手把手教你在 Google Colab 里把谷歌 TPU 用起来</a></p>
</body></html>]]></content>
      <categories>
        <category>工具</category>
      </categories>
      <tags>
        <tag>GPU</tag>
      </tags>
  </entry>
  <entry>
    <title>HEXO 博客迁移的步骤</title>
    <url>/post/27014.html</url>
    <content><![CDATA[<html><head><link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script></head><body><p>最近买了新电脑，但是博客是今天才迁移过来。本以为很麻烦，实际上操作非常简单，只需要三个步骤。</p>
<h3 id="拷贝博客文件夹" class="heading-control"><a href="#拷贝博客文件夹" class="headerlink" title="拷贝博客文件夹"></a>拷贝博客文件夹<a class="heading-anchor" href="#拷贝博客文件夹" aria-hidden="true"></a></h3><p>大概 50 多 M 的样子，原封不动的拷贝到新电脑上。</p>
<h3 id="安装hexo" class="heading-control"><a href="#安装hexo" class="headerlink" title="安装hexo"></a>安装 hexo<a class="heading-anchor" href="#安装hexo" aria-hidden="true"></a></h3><figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">$ npm install -g hexo-cli</span><br></pre></td></tr></tbody></table></figure>
<p>有时候会出现 <code>warning: LF will be replaced by CRLF in</code> 的警告，输入下面的命令解决：<br></p><figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">git config --global core.autocrlf <span class="literal">false</span></span><br></pre></td></tr></tbody></table></figure><p></p>
<h3 id="重新配置ssh密钥" class="heading-control"><a href="#重新配置ssh密钥" class="headerlink" title="重新配置ssh密钥"></a>重新配置 ssh 密钥<a class="heading-anchor" href="#重新配置ssh密钥" aria-hidden="true"></a></h3><figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">ssh-keygen</span><br><span class="line">cat ~/.ssh/id_rsa.pub</span><br></pre></td></tr></tbody></table></figure>
<p>复制到 github ssh 里面就行了。</p>
</body></html>]]></content>
      <tags>
        <tag>HEXO</tag>
      </tags>
  </entry>
  <entry>
    <title>HMM,MEMM 和 CRF</title>
    <url>/post/38864.html</url>
    <content><![CDATA[<html><head><link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script></head><body><h2 id="概率图模型" class="heading-control"><a href="#概率图模型" class="headerlink" title="概率图模型"></a>概率图模型<a class="heading-anchor" href="#概率图模型" aria-hidden="true"></a></h2><p>概率图模型（probabilistic graphical model, PGM）指用图表示变量相关（依赖）关系的概率模型，主要分为两类：</p>
<ul>
<li>有向图模型或贝叶斯网（Bayesian network），使用有向图表示变量间的依赖关系；</li>
<li>无向图模型或马尔可夫网（Markov network），使用无向图表示变量间相关关系。</li>
</ul>
<a id="more"></a>
<p>PGM 对应的图有两种表示形式：independency graph, factor graph. independency graph 直接描述了变量的条件独立，而 factor graph 则是通过因子分解（ factorization）的方式暗含变量的条件独立。比如，NB 与 HMM 所对应的两种图表示如下：<br><img src="https://i.loli.net/2019/07/23/5d36cab00296c27882.png" alt><br><img src="https://i.loli.net/2019/07/23/5d36caaeecafa44027.png" alt><br>可以看出，NB 与 HMM 所对应的 independency graph 为有向图。</p>
<p>从生成随机模型和判别式模型的角度可以得到：<br><img src="https://i.loli.net/2019/07/23/5d36caac95d1e65928.png" alt></p>
<h2 id="HMM" class="heading-control"><a href="#HMM" class="headerlink" title="HMM"></a>HMM<a class="heading-anchor" href="#HMM" aria-hidden="true"></a></h2><p><img src="https://i.loli.net/2019/07/23/5d36caab70d8931864.png" alt><br>HMM 模型将标注看作马尔可夫链，一阶马尔可夫链式针对相邻标注的关系进行建模，其中每个标记对应一个概率函数。HMM 是一种生成式模型，定义了联合概率分布 ，其中 x 和 y 分别表示观察序列和相对应的标注序列的随机变量。为了能够定义这种联合概率分布，生成式模型需要枚举出所有可能的观察序列，这在实际运算过程中很困难，因为我们需要将观察序列的元素看做是彼此孤立的个体即假设每个元素彼此独立，任何时刻的观察结果只依赖于该时刻的状态。</p>
<p>HMM 模型的这个假设前提在比较小的数据集上是合适的，但实际上在大量真实语料中观察序列更多的是以一种多重的交互特征形式表现，观察元素之间广泛存在长程相关性。在命名实体识别的任务中，由于实体本身结构所具有的复杂性，利用简单的特征函数往往无法涵盖所有的特性，这时 HMM 的假设前提使得它无法使用复杂特征 (它无法使用多于一个标记的特征）。</p>
<h2 id="MEMM" class="heading-control"><a href="#MEMM" class="headerlink" title="MEMM"></a>MEMM<a class="heading-anchor" href="#MEMM" aria-hidden="true"></a></h2><p>HMM 与 MEMM 的图模型如下：<br><img src="https://i.loli.net/2019/07/23/5d36caaaa381829440.png" alt><br>最大熵模型可以使用任意的复杂相关特征，在性能上最大熵分类器超过了 Byaes 分类器。但是，作为一种分类器模型，这两种方法有一个共同的缺点：每个词都是单独进行分类的，标记之间的关系无法得到充分利用，具有马尔可夫链的 HMM 模型可以建立标记之间的马尔可夫关联性，这是最大熵模型所没有的。</p>
<p><strong>最大熵模型的优点</strong>：首先，最大熵统计模型获得的是所有满足约束条件的模型中信息熵极大的模型；其次，最大熵统计模型可以灵活地设置约束条件，通过约束条件的多少可以调节模型对未知数据的适应度和对已知数据的拟合程度；再次，它还能自然地解决了统计模型中参数平滑的问题。</p>
<p><strong>最大熵模型的不足</strong>：首先，最大熵统计模型中二值化特征只是记录特征的出现是否，而文本分类需要知道特征的强度，因此，它在分类方法中不是最优的；其次，由于算法收敛的速度较慢，所以导致最大熵统计模型它的计算代价较大，时空开销大；再次，数据稀疏问题比较严重。</p>
<p>最大熵马尔科夫模型把 HMM 模型和 maximum-entropy 模型的优点集合成一个判别式模型，这个模型允许状态转移概率依赖于序列中彼此之间非独立的特征上，从而将上下文信息引入到模型的学习和识别过程中，提高了识别的精确度，召回率也大大的提高，有实验证明，这个新的模型在序列标注任务上表现的比 HMM 和无状态的最大熵模型要好得多。</p>
<h2 id="CRF" class="heading-control"><a href="#CRF" class="headerlink" title="CRF"></a>CRF<a class="heading-anchor" href="#CRF" aria-hidden="true"></a></h2><p><img src="https://i.loli.net/2019/07/23/5d36caafaa04252797.png" alt><br>首先，CRF 在给定了观察序列的情况下，对整个的序列的联合概率有一个统一的指数模型。一个比较吸引人的特性是其损失函数 的凸面性。</p>
<p>其次，条件随机域模型相比较改进的隐马尔可夫模型可以更好更多的利用待识别文本中所提供的上下文信息以得更好的实验结果。条件随机域在中文组块识别方面有效，并避免了严格的独立性假设和数据归纳偏置问题。条件随机域 (CRF) 模型应用到了中文名实体识别中，并且根据中文的特点，定义了多种特征模板。并且有测试结果表明：在采用相同特征集合的条件下，条件随机域模型较其他概率模型有更好的性能表现。</p>
<p>再次，词性标注主要面临兼类词消歧以及未知词标注的难题，传统隐马尔科夫方法不易融合新特征，而最大熵马尔科夫模型存在标注偏置等问题。论文引入条件随机域建立词性标注模型，易于融合新的特征，并能解决标注偏置的问题。CRFs 具有很强的推理能力，并且能够使用复杂、有重叠性和非独立的特征进行训练和推理，能够充分地利用上下文信息作为特征，还可以任意地添加其他外部特征，使得模型能够获取的信息非常丰富。同时，CRFs 解决了最大熵模型中的 “label bias” 问题。CRFs 与最大熵模型的本质区别是：最大熵模型在每个状态都有一个概率模型，在每个状态转移时都要进行归一化。如果某个状态只有一个后续状态，那么该状态到后续状态的跳转概率即为 1。这样，不管输入为任何内容，它都向该后续状态跳转。而 CRFs 是在所有的状态上建立一个统一的概率模型，这样在进行归一化时，即使某个状态只有一个后续状态，它到该后续状态的跳转概率也不会为 1，从而解决了 “labelbias” 问题。因此，从理论上讲，CRFs 非常适用于中文的词性标注。</p>
<p><strong>CRF 模型的优点</strong>：首先，CRF 模型由于其自身在结合多种特征方面的优势和避免了标记偏置问题。其次，CRF 的性能更好，CRF 对特征的融合能力比较强，对于实例较小的时间类 ME 来说，CRF 的识别效果明显高于 ME 的识别结果。</p>
<p><strong>CRF 模型的不足</strong>：首先，通过对基于 CRF 的结合多种特征的方法识别英语命名实体的分析，发现在使用 CRF 方法的过程中，特征的选择和优化是影响结果的关键因素，特征选择问题的好与坏，直接决定了系统性能的高低。其次，训练模型的时间比 ME 更长，且获得的模型很大，在一般的 PC 机上无法运行。</p>
<h2 id="总结" class="heading-control"><a href="#总结" class="headerlink" title="总结"></a>总结<a class="heading-anchor" href="#总结" aria-hidden="true"></a></h2><p><strong>HMM 模型</strong>中存在两个假设：一是输出<strong>观察值之间严格独立</strong>，二是状态的转移过程中当前状态只与前一状态有关 (<strong>一阶马尔可夫模型</strong>)。HMM 是有向图模型，是生成模型；</p>
<p><strong>MEMM 模型</strong>克服了观察值之间严格独立产生的问题，但是由于状态之间的假设理论，使得该模型存在<strong>标注偏置问题</strong>。MEMM（最大熵马尔科夫模型）是有向图模型，是判别模型；</p>
<p><strong>CRF 模型</strong>解决了标注偏置问题，去除了 HMM 中两个不合理的假设，当然，模型相应得也变复杂了。</p>
<p>这三个模型都可以用来做序列标注模型。但是其各自有自身的特点。</p>
<ul>
<li>HMM 模型是对转移概率和表现概率直接建模，统计共现概率。</li>
<li>MEMM 模型是对转移概率和表现概率建立联合概率，统计时统计的是条件概率。MEMM 容易陷入局部最优，是因为 MEMM 只在局部做归一化。</li>
<li>CRF 模型中，统计了全局概率，在做归一化时，考虑了数据在全局的分布，而不是仅仅在局部归一化，这样就解决了 MEMM 中的标记偏置的问题。</li>
</ul>
<h2 id="视觉问题的应用" class="heading-control"><a href="#视觉问题的应用" class="headerlink" title="视觉问题的应用"></a>视觉问题的应用<a class="heading-anchor" href="#视觉问题的应用" aria-hidden="true"></a></h2><ul>
<li>HMMs: 图像去噪、图像纹理分割、模糊图像复原、纹理图像检索、自动目标识别等</li>
<li> MRF: 图像恢复、图像分割、边缘检测、纹理分析、目标匹配和识别等</li>
<li> CRF: 目标检测、识别、序列图像中的目标分割</li>
</ul>
<h2 id class="heading-control"><a href="#" class="headerlink" title=" "></a> <a class="heading-anchor" href="#" aria-hidden="true"></a></h2></body></html>]]></content>
      <tags>
        <tag>NLP</tag>
      </tags>
  </entry>
  <entry>
    <title>Hadoop 集群基本配置</title>
    <url>/post/8797.html</url>
    <content><![CDATA[<html><head><link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script></head><body><p><img src="https://i.loli.net/2018/11/30/5c014444993e8.png" alt="CDAP.png"><br><a id="more"></a></p>
<h2 id="集群规划" class="heading-control"><a href="#集群规划" class="headerlink" title="集群规划"></a>集群规划<a class="heading-anchor" href="#集群规划" aria-hidden="true"></a></h2><div class="table-container">
<table>
<thead>
<tr>
<th>集群节点分配</th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td>主机名</td>
<td>主机 IP</td>
</tr>
<tr>
<td>master</td>
<td>192.168.100.100</td>
</tr>
<tr>
<td>slave1</td>
<td>192.168.100.101</td>
</tr>
<tr>
<td>slave2</td>
<td>192.168.100.102</td>
</tr>
<tr>
<td>slave3</td>
<td>192.168.100.103</td>
</tr>
</tbody>
</table>
</div>
<!--more-->
<div class="table-container">
<table>
<thead>
<tr>
<th> 软件版本</th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td>软件名称</td>
<td>版本号</td>
</tr>
<tr>
<td> Java</td>
<td>1.8.0_152</td>
</tr>
<tr>
<td>CentOS</td>
<td>CentOS-7-x64-1708</td>
</tr>
<tr>
<td>Hadoop</td>
<td>2.7.5</td>
</tr>
<tr>
<td>MySQL</td>
<td>5.7.20</td>
</tr>
<tr>
<td>Hive</td>
<td>2.3.2</td>
</tr>
</tbody>
</table>
</div>
<div class="table-container">
<table>
<thead>
<tr>
<th> 各软件安装路径</th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td> Hadoop</td>
<td>/opt/SoftWare/Hadoop/</td>
</tr>
<tr>
<td>Java</td>
<td>/opt/SoftWare/Java/</td>
</tr>
<tr>
<td>Hive</td>
<td>/opt/SoftWare/Hive</td>
</tr>
<tr>
<td>MySQL</td>
<td>/opt/SoftWare/MySQL</td>
</tr>
</tbody>
</table>
</div>
<h2 id="各主机基础软件安装及操作" class="heading-control"><a href="#各主机基础软件安装及操作" class="headerlink" title="各主机基础软件安装及操作"></a>各主机基础软件安装及操作<a class="heading-anchor" href="#各主机基础软件安装及操作" aria-hidden="true"></a></h2><p>由于使用的是最小化安装，因此这里需要安装不少软件才能进行后续操作。</p>
<h3 id="openssh安装，便于远程上传文件" class="heading-control"><a href="#openssh安装，便于远程上传文件" class="headerlink" title="openssh安装，便于远程上传文件"></a>openssh 安装，便于远程上传文件<a class="heading-anchor" href="#openssh安装，便于远程上传文件" aria-hidden="true"></a></h3><figure class="highlight shell"><table><tbody><tr><td class="code"><pre><span class="line">[root@master ~]# sudo yum -y install openssh-clients openssh-server</span><br></pre></td></tr></tbody></table></figure>
<p>安装完成后，可以使用下面命令进行测试：<br><code>ssh localhost</code><br>输入 root 账户的密码，如果可以正常登录，则说明 SSH 安装没有问题。测试正常后使用 exit 命令退出 ssh。</p>
<h3 id="同步时间工具" class="heading-control"><a href="#同步时间工具" class="headerlink" title="同步时间工具"></a>同步时间工具<a class="heading-anchor" href="#同步时间工具" aria-hidden="true"></a></h3><figure class="highlight shell"><table><tbody><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">安装ntpdate工具</span></span><br><span class="line">[root@master ~]# yum -y install ntp ntpdate</span><br><span class="line"><span class="meta">#</span><span class="bash">设置与网络时间同步</span></span><br><span class="line">[root@master ~]# ntpdate cn.pool.ntp.org</span><br><span class="line"><span class="meta">#</span><span class="bash">系统时间写入硬件时间</span></span><br><span class="line">[root@master ~]# hwclock --systohc</span><br></pre></td></tr></tbody></table></figure>
<h3 id="文件上传-rz-下载-sz-工具" class="heading-control"><a href="#文件上传-rz-下载-sz-工具" class="headerlink" title="文件上传(rz)下载(sz)工具"></a>文件上传 (rz) 下载 (sz) 工具<a class="heading-anchor" href="#文件上传-rz-下载-sz-工具" aria-hidden="true"></a></h3><p>可以在 Xshell 工具中通过 rz 调出上传文件的窗口进行文件上传，也可以通过 sz 文件名下载某一个文件。</p>
<figure class="highlight shell"><table><tbody><tr><td class="code"><pre><span class="line">[root@master ~]# yum -y install lrzsz</span><br></pre></td></tr></tbody></table></figure>
<h3 id="安装网络下载yum工具-wget" class="heading-control"><a href="#安装网络下载yum工具-wget" class="headerlink" title="安装网络下载yum工具 wget"></a>安装网络下载 yum 工具 wget<a class="heading-anchor" href="#安装网络下载yum工具-wget" aria-hidden="true"></a></h3><figure class="highlight shell"><table><tbody><tr><td class="code"><pre><span class="line">[root@test ~]# yum -y install wget</span><br></pre></td></tr></tbody></table></figure>
<h3 id="关闭防火墙" class="heading-control"><a href="#关闭防火墙" class="headerlink" title="关闭防火墙"></a>关闭防火墙<a class="heading-anchor" href="#关闭防火墙" aria-hidden="true"></a></h3><figure class="highlight shell"><table><tbody><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">查看防火墙开启状态</span></span><br><span class="line">[root@test ~]# systemctl status firewalld</span><br><span class="line"><span class="meta">#</span><span class="bash">关闭防火墙</span></span><br><span class="line">[root@test ~]# systemctl stop firewalld</span><br><span class="line"><span class="meta">#</span><span class="bash">禁止开机启动防火墙</span></span><br><span class="line">[root@test ~]# systemctl disable firewalld</span><br><span class="line"><span class="meta">#</span><span class="bash">开启防火墙</span></span><br><span class="line">[root@test ~]# systemctl start firewalld</span><br><span class="line"><span class="meta">#</span><span class="bash">设置开机启动防火墙</span></span><br><span class="line">[root@test ~]# systemctl enable firewalld</span><br><span class="line"><span class="meta">#</span><span class="bash">重启防火墙</span></span><br><span class="line">[root@test ~]# systemctl restart firewalld</span><br></pre></td></tr></tbody></table></figure>
<h2 id="配置SSH免密码登录" class="heading-control"><a href="#配置SSH免密码登录" class="headerlink" title="配置SSH免密码登录"></a>配置 SSH 免密码登录<a class="heading-anchor" href="#配置SSH免密码登录" aria-hidden="true"></a></h2><p>四台主机均按照步骤 2 安装基础软件工具（这里不再过多叙述）</p>
<p>修改 hosts 文件，添加以下内容，四台主机均进行操作</p>
<figure class="highlight shell"><table><tbody><tr><td class="code"><pre><span class="line">[root@master ~]# vi /etc/hosts</span><br><span class="line"><span class="meta">#</span><span class="bash">127.0.0.1   localhost localhost.localdomain localhost4 localhost4.localdomain4</span></span><br><span class="line"><span class="meta">#</span><span class="bash">::1         localhost localhost.localdomain localhost6 localhost6.localdomain6</span></span><br><span class="line">192.168.100.100 master</span><br><span class="line">192.168.100.101 slave1</span><br><span class="line">192.168.100.102 slave2</span><br><span class="line">192.168.100.103 slave3</span><br></pre></td></tr></tbody></table></figure>
<p>配置 SSH 免密码登录</p>
<figure class="highlight shell"><table><tbody><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">每台机器先使用ssh执行以下，以在主目录产生一个.ssh 文件夹</span></span><br><span class="line">[root@master ~]# ssh master</span><br><span class="line"><span class="meta">#</span><span class="bash">然后输入no即可</span></span><br><span class="line"><span class="meta">#</span><span class="bash">每台机器均进入~/.ssh 目录进行操作</span></span><br><span class="line">[root@master ~]# cd ~/.ssh</span><br><span class="line"><span class="meta">#</span><span class="bash">输入以下命令，一路回车，用以产生公钥和秘钥</span></span><br><span class="line">[root@master .ssh]# ssh-keygen -t rsa -P ''</span><br><span class="line"><span class="meta">#</span><span class="bash">出现以下信息说明生成成功</span></span><br><span class="line">Generating public/private rsa key pair.</span><br><span class="line">Enter file in which to save the key (/root/.ssh/id_rsa): </span><br><span class="line">Your identification has been saved in /root/.ssh/id_rsa.</span><br><span class="line">Your public key has been saved in /root/.ssh/id_rsa.pub.</span><br><span class="line">The key fingerprint is:</span><br><span class="line">SHA256:6YO1h1emM9gcWvv9OT6ftHxLnjP9u8p25x1o30oq3No root@master</span><br><span class="line">The key's randomart image is:</span><br><span class="line">+---[RSA 2048]----+</span><br><span class="line">|                 |</span><br><span class="line">|                 |</span><br><span class="line">|                 |</span><br><span class="line">|         .       |</span><br><span class="line">|        S o o    |</span><br><span class="line">|       + O *  .  |</span><br><span class="line">|      . B.X. o.+.|</span><br><span class="line">|         +o=+=**%|</span><br><span class="line">|          .oEo*^^|</span><br><span class="line">+----[SHA256]-----+</span><br><span class="line"><span class="meta">#</span><span class="bash">将每台机器上的id_rsa.pub公钥内容复制到authorized_keys文件中</span></span><br><span class="line">[root@master .ssh]# cp id_rsa.pub authorized_keyscd</span><br><span class="line"><span class="meta">#</span><span class="bash">将所有的authorized_keys文件进行合并（最简单的方法是将其余三台slave主机的文件内容追加到master主机上）</span></span><br><span class="line">[root@slave1 .ssh]# cat ~/.ssh/authorized_keys | ssh root@master 'cat >> ~/.ssh/authorized_keys'</span><br><span class="line">[root@slave2 .ssh]# cat ~/.ssh/authorized_keys | ssh root@master 'cat >> ~/.ssh/authorized_keys'</span><br><span class="line">[root@slave3 .ssh]# cat ~/.ssh/authorized_keys | ssh root@master 'cat >> ~/.ssh/authorized_keys'</span><br><span class="line"><span class="meta">#</span><span class="bash">查看master上的authorized_keys文件内容，类似如下即可</span></span><br><span class="line">[root@master .ssh]# more authorized_keys </span><br><span class="line">ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQC5iw8+LlLxo0d77uaTChOKKJqfMHzp2jgzqV2hFAneFXqqWmr</span><br><span class="line">Z4/FrMUPenmdss19bP4Up9G7PGbJu29yZDvkDwlmuqnVajYyDOsCl7PPXPWXMIlxMGUHgSXLnQQi6QnWp04vJKDs0EbiRTd0ZYCSQefzJcZ8jbQ7bLYt6jtil7FfUupTdHTeexKKd8Mq3K7YFZHumKvhzs6wWiM+n41jANS083ss3OYmAdO2cU0w1BhLVvJhdzd6fNG3RXVCXI2v0XxCUHiqI9Oewl2qPOfKzeyy09bJxo371Ezjmt8GMrkA/Ecepkvx12qwNzC9bSPLfbnPWVo2gIxe4mMaFqCFJ root@master</span><br><span class="line">ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQC3CkB3Jejavt+yFphsbciktWciJmbcUBOv3ZLPVLW18ZxXGZK</span><br><span class="line">vG50EPXo/4By7P6IRW0wCa5YuckQEW+q6kmSatxqJ8e/K9a1mAk13N4f7V7M71Nn8IkujlF3gHYjKrmnEWpGJCy5YBURzywIQTRArlIac1xj2SeM6q+gTMV9WrAKJupIRHli+W0kHVaYHNdKl7KMUT4KVrSl+h4wFwAd7Tcyj7JIbUcCCL6o/v/LqGFwpcJfbfUsuKJJho+tImh41j7mSXR8kRbTSZkcq5KX+iANrANwOHZ58tV5KXmMQjuVq7aJ985C16hHssB6zq/zjAxpxAyQIeE8Incc8U8ix root@slave1</span><br><span class="line">ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQC//uaMbzbkYqxdgZJSdq+gdQYldzMQ7D3SxsUaNO5oVnVOszw</span><br><span class="line">+mbNnmL8vp1EUUehabQHPCAvCmLKUPXzfcxlyJEF/pnY77u4ySwsRVEpHvsDZbrclgCOrS6hW00sSx303KHLOgXT70LfrmnohfUhvTxajzLXT+C8f5ZfTZ8meKD73HKl16jRwZQ8YhW9GUyuCkgQTGtKtTKPsRUd9LpAc/7/u8xvvvNvTYPxgyTJcUMzGSOHh8J3upI54ykY0FgBkjs1fCUaDalxAgsHw9B1iyx706WbcT6ymiQVMKGnnnM6k2KPvUvfDswVfUSG+4ZsYSRHRTgWuiBbHoIr7DVd root@slave2</span><br><span class="line">ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQDDTzTTdGRTd1zts3m7uKobcgRom4lVyF9EdNOdbBWMucYjbCs</span><br><span class="line">BgP1ideDDQed2TyBj3Szz3Yx6h1L4McGmATY/D9qRLml26VW/x0Tod8JYkqOQpQL9knLW2cwITnhLzq5VDugOix06r/uweP3Zed9CO7ld3jUxJJNZCYpsNz+eUKq9SWM5+ehUu9pfZZu9zUk7Q01js3uCHzu1AhsajgNzgB4+YLLccdHBfxGg4ix5wuaF82PlEEh70hTdfRkq8pqPMZ+FIQtTgfD5XllKTcnPItUY23hc7Umx4I3ujOd810vzffWYK07cOtv1r7LEcYtYqbZ6zIvII+M775iRkzQX root@slave3</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">将master上的authorized_keys文件分发到其他主机上</span></span><br><span class="line">[root@master .ssh]# scp ~/.ssh/authorized_keys root@slave1:~/.ssh/</span><br><span class="line">[root@master .ssh]# scp ~/.ssh/authorized_keys root@slave2:~/.ssh/</span><br><span class="line">[root@master .ssh]# scp ~/.ssh/authorized_keys root@slave3:~/.ssh/</span><br><span class="line"><span class="meta">#</span><span class="bash">每台机器之间进行ssh免密码登录操作，包括自己与自己</span></span><br><span class="line">[root@master ~]# ssh master</span><br><span class="line">[root@master ~]# ssh slave1</span><br><span class="line">[root@slave1 ~]# ssh master</span><br><span class="line">[root@master ~]# ssh slave2</span><br><span class="line">[root@slave2 ~]# ssh master</span><br><span class="line">[root@master ~]# ssh slave3</span><br><span class="line">[root@slave3 ~]# ssh master</span><br><span class="line">[root@master ~]# ssh slave1</span><br><span class="line">[root@slave1 ~]# ssh slave1</span><br><span class="line">[root@slave1 ~]# ssh slave2</span><br><span class="line">[root@slave2 ~]# ssh slave1</span><br><span class="line">[root@slave1 ~]# ssh slave3</span><br><span class="line">[root@slave3 ~]# ssh slave1</span><br><span class="line">[root@slave1 ~]# ssh slave2</span><br><span class="line">[root@slave2 ~]# ssh slave2</span><br><span class="line">[root@slave2 ~]# ssh slave3</span><br><span class="line">[root@slave3 ~]# ssh slave2</span><br><span class="line">[root@slave2 ~]# ssh slave3</span><br><span class="line">[root@slave3 ~]# ssh slave2</span><br><span class="line">[root@slave2 ~]# ssh slave3</span><br><span class="line">[root@slave3 ~]# ssh slave3</span><br></pre></td></tr></tbody></table></figure>
<h2 id="安装配置Java环境并测试" class="heading-control"><a href="#安装配置Java环境并测试" class="headerlink" title="安装配置Java环境并测试"></a>安装配置 Java 环境并测试<a class="heading-anchor" href="#安装配置Java环境并测试" aria-hidden="true"></a></h2><h3 id="下载jdk" class="heading-control"><a href="#下载jdk" class="headerlink" title="下载jdk"></a>下载 jdk<a class="heading-anchor" href="#下载jdk" aria-hidden="true"></a></h3><p>使用 yum 来安装 1.8 版本 OpenJDK：<br></p><figure class="highlight shell"><table><tbody><tr><td class="code"><pre><span class="line">sudo yum install java-1.8.0-openjdk java-1.8.0-openjdk-devel</span><br></pre></td></tr></tbody></table></figure><br>安装完成后，输入 java 和 javac 命令，如果能输出对应的命令帮助，则表明jdk已正确安装。<p></p>
<h3 id="配置-JAVA-环境变量" class="heading-control"><a href="#配置-JAVA-环境变量" class="headerlink" title="配置 JAVA 环境变量"></a>配置 JAVA 环境变量<a class="heading-anchor" href="#配置-JAVA-环境变量" aria-hidden="true"></a></h3><p>执行命令：编辑～/.bashrc，在结尾追加：<br></p><figure class="highlight shell"><table><tbody><tr><td class="code"><pre><span class="line">export JAVA_HOME=/usr/lib/jvm/java-1.8.0-openjdk</span><br></pre></td></tr></tbody></table></figure><br>保存文件后执行下面命令使 JAVA_HOME 环境变量生效:<br><figure class="highlight shell"><table><tbody><tr><td class="code"><pre><span class="line">source ~/.bashrc</span><br></pre></td></tr></tbody></table></figure><br>为了检测系统中 JAVA 环境是否已经正确配置并生效，可以分别执行下面命令:<br><figure class="highlight shell"><table><tbody><tr><td class="code"><pre><span class="line">java -version</span><br><span class="line"><span class="meta">$</span><span class="bash">JAVA_HOME/bin/java -version</span></span><br></pre></td></tr></tbody></table></figure><br>若两条命令输出的结果一致，且都为我们前面安装的openjdk-1.8.0的版本，则表明JDK环境已经正确安装并配置。<p></p>
<h2 id="安装配置Hadoop并配置" class="heading-control"><a href="#安装配置Hadoop并配置" class="headerlink" title="安装配置Hadoop并配置"></a>安装配置 Hadoop 并配置<a class="heading-anchor" href="#安装配置Hadoop并配置" aria-hidden="true"></a></h2><h3 id="下载Hadoop到本地" class="heading-control"><a href="#下载Hadoop到本地" class="headerlink" title="下载Hadoop到本地"></a>下载 Hadoop 到本地<a class="heading-anchor" href="#下载Hadoop到本地" aria-hidden="true"></a></h3><figure class="highlight shell"><table><tbody><tr><td class="code"><pre><span class="line">wget https://mirrors.tuna.tsinghua.edu.cn/apache/hadoop/common/hadoop-2.7.6/hadoop-2.7.6.tar.gz</span><br></pre></td></tr></tbody></table></figure>
<h3 id="上传至master节点" class="heading-control"><a href="#上传至master节点" class="headerlink" title="上传至master节点"></a>上传至 master 节点<a class="heading-anchor" href="#上传至master节点" aria-hidden="true"></a></h3><figure class="highlight shell"><table><tbody><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">上传</span></span><br><span class="line">[root@master ~]# cd /opt/SoftWare/Hadoop</span><br><span class="line">[root@master Hadoop]# rz</span><br><span class="line"><span class="meta">#</span><span class="bash">解压</span></span><br><span class="line">[root@master Hadoop]# tar -zxvf hadoop-2.7.5.tar.gz</span><br></pre></td></tr></tbody></table></figure>
<h3 id="创建目录" class="heading-control"><a href="#创建目录" class="headerlink" title="创建目录"></a>创建目录<a class="heading-anchor" href="#创建目录" aria-hidden="true"></a></h3><figure class="highlight shell"><table><tbody><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">进入hadoop-2.7.5主目录</span></span><br><span class="line">[root@master Hadoop]# cd hadoop-2.7.5</span><br><span class="line"><span class="meta">#</span><span class="bash">创建以下目录，以备后用</span></span><br><span class="line">[root@master hadoop-2.7.5]# mkdir tmp</span><br><span class="line">[root@master hadoop-2.7.5]# mkdir logs</span><br><span class="line">[root@master hadoop-2.7.5]# mkdir -p hdfs/name</span><br><span class="line">[root@master hadoop-2.7.5]# mkdir -p hdfs/dat</span><br></pre></td></tr></tbody></table></figure>
<h2 id="修改配置" class="heading-control"><a href="#修改配置" class="headerlink" title="修改配置"></a>修改配置<a class="heading-anchor" href="#修改配置" aria-hidden="true"></a></h2><h3 id="修改hadoop-env-sh文件" class="heading-control"><a href="#修改hadoop-env-sh文件" class="headerlink" title="修改hadoop-env.sh文件"></a>修改 hadoop-env.sh 文件<a class="heading-anchor" href="#修改hadoop-env-sh文件" aria-hidden="true"></a></h3><figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">[root@master hadoop-2.7.5]<span class="comment"># vi etc/hadoop/hadoop-env.sh</span></span><br><span class="line"><span class="comment">#修改JAVA_HOME为以下内容，否则容易出现Hadoop无法启动问题</span></span><br><span class="line"><span class="built_in">export</span> JAVA_HOME=/opt/SoftWare/Java/jdk1.8.0_152</span><br></pre></td></tr></tbody></table></figure>
<h3 id="修改yarn-env-sh文件" class="heading-control"><a href="#修改yarn-env-sh文件" class="headerlink" title="修改yarn-env.sh文件"></a>修改 yarn-env.sh 文件<a class="heading-anchor" href="#修改yarn-env-sh文件" aria-hidden="true"></a></h3><figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">[root@master hadoop-2.7.5]<span class="comment"># vi etc/hadoop/yarn-env.sh </span></span><br><span class="line"><span class="comment">#修改JAVA_HOME为以下内容</span></span><br><span class="line"><span class="built_in">export</span> JAVA_HOME=/opt/SoftWare/Java/jdk1.8.0_152</span><br></pre></td></tr></tbody></table></figure>
<h2 id="编辑slaves文件" class="heading-control"><a href="#编辑slaves文件" class="headerlink" title="编辑slaves文件"></a>编辑 slaves 文件<a class="heading-anchor" href="#编辑slaves文件" aria-hidden="true"></a></h2><figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line"><span class="comment">#该文件用于记录本集群有哪些数据节点</span></span><br><span class="line">[root@master hadoop-2.7.5]<span class="comment"># vi etc/hadoop/slaves </span></span><br><span class="line"><span class="comment">#删除该文件中原来的内容，添加以下内容</span></span><br><span class="line">slave1</span><br><span class="line">slave2</span><br><span class="line">slave3</span><br></pre></td></tr></tbody></table></figure>
<p>echo $JAVA_HOME</p>
<h2 id="修改core-site-xml文件" class="heading-control"><a href="#修改core-site-xml文件" class="headerlink" title="修改core-site.xml文件"></a>修改 core-site.xml 文件<a class="heading-anchor" href="#修改core-site-xml文件" aria-hidden="true"></a></h2><figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">[root@master hadoop-2.7.5]<span class="comment"># vi etc/hadoop/core-site.xml</span></span><br></pre></td></tr></tbody></table></figure>
<p>该文件为 Hadoop 的核心配置文件，非常重要</p>
<figure class="highlight xml"><table><tbody><tr><td class="code"><pre><span class="line"><span class="comment"><!--在<configuration></configuration>中间添加一下内容--></span></span><br><span class="line"><span class="tag"><<span class="name">property</span>></span></span><br><span class="line">    <span class="tag"><<span class="name">name</span>></span>fs.defaultFS<span class="tag"></<span class="name">name</span>></span><span class="comment"><!--定义Hadoop Master的URI和端口--></span></span><br><span class="line">    <span class="tag"><<span class="name">value</span>></span>hdfs://master:9000<span class="tag"></<span class="name">value</span>></span></span><br><span class="line"><span class="tag"></<span class="name">property</span>></span></span><br><span class="line"><span class="tag"><<span class="name">property</span>></span></span><br><span class="line">    <span class="tag"><<span class="name">name</span>></span>hadoop.tmp.dir<span class="tag"></<span class="name">name</span>></span><span class="comment"><!--hadoop的临时存储目录--></span></span><br><span class="line">    <span class="tag"><<span class="name">value</span>></span>file:/opt/SoftWare/Hadoop/hadoop-2.7.5/tmp<span class="tag"></<span class="name">value</span>></span></span><br><span class="line"><span class="tag"></<span class="name">property</span>></span></span><br><span class="line"><span class="tag"><<span class="name">property</span>></span></span><br><span class="line">    <span class="tag"><<span class="name">name</span>></span>io.file.buffer.size<span class="tag"></<span class="name">name</span>></span><span class="comment"><!--用作序列化文件处理时读写buffer的大小--></span></span><br><span class="line">    <span class="tag"><<span class="name">value</span>></span>131702<span class="tag"></<span class="name">value</span>></span></span><br><span class="line"><span class="tag"></<span class="name">property</span>></span></span><br></pre></td></tr></tbody></table></figure>
</body></html>]]></content>
      <categories>
        <category>项目</category>
      </categories>
      <tags>
        <tag>Hadoop</tag>
      </tags>
  </entry>
  <entry>
    <title>Hexo Customization</title>
    <url>/post/64470.html</url>
    <content><![CDATA[<html><head><link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script></head><body><h3 id="bilibili插件" class="heading-control"><a href="#bilibili插件" class="headerlink" title="bilibili插件"></a>bilibili 插件<a class="heading-anchor" href="#bilibili插件" aria-hidden="true"></a></h3><p><a href="https://github.com/Z4Tech/hexo-tag-bilibili">bilibili</a></p>
<h3 id="颜文字" class="heading-control"><a href="#颜文字" class="headerlink" title="颜文字"></a>颜文字<a class="heading-anchor" href="#颜文字" aria-hidden="true"></a></h3><p><a href="http://www.yanwenzi.com/changyong/">颜文字</a></p>
<h3 id="表情" class="heading-control"><a href="#表情" class="headerlink" title="表情"></a>表情<a class="heading-anchor" href="#表情" aria-hidden="true"></a></h3><p><a href="https://www.emojicopy.com/">表情</a></p>
<h3 id="下载按钮" class="heading-control"><a href="#下载按钮" class="headerlink" title="下载按钮"></a>下载按钮<a class="heading-anchor" href="#下载按钮" aria-hidden="true"></a></h3><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">{% btn https://www.baidu.com, 点击下载百度, download fa-lg fa-fw %}</span><br></pre></td></tr></tbody></table></figure>
<a class="btn" href="https://www.baidu.com">
            <i class="fa fa-download fa-lg fa-fw"></i>点击下载百度
          </a>
<h3 id="引用" class="heading-control"><a href="#引用" class="headerlink" title="引用"></a>引用<a class="heading-anchor" href="#引用" aria-hidden="true"></a></h3><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">{% cq %}</span><br><span class="line">人生乃是一面镜子，</span><br><span class="line">从镜子里认识自己，</span><br><span class="line">我要称之为头等大事，</span><br><span class="line">也只是我们追求的目的！</span><br><span class="line">{% endcq %}</span><br></pre></td></tr></tbody></table></figure>
<blockquote class="blockquote-center">
            <i class="fa fa-quote-left"></i>
            <p>人生乃是一面镜子，<br>从镜子里认识自己，<br>我要称之为头等大事，<br>也只是我们追求的目的！</p>

            <i class="fa fa-quote-right"></i>
          </blockquote>
<a id="more"></a>
<h3 id="代码块" class="heading-control"><a href="#代码块" class="headerlink" title="代码块"></a>代码块<a class="heading-anchor" href="#代码块" aria-hidden="true"></a></h3><figure class="highlight plain"><figcaption><span>[代码]</span></figcaption><table><tbody><tr><td class="code"><pre><span class="line">代码</span><br></pre></td></tr></tbody></table></figure>
<h3 id="图标" class="heading-control"><a href="#图标" class="headerlink" title="图标"></a>图标<a class="heading-anchor" href="#图标" aria-hidden="true"></a></h3><p><a href="https://fontawesome.com/v4.7.0/">https://fontawesome.com/v4.7.0/</a><br></p><figure class="highlight shell"><table><tbody><tr><td class="code"><pre><span class="line">- <i class="fa fa-pencil"></i> 铅笔</span><br><span class="line">- <i class="fa fa-cloud-upload"></i> 上传</span><br><span class="line">- <i class="fa fa-download"></i> 下载</span><br></pre></td></tr></tbody></table></figure><p></p>
<ul>
<li><i class="fa fa-pencil"></i> 铅笔</li>
<li><i class="fa fa-cloud-upload"></i> 上传</li>
<li><i class="fa fa-download"></i> 下载</li>
</ul>
<h3 id="音乐" class="heading-control"><a href="#音乐" class="headerlink" title="音乐"></a>音乐<a class="heading-anchor" href="#音乐" aria-hidden="true"></a></h3><p>首先在站点文件夹根目录安装插件：<br></p><figure class="highlight shell"><table><tbody><tr><td class="code"><pre><span class="line">npm install hexo-tag-aplayer --save</span><br></pre></td></tr></tbody></table></figure><br>然后文章中的写法：<br><figure class="highlight markdown"><table><tbody><tr><td class="code"><pre><span class="line">{% aplayer "歌曲名" "歌手名" "https://什么什么什么.mp3" "https://封面图.jpg" "lrc:https://歌词.lrc" %}</span><br></pre></td></tr></tbody></table></figure><br>另外可以支持歌单：<br><figure class="highlight markdown"><table><tbody><tr><td class="code"><pre><span class="line">{% aplayerlist %}</span><br><span class="line">{</span><br><span class="line"><span class="code">    "autoplay": false,</span></span><br><span class="line"><span class="code">    "showlrc": 3,</span></span><br><span class="line"><span class="code">    "mutex": true,</span></span><br><span class="line"><span class="code">    "music": [</span></span><br><span class="line"><span class="code">        {</span></span><br><span class="line"><span class="code">            "title": "歌曲名",</span></span><br><span class="line"><span class="code">            "author": "歌手名",</span></span><br><span class="line"><span class="code">            "url": "https://什么什么什么.mp3",</span></span><br><span class="line"><span class="code">            "pic": "https://封面图.jpg",</span></span><br><span class="line"><span class="code">            "lrc": "https://歌词.lrc"</span></span><br><span class="line"><span class="code">        },</span></span><br><span class="line"><span class="code">        {</span></span><br><span class="line"><span class="code">            "title": "歌曲名",</span></span><br><span class="line"><span class="code">            "author": "歌手名",</span></span><br><span class="line"><span class="code">            "url": "https://什么什么什么.mp3",</span></span><br><span class="line"><span class="code">            "pic": "https://封面图.jpg",</span></span><br><span class="line"><span class="code">            "lrc": "https://歌词.lrc"</span></span><br><span class="line"><span class="code">        }</span></span><br><span class="line"><span class="code">    ]</span></span><br><span class="line"><span class="code">}</span></span><br><span class="line"><span class="code">{% endaplayerlist %}</span></span><br></pre></td></tr></tbody></table></figure><p></p>
<h3 id="视频" class="heading-control"><a href="#视频" class="headerlink" title="视频"></a>视频<a class="heading-anchor" href="#视频" aria-hidden="true"></a></h3><p>首先在站点文件夹根目录安装插件：<br></p><figure class="highlight shell"><table><tbody><tr><td class="code"><pre><span class="line">npm install hexo-tag-dplayer --save</span><br></pre></td></tr></tbody></table></figure><br>然后文章中的写法：<br><figure class="highlight markdown"><table><tbody><tr><td class="code"><pre><span class="line">{% dplayer "url=https://什么什么什么.mp4" "https://封面图.jpg" "api=https://api.prprpr.me/dplayer/" "id=" "loop=false" %}</span><br></pre></td></tr></tbody></table></figure><p></p>
<h3 id="Hexo-中-MathJax-的静态显示（svg）" class="heading-control"><a href="#Hexo-中-MathJax-的静态显示（svg）" class="headerlink" title="Hexo 中 MathJax 的静态显示（svg）"></a>Hexo 中 MathJax 的静态显示（svg）<a class="heading-anchor" href="#Hexo-中-MathJax-的静态显示（svg）" aria-hidden="true"></a></h3><p><a href="https://reuixiy.github.io/technology/computer/computer-aided-art/2018/05/16/hexo-mathjax-svg.html">Hexo 中 MathJax 的静态显示（svg）</a></p>
<h3 id="Reference" class="heading-control"><a href="#Reference" class="headerlink" title="Reference"></a>Reference<a class="heading-anchor" href="#Reference" aria-hidden="true"></a></h3><p><a href="https://reuixiy.github.io/technology/computer/computer-aided-art/2017/06/09/hexo-next-optimization.html">打造个性超赞博客 Hexo+NexT+GitHubPages 的超深度优化</a></p>
</body></html>]]></content>
      <categories>
        <category>工具</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
      </tags>
  </entry>
  <entry>
    <title>Hexo 优化和 Github 插件</title>
    <url>/post/28311.html</url>
    <content><![CDATA[<html><head><link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script></head><body><h2 id="Hexo-Next主题优化" class="heading-control"><a href="#Hexo-Next主题优化" class="headerlink" title="Hexo Next主题优化"></a>Hexo Next 主题优化<a class="heading-anchor" href="#Hexo-Next主题优化" aria-hidden="true"></a></h2><p>记录一些 Hexo Next 博客优化的文章：</p>
<ul>
<li><a href="https://aoenian.github.io/2018/08/09/next-theme-customized-2/">代码块优化</a></li>
<li><a href="https://crayonnew.github.io/2018/11/05/Hexo-NexT%E4%B8%BB%E9%A2%98-%E8%AE%BE%E7%BD%AE%E5%9C%86%E5%BD%A2%E5%A4%B4%E5%83%8F%E5%B9%B6%E6%97%8B%E8%BD%AC/">设置圆形头像并旋转</a></li>
<li><a href="https://www.andyvj.com/2019/02/26/190226-02/">hexo 数学公式</a></li>
<li><a href="https://www.andyvj.com/2019/02/12/190213-01/">hexo 中插入视频音频</a></li>
<li><a href="https://www.anmou.me/20181017-Private_Setting_to_Next/">主题个性化配置</a></li>
<li><a href="https://blog.diqigan.cn/posts/add-background-picture-for-next.html">hexo 背景修改</a></li>
<li><a href="https://sjq597.github.io/2018/05/18/Hexo-%E4%BD%BF%E7%94%A8Gitment%E8%AF%84%E8%AE%BA%E5%8A%9F%E8%83%BD/">hexo gitment 配置</a></li>
</ul>
<a id="more"></a>
<h2 id="Github-Chrome插件" class="heading-control"><a href="#Github-Chrome插件" class="headerlink" title="Github Chrome插件"></a>Github Chrome 插件<a class="heading-anchor" href="#Github-Chrome插件" aria-hidden="true"></a></h2><ul>
<li>SourceGraph 插件</li>
<li> GitZip 插件：下载仓库中部分代码</li>
<li> Enhanced GitHub 插件</li>
</ul>
</body></html>]]></content>
      <tags>
        <tag>Github</tag>
        <tag>Hexo</tag>
      </tags>
  </entry>
  <entry>
    <title>Hexo 博客 + Next 主题深度优化与定制</title>
    <url>/post/16107.html</url>
    <content><![CDATA[<html><head><link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script></head><body><p>本文基于的 Hexo 版本：5.1.1，Next 主题版本：7.8.0，较低版本可能不适用，操作系统为 Windows。本文参考了很多博主的文章，在每一节结尾都有注明。</p>
<h2 id="环境准备" class="heading-control"><a href="#环境准备" class="headerlink" title="环境准备"></a>环境准备<a class="heading-anchor" href="#环境准备" aria-hidden="true"></a></h2><h3 id="Git安装" class="heading-control"><a href="#Git安装" class="headerlink" title="Git安装"></a>Git 安装<a class="heading-anchor" href="#Git安装" aria-hidden="true"></a></h3><p>我这里是直接下载的 cmder full 版本，已经包含 git 了。</p>
<p><img src="https://i.loli.net/2020/09/13/R2Sg5ImVv87TLEK.png" alt="Mmmm Monokai." style="zoom:50%;"></p>
<a id="more"></a>
<p>下载解压后，打开 cmder.exe，输入 <code>git --version</code> 检查 git 是否安装好了。</p>
<p><img src="https://i.loli.net/2020/09/13/ef4wys1ioUBnHc3.png" alt="image-20200913174328818"></p>
<h3 id="Node-js安装" class="heading-control"><a href="#Node-js安装" class="headerlink" title="Node.js安装"></a>Node.js 安装<a class="heading-anchor" href="#Node-js安装" aria-hidden="true"></a></h3><p>Windows 下载并安装。</p>
<p><a href="https://nodejs.org/en/" name="https://blog.butanediol.me/media/avatar.png" class="LinkCard">Node.js 下载</a></p>
<h2 id="Hexo安装" class="heading-control"><a href="#Hexo安装" class="headerlink" title="Hexo安装"></a>Hexo 安装<a class="heading-anchor" href="#Hexo安装" aria-hidden="true"></a></h2><h2 id="Hexo进阶语法" class="heading-control"><a href="#Hexo进阶语法" class="headerlink" title="Hexo进阶语法"></a>Hexo 进阶语法<a class="heading-anchor" href="#Hexo进阶语法" aria-hidden="true"></a></h2><h2 id="MathJax" class="heading-control"><a href="#MathJax" class="headerlink" title="MathJax"></a>MathJax<a class="heading-anchor" href="#MathJax" aria-hidden="true"></a></h2><script type="math/tex; mode=display">
\frac{1}{m}\lg C=\frac{1}{n}\left(\sum_{i=1}^n{Y_i+\frac{1}{m}\sum_{i=1}^n{X_i}}\right)</script><h2 id="abbrlink永久链接" class="heading-control"><a href="#abbrlink永久链接" class="headerlink" title="abbrlink永久链接"></a>abbrlink 永久链接<a class="heading-anchor" href="#abbrlink永久链接" aria-hidden="true"></a></h2><p>安装 hexo-abbrlink 插件</p>
<figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">npm install hexo-abbrlink --save</span><br></pre></td></tr></tbody></table></figure>
<p>修改站点配置文件里的 <code>permalink: :year/:month/:day/:title/</code> 为:</p>
<figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">permalink: post/:abbrlink.html</span><br><span class="line">abbrlink:</span><br><span class="line">  alg: crc32  # 算法：crc16(default) and crc32</span><br><span class="line">  rep: hex    # 进制：dec(default) and hex</span><br></pre></td></tr></tbody></table></figure>
<p>生成完后，原 <code>md</code> 文件的 Front-matter 内会增加 <code>abbrlink</code> 字段，值为生成的 ID 。这个字段确保了在我们修改了 Front-matter 内的博客标题 title 或创建日期 date 字段之后而不会改变链接地址。</p>
<p>参考文章</p>
<ol>
<li><a href="http://www.adanblog.com/hexo/6962f19.html">hexo 的永久链接之 abbrlink</a></li>
<li><a href="https://www.jianshu.com/p/c7de2ae59975">Hexo-abbrlink 生成唯一永久文章链接</a></li>
</ol>
<h2 id="链接" class="heading-control"><a href="#链接" class="headerlink" title="链接"></a>链接<a class="heading-anchor" href="#链接" aria-hidden="true"></a></h2><p><a href="https://blog.butanediol.me" name="https://blog.butanediol.me/media/avatar.png" class="LinkCard">一个测试链接</a></p>
<h2 id="背景图片" class="heading-control"><a href="#背景图片" class="headerlink" title="背景图片"></a>背景图片<a class="heading-anchor" href="#背景图片" aria-hidden="true"></a></h2><p>在 <code>blog\themes\next\source\css\_common\outline\outline.styl</code> 中添加代码。</p>
<figure class="highlight css"><table><tbody><tr><td class="code"><pre><span class="line"><span class="selector-tag">body</span> {</span><br><span class="line">  <span class="attribute">background</span>: <span class="built_in">url</span>(<span class="string">"https://s2.ax1x.com/2019/09/12/nBFb28.jpg"</span>);</span><br><span class="line">  <span class="attribute">background-size</span>: cover;</span><br><span class="line">  <span class="attribute">background-repeat</span>: no-repeat;</span><br><span class="line">  <span class="attribute">background-attachment</span>: fixed;</span><br><span class="line">  <span class="attribute">background-position</span>: <span class="number">50%</span> <span class="number">50%</span>;</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure>
<h2 id="DaoVoice-在线联系" class="heading-control"><a href="#DaoVoice-在线联系" class="headerlink" title="DaoVoice 在线联系"></a>DaoVoice 在线联系<a class="heading-anchor" href="#DaoVoice-在线联系" aria-hidden="true"></a></h2><p>参考：</p>
<ol>
<li><a href="http://shenzekun.cn/hexo%E7%9A%84next%E4%B8%BB%E9%A2%98%E4%B8%AA%E6%80%A7%E5%8C%96%E9%85%8D%E7%BD%AE%E6%95%99%E7%A8%8B.html">hexo 的 next 主题个性化配置教程.html</a></li>
<li><a href="http://www.guaini.blog/archives/2426.html">hexo 博客美化之安装 DaoVoice 实现在线聊天功能</a></li>
</ol>
<h2 id="自定义友链页面" class="heading-control"><a href="#自定义友链页面" class="headerlink" title="自定义友链页面"></a>自定义友链页面<a class="heading-anchor" href="#自定义友链页面" aria-hidden="true"></a></h2><p>参考：</p>
<ol>
<li><a href="http://www.guaini.blog/archives/13407.html">hexo 博客美化之自定义友链页面</a></li>
<li></li>
</ol>
</body></html>]]></content>
      <categories>
        <category>Hexo</category>
      </categories>
      <tags>
        <tag>博客</tag>
      </tags>
  </entry>
  <entry>
    <title>Hexo 解决公式渲染问题</title>
    <url>/post/58604.html</url>
    <content><![CDATA[<html><head><link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script></head><body><h2 id="Next配置文件" class="heading-control"><a href="#Next配置文件" class="headerlink" title="Next配置文件"></a>Next 配置文件<a class="heading-anchor" href="#Next配置文件" aria-hidden="true"></a></h2><figure class="highlight shell"><table><tbody><tr><td class="code"><pre><span class="line">mathjax:</span><br><span class="line">  enable: True</span><br><span class="line">  per_page: false</span><br><span class="line">  cdn: //cdn.bootcss.com/mathjax/2.7.1/latest.js?config=TeX-AMS-MML_HTMLorMML</span><br></pre></td></tr></tbody></table></figure>
<h2 id="更换渲染引擎" class="heading-control"><a href="#更换渲染引擎" class="headerlink" title="更换渲染引擎"></a>更换渲染引擎<a class="heading-anchor" href="#更换渲染引擎" aria-hidden="true"></a></h2><p>更换 Hexo 的 markdown 渲染引擎，hexo-renderer-kramed 引擎是在默认的渲染引擎 hexo-renderer-marked 的基础上修改了一些 bug ，两者比较接近，也比较轻量级。</p>
<h2 id="更改渲染设置" class="heading-control"><a href="#更改渲染设置" class="headerlink" title="更改渲染设置"></a>更改渲染设置<a class="heading-anchor" href="#更改渲染设置" aria-hidden="true"></a></h2><p>到博客根目录下，找到 <code>node_modules\kramed\lib\rules\inline.js</code>，把第 11 行的 <code>escape</code> 变量的值做相应的修改：<br></p><figure class="highlight shell"><table><tbody><tr><td class="code"><pre><span class="line">//em: /^\b_((?:__|[\s\S])+?)_\b|^\*((?:\*\*|[\s\S])+?)\*(?!\*)/,</span><br><span class="line"> em: /^\*((?:\*\*|[\s\S])+?)\*(?!\*)/,</span><br></pre></td></tr></tbody></table></figure><br>同时把第20行的em变量也要做相应的修改。<br><figure class="highlight shell"><table><tbody><tr><td class="code"><pre><span class="line">//em: /^\b_((?:__|[\s\S])+?)_\b|^\*((?:\*\*|[\s\S])+?)\*(?!\*)/,</span><br><span class="line">  em: /^\*((?:\*\*|[\s\S])+?)\*(?!\*)/,</span><br></pre></td></tr></tbody></table></figure><br>重新启动hexo（先clean再generate）,问题完美解决。<p></p>
<a id="more"></a>
<h2 id="例子" class="heading-control"><a href="#例子" class="headerlink" title="例子"></a>例子<a class="heading-anchor" href="#例子" aria-hidden="true"></a></h2><h3 id="行内公式" class="heading-control"><a href="#行内公式" class="headerlink" title="行内公式"></a>行内公式<a class="heading-anchor" href="#行内公式" aria-hidden="true"></a></h3><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">$W_{b}$</span><br></pre></td></tr></tbody></table></figure>
<p>$W_{b}$</p>
<h3 id="行间公式" class="heading-control"><a href="#行间公式" class="headerlink" title="行间公式"></a>行间公式<a class="heading-anchor" href="#行间公式" aria-hidden="true"></a></h3><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">$$</span><br><span class="line">W_{b}</span><br><span class="line">$$</span><br></pre></td></tr></tbody></table></figure>
<script type="math/tex; mode=display">
W_{b}</script></body></html>]]></content>
      <categories>
        <category>工具</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
      </tags>
  </entry>
  <entry>
    <title>K 近邻分类</title>
    <url>/post/21708.html</url>
    <content><![CDATA[<html><head><link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script></head><body><p><img src="https://i.loli.net/2019/07/18/5d3073a2804ed47295.png" alt><br><strong>核心思想</strong>：基于距离的模板匹配<br>KNN 是一种判别模型，即支持分类问题，也支持回归问题，是一种非线性模型，天然支持多分类，而且没有训练过程。<br><a id="more"></a></p>
<h1 id="KNN算法的三要素" class="heading-control"><a href="#KNN算法的三要素" class="headerlink" title="KNN算法的三要素"></a>KNN 算法的三要素<a class="heading-anchor" href="#KNN算法的三要素" aria-hidden="true"></a></h1><p>三个要素分别是：</p>
<ul>
<li>K 值的选取</li>
<li>分类决策规则（多数投票法）</li>
<li>距离度量的方式，一般有欧氏距离，曼哈顿距离，闵可夫斯基距离等</li>
</ul>
<h1 id="K值的选取" class="heading-control"><a href="#K值的选取" class="headerlink" title="K值的选取"></a>K 值的选取<a class="heading-anchor" href="#K值的选取" aria-hidden="true"></a></h1><p><img src="https://i.loli.net/2019/07/18/5d3073b7d2fe148171.png" alt><br>在上图中，紫色虚线是贝叶斯决策边界线，也是最理想的分类边界，黑色实线是 KNN 的分类边界。<br>K 值的选取没有固定经验，一般根据样本分布选择一个较小的值，可以通过交叉验证确定；K 值较小意味着整体模型变复杂，容易过拟合；K 值增大意味着模型变简单。另外，K 的取值尽量要取奇数，以保证在计算结果最后会产生一个较多的类别，如果取偶数可能会产生相等的情况，不利于预测。</p>
<h1 id="KNN的实现" class="heading-control"><a href="#KNN的实现" class="headerlink" title="KNN的实现"></a>KNN 的实现<a class="heading-anchor" href="#KNN的实现" aria-hidden="true"></a></h1><h4 id="暴力实现" class="heading-control"><a href="#暴力实现" class="headerlink" title="暴力实现"></a>暴力实现<a class="heading-anchor" href="#暴力实现" aria-hidden="true"></a></h4><h4 id="KD树实现" class="heading-control"><a href="#KD树实现" class="headerlink" title="KD树实现"></a>KD 树实现<a class="heading-anchor" href="#KD树实现" aria-hidden="true"></a></h4><h1 id="KNN的优缺点" class="heading-control"><a href="#KNN的优缺点" class="headerlink" title="KNN的优缺点"></a>KNN 的优缺点<a class="heading-anchor" href="#KNN的优缺点" aria-hidden="true"></a></h1><p>KNN 的主要<strong>优点</strong>有：<br>1） 理论成熟，思想简单，既可以用来做分类也可以用来做回归<br>2） 可用于非线性分类<br>3） 训练时间复杂度比支持向量机之类的算法低，仅为 O (n)<br>4） 和朴素贝叶斯之类的算法比，对数据没有假设，准确度高，对异常点不敏感<br>5） 由于 KNN 方法主要靠周围有限的邻近的样本，而不是靠判别类域的方法来确定所属类别的，因此对于类域的交叉或重叠较多的待分样本集来说，KNN 方法较其他方法更为适合<br>6）该算法比较适用于样本容量比较大的类域的自动分类，而那些样本容量较小的类域采用这种算法比较容易产生误分</p>
<p>KNN 的主要<strong>缺点</strong>有：<br>1）计算量大，尤其是特征数非常多的时候<br>2）样本不平衡的时候，对稀有类别的预测准确率低<br>3）KD 树，球树之类的模型建立需要大量的内存<br>4）使用懒散学习方法，基本上不学习，导致预测时速度比起逻辑回归之类的算法慢<br>5）相比决策树模型，KNN 模型可解释性不强</p>
<h1 id="代码实现" class="heading-control"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现<a class="heading-anchor" href="#代码实现" aria-hidden="true"></a></h1><p>numpy 版本<br></p><figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> math <span class="keyword">import</span> sqrt</span><br><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> Counter</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">KNNClassifier</span>:</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, k</span>):</span></span><br><span class="line">        <span class="string">"""初始化kNN分类器"""</span></span><br><span class="line">        <span class="keyword">assert</span> k >= <span class="number">1</span>, <span class="string">"k must be valid"</span></span><br><span class="line">        self.k = k</span><br><span class="line">        self._X_train = <span class="literal">None</span></span><br><span class="line">        self._y_train = <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">fit</span>(<span class="params">self, X_train, y_train</span>):</span></span><br><span class="line">        <span class="string">"""根据训练数据集X_train和y_train训练kNN分类器"""</span></span><br><span class="line">        <span class="keyword">assert</span> X_train.shape[<span class="number">0</span>] == y_train.shape[<span class="number">0</span>], \</span><br><span class="line">            <span class="string">"the size of X_train must be equal to the size of y_train"</span></span><br><span class="line">        <span class="keyword">assert</span> self.k <= X_train.shape[<span class="number">0</span>], \</span><br><span class="line">            <span class="string">"the size of X_train must be at least k."</span></span><br><span class="line"></span><br><span class="line">        self._X_train = X_train</span><br><span class="line">        self._y_train = y_train</span><br><span class="line">        <span class="keyword">return</span> self</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">predict</span>(<span class="params">self, X_predict</span>):</span></span><br><span class="line">        <span class="string">"""给定待预测数据集X_predict，返回表示X_predict的结果向量"""</span></span><br><span class="line">        <span class="keyword">assert</span> self._X_train <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span> <span class="keyword">and</span> self._y_train <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>, \</span><br><span class="line">                <span class="string">"must fit before predict!"</span></span><br><span class="line">        <span class="keyword">assert</span> X_predict.shape[<span class="number">1</span>] == self._X_train.shape[<span class="number">1</span>], \</span><br><span class="line">                <span class="string">"the feature number of X_predict must be equal to X_train"</span></span><br><span class="line"></span><br><span class="line">        y_predict = [self._predict(x) <span class="keyword">for</span> x <span class="keyword">in</span> X_predict]</span><br><span class="line">        <span class="keyword">return</span> np.array(y_predict)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_predict</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        <span class="string">"""给定单个待预测数据x，返回x的预测结果值"""</span></span><br><span class="line">        <span class="keyword">assert</span> x.shape[<span class="number">0</span>] == self._X_train.shape[<span class="number">1</span>], \</span><br><span class="line">            <span class="string">"the feature number of x must be equal to X_train"</span></span><br><span class="line"></span><br><span class="line">        distances = [sqrt(np.sum((x_train - x) ** <span class="number">2</span>))</span><br><span class="line">                     <span class="keyword">for</span> x_train <span class="keyword">in</span> self._X_train]</span><br><span class="line">        nearest = np.argsort(distances)</span><br><span class="line"></span><br><span class="line">        topK_y = [self._y_train[i] <span class="keyword">for</span> i <span class="keyword">in</span> nearest[:self.k]]</span><br><span class="line">        votes = Counter(topK_y)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> votes.most_common(<span class="number">1</span>)[<span class="number">0</span>][<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__repr__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">return</span> <span class="string">"KNN(k=%d)"</span> % self.k</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    X = [[<span class="number">3.393533211</span>, <span class="number">2.331273381</span>],</span><br><span class="line">         [<span class="number">3.110073483</span>, <span class="number">1.781539638</span>],</span><br><span class="line">         [<span class="number">1.343808831</span>, <span class="number">3.368360954</span>],</span><br><span class="line">         [<span class="number">3.582294042</span>, <span class="number">4.679179110</span>],</span><br><span class="line">         [<span class="number">2.280362439</span>, <span class="number">2.866990263</span>],</span><br><span class="line">         [<span class="number">7.423436942</span>, <span class="number">4.696522875</span>],</span><br><span class="line">         [<span class="number">5.745051997</span>, <span class="number">3.533989803</span>],</span><br><span class="line">         [<span class="number">9.172168622</span>, <span class="number">2.511101045</span>],</span><br><span class="line">         [<span class="number">7.792783481</span>, <span class="number">3.424088941</span>],</span><br><span class="line">         [<span class="number">7.939820817</span>, <span class="number">0.791637231</span>]</span><br><span class="line">         ]</span><br><span class="line">    y = [<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">    X_train = np.array(X)</span><br><span class="line">    y_train = np.array(y)</span><br><span class="line"></span><br><span class="line">    x_predict = np.array([<span class="number">8.093607318</span>, <span class="number">3.36571514</span>])</span><br><span class="line"></span><br><span class="line">    plt.scatter(X_train[y_train == <span class="number">0</span>, <span class="number">0</span>], X_train[y_train == <span class="number">0</span>, <span class="number">1</span>], color=<span class="string">'g'</span>)</span><br><span class="line">    plt.scatter(X_train[y_train == <span class="number">1</span>, <span class="number">0</span>], X_train[y_train == <span class="number">1</span>, <span class="number">1</span>], color=<span class="string">'r'</span>)</span><br><span class="line">    plt.scatter(x_predict[<span class="number">0</span>],x_predict[<span class="number">1</span>], color=<span class="string">'b'</span>)</span><br><span class="line"></span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line">    model = KNNClassifier(k=<span class="number">3</span>)</span><br><span class="line">    model.fit(X_train,y_train)</span><br><span class="line">    result = model.predict(np.expand_dims(x_predict,<span class="number">0</span>))</span><br><span class="line">    print(<span class="string">"class:"</span>,result)</span><br></pre></td></tr></tbody></table></figure><br><img src="https://i.loli.net/2019/07/18/5d3073a1ae01b87554.png" alt><br>tensorflow版本<br>kd树版本<p></p>
<h1 id="面试常见问题" class="heading-control"><a href="#面试常见问题" class="headerlink" title="面试常见问题"></a>面试常见问题<a class="heading-anchor" href="#面试常见问题" aria-hidden="true"></a></h1><ul>
<li>简述一下 KNN 算法的原理</li>
<li> KNN 算法有哪些优点和缺点？</li>
<li>不平衡的样本可以给 KNN 的预测结果造成哪些问题，有没有什么好的解决方式？</li>
<li>为了解决 KNN 算法计算量过大的问题，可以使用分组的方式进行计算，简述一下该方式的原理。</li>
<li>什么是欧氏距离和曼哈顿距离？<br>欧式距离：<script type="math/tex; mode=display">
D(x, y)=\sqrt{\left(x_{1}-y_{1}\right)^{2}+\left(x_{2}-y_{2}\right)^{2}+\ldots+\left(x_{n}-y_{n}\right)^{2}}=\sqrt{\sum_{i=1}^{n}\left(x_{i}-y_{i}\right)^{2}}</script>曼哈顿距离：<script type="math/tex; mode=display">
D(x, y)=\left|x_{1}-y_{1}\right|+\left|x_{2}-y_{2}\right|+\ldots+\left|x_{n}-y_{n}\right|=\sum_{i=1}^{n}\left|x_{i}-y_{i}\right|</script>闵可夫斯基距离:<script type="math/tex; mode=display">
D(x, y)=\sqrt[\psi]{\left(\left|x_{1}-y_{1}\right|\right)^{p}+\left(\left|x_{2}-y_{2}\right|\right)^{p}+\ldots+\left(\left|x_{n}-y_{n}\right|\right)^{p}}=\sqrt{\sum_{i=1}^{n}\left(\left|x_{i}-y_{i}\right|\right)^{p}}</script></li>
<li><p>KNN 中的 K 如何选取的？<br>①k 值较小时，相当于用较小的邻域中的训练实例进行预测，近似误差会减小，只有与输入实例很相近的样本才会对预测结果起作用。估计误差会增大，整体模型会变得复杂，容易过拟合。<br>②选取较大的 k 值是，相当于用较大的邻域中的训练实例进行预测，可以减少学习的估计误差，但是近似误差会增大，因为离输入实例较远的样本也对预测结果起作用，容易使预测发生错误。k 过大导致模型变得简单。<br>③在选取 k 上，一般取比较小的值，并采用交叉验证法进行调优。<br>K 的取值尽量要取奇数，以保证在计算结果最后会产生一个较多的类别，如果取偶数可能会产生相等的情况，不利于预测。</p>
</li>
<li><p>什么是 KD 树？</p>
</li>
<li>KD 树建立过程中切分维度的顺序是否可以优化？</li>
<li>KD 树每一次继续切分都要计算该子区间在需切分维度上的中值，计算量很大，有什么方法可以对其进行优化？</li>
</ul>
</body></html>]]></content>
      <tags>
        <tag>机器学习算法</tag>
      </tags>
  </entry>
  <entry>
    <title>Keras 迁移学习</title>
    <url>/post/60371.html</url>
    <content><![CDATA[<html><head><link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script></head><body><h2 id="迁移学习" class="heading-control"><a href="#迁移学习" class="headerlink" title="迁移学习"></a>迁移学习<a class="heading-anchor" href="#迁移学习" aria-hidden="true"></a></h2><p>简单来说迁移学习是把在 ImageNet 等大型数据集上训练好的 CNN 模型拿过来，经过简单的调整应用到自己的项目上去。<br><img src="https://i.loli.net/2018/11/03/5bdd5f94a2ad6.png" alt><br><a id="more"></a></p>
<h2 id="迁移学习的分类" class="heading-control"><a href="#迁移学习的分类" class="headerlink" title="迁移学习的分类"></a>迁移学习的分类<a class="heading-anchor" href="#迁移学习的分类" aria-hidden="true"></a></h2><p>迁移学习分为三种：</p>
<ul>
<li>第一种叫 transfer learning。用于图像分类的卷积神经网络由两部分组成：从一系列卷积层和池化层开始，并以全连接的分类器结束。第一部分称为模型的卷积基（convolutional base），即全连接层之前的卷积池化部分，特征提取就是利用预训练好的的网络模型的卷积基，运行新的数据，并在输出之上训练一个新的分类器（见图 1.1）。因此，我们只需要训练分类器部分，卷积基直接用现成的不动。<img src="https://i.loli.net/2018/11/03/5bdd38ae95f2f.png" alt><br>为什么只重用卷积基？能使用相同的分类器吗？一般来说前面的卷积基提取了低级特征，这在很多其他类似问题是可以通用的。而最后的全连接层是与具体问题相关的高级特征，因此不太可复用。</li>
<li>第二种是 fine tune，即微调，就是让一部分底层也参与训练。一般来说，只有在顶层的分类器已经被训练好之后，才去微调卷积基的顶层。</li>
<li><p>预训练模型。例如，Caffe 库有一个 model zoo，其他人可以在这里找到各种训练好的模型的 checkpoint。</p>
<p>一个典型的迁移学习过程是这样的。首先通过 transfer learning 对新的数据集进行训练，训练过一定 epoch 之后，改用 fine tune 方法继续训练，同时降低学习率。这样做是因为如果一开始就采用 fine tune 方法的话，网络还没有适应新的数据，那么在进行参数更新的时候，比较大的梯度可能会导致原本训练的比较好的参数被污染，反而导致效果下降。</p>
<h2 id="微调经验总结" class="heading-control"><a href="#微调经验总结" class="headerlink" title="微调经验总结"></a>微调经验总结<a class="heading-anchor" href="#微调经验总结" aria-hidden="true"></a></h2><p>主要的因素是数据集的大小和原始数据集的相似性。有一点一定记住：网络前几层学到的是通用特征，后面几层学到的是与类别相关的特征。下面分情况讨论：</p>
</li>
</ul>
<ol>
<li><strong>新数据集很小，与原始数据集类似。</strong> 因为新数据集比较小，如果 fine-tune 可能会过拟合；又因为新旧数据集类似，所以可能高层特征类似，可以使用预训练网络当做特征提取器，用提取的特征训练线性分类器。</li>
<li><strong>新数据集很大，与原始数据集类似。</strong> 可以微调，不用担心过拟合。</li>
<li><strong>新数据集很小但与原始数据集非常不同。</strong> 新数据集小，最好不要 fine-tune，和原数据集不类似，最好也不使用高层特征。这时可是使用前面层的特征来训练 SVM 分类器。</li>
<li><strong>新数据集很大，与原始数据集非常不同。</strong> 因为新数据集足够大，可以重新训练。但是实践中 fine-tune 预训练模型还是有益的。新数据集足够大，可以 fine-tine 整个网络。<br><img src="https://i.loli.net/2018/11/03/5bdd5fc54c2ca.png" alt><h2 id="代码步骤" class="heading-control"><a href="#代码步骤" class="headerlink" title="代码步骤"></a>代码步骤<a class="heading-anchor" href="#代码步骤" aria-hidden="true"></a></h2><h3 id="加载数据" class="heading-control"><a href="#加载数据" class="headerlink" title="加载数据"></a>加载数据<a class="heading-anchor" href="#加载数据" aria-hidden="true"></a></h3>这一步很正常，主要是处理图片数据和划分数据集<h3 id="加载MobileNetV2模型（不含全连接层）" class="heading-control"><a href="#加载MobileNetV2模型（不含全连接层）" class="headerlink" title="加载MobileNetV2模型（不含全连接层）"></a>加载 MobileNetV2 模型（不含全连接层）<a class="heading-anchor" href="#加载MobileNetV2模型（不含全连接层）" aria-hidden="true"></a></h3>Keras 的应用模块 Application 提供了带有预训练权重的 Keras 模型，这些模型可以用来进行预测、特征提取和 finetune。你可以从 keras.applications 模块中导入它。<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line">base_model = MobileNetV2(weights=<span class="string">'imagenet'</span>, include_top=<span class="literal">False</span>)</span><br></pre></td></tr></tbody></table></figure>
<h3 id="添加新的顶层" class="heading-control"><a href="#添加新的顶层" class="headerlink" title="添加新的顶层"></a>添加新的顶层<a class="heading-anchor" href="#添加新的顶层" aria-hidden="true"></a></h3><figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">add_new_last_layer</span>(<span class="params">base_model, nb_classes</span>):</span></span><br><span class="line">    x = base_model.output</span><br><span class="line">    x = GlobalAveragePooling2D()(x)</span><br><span class="line">    <span class="comment"># GlobalAveragePooling2D 将 MxNxC 的张量转换成 1xC 张量，C是通道数</span></span><br><span class="line">    x = Dense(FC_SIZE, activation=<span class="string">'relu'</span>)(x)</span><br><span class="line">    predictions = Dense(nb_classes, activation=<span class="string">'softmax'</span>)(x)</span><br><span class="line">    model = Model(input=base_model.input, output=predictions)</span><br><span class="line">    <span class="keyword">return</span> model</span><br></pre></td></tr></tbody></table></figure>
<h3 id="训练顶层分类器" class="heading-control"><a href="#训练顶层分类器" class="headerlink" title="训练顶层分类器"></a>训练顶层分类器<a class="heading-anchor" href="#训练顶层分类器" aria-hidden="true"></a></h3>冻结 base_model 所有层，然后进行训练。<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">setup_to_transfer_learn</span>(<span class="params">model, base_model</span>):</span></span><br><span class="line">    <span class="keyword">for</span> layer <span class="keyword">in</span> base_model.layers:</span><br><span class="line">        layer.trainable = <span class="literal">False</span></span><br><span class="line">    model.compile(optimizer=<span class="string">'rmsprop'</span>, loss=<span class="string">'categorical_crossentropy'</span>, metrics=[<span class="string">'accuracy'</span>])</span><br><span class="line">    </span><br><span class="line">setup_to_transfer_learn(model, base_model)</span><br></pre></td></tr></tbody></table></figure>
其实这一步也可以和上一步结合起来写，更加简洁：<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> models</span><br><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> layers</span><br><span class="line"><span class="comment"># 在conv_base的基础上添加全连接分类网络</span></span><br><span class="line">conv_base = MobileNetV2(weights=<span class="string">'imagenet'</span>, include_top=<span class="literal">False</span>)</span><br><span class="line">conv_base.trainable = <span class="literal">False</span></span><br><span class="line">model = models.Sequential()</span><br><span class="line">model.add(conv_base)</span><br><span class="line">model.add(layers.Flatten())</span><br><span class="line">model.add(layers.Dense(<span class="number">256</span>, activation=<span class="string">'relu'</span>))</span><br><span class="line">model.add(layers.Dense(<span class="number">1</span>, activation=<span class="string">'sigmoid'</span>))</span><br></pre></td></tr></tbody></table></figure>
<h3 id="对顶层分类器进行fine-tuning" class="heading-control"><a href="#对顶层分类器进行fine-tuning" class="headerlink" title="对顶层分类器进行fine_tuning"></a>对顶层分类器进行 fine_tuning<a class="heading-anchor" href="#对顶层分类器进行fine-tuning" aria-hidden="true"></a></h3>冻结部分层，对顶层分类器进行 Fine-tune</li>
</ol>
<p>Fine-tune 以一个预训练好的网络为基础，在新的数据集上重新训练一小部分权重。fine-tune 应该在很低的学习率下进行。<br></p><figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">setup_to_finetune</span>(<span class="params">model</span>):</span></span><br><span class="line">    <span class="keyword">for</span> layer <span class="keyword">in</span> model.layers[:NB_MobileNetV2_LAYERS_TO_FREEZE]:</span><br><span class="line">        layer.trainable = <span class="literal">False</span></span><br><span class="line">    <span class="keyword">for</span> layer <span class="keyword">in</span> model.layers[NB_MobileNetV2_LAYERS_TO_FREEZE:]:</span><br><span class="line">        layer.trainable = <span class="literal">True</span></span><br><span class="line">    model.compile(optimizer=SGD(lr=<span class="number">0.0001</span>, momentum=<span class="number">0.9</span>), loss=<span class="string">'categorical_crossentropy'</span>, metrics=[<span class="string">'accuracy'</span>])</span><br></pre></td></tr></tbody></table></figure><br>这里可能比较疑惑的是NB_MobileNetV2_LAYERS_TO_FREEZE是多少呢，怎么找呢。方法是利用Pycharm的Debug功能，查看base_model.layers中的值。<br>当然也可以选择使用layer name来进行选择：<br><figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line">conv_base.trainable = <span class="literal">True</span></span><br><span class="line"></span><br><span class="line">set_trainable = <span class="literal">False</span></span><br><span class="line"><span class="keyword">for</span> layer <span class="keyword">in</span> conv_base.layers:</span><br><span class="line">    <span class="keyword">if</span> layer.name == <span class="string">'block5_conv1'</span>:</span><br><span class="line">        set_trainable = <span class="literal">True</span></span><br><span class="line">    <span class="keyword">if</span> set_trainable:</span><br><span class="line">        layer.trainable = <span class="literal">True</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        layer.trainable = <span class="literal">False</span></span><br></pre></td></tr></tbody></table></figure><p></p>
<h2 id="总体代码" class="heading-control"><a href="#总体代码" class="headerlink" title="总体代码"></a>总体代码<a class="heading-anchor" href="#总体代码" aria-hidden="true"></a></h2><figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> keras.applications <span class="keyword">import</span> MobileNetV2</span><br><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> layers</span><br><span class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> Model</span><br><span class="line"><span class="keyword">from</span> keras.optimizers <span class="keyword">import</span> SGD</span><br><span class="line"><span class="keyword">from</span> keras.utils <span class="keyword">import</span> plot_model</span><br><span class="line"></span><br><span class="line">FC_SIZE = <span class="number">256</span></span><br><span class="line">IM_WIDTH, IM_HEIGHT = <span class="number">28</span>, <span class="number">28</span></span><br><span class="line">nb_classes = <span class="number">100</span></span><br><span class="line">NB_MobileNetV2_LAYERS_TO_FREEZE = <span class="number">149</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">add_new_last_layer</span>(<span class="params">base_model, nb_classes</span>):</span></span><br><span class="line">    x = base_model.output</span><br><span class="line">    x = layers.GlobalAveragePooling2D()(x)</span><br><span class="line">    x = layers.Dense(FC_SIZE, activation=<span class="string">'relu'</span>)(x)</span><br><span class="line">    predictions = layers.Dense(nb_classes, activation=<span class="string">'softmax'</span>)(x)</span><br><span class="line">    model = Model(inputs=base_model.input, outputs=predictions)</span><br><span class="line">    <span class="keyword">return</span> model</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">setup_to_transfer_learn</span>(<span class="params">model, base_model</span>):</span></span><br><span class="line">    <span class="keyword">for</span> layer <span class="keyword">in</span> base_model.layers:</span><br><span class="line">        layer.trainable = <span class="literal">False</span></span><br><span class="line">    model.compile(optimizer=<span class="string">'adam'</span>, loss=<span class="string">'categorical_crossentropy'</span>, metrics=[<span class="string">'accuracy'</span>])</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">setup_to_finetune</span>(<span class="params">model</span>):</span></span><br><span class="line">    <span class="keyword">for</span> layer <span class="keyword">in</span> model.layers[:NB_MobileNetV2_LAYERS_TO_FREEZE]:</span><br><span class="line">        layer.trainable = <span class="literal">False</span></span><br><span class="line">    <span class="keyword">for</span> layer <span class="keyword">in</span> model.layers[NB_MobileNetV2_LAYERS_TO_FREEZE:]:</span><br><span class="line">        layer.trainable = <span class="literal">True</span></span><br><span class="line">    model.compile(optimizer=SGD(lr=<span class="number">0.0001</span>, momentum=<span class="number">0.9</span>), loss=<span class="string">'categorical_crossentropy'</span>, metrics=[<span class="string">'accuracy'</span>])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line"></span><br><span class="line">    base_model = MobileNetV2(weights=<span class="string">'imagenet'</span>, include_top=<span class="literal">False</span>)</span><br><span class="line">    model = add_new_last_layer(base_model, nb_classes)</span><br><span class="line">    setup_to_transfer_learn(model, base_model)</span><br><span class="line">    model.fit()</span><br><span class="line">    setup_to_finetune(model)</span><br><span class="line">    model.fit()</span><br><span class="line">    print(model.summary())</span><br><span class="line">    plot_model(model, to_file=<span class="string">'mobilev2.png'</span>, show_shapes=<span class="literal">True</span>)</span><br></pre></td></tr></tbody></table></figure>
<h2 id="总结" class="heading-control"><a href="#总结" class="headerlink" title="总结"></a>总结<a class="heading-anchor" href="#总结" aria-hidden="true"></a></h2><ul>
<li>在小数据集上，过拟合将是主要问题。数据扩充是处理图像数据时过拟合的强大方法。</li>
<li>通过卷积基特征提取可以利用先前学习的特征。</li>
<li>作为特征提取的补充，我们可以使用微调来适应新的问题。<h2 id="Reference" class="heading-control"><a href="#Reference" class="headerlink" title="Reference"></a>Reference <a class="heading-anchor" href="#Reference" aria-hidden="true"></a></h2></li>
</ul>
<ol>
<li><a href="https://blog.csdn.net/tsyccnh/article/details/78889838">使用 Inception V3 模型进行迁移学习</a></li>
<li><a href="https://blog.csdn.net/starter_____/article/details/79369382">基于 InceptionV3 模型的迁移学习应用</a></li>
<li><a href="https://github.com/Zheng-Wenkai/Keras_Demo">Keras Demo</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/33346258">在小数据集上迁移学习 (上)</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/33363701">在小数据集上迁移学习 (下)</a></li>
<li><a href="http://cs231n.github.io/transfer-learning/">CS231N: 迁移学习</a></li>
</ol>
</body></html>]]></content>
      <categories>
        <category>项目</category>
      </categories>
      <tags>
        <tag>迁移学习</tag>
        <tag>cnn</tag>
      </tags>
  </entry>
  <entry>
    <title>Kmeans 聚类算法</title>
    <url>/post/42756.html</url>
    <content><![CDATA[<html><head><link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script></head><body><h2 id="kmeans算法步骤" class="heading-control"><a href="#kmeans算法步骤" class="headerlink" title="kmeans算法步骤"></a>kmeans 算法步骤<a class="heading-anchor" href="#kmeans算法步骤" aria-hidden="true"></a></h2><ul>
<li>第一步 - 随机选择 K 个点作为点的聚类中心，这表示我们要将数据分为 K 类。</li>
<li>第二步 - 遍历所有的点 P, 算出 P 到每个聚类中心的距离，将 P 放到最近的聚类中心的点集中。遍历结束后我们将得到 K 个点集。</li>
<li>第三步 - 遍历每一个点集，算出每一个点集的中心位置，将其作为新的聚类中心。</li>
<li>第四步 - 重复步骤 2 和步骤 3，直到聚类中心位置不再移动。</li>
</ul>
<p><img src="https://s2.ax1x.com/2019/07/23/ekGzVK.gif" alt="ekGzVK.gif"></p>
<h2 id="如何确定K值" class="heading-control"><a href="#如何确定K值" class="headerlink" title="如何确定K值"></a>如何确定 K 值<a class="heading-anchor" href="#如何确定K值" aria-hidden="true"></a></h2><p>在确定 K 的时候，可以测试 10 个不同的聚类中心，然后绘制 K 与误差平方和的曲线图，找到曲线的拐点，即是合适的 K 值。<br><img src="https://i.loli.net/2019/07/23/5d36b6b39df1e49840.png" alt></p>
</body></html>]]></content>
      <tags>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title>LSTM 参数计算与 TimeDistributed 层</title>
    <url>/post/27641.html</url>
    <content><![CDATA[<html><head><link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script></head><body><p><img src="https://i.loli.net/2018/11/14/5bebe405d0716.png" alt></p>
<h2 id="前言" class="heading-control"><a href="#前言" class="headerlink" title="前言"></a>前言<a class="heading-anchor" href="#前言" aria-hidden="true"></a></h2><p>本篇主要讲 LSTM 的参数计算和 Keras TimeDistributed 层的使用。LSTM 的输入格式为：[Simples,Time Steps,Features]</p>
<ul>
<li>Samples. One sequence is one sample. A batch is comprised of one or more samples.(就是有几条数据)</li>
<li>Time Steps. One time step is one point of observation in the sample.（时间步长，通常对应时间序列的长度）</li>
<li>Features. One feature is one observation at a time step.（一个时间步长对应的向量长度）</li>
</ul>
<p>举个文本的例子，原始一个 batch_size=50, 一行文本的长度 max_len=10, 所以输入矩阵为 [50,10],embedding 成 300 维的向量后，格式为 [50,10,300]，分别对应 Simples,Time Steps,Features。<br>另外一个需要设置的参数是 LSTM 的输出维度 (Output_dim)，比如为 128，LSTM 的参数量计算为</p>
<script type="math/tex; mode=display">
\begin{equation}

Number=4*((Features+Output\_dim) x Output\_dim+Output\_dim)

\end{equation}</script><a id="more"></a>
<h2 id="计算LSTM层的参数" class="heading-control"><a href="#计算LSTM层的参数" class="headerlink" title="计算LSTM层的参数"></a>计算 LSTM 层的参数<a class="heading-anchor" href="#计算LSTM层的参数" aria-hidden="true"></a></h2><p>上面计算 LSTM 参数数目的方法是怎么来的呢？首先理解 RNN 权重共享。对于 LSTM，cell 的<strong>权重是共享</strong>的，这是什么意思呢？这是指图片上三个绿色的大框，即三个 cell ，但是实际上，它只是代表了<strong>一个 cell 在不同时序时候的状态</strong>，所有的数据只会通过一个 cell，然后不断更新它的权重。<br>我们现在来考虑遗忘门：<br><img src="https://i.loli.net/2018/11/14/5bec0397c15fc.png" alt><br>图中的公式 $h<em>{t-1}$ 的长度是 Output_dim， $[h</em>{t-1},x<em>{t}]$ 的长度就是 Output_dim+Features， $W</em>{f}$  和 $b<em>{f}$ 为该层的参数。 $W</em>{f}$ 的大小为 (Output<em>dim+Features)xOutput_dim,$b</em>{f}$ 的大小为 Output_dim，所以这个门总的参数为：</p>
<script type="math/tex; mode=display">
\begin{equation}

Number=(Features+Output\_dim) x Output\_dim+Output\_dim

\end{equation}</script><p><img src="https://i.loli.net/2018/11/14/5bec17fcbdcc4.png" alt="1.png"><br>同样的更新门，有两倍的遗忘门参数。<br><img src="https://i.loli.net/2018/11/14/5bec17fcbc135.png" alt="2.png"><br>更新过程中没有参数需要学习。<br><img src="https://i.loli.net/2018/11/14/5bec17fd1ac9d.png" alt="3.png"><br>输出门参数和遗忘门一样多。</p>
<h2 id="一对一序列预测" class="heading-control"><a href="#一对一序列预测" class="headerlink" title="一对一序列预测"></a>一对一序列预测<a class="heading-anchor" href="#一对一序列预测" aria-hidden="true"></a></h2><p>首先做一个序列的问题，假设有数据 X 和数据如下，然后用 LSTM 做序列预测：<br></p><figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line">X:[ <span class="number">0.</span>  <span class="number">0.2</span>  <span class="number">0.4</span>  <span class="number">0.6</span>  <span class="number">0.8</span>]</span><br><span class="line">Y:[ <span class="number">0.</span>  <span class="number">0.2</span>  <span class="number">0.4</span>  <span class="number">0.6</span>  <span class="number">0.8</span>]</span><br></pre></td></tr></tbody></table></figure><br>代码很简单，结果正确：<br><figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> Sequential</span><br><span class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Dense</span><br><span class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> LSTM</span><br><span class="line"><span class="keyword">from</span> numpy <span class="keyword">import</span> array</span><br><span class="line"><span class="comment"># prepare sequence</span></span><br><span class="line">length = <span class="number">5</span></span><br><span class="line">seq = array([i/float(length) <span class="keyword">for</span> i <span class="keyword">in</span> range(length)])</span><br><span class="line">X = seq.reshape(len(seq), <span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">y = seq.reshape(len(seq), <span class="number">1</span>)</span><br><span class="line"><span class="comment"># define LSTM configuration</span></span><br><span class="line">n_neurons = length</span><br><span class="line">n_batch = length</span><br><span class="line">n_epoch = <span class="number">1000</span></span><br><span class="line"><span class="comment"># create LSTM</span></span><br><span class="line">model = Sequential()</span><br><span class="line">model.add(LSTM(n_neurons, input_shape=(<span class="number">1</span>, <span class="number">1</span>)))</span><br><span class="line">model.add(Dense(<span class="number">1</span>))</span><br><span class="line">model.compile(loss=<span class="string">'mean_squared_error'</span>, optimizer=<span class="string">'adam'</span>)</span><br><span class="line">print(model.summary())</span><br><span class="line"><span class="comment"># train LSTM</span></span><br><span class="line">model.fit(X, y, epochs=n_epoch, batch_size=n_batch, verbose=<span class="number">2</span>)</span><br><span class="line"><span class="comment"># evaluate</span></span><br><span class="line">result = model.predict(X, batch_size=n_batch, verbose=<span class="number">0</span>)</span><br><span class="line"><span class="keyword">for</span> value <span class="keyword">in</span> result:</span><br><span class="line">	print(<span class="string">'%.1f'</span> % value)</span><br></pre></td></tr></tbody></table></figure><br>下面我们来手动计算一下LSTM层的参数：<br><figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line">n = <span class="number">4</span> * ((inputs + <span class="number">1</span>) * outputs + outputs^<span class="number">2</span>)</span><br><span class="line">n = <span class="number">4</span> * ((<span class="number">1</span> + <span class="number">1</span>) * <span class="number">5</span> + <span class="number">5</span>^<span class="number">2</span>)</span><br><span class="line">n = <span class="number">4</span> * <span class="number">35</span></span><br><span class="line">n = <span class="number">140</span></span><br></pre></td></tr></tbody></table></figure><br>全连接层的参数计算如下：<br><figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line">n = inputs * outputs + outputs</span><br><span class="line">n = <span class="number">5</span> * <span class="number">1</span> + <span class="number">1</span></span><br><span class="line">n = <span class="number">6</span></span><br></pre></td></tr></tbody></table></figure><br>和Keras打印的参数一致：<br><figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line">_________________________________________________________________</span><br><span class="line">Layer (type)                 Output Shape              Param <span class="comment">#</span></span><br><span class="line">=================================================================</span><br><span class="line">lstm_1 (LSTM)                (<span class="literal">None</span>, <span class="number">1</span>, <span class="number">5</span>)              <span class="number">140</span></span><br><span class="line">_________________________________________________________________</span><br><span class="line">dense_1 (Dense)              (<span class="literal">None</span>, <span class="number">1</span>, <span class="number">1</span>)              <span class="number">6</span></span><br><span class="line">=================================================================</span><br><span class="line">Total params: <span class="number">146.0</span></span><br><span class="line">Trainable params: <span class="number">146</span></span><br><span class="line">Non-trainable params: <span class="number">0.0</span></span><br><span class="line">_________________________________________________________________</span><br></pre></td></tr></tbody></table></figure><br>模型的结构图如下：<br><img src="https://i.loli.net/2018/11/14/5bebdfce158d7.png" alt><p></p>
<h2 id="多对一序列预测" class="heading-control"><a href="#多对一序列预测" class="headerlink" title="多对一序列预测"></a>多对一序列预测<a class="heading-anchor" href="#多对一序列预测" aria-hidden="true"></a></h2><p>同样准备数据：<br></p><figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line">X1: <span class="number">0</span></span><br><span class="line">X2: <span class="number">0.2</span></span><br><span class="line">X3: <span class="number">0.4</span></span><br><span class="line">X4: <span class="number">0.6</span></span><br><span class="line">X5: <span class="number">0.8</span></span><br><span class="line">Y :[ <span class="number">0.</span>   <span class="number">0.2</span>  <span class="number">0.4</span>  <span class="number">0.6</span>  <span class="number">0.8</span>]</span><br></pre></td></tr></tbody></table></figure><br>代码如下：<br><figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> numpy <span class="keyword">import</span> array</span><br><span class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> Sequential</span><br><span class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Dense</span><br><span class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> LSTM</span><br><span class="line"><span class="comment"># prepare sequence</span></span><br><span class="line">length = <span class="number">5</span></span><br><span class="line">seq = array([i/float(length) <span class="keyword">for</span> i <span class="keyword">in</span> range(length)])</span><br><span class="line">X = seq.reshape(<span class="number">1</span>, length, <span class="number">1</span>)</span><br><span class="line">y = seq.reshape(<span class="number">1</span>, length)</span><br><span class="line"><span class="comment"># define LSTM configuration</span></span><br><span class="line">n_neurons = length</span><br><span class="line">n_batch = <span class="number">1</span></span><br><span class="line">n_epoch = <span class="number">500</span></span><br><span class="line"><span class="comment"># create LSTM</span></span><br><span class="line">model = Sequential()</span><br><span class="line">model.add(LSTM(n_neurons, input_shape=(length, <span class="number">1</span>)))</span><br><span class="line">model.add(Dense(length))</span><br><span class="line">model.compile(loss=<span class="string">'mean_squared_error'</span>, optimizer=<span class="string">'adam'</span>)</span><br><span class="line">print(model.summary())</span><br><span class="line"><span class="comment"># train LSTM</span></span><br><span class="line">model.fit(X, y, epochs=n_epoch, batch_size=n_batch, verbose=<span class="number">2</span>)</span><br><span class="line"><span class="comment"># evaluate</span></span><br><span class="line">result = model.predict(X, batch_size=n_batch, verbose=<span class="number">0</span>)</span><br><span class="line"><span class="keyword">for</span> value <span class="keyword">in</span> result[<span class="number">0</span>,:]:</span><br><span class="line">	print(<span class="string">'%.1f'</span> % value)</span><br></pre></td></tr></tbody></table></figure><br>用Keras打印网络结构如下：<br><figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line">_________________________________________________________________</span><br><span class="line">Layer (type)                 Output Shape              Param <span class="comment">#</span></span><br><span class="line">=================================================================</span><br><span class="line">lstm_1 (LSTM)                (<span class="literal">None</span>, <span class="number">5</span>)                 <span class="number">140</span></span><br><span class="line">_________________________________________________________________</span><br><span class="line">dense_1 (Dense)              (<span class="literal">None</span>, <span class="number">5</span>)                 <span class="number">30</span></span><br><span class="line">=================================================================</span><br><span class="line">Total params: <span class="number">170.0</span></span><br><span class="line">Trainable params: <span class="number">170</span></span><br><span class="line">Non-trainable params: <span class="number">0.0</span></span><br><span class="line">_________________________________________________________________</span><br></pre></td></tr></tbody></table></figure><br>这一次的参数有170个。原因是全连接层参数变多了,计算如下;<br><figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line">n = inputs * outputs + outputs</span><br><span class="line">n = <span class="number">5</span> * <span class="number">5</span> + <span class="number">5</span></span><br><span class="line">n = <span class="number">30</span></span><br></pre></td></tr></tbody></table></figure><br>整体的模型结构如下：<br><img src="https://i.loli.net/2018/11/14/5bebe05eb3187.png" alt><p></p>
<h2 id="带TimeDistributed的多对多LSTM序列预测" class="heading-control"><a href="#带TimeDistributed的多对多LSTM序列预测" class="headerlink" title="带TimeDistributed的多对多LSTM序列预测"></a>带 TimeDistributed 的多对多 LSTM 序列预测<a class="heading-anchor" href="#带TimeDistributed的多对多LSTM序列预测" aria-hidden="true"></a></h2><figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> numpy <span class="keyword">import</span> array</span><br><span class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> Sequential</span><br><span class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Dense</span><br><span class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> TimeDistributed</span><br><span class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> LSTM</span><br><span class="line"><span class="comment"># prepare sequence</span></span><br><span class="line">length = <span class="number">5</span></span><br><span class="line">seq = array([i/float(length) <span class="keyword">for</span> i <span class="keyword">in</span> range(length)])</span><br><span class="line">X = seq.reshape(<span class="number">1</span>, length, <span class="number">1</span>)</span><br><span class="line">y = seq.reshape(<span class="number">1</span>, length, <span class="number">1</span>)</span><br><span class="line"><span class="comment"># define LSTM configuration</span></span><br><span class="line">n_neurons = length</span><br><span class="line">n_batch = <span class="number">1</span></span><br><span class="line">n_epoch = <span class="number">1000</span></span><br><span class="line"><span class="comment"># create LSTM</span></span><br><span class="line">model = Sequential()</span><br><span class="line">model.add(LSTM(n_neurons, input_shape=(length, <span class="number">1</span>), return_sequences=<span class="literal">True</span>))</span><br><span class="line">model.add(TimeDistributed(Dense(<span class="number">1</span>)))</span><br><span class="line">model.compile(loss=<span class="string">'mean_squared_error'</span>, optimizer=<span class="string">'adam'</span>)</span><br><span class="line">print(model.summary())</span><br><span class="line"><span class="comment"># train LSTM</span></span><br><span class="line">model.fit(X, y, epochs=n_epoch, batch_size=n_batch, verbose=<span class="number">2</span>)</span><br><span class="line"><span class="comment"># evaluate</span></span><br><span class="line">result = model.predict(X, batch_size=n_batch, verbose=<span class="number">0</span>)</span><br><span class="line"><span class="keyword">for</span> value <span class="keyword">in</span> result[<span class="number">0</span>,:,<span class="number">0</span>]:</span><br><span class="line">	print(<span class="string">'%.1f'</span> % value)</span><br></pre></td></tr></tbody></table></figure>
<p>用 Keras 打印网络结构如下：<br></p><figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line">_________________________________________________________________</span><br><span class="line">Layer (type)                 Output Shape              Param <span class="comment">#</span></span><br><span class="line">=================================================================</span><br><span class="line">lstm_1 (LSTM)                (<span class="literal">None</span>, <span class="number">5</span>, <span class="number">5</span>)              <span class="number">140</span></span><br><span class="line">_________________________________________________________________</span><br><span class="line">time_distributed_1 (TimeDist (<span class="literal">None</span>, <span class="number">5</span>, <span class="number">1</span>)              <span class="number">6</span></span><br><span class="line">=================================================================</span><br><span class="line">Total params: <span class="number">146.0</span></span><br><span class="line">Trainable params: <span class="number">146</span></span><br><span class="line">Non-trainable params: <span class="number">0.0</span></span><br><span class="line">_________________________________________________________________</span><br></pre></td></tr></tbody></table></figure><br>整体的模型结构如下：<br><img src="https://i.loli.net/2018/11/14/5bebdf475db9f.png" alt><p></p>
<h2 id="Reference" class="heading-control"><a href="#Reference" class="headerlink" title="Reference"></a>Reference<a class="heading-anchor" href="#Reference" aria-hidden="true"></a></h2><ol>
<li><a href="https://machinelearningmastery.com/timedistributed-layer-for-long-short-term-memory-networks-in-python/">How to Use the TimeDistributed Layer for Long Short-Term Memory Networks in Python</a></li>
</ol>
</body></html>]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>Keras</tag>
      </tags>
  </entry>
  <entry>
    <title>Leetcode 387— 字符串中的第一个唯一字符</title>
    <url>/post/56348.html</url>
    <content><![CDATA[<html><head><link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script></head><body><p><img src="https://i.loli.net/2019/08/10/3RJKsiQIWL8qfUr.png" alt><br><a id="more"></a></p>
<h2 id="方法一：Hash" class="heading-control"><a href="#方法一：Hash" class="headerlink" title="方法一：Hash"></a>方法一：Hash<a class="heading-anchor" href="#方法一：Hash" aria-hidden="true"></a></h2><p>和出现次数有关的，不要犹豫，hash<br><strong>具体思路</strong>：首先用字典统计每个字符出现的频率，然后顺序遍历字符串，并在字典中进行查找，出现频率为 1，返回。<br>时间复杂度 O (n), 空间复杂度 O (n)<br></p><figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">firstUniqChar</span>(<span class="params">self, s: str</span>) -> int:</span></span><br><span class="line">        <span class="comment">#字典存储字符频率</span></span><br><span class="line">        dic = dict()</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> s:</span><br><span class="line">            <span class="keyword">if</span> i <span class="keyword">in</span> dic:</span><br><span class="line">                dic[i] = dic[i] + <span class="number">1</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                dic[i] = <span class="number">1</span></span><br><span class="line">        <span class="comment">#顺序查找</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(len(s)):</span><br><span class="line">            <span class="keyword">if</span> dic[s[i]] == <span class="number">1</span>:</span><br><span class="line">                <span class="keyword">return</span> i</span><br><span class="line">        <span class="keyword">return</span> <span class="number">-1</span></span><br></pre></td></tr></tbody></table></figure><p></p>
<h2 id="方法二：空间换时间" class="heading-control"><a href="#方法二：空间换时间" class="headerlink" title="方法二：空间换时间"></a>方法二：空间换时间<a class="heading-anchor" href="#方法二：空间换时间" aria-hidden="true"></a></h2><p>因为只有 26 个字母，因此可以开一个 26 的数组记录每个字符出现的频率。然后顺序查找，频率为 1，返回。<strong>优点</strong>：对于很长的字符串节约空间复杂度。<br></p><figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">firstUniqChar</span>(<span class="params">self, s: str</span>) -> int:</span></span><br><span class="line">    <span class="keyword">if</span> len(s)==<span class="number">0</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="number">-1</span></span><br><span class="line"></span><br><span class="line">    table = [<span class="number">0</span>]*<span class="number">26</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(len(s)):</span><br><span class="line">        table[ord(s[i])-ord(<span class="string">'a'</span>)]+=<span class="number">1</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(len(s)):</span><br><span class="line">        <span class="keyword">if</span> table[ord(s[i])-ord(<span class="string">'a'</span>)]==<span class="number">1</span>:</span><br><span class="line">            <span class="keyword">return</span> i</span><br><span class="line">    <span class="keyword">return</span> <span class="number">-1</span></span><br></pre></td></tr></tbody></table></figure><p></p>
</body></html>]]></content>
      <tags>
        <tag>字符串</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux 使用百度云下载</title>
    <url>/post/17514.html</url>
    <content><![CDATA[<html><head><link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script></head><body><h3 id="前言" class="heading-control"><a href="#前言" class="headerlink" title="前言"></a>前言<a class="heading-anchor" href="#前言" aria-hidden="true"></a></h3><p>项目 github 地址：<a href="https://github.com/iikira/BaiduPCS-Go">https://github.com/iikira/BaiduPCS-Go</a></p>
<h3 id="安装" class="heading-control"><a href="#安装" class="headerlink" title="安装"></a>安装<a class="heading-anchor" href="#安装" aria-hidden="true"></a></h3><ul>
<li>下载到本地：<a href="https://github.com/iikira/BaiduPCS-Go/releases/download/v3.6/BaiduPCS-Go-v3.6-linux-386.zip">3.6 版本</a></li>
<li> scp 传输到服务器：<code>scp -P 2222 C:\Users\lenovo\Pictures\BaiduPCS-Go-v3.6-linux-386.zip root@127.0.0.1:/home</code></li>
<li>解压：<code>unzip BaiduPCS-Go-v3.6-linux-386.zip</code><br>询问是否覆盖：y<br>进入目录：<code>cd BaiduPCS-Go-v3.6-linux-386</code><br>启动：<code>./BaiduPCS-Go</code></li>
</ul>
<h3 id="登录" class="heading-control"><a href="#登录" class="headerlink" title="登录"></a>登录<a class="heading-anchor" href="#登录" aria-hidden="true"></a></h3><ul>
<li>登录：<code>login</code></li>
<li>然后按照提示输入用户名，密码。回车后，会让输入验证码。会提示打开浏览器查看验证码，可能试验登录多次，才正确。</li>
</ul>
<p>然后让你输入验证手机号，会给你发短信，输入短信的验证码后，就能登录了。</p>
<h3 id="操作" class="heading-control"><a href="#操作" class="headerlink" title="操作"></a>操作<a class="heading-anchor" href="#操作" aria-hidden="true"></a></h3><ul>
<li>登录进去后，查看有哪些百度网盘命令：<code>help</code></li>
<li>列出百度网盘的目录：<code>ls</code></li>
<li>下载百度网盘的文件： <code>d 文件名</code></li>
<li>下载完成后，会提示你，把文件下载到哪个目录了。 一般在 根目录下，点进去 <code>root</code> 文件夹，即 <code>/root/Downloads/</code></li>
<li>修改默认储存路径：<code>BaiduPCS-Go config set -savedir download</code></li>
<li>退出程序：运行命令 <code>quit</code> 或 <code>exit</code> 或 组合键 <code>Ctrl+C</code> 或 组合键 <code>Ctrl+D</code></li>
<li>下载大文件：<code>./BaiduPCS-Go config set -user_agent=""</code></li>
</ul>
<h3 id="退出" class="heading-control"><a href="#退出" class="headerlink" title="退出"></a>退出<a class="heading-anchor" href="#退出" aria-hidden="true"></a></h3><p>退出当前登录的百度帐号：<code>logout</code></p>
</body></html>]]></content>
      <tags>
        <tag>百度云</tag>
      </tags>
  </entry>
  <entry>
    <title>BiliBili 蒙版弹幕</title>
    <url>/post/34384.html</url>
    <content><![CDATA[<html><head><link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script></head><body><h2 id="What-is-Mask-RCNN" class="heading-control"><a href="#What-is-Mask-RCNN" class="headerlink" title="What is Mask RCNN"></a>What is Mask RCNN<a class="heading-anchor" href="#What-is-Mask-RCNN" aria-hidden="true"></a></h2><ul>
<li>Faster RCNN + Masks</li>
<li><p>Developed by Facebook AI Research(FAIR)</p>
<p><img src="https://i.loli.net/2018/10/26/5bd2bd96503da.png" alt></p>
<a id="more"></a>
</li>
</ul>
<h2 id="Setup-and-Installation" class="heading-control"><a href="#Setup-and-Installation" class="headerlink" title="Setup and Installation"></a>Setup and Installation<a class="heading-anchor" href="#Setup-and-Installation" aria-hidden="true"></a></h2><ul>
<li>Step1: Python3.6</li>
<li><p>Step2: Clone the Mask_RCNN repo</p>
  <figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line">git clone https://github.com/matterport/Mask_RCNN.git</span><br></pre></td></tr></tbody></table></figure>
</li>
<li><p>Step3: Install the dependencies<br>下载下来的 Mask RCNN 中有一个 requirements.txt 文件。</p>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line">pip install -r requirements</span><br></pre></td></tr></tbody></table></figure>
</li>
<li><p>Step4: Install cocoapi</p>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line">pip install git+https://github.com/philferriere/cocoapi.git<span class="comment">#subdirectory=PythonAPI</span></span><br></pre></td></tr></tbody></table></figure>
</li>
<li><p>Step5: Dowload the Pre-trained Weights<br><a href="https://github.com/matterport/Mask_RCNN/releases/download/v2.0/mask_rcnn_coco.h5">https://github.com/matterport/Mask_RCNN/releases/download/v2.0/mask_rcnn_coco.h5</a><br>把下载的 h5 文件放入 Mask-RCNN 的文件夹里面</p>
</li>
</ul>
<h2 id="Run" class="heading-control"><a href="#Run" class="headerlink" title="Run"></a>Run<a class="heading-anchor" href="#Run" aria-hidden="true"></a></h2><p>首先打开 Mask_RCNN/samples notebook，运行。<br>出现两个错误：</p>
<ul>
<li><p>No module named ‘imgaug’</p>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line">pip install imgaug</span><br><span class="line">pip install opencv-python</span><br></pre></td></tr></tbody></table></figure>
</li>
</ul>
<ul>
<li>TypeError: softmax() got an unexpected keyword argument ‘axis’<br>keras 2.1.6 的 softmax 没有 axis 这个参数了，回退 keras 版本：<code>pip install keras==2.1</code></li>
</ul>
<h2 id="结果" class="heading-control"><a href="#结果" class="headerlink" title="结果"></a>结果<a class="heading-anchor" href="#结果" aria-hidden="true"></a></h2><p><img src="https://i.loli.net/2018/10/26/5bd2bd104eeac.png" alt></p>
<h2 id="BiliBili蒙版弹幕" class="heading-control"><a href="#BiliBili蒙版弹幕" class="headerlink" title="BiliBili蒙版弹幕"></a>BiliBili 蒙版弹幕<a class="heading-anchor" href="#BiliBili蒙版弹幕" aria-hidden="true"></a></h2><p>原版视频地址：<a href="https://www.bilibili.com/video/av16789504">新垣结衣日清鸡肉拉面广告</a></p>
<h3 id="视频弹幕压缩" class="heading-control"><a href="#视频弹幕压缩" class="headerlink" title="视频弹幕压缩"></a>视频弹幕压缩<a class="heading-anchor" href="#视频弹幕压缩" aria-hidden="true"></a></h3><p>给视频加硬字幕是把字幕加到视频流中，不是单独的字幕流。</p>
<figure class="highlight shell"><table><tbody><tr><td class="code"><pre><span class="line">ffmpeg -i demo.mp4 -vf ass=subtitle.ass output.mp4</span><br></pre></td></tr></tbody></table></figure>
<p>参考链接：<a href="https://blog.csdn.net/fallfollowernolisten/article/details/68489499">https://blog.csdn.net/fallfollowernolisten/article/details/68489499</a></p>
<h3 id="准备工作" class="heading-control"><a href="#准备工作" class="headerlink" title="准备工作"></a>准备工作<a class="heading-anchor" href="#准备工作" aria-hidden="true"></a></h3><ol>
<li>准备带弹幕的视频文件和不带弹幕的视频文件。</li>
<li>配置视频文件路径。</li>
<li>在 coco 文件下的<code>__init__.py</code> 中加入代码：<code>from .coco import *</code> 。</li>
<li>执行代码，等待完成。</li>
</ol>
<h3 id="执行程序" class="heading-control"><a href="#执行程序" class="headerlink" title="执行程序"></a>执行程序<a class="heading-anchor" href="#执行程序" aria-hidden="true"></a></h3><p>内存占用情况：<br><img src="https://i.loli.net/2018/10/26/5bd304c51f8f6.png" alt><br>显卡使用情况：<br><img src="https://i.loli.net/2018/10/26/5bd305046a62e.png" alt><br>可以看到还是很耗费显存的，我的电脑差一点就不够了，而且实际训练起来速度也很慢。</p>
<h2 id="视频音频压缩" class="heading-control"><a href="#视频音频压缩" class="headerlink" title="视频音频压缩"></a>视频音频压缩<a class="heading-anchor" href="#视频音频压缩" aria-hidden="true"></a></h2><p>生成的蒙版弹幕视频文件没有声音，所以需要手动添加声音，还是用 ffmpeg。</p>
<ul>
<li>首先在把视频上传到 <a href>123app</a>，使用 Audio Convert 来转换为 MP3 格式，就是音频文件了，文件大小大概有几 M。</li>
<li><p>下一步是合并音视频。假设现有视频文件 video.avi (包含声音) 和音频文件 audio.mp3，要把 video.avi 中的视频和 audio.mp3 合并，步骤如下：</p>
<figure class="highlight shell"><table><tbody><tr><td class="code"><pre><span class="line">//将video.avi 中的视频提取到临时文件video2.avi中</span><br><span class="line">ffmpeg -i video.avi -vcodec copy -an video2.avi </span><br><span class="line">//合并 video2.avi 和  audio.mp3 到output.avi</span><br><span class="line">ffmpeg -i video2.avi -i audio.mp3 -vcodec copy -acodec copy output.avi </span><br><span class="line">//video2是临时文件，最后可以删除。</span><br></pre></td></tr></tbody></table></figure>
<h2 id="完成效果" class="heading-control"><a href="#完成效果" class="headerlink" title="完成效果"></a>完成效果<a class="heading-anchor" href="#完成效果" aria-hidden="true"></a></h2><p><img src="https://i.loli.net/2018/10/27/5bd40075b2092.png" alt></p>
<h2 id="Reference" class="heading-control"><a href="#Reference" class="headerlink" title="Reference"></a>Reference<a class="heading-anchor" href="#Reference" aria-hidden="true"></a></h2></li>
<li><p><a href="https://github.com/matterport/Mask_RCNN">Mask-RCNN</a></p>
</li>
<li><a href="https://github.com/markjay4k/Mask-RCNN-series?1540532721233">Mask-RCNN-series</a></li>
<li><a href="https://github.com/philferriere/cocoapi">cocoapi</a></li>
<li><a href="https://www.bilibili.com/video/av23064129/?p=1">Mask RCNN with Keras and Tensorflow</a></li>
<li><a href="https://github.com/youyuge34/Mask_Danmu">Mask_Danmu</a></li>
</ul>
</body></html>]]></content>
      <categories>
        <category>项目</category>
      </categories>
      <tags>
        <tag>CNN</tag>
      </tags>
  </entry>
  <entry>
    <title>Machine Reading Comprehension 文章阅读</title>
    <url>/post/21734.html</url>
    <content><![CDATA[<html><head><link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script></head><body><h3 id="《Relation-Module-for-Non-Answerable-Predictions-on-Reading-Comprehension》" class="heading-control"><a href="#《Relation-Module-for-Non-Answerable-Predictions-on-Reading-Comprehension》" class="headerlink" title="《Relation Module for Non-Answerable Predictions on Reading Comprehension》"></a>《Relation Module for Non-Answerable Predictions on Reading Comprehension》<a class="heading-anchor" href="#《Relation-Module-for-Non-Answerable-Predictions-on-Reading-Comprehension》" aria-hidden="true"></a></h3><blockquote>
<p>ACL 2019 paper, <a href="https://www.aclweb.org/anthology/K19-1070/">论文地址</a></p>
</blockquote>
<h4 id="摘要" class="heading-control"><a href="#摘要" class="headerlink" title="摘要"></a>摘要<a class="heading-anchor" href="#摘要" aria-hidden="true"></a></h4><p>由于具有挑战性的阅读理解数据集的增加，机器阅读理解（MRC）近来引起了大量研究关注。在本文中，我们旨在提高 MRC 模型确定问题在给定上下文中是否具有答案的能力（例如，最近提出的 SQuAD 2.0 任务）。关系模块包括语义提取和关系信息。我们首先使用多头自我关注池从问题和上下文中提取高级语义作为对象。然后将这些语义对象传递到关系网络，该关系网络为句子中每个对象对生成关系得分。这些分数用于确定问题是否无法回答。我们使用 BiDAF 和 BERT 模型作为基线读取器，在 SQuAD 2.0 数据集上测试关系模块。在 BiDAF 阅读器上，我们获得 F1 精度的 1.8％增益，在 BERT 基本模型上，获得 1.0％的 F1 精度。这些结果表明我们的关系模块在 MRC 上的有效性。</p>
<h3 id class="heading-control"><a href="#" class="headerlink" title=" "></a> <a class="heading-anchor" href="#" aria-hidden="true"></a></h3></body></html>]]></content>
      <tags>
        <tag>论文</tag>
      </tags>
  </entry>
  <entry>
    <title>Mathpix:Image to Latex</title>
    <url>/post/31913.html</url>
    <content><![CDATA[<html><head><link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script></head><body><p><img src="https://i.loli.net/2018/10/31/5bd9905467947.png" alt><br>使用 Mathpix，你可以截取数学方程式的截图，它会立即为你提供 LaTeX 代码。然后，你可以在 LaTeX 编辑器中使用代码写公式啦。<br><a id="more"></a></p>
<h2 id="Mac和Win安装方法" class="heading-control"><a href="#Mac和Win安装方法" class="headerlink" title="Mac和Win安装方法"></a>Mac 和 Win 安装方法<a class="heading-anchor" href="#Mac和Win安装方法" aria-hidden="true"></a></h2><p><a href="https://mathpix.com/">官网在这里</a>，可以直接下载安装。</p>
<h2 id="Linux安装" class="heading-control"><a href="#Linux安装" class="headerlink" title="Linux安装"></a>Linux 安装<a class="heading-anchor" href="#Linux安装" aria-hidden="true"></a></h2><ol>
<li>需要先安装 snapd<br><a href="https://docs.snapcraft.io/installing-snapd/6735">安装方法</a> , 我的是深度系统，所以是：<figure class="highlight shell"><table><tbody><tr><td class="code"><pre><span class="line">sudo apt install snapd</span><br></pre></td></tr></tbody></table></figure></li>
<li>安装软件 <figure class="highlight shell"><table><tbody><tr><td class="code"><pre><span class="line">sudo snap install mathpix-snipping-tool</span><br></pre></td></tr></tbody></table></figure></li>
<li><p>快捷方式<br>这个比较麻烦，我找了一下我的是在这个目录里面 <code>/snap/mathpix-snipping-tool/23/usr/bin</code>，有一个 <code>mathpix-snipping-tool</code>，右键发送到桌面即可。</p>
</li>
<li><p>截屏快捷键<br><code>Ctrl+Alt+M</code></p>
</li>
</ol>
</body></html>]]></content>
      <categories>
        <category>工具</category>
      </categories>
      <tags>
        <tag>Latex</tag>
      </tags>
  </entry>
  <entry>
    <title>NLP 常用模型和数据集高速下载</title>
    <url>/post/28052.html</url>
    <content><![CDATA[<html><head><link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script></head><body><h2 id="楔子" class="heading-control"><a href="#楔子" class="headerlink" title="楔子"></a>楔子<a class="heading-anchor" href="#楔子" aria-hidden="true"></a></h2><p>由于大部分 NLP 的模型和数据集都在国外，导致国内下载速度实在感人😭。好在有很多 NLP 的框架内置了很多数据集，都是国内链接，亲测下载速度很快，本文汇总一下一些我见到的国内链接，文末感谢这些平台提供的存储和下载服务。<br><a id="more"></a></p>
<h2 id="正文" class="heading-control"><a href="#正文" class="headerlink" title="正文"></a>正文<a class="heading-anchor" href="#正文" aria-hidden="true"></a></h2><h3 id="模型" class="heading-control"><a href="#模型" class="headerlink" title="模型"></a>模型<a class="heading-anchor" href="#模型" aria-hidden="true"></a></h3><div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">模型</th>
<th style="text-align:center">文件名称</th>
<th style="text-align:center">下载链接</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center"><code>bert-base-cased</code></td>
<td style="text-align:center"><a href="http://212.129.155.247/embedding/bert-base-cased.zip">下载</a></td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center"><code>bert-base-chinese</code></td>
<td style="text-align:center"><a href="http://212.129.155.247/embedding/bert-base-chinese.zip">下载</a></td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center"><code>bert-base-uncased</code></td>
<td style="text-align:center"><a href="http://212.129.155.247/embedding/bert-base-uncased.zip">下载</a></td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center"><code>bert-chinese-wwm-ext</code></td>
<td style="text-align:center"><a href="http://212.129.155.247/embedding/bert-chinese-wwm-ext.zip">下载</a></td>
</tr>
<tr>
<td style="text-align:center"> BERT</td>
<td style="text-align:center"><code>bert-chinese-wwm</code></td>
<td style="text-align:center"><a href="http://212.129.155.247/embedding/bert-chinese-wwm.zip">下载</a></td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center"><code>bert-large-cased-wwm</code></td>
<td style="text-align:center"><a href="http://212.129.155.247/embedding/bert-large-cased-wwm.zip">下载</a></td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center"><code>bert-large-cased</code></td>
<td style="text-align:center"><a href="http://212.129.155.247/embedding/bert-large-cased.zip">下载</a></td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center"><code>bert-large-uncased-wwm</code></td>
<td style="text-align:center"><a href="http://212.129.155.247/embedding/bert-large-uncased-wwm.zip">下载</a></td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center"><code>bert-large-uncased</code></td>
<td style="text-align:center"><a href="http://212.129.155.247/embedding/bert-large-uncased.zip">下载</a></td>
</tr>
</tbody>
</table>
</div>
<h3 id="数据集" class="heading-control"><a href="#数据集" class="headerlink" title="数据集"></a>数据集<a class="heading-anchor" href="#数据集" aria-hidden="true"></a></h3><div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">数据集</th>
<th style="text-align:center">文件名称</th>
<th style="text-align:center">下载链接</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">中文情感分析</td>
<td style="text-align:center"><code>ChnSentiCorp</code></td>
<td style="text-align:center"><a href="https://bj.bcebos.com/paddlehub-dataset/chnsenticorp.tar.gz">下载</a></td>
</tr>
<tr>
<td style="text-align:center">语义相似度</td>
<td style="text-align:center"><code>LCQMC</code></td>
<td style="text-align:center"><a href="https://bj.bcebos.com/paddlehub-dataset/lcqmc.tar.gz">下载</a></td>
</tr>
<tr>
<td style="text-align:center">问答匹配</td>
<td style="text-align:center"><code>NLPCC_DPQA</code></td>
<td style="text-align:center"><a href="https://bj.bcebos.com/paddlehub-dataset/nlpcc-dbqa.tar.gz">下载</a></td>
</tr>
<tr>
<td style="text-align:center">中文命名实体识别</td>
<td style="text-align:center"><code>MSRA_NER</code></td>
<td style="text-align:center"><a href="https://bj.bcebos.com/paddlehub-dataset/msra_ner.tar.gz">下载</a></td>
</tr>
<tr>
<td style="text-align:center">英文多标签分类数据集</td>
<td style="text-align:center"><code>Toxic</code></td>
<td style="text-align:center"><a href="https://bj.bcebos.com/paddlehub-dataset/toxic.tar.gz">下载</a></td>
</tr>
<tr>
<td style="text-align:center">抽取式英文阅读理解</td>
<td style="text-align:center"><code>SQUAD</code></td>
<td style="text-align:center"><a href="https://bj.bcebos.com/paddlehub-dataset/squad.tar.gz">下载</a></td>
</tr>
<tr>
<td style="text-align:center">抽取式中文阅读理解</td>
<td style="text-align:center"><code>CMRC2018</code></td>
<td style="text-align:center"><a href="https://bj.bcebos.com/paddlehub-dataset/cmrc2018.tar.gz">下载</a></td>
</tr>
<tr>
<td style="text-align:center">抽取式繁体阅读理解</td>
<td style="text-align:center"><code>DRCD</code></td>
<td style="text-align:center"><a href="https://bj.bcebos.com/paddlehub-dataset/drcd.tar.gz">下载</a></td>
</tr>
<tr>
<td style="text-align:center">英文数据集集合</td>
<td style="text-align:center"><code>GLUE</code></td>
<td style="text-align:center"><a href="https://bj.bcebos.com/paddlehub-dataset/glue_data.tar.gz">下载</a></td>
</tr>
<tr>
<td style="text-align:center">跨语言自然语言推理</td>
<td style="text-align:center"><code>XNLI</code></td>
<td style="text-align:center"><a href=""https://bj.bcebos.com/paddlehub-dataset/XNLI-lan.tar.gz">下载</a></td>
</tr>
<tr>
<td style="text-align:center">今日头条中文新闻短文本分类</td>
<td style="text-align:center"><code>TNews</code></td>
<td style="text-align:center"><a href="https://bj.bcebos.com/paddlehub-dataset/tnews.tar.gz">下载</a></td>
</tr>
<tr>
<td style="text-align:center">互联网情感分析</td>
<td style="text-align:center"><code>INews</code></td>
<td style="text-align:center"><a href="https://bj.bcebos.com/paddlehub-dataset/inews.tar.gz">下载</a></td>
</tr>
<tr>
<td style="text-align:center">智能客服中文问句匹配</td>
<td style="text-align:center"><code>BQ</code></td>
<td style="text-align:center"><a href="https://bj.bcebos.com/paddlehub-dataset/bq.tar.gz">下载</a></td>
</tr>
<tr>
<td style="text-align:center">中文长文本分类</td>
<td style="text-align:center"><code>IFLYTEK</code></td>
<td style="text-align:center"><a href="https://bj.bcebos.com/paddlehub-dataset/iflytek.tar.gz">下载</a></td>
</tr>
<tr>
<td style="text-align:center">中文长文本分类</td>
<td style="text-align:center"><code>THUCNEWS</code></td>
<td style="text-align:center"><a href="https://bj.bcebos.com/paddlehub-dataset/thucnews.tar.gz">下载</a></td>
</tr>
</tbody>
</table>
</div>
<h3 id="词向量" class="heading-control"><a href="#词向量" class="headerlink" title="词向量"></a>词向量<a class="heading-anchor" href="#词向量" aria-hidden="true"></a></h3><div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">词向量</th>
<th style="text-align:center">文件名称</th>
<th style="text-align:center">下载链接</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center"><code>glove.6B.50d</code></td>
<td style="text-align:center"><a href="http://212.129.155.247/embedding/glove.6B.50d.zip">下载</a></td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center"><code>glove.6B.100d</code></td>
<td style="text-align:center"><a href="http://212.129.155.247/embedding/glove.6B.100d.zip">下载</a></td>
</tr>
<tr>
<td style="text-align:center"> GloVe</td>
<td style="text-align:center"><code>glove.6B.200d</code></td>
<td style="text-align:center"><a href="http://212.129.155.247/embedding/glove.6B.200d.zip">下载</a></td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center"><code>glove.6B.300d</code></td>
<td style="text-align:center"><a href="http://212.129.155.247/embedding/glove.6B.300d.zip">下载</a></td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center"><code>glove.42B.300d</code></td>
<td style="text-align:center"><a href="http://212.129.155.247/embedding/glove.42B.300d.zip">下载</a></td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center"><code>glove.840B.300d</code></td>
<td style="text-align:center"><a href="http://212.129.155.247/embedding/glove.840B.300d.zip">下载</a></td>
</tr>
</tbody>
</table>
</div>
<h2 id="数据集下载代码" class="heading-control"><a href="#数据集下载代码" class="headerlink" title="数据集下载代码"></a>数据集下载代码<a class="heading-anchor" href="#数据集下载代码" aria-hidden="true"></a></h2><p>有些时候想在代码里面直接下载数据集，这里给一份参考的代码：</p>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="comment"># 下载文件包并解压，解压文件夹在当前文件夹的datasets目录下</span></span><br><span class="line"><span class="comment"># 注意：datasets目录不需要新建，重复执行代码会自动检查文件是否存在，不会重复下载</span></span><br><span class="line">file = tf.keras.utils.get_file(</span><br><span class="line">        fname=<span class="string">"cmrc2018.tar.gz"</span>,</span><br><span class="line">        origin=<span class="string">"https://bj.bcebos.com/paddlehub-dataset/cmrc2018.tar.gz"</span>,</span><br><span class="line">        extract=<span class="literal">True</span>,</span><br><span class="line">        cache_dir=<span class="string">'.'</span>,</span><br><span class="line">    )</span><br><span class="line"><span class="comment"># 文件路径</span></span><br><span class="line">train_path = os.path.join(<span class="string">"."</span>, <span class="string">'datasets/cmrc2018/cmrc2018_train.json'</span>)</span><br><span class="line">eval_path = os.path.join(<span class="string">"."</span>, <span class="string">'datasets/cmrc2018/cmrc2018_dev.json'</span>)</span><br></pre></td></tr></tbody></table></figure>
<h2 id="感谢" class="heading-control"><a href="#感谢" class="headerlink" title="感谢"></a>感谢<a class="heading-anchor" href="#感谢" aria-hidden="true"></a></h2><ul>
<li>fastnlp 提供的模型和词向量，<a href="https://docs.qq.com/sheet/DVnpkTnF6VW9UeXdh?tab=BB08J2&c=D22A0I0">more</a> 😘</li>
<li>paddlehub 提供的数据集，<a href="https://github.com/PaddlePaddle/PaddleHub/wiki/PaddleHub-API:-Dataset">more</a>😘</li>
</ul>
<h2 id="Tips" class="heading-control"><a href="#Tips" class="headerlink" title="Tips"></a>Tips<a class="heading-anchor" href="#Tips" aria-hidden="true"></a></h2><p>如果还有其他的国外文件需要下载，国内下载很慢，可以尝试使用 kaggle 的 notebook 先下载到 kaggle，然后再下载到本地，亲测有效😄。</p>
</body></html>]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>数据集</tag>
      </tags>
  </entry>
  <entry>
    <title>NLP 面试</title>
    <url>/post/62924.html</url>
    <content><![CDATA[<html><head><link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script></head><body><p><img src="https://i.loli.net/2020/09/02/jY67e5ovS8ApkD2.jpg" alt="v2-4ce31ce804e18089a463534fb58657de_r.jpg"><br><a id="more"></a></p>
<h2 id="深度学习和NLP" class="heading-control"><a href="#深度学习和NLP" class="headerlink" title="深度学习和NLP"></a>深度学习和 NLP<a class="heading-anchor" href="#深度学习和NLP" aria-hidden="true"></a></h2><h3 id="过拟合欠拟合，偏差方差，正则化，-交叉验证" class="heading-control"><a href="#过拟合欠拟合，偏差方差，正则化，-交叉验证" class="headerlink" title="过拟合欠拟合，偏差方差，正则化， 交叉验证"></a>过拟合欠拟合，偏差方差，正则化， 交叉验证<a class="heading-anchor" href="#过拟合欠拟合，偏差方差，正则化，-交叉验证" aria-hidden="true"></a></h3><ol>
<li><p><strong>怎么判断过拟合， 过拟合如何处理</strong><br> 定义：过拟合（overfitting）是指在模型训练中由于训练数据包含抽样误差，对抽样误差也进行了很好的拟合。<br> 表现：模型在训练集上效果好，在测试集上效果差（相差 20% 以上），模型泛化能力弱。<br> 原因：（1）观察值与真实值存在偏差。（2）训练数据不足，数据太少，导致无法描述问题的真实分布。（3）训练模型过度，导致模型非常复杂。<br> 处理方法：（1）数据层面上，增加数据或者数据增广 （2）模型层面，主要是降低模型的复杂度：减少数据特征，L1，L2，Droupout，BN，集成学习，早期停止策略 ，使用简单的模型</p>
</li>
<li><p><strong>怎么判断欠拟合， 欠拟合如何处理</strong><br> 定义：欠拟合（underfitting）是指模型无法得到较低的训练误差。<br> 表现：训练的模型在训练集上面的表现很差，在验证集上面的表现也很差。<br> 原因：模型发生欠拟合的最本质原因是训练的模型太简单，最通用的特征模型都没有学习到<br> 处理方法：（1）添加新的特征 （2）减少正则化参数 （3）使用更深或者更宽的模型 （4）使用集成方法</p>
</li>
</ol>
<p><img src="https://s2.ax1x.com/2020/03/07/3jc2VJ.png" alt="3jc2VJ.png"></p>
<ol>
<li><p><strong>偏差和方差的定义，为什么要在两者之间进行权衡</strong><br> 偏差（Bias）表示模型输出与真实值之间的误差，刻画模型的准确度，方差（Variance）表示模型在训练集和验证集之间的误差，刻画模型的稳定性。<br> 在一个实际系统中，Bias 与 Variance 往往是不能兼得的。如果要降低模型的 Bias，就一定程度上会提高模型的 Variance，反之亦然。造成这种现象的根本原因是，我们总是希望试图用有限训练样本去估计无限的真实数据。当我们更加相信这些数据的真实性，而忽视对模型的先验知识，就会尽量保证模型在训练样本上的准确度，这样可以减少模型的 Bias。但是，这样学习到的模型，很可能会失去一定的泛化能力，从而造成过拟合，降低模型在真实数据上的表现，增加模型的不确定性。相反，如果更加相信我们对于模型的先验知识，在学习模型的过程中对模型增加更多的限制，就可以降低模型的 variance，提高模型的稳定性，但也会使模型的 Bias 增大。因此通常需要在两者之间权衡。</p>
</li>
<li><p>L1 和 L2 正则化的区别，为什么 L1 可以获得稀疏解，L2 解接近于 0？<br> L1 正则化就是在 loss function 后边所加正则项为 L1 范数，加上 L1 范数容易得到稀疏解（0 比较多）。L2 正则化就是 loss function 后边所加正则项为 L2 范数的平方，加上 L2 正则相比于 L1 正则来说，得到的解比较平滑（不是稀疏），但是同样能够保证解中接近于 0（但不是等于 0，所以相对平滑）的维度比较多，降低模型的复杂度。</p>
</li>
<li><p>word2vec 如何实现，实现方法有什么区别</p>
</li>
<li>基于业务的问答系统如何设计</li>
<li>如何训练基于知识图谱的问答系统</li>
<li>在训练 KBQA 时会用到例如 freebase 这样的开源知识图谱，他们过大的体积在训练中要如何进行优化</li>
<li>基于匹配的问答系统的关键技术是什么（文本相似度匹配）</li>
<li>文本相似度匹配有哪些实现方法（转特征求距离，或者使用自然语言推理的模型）</li>
<li>开放式的对话系统如何训练</li>
<li> transformer 和 RNN 的区别</li>
<li>推荐系统了解吗，有那两部分（召回和排序）</li>
<li>怎么抓取热门</li>
<li>召回有哪些（微博召回怎么做），排序算法了解吗</li>
<li>小样本数据集怎么做</li>
<li>样本不均衡怎么搞（重点考核损失函数优化）</li>
<li>AUC 的具体含义</li>
<li>介绍推荐系统的召回和排序系统，召回系统的输出是什么</li>
<li> RF 和 GBDT 介绍、RF 的属性采样时有放回还是不放回</li>
<li>手写 LSTM 的公式（手画 LSTM 图）</li>
<li>lightgbm 对缺失值的处理方法</li>
<li> kmeans 的 K 值确定方法</li>
<li> FM（factorization machine）模型的公式写一下，模型解决了什么问题</li>
<li> DIN（deep interest network）主要使用了什么机制，解释一下，画一下 DIN 的框图</li>
<li> DIN 的 activation unit 的作用</li>
<li>一个模型的 bais 和 variance 的具体定义是什么，bais 和 variance 哪个比较重要，为什么是 trade-off<br>任何机器学习算法的预测误差可以分解为三部分，即：偏差 + 方差 + 不可约的误差（对于给定的模型，我们不能进一步减少的误差）。</li>
<li>泛化误差解释（bais^2+variance+noise）</li>
<li>dropout 的工作机制，dropout 在训练过程如何使用</li>
<li>聚类算法了解程度、kmeans 介绍、K 值选择、kmeans++ 算法)</li>
<li> 推荐系统还有融合框架，假如通过两种不同的召回和 ranking 系统得到结果，如何在两种备选结果中最终给用户推荐出最适合的十个广告</li>
<li> XGBOOST ，LGB，GBDT 的区别</li>
<li>一阶优化器，二阶优化器</li>
<li> Attention 怎么做，self-attention 怎么做</li>
<li> Transformer 细节，Bert 细节（多头和缩放）</li>
<li>标签平滑怎么做的</li>
<li>交叉熵，相对熵</li>
<li> Bagging, boosting , 偏差，方差关系<br>二者都是集成学习算法，都是将多个弱学习器组合成强学习器的方法。<br>Bagging：从原始数据集中每一轮有放回地抽取训练集，训练得到 k 个弱学习器，将这 k 个弱学习器以投票的方式得到最终的分类结果。<br>Boosting：每一轮根据上一轮的分类结果动态调整每个样本在分类器中的权重，训练得到 k 个弱分类器，他们都有各自的权重，通过加权组合的方式得到最终的分类结果。</li>
<li>CRF 理论与代码实现细节，CRF 与 HMM 关系，区别</li>
<li>维特比，beam-search 时间复杂度，区别</li>
<li> XGBOOST ，LGB 生长策略，分类策略</li>
<li>少样本情况怎么缓解</li>
<li><p>实际场景做 softmax 很容易出现下溢问题，怎么解决<br>可以用每个维度减去一个固定值</p>
</li>
<li><p>正则项为什么能减缓过拟合</p>
</li>
<li>过拟合解决方法，正则项为什么能减缓过拟合，权重衰减等价于哪个正则项</li>
<li>随机森林的随机体现在哪里</li>
<li> tm 和 rnn 的区别</li>
<li> LR 和 svm 的区别是什么</li>
<li> lstm 的优点，记忆单元是怎么工作的，他为什么可以克服梯度消失</li>
<li> bp 的原理</li>
<li> bn 的原理</li>
<li>解释一下 AUC 的计算方法和它代表的意义。问了一个相关的问题，当时没有答的很好，就是一个数据如果分成两份，分别在两份数据上计算出 AUC 为 AUC_1 和 AUC_2，问整体数据的 AUC 是多少？面试的时候一直以为这个是能算出来的，所以一直在推导公式。最后的答案其实是无法得到，因为从局部的有序无法直接退出全局的有序，这个题目其实还是考查对于 AUC 这个指标的理解深度。</li>
<li>word2vec 的两种优化方法，说下分层 softmax 是怎么做的。word2vec 的优点和缺点，是如何解决 oov 的问题的，实际上 word2vec 如何使用</li>
<li> lucene 搜索</li>
<li>关键字搜索如何实现</li>
<li>单元测试。</li>
<li>深度优先和广度优先的本质区别。</li>
<li>从搜谷歌到返回页面，发生了什么。</li>
<li>batchsize 大或小有什么问题，LR 怎么设置</li>
</ol>
<h2 id="计算机网络" class="heading-control"><a href="#计算机网络" class="headerlink" title="计算机网络"></a>计算机网络<a class="heading-anchor" href="#计算机网络" aria-hidden="true"></a></h2><ol>
<li>TCP 和 UDP 的区别<br> 1、TCP 面向连接（如打电话要先拨号建立连接）;UDP 是无连接的，即发送数据之前不需要建立连接<br> 2、TCP 提供可靠的服务。也就是说，通过 TCP 连接传送的数据，无差错，不丢失，不重复，且按序到达；UDP 尽最大努力交付，即不保证可靠交付<br> 3、TCP 面向字节流，实际上是 TCP 把数据看成一连串无结构的字节流；UDP 是面向报文的 UDP 没有拥塞控制，因此网络出现拥塞不会使源主机的发送速率降低（对实时应用很有用，如 IP 电话，实时视频会议等<br> 4、每一条 TCP 连接只能是点到点的；UDP 支持一对一，一对多，多对一和多对多的交互通信<br> 5、TCP 首部开销 20 字节；UDP 的首部开销小，只有 8 个字节<br> 6、TCP 的逻辑通信信道是全双工的可靠信道，UDP 则是不可靠信道</li>
<li>线程和进程的区别，如何实现多线程；</li>
<li>L1 范数能否去除冗余特征</li>
<li>没坐标怎么做 kmeans</li>
<li> 决策树的特征和神经网络特征有什么差异</li>
<li>句子向量有哪些生成方式</li>
<li>词袋模型有哪些不足的地方<br>稀疏，无序，纬度爆炸，每个词都是正交的，相当于每个词都没有关系。</li>
<li>albert 相对于 bert 的改进</li>
<li>稀疏词向量 用 skip-gram 还是 cbow 训练好</li>
<li> word2vec  两种训练方式哪种更好？对生僻词谁更好？</li>
<li>在工程中什么样的结果会表明是 over fitting/under fitting</li>
<li> 对于 CNN 卷积层、和池化层的物理意义是什么，对于池化的 max 方法和 mean 方法 分别适合针对什么情况下应用？<br>当 feature map 中的信息都具有一定贡献的时候使用 AvgPooling，比如网络走到比较深的地方，这个时候特征图的 H W 都比较小，包含的语义信息较多，这个时候再使用 MaxPooling 就不太合适了。反之为了减少无用信息的影响时用 maxpool，比如网络浅层常常见到 maxpool，因为开始几层对图像而言包含较多的无关信息。二者的具体使用场景只有在具体任务上观察，实际效果炼丹后才知道。</li>
<li>L2 正则化的 penalize term 和先验有关系嘛？如有是什么样的关系</li>
<li>树模型怎么剪枝？如何处理缺失值？</li>
<li>讲讲 Glove 的原理，它和 Word2vec 有什么区别？Fasttext 说一下</li>
<li>画一下 ELMo 的模型图，讲一下 ELMo 的原理，为什么它能解决词歧义的问题？</li>
<li>画 Bert 的模型图，讲原理，预训练的过程。Bert 输入是由哪些组成的？Bert 相比于 ELMo 有什么优点？它是怎么用作下游任务的？</li>
<li>Attention 机制的原理，常用的 Attention 计算相似度方式有哪些，写一下公式。</li>
<li>有分布式训练神经网络的经验吗？多卡跑模型的命令是什么</li>
<li>简述一种中文分词算法。</li>
<li>讲一下 Hessian 矩阵？ Hessian 矩阵是对称矩阵吗？</li>
<li>SVM 的优化函数讲一下？</li>
<li>聚类算法了解吗？DBSCAN 讲一下</li>
</ol>
<h2 id="机器学习" class="heading-control"><a href="#机器学习" class="headerlink" title="机器学习"></a>机器学习<a class="heading-anchor" href="#机器学习" aria-hidden="true"></a></h2><ol>
<li>Xgboost 的原理介绍以及如何并行化实现</li>
<li>生成模型和判别模型（SVM、LR 属于哪种）</li>
</ol>
<h2 id="Python" class="heading-control"><a href="#Python" class="headerlink" title="Python"></a>Python<a class="heading-anchor" href="#Python" aria-hidden="true"></a></h2><ol>
<li>Python 的装饰器，迭代器和生成器<br> 装饰器的功能：在不修改原函数及其调用方式的情况下对原函数功能进行扩展<br> 装饰器的本质：就是一个闭包函数<br> 迭代器就是用于迭代操作的的对象，遵从迭代协议（内部实现了 <strong>iter</strong>() 和 <strong>next</strong>() 方法，可以像列表（可迭代对象，只有 <strong>iter</strong>() 方法）一样迭代获取其中的值，与列表不同的是，构建迭代器的时候，不像列表一样一次性把数据加到内存，而是以一种延迟计算的方式返回元素，即调用 next 方法时候返回此值。<br> 生成器本质上也是一个迭代器，自己实现了可迭代协议，与迭代器器不同的是生成器的实现方式不同，可以通过生成器表达式和生成器函数两种方式实现，代码更简洁。生成器和迭代器都是惰性可迭代对象，只能遍历一次，数据取完抛出 Stopiteration 异常 <figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="comment">#生成器函数（带yield语句）</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">gen</span>():</span></span><br><span class="line">    <span class="keyword">yield</span> <span class="number">3</span></span><br><span class="line"><span class="comment">#生成器表达式（类似列表推导式）</span></span><br><span class="line">gen=(x <span class="keyword">for</span> x <span class="keyword">in</span> range(<span class="number">1</span>,<span class="number">5</span>))</span><br></pre></td></tr></tbody></table></figure></li>
<li>Python 中的 Lambda 函数</li>
<li> Python 回调</li>
<li> python 中函数 self 的区别，读取一个 txt 文件中 2.5 是什么数据类型，2.5+2.5 等于多少</li>
<li>深拷贝和浅拷贝的区别</li>
<li>线程进程的区别，python 内部实现的多线程有什么问题</li>
<li> Python2 和 Python3 map 的差别<br> Python3 map 函数返回一个迭代器，Python2 中返回一个列表。</li>
<li>Python 可变数据类型和不可变数据类型分别有哪些？<br> 可变数据类型：列表 list 和字典 dict。<br> 不可变数据类型：整型 int、浮点型 float、字符串型 string 和元组 tuple。</li>
<li>Python 是如何进行内存管理的<br>Python 采用的是基于值的内存管理方式，如果为不同变量赋值相同值，则在内存中只有一份该值，多个变量指向同一块内存地址</li>
</ol>
<h2 id="Linux基础" class="heading-control"><a href="#Linux基础" class="headerlink" title="Linux基础"></a>Linux 基础<a class="heading-anchor" href="#Linux基础" aria-hidden="true"></a></h2><ol>
<li>AWK</li>
<li>nohup  </li>
</ol>
<h2 id="代码" class="heading-control"><a href="#代码" class="headerlink" title="代码"></a>代码<a class="heading-anchor" href="#代码" aria-hidden="true"></a></h2><ol>
<li>最长回文子串</li>
<li>给你 10 亿数据，不重复，求前 k 大。（n 为 10 亿，k 为 2 亿）</li>
<li>给你 1000 个数组，求最长的等差数列</li>
<li> TopK（快排和小顶堆分别实现，分析时间和空间复杂度）</li>
<li>分析插入和快排的时间和空间复杂度，稳定，不稳定？稳定排序和不稳定排序算法的定义？手写快排</li>
<li> LR 的随机梯度实现</li>
<li>数组的最大和，数组的最大乘积</li>
<li>数组排成最大的数字</li>
<li>数据中出现空值处理的方法</li>
<li>给定一个矩阵，在矩阵中选取一行，求取某一行某个数附近的 5 个数的值，需要用哪种数据结构（KD 树）</li>
<li>二叉树的最短路径</li>
<li>给定 10G 的文件，只有 2G 的内存，如何将文件放到内存中</li>
<li>编辑距离</li>
<li>完全二叉树的节点个数</li>
<li>二叉树的前序遍历的递归和非递归、时间复杂度</li>
<li> 15 分钟 写一个 k-means，没写完时间不够</li>
<li>打家劫舍 II</li>
<li> 反转链表</li>
<li>用神经网络搭建一个 LR</li>
<li> 如果有很大的文件，怎么统计文件里面出现的各个单词的数量</li>
<li>用两个栈实现一个队列</li>
<li> o (n) 实现三色排序</li>
<li>有一个城市名称列表，如何判断语句中是否出现了列表中的城市 (KMP)</li>
<li> 手写 tfidf</li>
<li> 二叉树层次遍历</li>
<li>大数加法 大数相乘</li>
<li>二叉树之子型遍历，每行打印</li>
<li>数组，可以分别从最左边最右边取个数字，求取得 k 个数的最大值，O（1）空间呢，k 的取值范围的条件</li>
<li> k 个的列表反转</li>
<li>对称二叉树</li>
<li>连续数组，给定 k，求连续数组最小区间。动态规划要优化时间，贪心法需要证明。</li>
<li>圆上三点组成锐角三角形概率</li>
<li> cnn 的卷积计算，参数计算。</li>
<li>倒水问题</li>
<li>最长公共子序列</li>
<li>最大上升子序列</li>
<li>旋转数组找 K 值</li>
<li>蓄水池抽样算法（Reservoir Sampling）</li>
<li>跳台阶 + 有一次后退机会</li>
<li>排序二叉树 插入新数字</li>
<li>归并排序中的归并</li>
<li>给定一个 int 数组，求数组中能组成三角形的个数。</li>
<li>数组中索引 K 前面是有序的，K 之后也是有序的，调整使得整个数组有序，要求空间复杂度 O (1)</li>
<li> 有 1,2,5,10,20,50 的纸币，求凑到 100 元一共有多少种方法</li>
<li>合并两个有序链表，合并 K 个有序链表</li>
<li>顺时针打印矩阵</li>
</ol>
<h2 id="智力题" class="heading-control"><a href="#智力题" class="headerlink" title="智力题"></a>智力题<a class="heading-anchor" href="#智力题" aria-hidden="true"></a></h2><ol>
<li>2 个蜡烛 1 个小时，如何记录 15 分钟</li>
<li>只有 01 生成器，如何生成 0-3 等概率，如何生成 0-k 等概率（模拟二进制）</li>
<li>ABCD 乘以 9 等于 DCBA，那么 ABCD 各等于几？</li>
</ol>
<p>反转链表</p>
</body></html>]]></content>
      <categories>
        <category>面试</category>
      </categories>
      <tags>
        <tag>面试</tag>
      </tags>
  </entry>
  <entry>
    <title>NLP 面试比较重要的知识点</title>
    <url>/post/21849.html</url>
    <content><![CDATA[<html><head><link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script></head><body><p><img src="https://s2.ax1x.com/2019/07/22/ei2rqS.png" alt="ei2rqS.png"><br><a id="more"></a></p>
<h2 id="基础" class="heading-control"><a href="#基础" class="headerlink" title="基础"></a>基础<a class="heading-anchor" href="#基础" aria-hidden="true"></a></h2><p>Python 内存管理的方式  <a href="http://kkpattern.github.io/2015/06/20/python-memory-optimization-zh.html">参考答案</a></p>
<h2 id="机器学习" class="heading-control"><a href="#机器学习" class="headerlink" title="机器学习"></a>机器学习<a class="heading-anchor" href="#机器学习" aria-hidden="true"></a></h2><ol>
<li>逻辑回归完整推导过程</li>
<li>逻辑回归属于线性分类器还是非线性分类器？(同属于广义线性模型)</li>
<li> 朴素贝叶斯为什么朴素？（假设特征之间相互独立）</li>
<li>介绍一下 SVM 核函数</li>
<li> MLP 和 MAP 的区别（MAP 加入了先验信息）</li>
<li>svm 如何处理多分类（一对多法设计 k 个分类器，一对一法设计 k (k-1)/2 个分类器）</li>
<li>svm 对缺失数据敏感吗，为什么，决策树呢。（svm 没有处理缺失数据的方法，决策树有）</li>
<li>为什么 svm 采用最大间隔（最大间隔得到决策边界是唯一的，具有鲁棒性）</li>
<li>聚类了解哪些？基于密度的聚类了解哪些？（<strong>原型聚类</strong>：KMeans, 高斯混合聚类，<strong>密度聚类</strong>：DBSCAN、Mean-Shift，<strong>层次聚类</strong>：AGNES、BIRCH，<strong>谱聚类</strong>）</li>
</ol>
<h2 id="深度学习基础" class="heading-control"><a href="#深度学习基础" class="headerlink" title="深度学习基础"></a>深度学习基础<a class="heading-anchor" href="#深度学习基础" aria-hidden="true"></a></h2><ol>
<li>L1、L2 正则（贝叶斯角度分析，加入了先验信息）</li>
<li>怎样判断过拟合？过拟合怎么解决？（1. <strong>交叉验证</strong>的结果比单次的结果下，2. 通过<strong>学习曲线</strong> Learning Curves 判断，3. 实际的话也可以通过<strong>观察</strong>训练误差很小，而预测误差很大的模型通常过拟合）</li>
<li>梯度消失和梯度爆炸的原因，为什么 rnn 比 cnn 和全连接层神经网络更容易发生梯度消失或爆炸（RNN 在梯度的反向传播中只有连乘，LSTM 和 GRU 加入了门机制，梯度的计算中同时还有 $h_t$ 的加法）</li>
<li>说一下 dropout 的训练和测试过程（在训练过程中以一定的概率 p 的使神经元失活，测试过程不需要 dropout，对层的输出乘以 p）</li>
<li>说一下 BN 和 LN，有什么区别，BN 为什么可以提升效果 ()</li>
<li>CNN 的旋转不变性怎么理解 (CNN 具有平移不变性)</li>
</ol>
<h2 id="自然语言处理基础" class="heading-control"><a href="#自然语言处理基础" class="headerlink" title="自然语言处理基础"></a>自然语言处理基础<a class="heading-anchor" href="#自然语言处理基础" aria-hidden="true"></a></h2><p>输入补全可以用哪个数据结构来做？（字典树）<br>假如有 10 亿条搜索请求，怎么找出最热的前 10 条？<br>讲一下 LDA，讲一下隐狄利克雷分布，里面有个辛普森采样了解吗<br>pointwise、pairwise 、listwise 的区别<br>word2vec 是有监督的还是无监督的<br>word2vec 的损失函数形式<br>分层 softmax 和负采样原理<br>Glove 的思想以及和 word2vec 的区别<br>Fasttext 和 word2vec 的区别<br>Fasttext 哈希规则，怎么把语义相近的词哈希到一个桶里<br>RNN、LSTM、GRU 公式。<br>RNN、LSTM、GRU 参数大小<br>Attention 机制的原理，有哪些变种<br>sigmoid 用作激活函数时，分类为什么要用交叉熵损失，而不用均方损失？</p>
<h2 id="文本分类" class="heading-control"><a href="#文本分类" class="headerlink" title="文本分类"></a>文本分类<a class="heading-anchor" href="#文本分类" aria-hidden="true"></a></h2><p>精确率，召回率，F1 值<br><img src="https://i.loli.net/2019/07/22/5d35bda25c13e20464.png" alt><br>AUC 和 ROC<br><img src="https://i.loli.net/2019/07/22/5d35beceefac074363.png" alt></p>
<figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">Precision：P=TP/(TP+FP)</span><br><span class="line">Recall：R=TP/(TP+FN)</span><br><span class="line">F1-score：2/(1/P+1/R)</span><br><span class="line">ROC/AUC：TPR=TP/(TP+FN), FPR=FP/(FP+TN)</span><br></pre></td></tr></tbody></table></figure>
<p>讲一下 Textcnn 的过程<br>Fasttext 怎么做分类的<br>CNN 和 LSTM 都可以用于分类，两者用于分类有什么区别？<br>样本不均衡的处理方法</p>
<h3 id="Sequence-Label" class="heading-control"><a href="#Sequence-Label" class="headerlink" title="Sequence Label"></a>Sequence Label<a class="heading-anchor" href="#Sequence-Label" aria-hidden="true"></a></h3><p>有了 BILSTM 为什么还要用 CRF？<br>BILSTM+CRF 的训练目标？状态转移矩阵是 joint learn 的吗？维度是多少？<br>维特比算法的时间复杂度<br>HMM 和 CRF 的区别<br>CRF、HMM 原理 公式、维特比算法的公式<br>HMM 做了哪些独立性假设<br>CRF 的训练目标是什么？<br>CRF 和深度学习的结合还知道哪些？<br>为什么 Transformer self-attention 可以替代 seq2seq</p>
<h3 id="文本生成" class="heading-control"><a href="#文本生成" class="headerlink" title="文本生成"></a>文本生成<a class="heading-anchor" href="#文本生成" aria-hidden="true"></a></h3><p>生成式问答解决生成句子多样性的方法<br>怎么评价生成效果的好坏<br>讲一下 BLEU</p>
<h3 id="思考题" class="heading-control"><a href="#思考题" class="headerlink" title="思考题"></a>思考题<a class="heading-anchor" href="#思考题" aria-hidden="true"></a></h3><ol>
<li>一个村子里重男轻女，生了女孩就继续生，直到生出男孩为止，试想在 N 年之后该村子的男女比例。答案：1:1</li>
<li> 有 A（红）B（蓝）两瓶墨水，从 A 中取一勺倒到 B 中，混匀后，再从 B 中取等量墨水，倒到 A 中。问，是 A 中蓝墨水多还是 B 中红墨水多？</li>
<li>一枚硬币，正反分布均匀，掷硬币，问至少多少次可以把这枚硬币的正面和反面都掷出来？</li>
<li>一根绳子，允许你剪两刀，试问，剪完之后的绳子能构成三角形的概率是多少</li>
</ol>
<h3 id="算法" class="heading-control"><a href="#算法" class="headerlink" title="算法"></a>算法<a class="heading-anchor" href="#算法" aria-hidden="true"></a></h3><ol>
<li>稳定和非稳定的排序算法有哪些</li>
<li>快速排序的最好，最坏，平均以及空间复杂度</li>
<li>二分查找递归和非递归的时间和空间复杂度</li>
<li>用两个栈实现一个队列操作，实现 push、pop、len 操作</li>
<li>给定字符串 s ，求与 s 编辑距离为 2 的字符串集合。</li>
<li>一个圆被分成 M 个扇形，一共有 N 种颜色，相邻扇形不同色，一共有几种涂法？</li>
<li>有 n 枚硬币，每次从左边或右边拿一枚，一共拿 m 次，求能拿到的最高价值</li>
<li>二叉搜索树转有序双向链表，要求不能创建新的节点</li>
<li>统计一个十进制数字的二进制表示中有多少个一，用位运算写</li>
<li>滑动窗口里的最大数</li>
<li>给定一个乱序不重复数组，找到所有的三个数的集合，每个集合中 a + b + c == 0</li>
<li> 排序数组中绝对值不相等的元素个数，算法复杂度（M+N）</li>
<li>搜索有序二维矩阵，复杂度</li>
<li>层次遍历二叉树</li>
<li>字符串的最长公共子串</li>
<li>写一个函数判断一个字符串是否为回文串</li>
<li>求一个字符串中的最长回文子串<h4 id="归并排序" class="heading-control"><a href="#归并排序" class="headerlink" title="归并排序"></a>归并排序<a class="heading-anchor" href="#归并排序" aria-hidden="true"></a></h4><img src="https://s2.ax1x.com/2019/07/22/eiNXFS.md.png" alt><figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">merge</span>(<span class="params">a, b</span>):</span></span><br><span class="line">    c = []</span><br><span class="line">    h = j = <span class="number">0</span></span><br><span class="line">    <span class="keyword">while</span> j < len(a) <span class="keyword">and</span> h < len(b):</span><br><span class="line">        <span class="keyword">if</span> a[j] < b[h]:</span><br><span class="line">            c.append(a[j])</span><br><span class="line">            j += <span class="number">1</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            c.append(b[h])</span><br><span class="line">            h += <span class="number">1</span></span><br><span class="line">    <span class="keyword">if</span> j == len(a):</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> b[h:]:</span><br><span class="line">            c.append(i)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> a[j:]:</span><br><span class="line">            c.append(i)</span><br><span class="line">    <span class="keyword">return</span> c</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">merge_sort</span>(<span class="params">lists</span>):</span></span><br><span class="line">    <span class="keyword">if</span> len(lists) <= <span class="number">1</span>:</span><br><span class="line">        <span class="keyword">return</span> lists</span><br><span class="line">    middle = len(lists)//<span class="number">2</span></span><br><span class="line">    left = merge_sort(lists[:middle])</span><br><span class="line">    right = merge_sort(lists[middle:])</span><br><span class="line">    <span class="keyword">return</span> merge(left, right)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    a = [<span class="number">14</span>, <span class="number">2</span>, <span class="number">34</span>, <span class="number">43</span>, <span class="number">21</span>, <span class="number">19</span>]</span><br><span class="line">    <span class="keyword">print</span> (merge_sort(a))</span><br></pre></td></tr></tbody></table></figure>
</li>
</ol>
</body></html>]]></content>
      <tags>
        <tag>面试</tag>
      </tags>
  </entry>
  <entry>
    <title>Network In Network</title>
    <url>/post/27176.html</url>
    <content><![CDATA[<html><head><link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script></head><body><p>论文 <a href="https://arxiv.org/abs/1312.4400">Network In Network</a>(Min Lin, ICLR2014).</p>
<h2 id="论文的主要贡献" class="heading-control"><a href="#论文的主要贡献" class="headerlink" title="论文的主要贡献"></a>论文的主要贡献<a class="heading-anchor" href="#论文的主要贡献" aria-hidden="true"></a></h2><ol>
<li>采用 mlpcon 的结构来代替 traditional 卷积层</li>
<li>采用 global average pooling 层代替卷积神经网络最后的全连接层</li>
</ol>
<a id="more"></a>
<h2 id="NIN" class="heading-control"><a href="#NIN" class="headerlink" title="NIN"></a>NIN<a class="heading-anchor" href="#NIN" aria-hidden="true"></a></h2><p>传统 cnn 网络中的卷积层其实就是用线性滤波器对图像进行内积运算，在每个局部输出后面跟着一个非线性的激活函数，最终得到的叫作特征图。而这种卷积滤波器是一种广义线性模型。所以用 CNN 进行特征提取时，其实就隐含地假设了特征是线性可分的，可实际问题往往是难以线性可分的。</p>
<p>什么样的模型抽象水平更高呢。当然是比线性模型更有表达能力的非线性函数近似器了（比如 MLP 多层感知神经网络）。</p>
<p><img src="https://i.loli.net/2019/01/19/5c43055c40b1d.png" alt></p>
<p>MLP 的优点： </p>
<ol>
<li>非常有效的通用函数近似器 </li>
<li>可用 BP 算法训练，可以完美地融合进 CNN </li>
<li>其本身也是一种深度模型，可以特征再利用</li>
</ol>
<h2 id="NIN和1x1卷积的关系" class="heading-control"><a href="#NIN和1x1卷积的关系" class="headerlink" title="NIN和1x1卷积的关系"></a>NIN 和 1x1 卷积的关系<a class="heading-anchor" href="#NIN和1x1卷积的关系" aria-hidden="true"></a></h2><p>因为 NIN 中的 MLP 层可以用两层 1×1 卷积核来代替，比如当前这一层是 54×54×96 的图像层，然后过一个 1×1×96 的卷积核，还是一个 54×54×96 的卷积层，然后再过一个 1×1×96 的卷积核，还是一个 54×54×96 的卷积层。 但是这样但看最开始那个 96 个特征层的图像同一个位置不同层之间的像素点，相当于过了一个 96×96×96 的 MLP 网络 。</p>
<p><img src="https://i.loli.net/2019/01/19/5c4306c0ca21e.png" alt="20160117131304843.png"></p>
<h2 id="1x1卷积" class="heading-control"><a href="#1x1卷积" class="headerlink" title="1x1卷积"></a>1x1 卷积<a class="heading-anchor" href="#1x1卷积" aria-hidden="true"></a></h2><p><img src="https://i.loli.net/2019/01/19/5c4302ace8ca9.png" alt></p>
<p> 如果卷积的输出输入都只是一个平面，那么 1x1 卷积核并没有什么意义，它是完全不考虑像素与周边其他像素关系。 但卷积的输出输入是长方体，所以 1x1 卷积实际上是对每个像素点，在不同的 channels 上进行线性组合（信息整合），且保留了图片的原有平面结构，调控 depth，从而完成升维或降维的功能。</p>
<p>比如 3x3 卷积或者 5x5 卷积在几百个 filter 的卷积层上做卷积操作时相当耗时，所以 1x1 卷积在 3x3 卷积或者 5x5 卷积计算之前先降低维度。比如，一张 500×500 且厚度 depth 为 100 的图片在 20 个 filter 上做 1×1 的卷积，那么结果的大小为 500×500×20。然后再进行 3x3 卷积或者 5x5 卷积就可以了。</p>
<p><strong>总结一下</strong>：</p>
<ol>
<li>相当于输入每个元素对应的所有通道分别进行了全连接运算，输出即为 filters 的数量。</li>
<li>池化层可以压缩高度和宽度，1×1 卷积可以压缩或增加通道数。</li>
<li>加入非线性。卷积层之后经过激励层，1×1 的卷积在前一层的学习表示上添加了非线性激励（ non-linear activation ），提升网络的表达能力</li>
</ol>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center"> 3x3 卷积</th>
<th style="text-align:center"> 1x1 卷积</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center"><img src="https://i.loli.net/2019/01/19/5c43004513776.gif" alt="full_padding_no_strides_transposed.gif"></td>
<td style="text-align:center"><img src="https://i.loli.net/2019/01/19/5c43009b6369c.gif" alt="full_padding_no_strides_transposed_small.gif"></td>
</tr>
</tbody>
</table>
</div>
<h2 id="Global-Average-Pooling" class="heading-control"><a href="#Global-Average-Pooling" class="headerlink" title="Global Average Pooling"></a>Global Average Pooling<a class="heading-anchor" href="#Global-Average-Pooling" aria-hidden="true"></a></h2><p>传统的 cnn 是在较低层使用卷积，如分类任务中，最后的卷积层所得 feature map 被矢量化进行全连接层，然后使用 softmax 回归进行分类。一般来说，在卷积的末端完成的卷积与传统分类器的桥接。全连接阶段易于过拟合，妨碍整个网络的泛化能力，一般应有一些规则方法来处理过拟合。</p>
<p>在传统 CNN 中很难解释最后的全连接层输出的类别信息的误差怎么传递给前边的卷积层。而 global average pooling 更容易解释。另外，全连接层容易过拟合，往往依赖于 dropout 等正则化手段.</p>
<p>global average pooling 的概念非常简单，分类任务有多少个类别，就控制最终产生多少个 feature map. 对每个 feature map 的数值求平均作为某类别的置信度，类似 FC 层输出的特征向量，再经过 softmax 分类。其优点有:</p>
<ol>
<li>参数数量减少，减轻过拟合 (应用于 AlexNet, 模型 230MB->29MB);</li>
<li> 更符合卷积网络的结构，使 feature map 和类别信息直接映射；</li>
<li>求和取平均操作综合了空间信息，使得对输入的空间变换更鲁棒 (与卷积层相连的 FC 按顺序对特征进行了重新编排 (flatten), 可能破坏了特征的位置信息).</li>
<li>FC 层输入的大小须固定，这限制了网络输入的图像大小</li>
</ol>
<p><img src="https://i.loli.net/2019/01/19/5c43064d59f83.png" alt></p>
</body></html>]]></content>
      <categories>
        <category>CNN</category>
      </categories>
      <tags>
        <tag>CNN</tag>
      </tags>
  </entry>
  <entry>
    <title>PaddleHub 使用示例</title>
    <url>/post/945.html</url>
    <content><![CDATA[<html><head><link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script></head><body><p>最近用了一下 PaddleHub，感觉还挺好用的。这里两个使用 PaddleHub 的示例。<br><a id="more"></a></p>
<h2 id="分词" class="heading-control"><a href="#分词" class="headerlink" title="分词"></a>分词<a class="heading-anchor" href="#分词" aria-hidden="true"></a></h2><p>这个分词和官网的分词效果一样，觉得比 jieba 之类的要好。<br></p><figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="comment"># pip install pyahocorasick</span></span><br><span class="line"><span class="comment"># https://www.paddlepaddle.org.cn/hubdetail?name=lac&en_category=LexicalAnalysis</span></span><br><span class="line"><span class="keyword">import</span> paddlehub <span class="keyword">as</span> hub</span><br><span class="line"></span><br><span class="line">temp_user_dict = [</span><br><span class="line">    dict(word=<span class="string">'自然'</span>, tag=<span class="string">'n'</span>, freq=<span class="string">'10000'</span>)</span><br><span class="line">]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">make_dict</span>(<span class="params">user_dicts</span>):</span></span><br><span class="line">    <span class="keyword">with</span> open(<span class="string">'user.dict'</span>, <span class="string">'w'</span>) <span class="keyword">as</span> f:</span><br><span class="line">        <span class="keyword">for</span> user_dict <span class="keyword">in</span> user_dicts:</span><br><span class="line">            f.write(user_dict[<span class="string">'word'</span>] + <span class="string">'\t'</span> +</span><br><span class="line">                    user_dict[<span class="string">'tag'</span>] + <span class="string">'\t'</span> +</span><br><span class="line">                    user_dict[<span class="string">'freq'</span>] + <span class="string">'\n'</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">make_dict(temp_user_dict)</span><br><span class="line"></span><br><span class="line">lac = hub.Module(name=<span class="string">'lac'</span>)</span><br><span class="line">lac.set_user_dict(dict_path=<span class="string">'user.dict'</span>)</span><br><span class="line">results = lac.lexical_analysis(texts=[<span class="string">'我爱自然语言处理'</span>],</span><br><span class="line">                               use_gpu=<span class="literal">False</span>,</span><br><span class="line">                               batch_size=<span class="number">1</span>,</span><br><span class="line">                               return_tag=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> result <span class="keyword">in</span> results:</span><br><span class="line">    print(result[<span class="string">"word"</span>])</span><br><span class="line">    print(result[<span class="string">"tag"</span>])</span><br></pre></td></tr></tbody></table></figure><p></p>
<h2 id="阅读理解" class="heading-control"><a href="#阅读理解" class="headerlink" title="阅读理解"></a>阅读理解<a class="heading-anchor" href="#阅读理解" aria-hidden="true"></a></h2><figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> paddlehub <span class="keyword">as</span> hub</span><br><span class="line"></span><br><span class="line">module = hub.Module(name=<span class="string">"roberta_wwm_ext_chinese_L-24_H-1024_A-16"</span>)</span><br><span class="line">inputs, outputs, program = module.context(trainable=<span class="literal">True</span>, max_seq_len=<span class="number">384</span>)</span><br><span class="line">dataset = hub.dataset.CMRC2018()</span><br><span class="line"></span><br><span class="line">reader = hub.reader.ReadingComprehensionReader(</span><br><span class="line">    dataset=dataset,</span><br><span class="line">    vocab_path=module.get_vocab_path(),</span><br><span class="line">    max_seq_len=<span class="number">384</span>)</span><br><span class="line"></span><br><span class="line">strategy = hub.AdamWeightDecayStrategy(</span><br><span class="line">    learning_rate=<span class="number">5e-5</span>,</span><br><span class="line">    weight_decay=<span class="number">0.01</span>,</span><br><span class="line">    warmup_proportion=<span class="number">0.1</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">config = hub.RunConfig(use_cuda=<span class="literal">False</span>, num_epoch=<span class="number">2</span>, batch_size=<span class="number">12</span>, strategy=strategy)</span><br><span class="line">seq_output = outputs[<span class="string">"sequence_output"</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># feed_list的Tensor顺序不可以调整</span></span><br><span class="line">feed_list = [</span><br><span class="line">    inputs[<span class="string">"input_ids"</span>].name,</span><br><span class="line">    inputs[<span class="string">"position_ids"</span>].name,</span><br><span class="line">    inputs[<span class="string">"segment_ids"</span>].name,</span><br><span class="line">    inputs[<span class="string">"input_mask"</span>].name,</span><br><span class="line">]</span><br><span class="line"></span><br><span class="line">reading_comprehension_task = hub.ReadingComprehensionTask(</span><br><span class="line">    data_reader=reader,</span><br><span class="line">    feature=seq_output,</span><br><span class="line">    feed_list=feed_list,</span><br><span class="line">    config=config,</span><br><span class="line">    sub_task=<span class="string">"cmrc2018"</span>)</span><br><span class="line"></span><br><span class="line">reading_comprehension_task.finetune_and_eval()</span><br></pre></td></tr></tbody></table></figure>
</body></html>]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>PaddleHub</tag>
      </tags>
  </entry>
  <entry>
    <title>Progressive learning:Learn Python the Hard Way</title>
    <url>/post/2054.html</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p><a href="https://learnpythonthehardway.org/book/">Learn Python the Hard Way</a></p>
]]></content>
      <categories>
        <category>me</category>
      </categories>
      <tags>
        <tag>NLP</tag>
      </tags>
  </entry>
  <entry>
    <title>Python 音频信号处理</title>
    <url>/post/20005.html</url>
    <content><![CDATA[<html><head><link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script></head><body><blockquote>
<p>本文主要是对网上的一些文章的总结，参考的文章在文末已经列出</p>
</blockquote>
<p>音频信号是模拟信号，我们需要将其保存为数字信号，才能对语音进行算法操作，WAV 是 Microsoft 开发的一种声音文件格式，通常被用来保存未压缩的声音数据。</p>
<p>语音信号有三个重要的参数：<strong>声道数</strong>、<strong>取样频率</strong>和<strong>量化位数</strong>。</p>
<ul>
<li><strong>声道数</strong>：可以是单声道或者是双声道</li>
<li><strong>采样频率</strong>：一秒内对声音信号的采集次数，44100Hz 采样频率意味着每秒钟信号被分解成 44100 份，如果采样率高，那么媒体播放音频时会感觉信号是连续的。</li>
<li><strong>量化位数</strong>：用多少 bit 表达一次采样所采集的数据，通常有 8bit、16bit、24bit 和 32bit 等几种</li>
</ul>
<p>如果你需要自己录制和编辑声音文件，推荐使用 Audacity (<a href="http://audacity.sourceforge.net)，">http://audacity.sourceforge.net)，</a> 它是一款开源的、跨平台、多声道的录音编辑软件。</p>
<a id="more"></a>
<h2 id="音频信号读取" class="heading-control"><a href="#音频信号读取" class="headerlink" title="音频信号读取"></a>音频信号读取<a class="heading-anchor" href="#音频信号读取" aria-hidden="true"></a></h2><figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> scipy.io <span class="keyword">import</span> wavfile</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pylab <span class="keyword">as</span> plt</span><br><span class="line">samplimg_freq, audio = wavfile.read(<span class="string">"data/input_freq.wav"</span>)</span><br><span class="line">plt.plot(np.arange(audio.shape[<span class="number">0</span>]),audio)</span><br><span class="line">plt.show()</span><br></pre></td></tr></tbody></table></figure>
<p>音频的时域信号波形：<br><img src="https://i.loli.net/2019/09/10/taJsWjAQe21xb6g.png" alt></p>
<p>语音信号是一个非平稳的时变信号，但语音信号是由声门的激励脉冲通过声道形成的，而声道 (人的口腔、鼻腔) 的肌肉运动是缓慢的，所以 “短时间”(10-30ms) 内可以认为语音信号是平稳时不变的。由此构成了语音信号的 “短时分析技术”。<br>在短时分析中，将语音信号分为一段一段的语音帧，每一帧一般取 10-30ms，我们的研究就建立在每一帧的语音特征分析上。<br>提取的不同的语音特征参数对应着不同的语音信号分析方法：时域分析、频域分析、倒谱域分析… 由于语音信号最重要的感知特性反映在功率谱上，而相位变化只起到很小的作用，所有语音频域分析更加重要。</p>
<h2 id="预加重" class="heading-control"><a href="#预加重" class="headerlink" title="预加重"></a>预加重<a class="heading-anchor" href="#预加重" aria-hidden="true"></a></h2><p>预增强以帧为单位进行，目的在于加强高频。去除口唇辐射的影响，增加语音的高频分辨率。因为高频端大约在 800Hz 以上按 6dB/oct (倍频程) 衰减，频率越高相应的成分越小，为此要在对语音信号进行分析之前对其高频部分加以提升，也可以改善高频信噪比。k 是预增强系数，常用 0.97。</p>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line">pre_emphasis = <span class="number">0.97</span></span><br><span class="line">emphasized_signal = np.append(audio[<span class="number">0</span>], audio[<span class="number">1</span>:] - pre_emphasis * audio[:<span class="number">-1</span>])</span><br><span class="line">plt.plot(np.arange(emphasized_signal.shape[<span class="number">0</span>]),emphasized_signal)</span><br><span class="line">plt.show()</span><br></pre></td></tr></tbody></table></figure>
<p><img src="https://i.loli.net/2019/09/10/hycELdZWD5qo2AH.png" alt></p>
<h2 id="分帧" class="heading-control"><a href="#分帧" class="headerlink" title="分帧"></a>分帧<a class="heading-anchor" href="#分帧" aria-hidden="true"></a></h2><p>分帧是将不定长的音频切分成固定长度的小段。为了避免窗边界对信号的遗漏，因此对帧做偏移时候，帧间要有帧移 (帧与帧之间需要重叠一部分)，帧长 (wlen) = 重叠 (overlap)+ 帧移 (inc)。inc 为帧移，表示后一帧第前一帧的偏移量，fs 表示采样率，fn 表示一段语音信号的分帧数。</p>
<script type="math/tex; mode=display">\frac{N-overlap}{inc}=\frac{N-wlen+inc}{inc}</script><p>通常的选择是帧长 25ms（下图绿色），帧移为 10ms（下图黄色）。接下来的操作是对单帧进行的。要分帧是因为语音信号是快速变化的，而傅里叶变换适用于分析平稳的信号。帧和帧之间的时间差常常取为 10ms，这样帧与帧之间会有重叠（下图红色），否则，由于帧与帧连接处的信号会因为加窗而被弱化，这部分的信息就丢失了。<br><img src="https://i.loli.net/2019/09/10/QA89CdDfL3qibS6.png" alt></p>
<h2 id="语音信号的短时频域处理" class="heading-control"><a href="#语音信号的短时频域处理" class="headerlink" title="语音信号的短时频域处理"></a>语音信号的短时频域处理<a class="heading-anchor" href="#语音信号的短时频域处理" aria-hidden="true"></a></h2><p>在语音信号处理中，在语音信号处理中，信号在频域或其他变换域上的分析处理占重要的位置，在频域上研究语音可以使信号在时域上无法表现出来的某些特征变得十分明显，一个音频信号的本质是由其频率内容决定的，将时域信号转换为频域信号一般对语音进行<strong>短时傅里叶变换</strong>。</p>
<h2 id="python-speech-features" class="heading-control"><a href="#python-speech-features" class="headerlink" title="python_speech_features"></a>python_speech_features<a class="heading-anchor" href="#python-speech-features" aria-hidden="true"></a></h2><p>python_speech_features 的比较好用的地方就是自带预加重参数，只需要设定 preemph 的值，就可以对语音信号进行预加重，增强高频信号。<br>python_speech_features 模块提供的函数主要包括两个：MFCC 和 FBank。API 定义如下：</p>
<blockquote>
<p>python_speech_features.base.fbank(signal, samplerate=16000, winlen=0.025, winstep=0.01, nfilt=26, nfft=512, lowfreq=0, highfreq=None, preemph=0.97, winfunc=<function <lambda>>)</function></p>
</blockquote>
<p>从一个音频信号中计算梅尔滤波器能量特征，返回：2 个值。第一个是一个包含着特征的大小为 nfilt 的 numpy 数组，每一行都有一个特征向量。第二个返回值是每一帧的能量。</p>
<blockquote>
<p>python_speech_features.base.logfbank(signal, samplerate=16000, winlen=0.025, winstep=0.01, nfilt=26, nfft=512, lowfreq=0, highfreq=None, preemph=0.97)</p>
</blockquote>
<p>从一个音频信号中计算梅尔滤波器能量特征的对数，返回： 一个包含特征的大小为 nfilt 的 numpy 数组，每一行都有一个特征向量</p>
<p>参数<br></p><figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line">参数：</span><br><span class="line"></span><br><span class="line">signal - 需要用来计算特征的音频信号，应该是一个N*<span class="number">1</span>的数组</span><br><span class="line"></span><br><span class="line">samplerate - 我们用来工作的信号的采样率</span><br><span class="line"></span><br><span class="line">winlen - 分析窗口的长度，按秒计，默认<span class="number">0.025</span>s(<span class="number">25</span>ms)</span><br><span class="line"></span><br><span class="line">winstep - 连续窗口之间的步长，按秒计，默认<span class="number">0.01</span>s（<span class="number">10</span>ms）</span><br><span class="line"></span><br><span class="line">numcep - 倒频谱返回的数量，默认<span class="number">13</span></span><br><span class="line"></span><br><span class="line">nfilt - 滤波器组的滤波器数量，默认<span class="number">26</span></span><br><span class="line"></span><br><span class="line">nfft - FFT的大小，默认<span class="number">512</span></span><br><span class="line"></span><br><span class="line">lowfreq - 梅尔滤波器的最低边缘，单位赫兹，默认为<span class="number">0</span></span><br><span class="line"></span><br><span class="line">highfreq - 梅尔滤波器的最高边缘，单位赫兹，默认为采样率/<span class="number">2</span></span><br><span class="line"></span><br><span class="line">preemph - 应用预加重过滤器和预加重过滤器的系数，<span class="number">0</span>表示没有过滤器，默认<span class="number">0.97</span></span><br><span class="line"></span><br><span class="line">ceplifter - 将升降器应用于最终的倒谱系数。 <span class="number">0</span>没有升降机。默认值为<span class="number">22</span>。</span><br><span class="line"></span><br><span class="line">appendEnergy - 如果是true，则将第<span class="number">0</span>个倒谱系数替换为总帧能量的对数。</span><br><span class="line"></span><br><span class="line">winfunc - 分析窗口应用于每个框架。 默认情况下不应用任何窗口。 你可以在这里使用numpy窗口函数 例如：winfunc=numpy.hamming</span><br></pre></td></tr></tbody></table></figure><p></p>
<h2 id="MFCC特征和过滤器特征" class="heading-control"><a href="#MFCC特征和过滤器特征" class="headerlink" title="MFCC特征和过滤器特征"></a>MFCC 特征和过滤器特征<a class="heading-anchor" href="#MFCC特征和过滤器特征" aria-hidden="true"></a></h2><figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> python_speech_features <span class="keyword">import</span> mfcc, logfbank</span><br><span class="line"></span><br><span class="line"><span class="comment">#提取MFCC特征和过滤器特征</span></span><br><span class="line">mfcc_features = mfcc(audio, samplimg_freq)</span><br><span class="line">filterbank_features = logfbank(audio, samplimg_freq)</span><br><span class="line"></span><br><span class="line"><span class="comment">#打印参数，查看可生成多少个窗体：</span></span><br><span class="line">print(<span class="string">'\nMFCC:\nNumber of windows ='</span>, mfcc_features.shape[<span class="number">0</span>])</span><br><span class="line">print(<span class="string">'Length of each feature ='</span>, mfcc_features.shape[<span class="number">1</span>])</span><br><span class="line">print(<span class="string">'\nFilter bank:\nNumber of windows='</span>, filterbank_features.shape[<span class="number">0</span>])</span><br><span class="line">print(<span class="string">'Length of each feature ='</span>, filterbank_features.shape[<span class="number">1</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment">#将MFCC特征可视化。转置矩阵，使得时域是水平的。</span></span><br><span class="line">mfcc_features = mfcc_features.T</span><br><span class="line">plt.matshow(mfcc_features)</span><br><span class="line">plt.title(<span class="string">'MFCC'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#将滤波器组特征可视化。转置矩阵，使得时域是水平的。</span></span><br><span class="line">filterbank_features = filterbank_features.T</span><br><span class="line">plt.matshow(filterbank_features)</span><br><span class="line">plt.title(<span class="string">'Filter bank'</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></tbody></table></figure>
<p>输出如下：<br></p><figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line">MFCC:</span><br><span class="line">Number of windows = <span class="number">42</span></span><br><span class="line">Length of each feature = <span class="number">13</span></span><br><span class="line"></span><br><span class="line">Filter bank:</span><br><span class="line">Number of windows= <span class="number">42</span></span><br><span class="line">Length of each feature = <span class="number">26</span></span><br></pre></td></tr></tbody></table></figure><br><img src="https://i.loli.net/2019/09/10/9PzrY5gIXxTiM7U.png" alt><br><img src="https://i.loli.net/2019/09/10/rEyK4ZjAeOLDmC6.png" alt><p></p>
<h2 id="触发词检测" class="heading-control"><a href="#触发词检测" class="headerlink" title="触发词检测"></a>触发词检测<a class="heading-anchor" href="#触发词检测" aria-hidden="true"></a></h2><p><img src="https://s2.ax1x.com/2019/09/26/unhpCt.png" alt="unhpCt.png"></p>
<h2 id="Reference" class="heading-control"><a href="#Reference" class="headerlink" title="Reference"></a>Reference<a class="heading-anchor" href="#Reference" aria-hidden="true"></a></h2><ul>
<li><a href="https://jingyan.baidu.com/article/1709ad804e575b4634c4f0b1.html">https://jingyan.baidu.com/article/1709ad804e575b4634c4f0b1.html</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/57004884">https://zhuanlan.zhihu.com/p/57004884</a></li>
<li><a href="https://python-speech-features.readthedocs.io/en/latest/">https://python-speech-features.readthedocs.io/en/latest/</a></li>
<li><a href="https://www.meiwen.com.cn/subject/ahyxuqtx.html">https://www.meiwen.com.cn/subject/ahyxuqtx.html</a></li>
<li><a href="https://haythamfayek.com/2016/04/21/speech-processing-for-machine-learning.html">https://haythamfayek.com/2016/04/21/speech-processing-for-machine-learning.html</a></li>
<li><a href="https://www.cnblogs.com/LXP-Never/p/10078200.html#%E9%9F%B3%E9%A2%91%E4%BF%A1%E5%8F%B7%E7%9A%84%E8%AF%BB%E5%86%99%E3%80%81%E6%92%AD%E6%94%BE%E5%8F%8A%E5%BD%95%E9%9F%B3">https://www.cnblogs.com/LXP-Never/p/10078200.html#%E9%9F%B3%E9%A2%91%E4%BF%A1%E5%8F%B7%E7%9A%84%E8%AF%BB%E5%86%99%E3%80%81%E6%92%AD%E6%94%BE%E5%8F%8A%E5%BD%95%E9%9F%B3</a></li>
<li><a href="https://github.com/majianjia/nnom/tree/master/examples/keyword_spotting">https://github.com/majianjia/nnom/tree/master/examples/keyword_spotting</a></li>
</ul>
</body></html>]]></content>
      <tags>
        <tag>Python</tag>
        <tag>音频信号处理</tag>
      </tags>
  </entry>
  <entry>
    <title>Python 高级语法</title>
    <url>/post/33390.html</url>
    <content><![CDATA[<html><head><link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script></head><body><p><iframe src="https://trinket.io/embed/python/b970f02d2e" width="100%" height="356" frameborder="0" marginwidth="0" marginheight="0" allowfullscreen></iframe></p>
<h2 id="前言" class="heading-control"><a href="#前言" class="headerlink" title="前言"></a>前言<a class="heading-anchor" href="#前言" aria-hidden="true"></a></h2><p>本篇博客记录的是一些 python 的高级用法，更加深刻的理解 Python 的语法，。<br><a id="more"></a></p>
<h2 id="基本操作进阶" class="heading-control"><a href="#基本操作进阶" class="headerlink" title="基本操作进阶"></a>基本操作进阶<a class="heading-anchor" href="#基本操作进阶" aria-hidden="true"></a></h2><h3 id="各式各样的解析" class="heading-control"><a href="#各式各样的解析" class="headerlink" title="各式各样的解析"></a>各式各样的解析<a class="heading-anchor" href="#各式各样的解析" aria-hidden="true"></a></h3><p>问题：如何更高效的筛选数据？</p>
<p><img src="https://i.loli.net/2018/11/28/5bfe1d9518aa1.png" alt></p>
<h3 id="命名元组" class="heading-control"><a href="#命名元组" class="headerlink" title="命名元组"></a>命名元组<a class="heading-anchor" href="#命名元组" aria-hidden="true"></a></h3><p>利用 <code>collections</code> 模块中的 <code>namedtuple</code> 函数</p>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="meta">>>> </span><span class="keyword">from</span> collections <span class="keyword">import</span> namedtuple</span><br><span class="line"><span class="meta">>>> </span>Student = namedtuple(<span class="string">'Student'</span>, [<span class="string">'name'</span>, <span class="string">'age'</span>, <span class="string">'sex'</span>, <span class="string">'email'</span>])</span><br><span class="line"><span class="meta">>>> </span>s = Student(<span class="string">'Jim'</span>, <span class="number">21</span>, <span class="string">'male'</span>, <span class="string">'123@qq.com'</span>)</span><br><span class="line"><span class="meta">>>> </span>s.name</span><br><span class="line"><span class="string">'Jim'</span></span><br><span class="line"><span class="meta">>>> </span>s.age</span><br><span class="line"><span class="number">21</span></span><br></pre></td></tr></tbody></table></figure>
<h3 id="统计元素的频度" class="heading-control"><a href="#统计元素的频度" class="headerlink" title="统计元素的频度"></a>统计元素的频度<a class="heading-anchor" href="#统计元素的频度" aria-hidden="true"></a></h3><p><img src="https://i.loli.net/2018/11/28/5bfe1d6b9d859.png" alt></p>
<h3 id="元组排序" class="heading-control"><a href="#元组排序" class="headerlink" title="元组排序"></a>元组排序<a class="heading-anchor" href="#元组排序" aria-hidden="true"></a></h3><p>元组是可以比较大小的，两个元组比较大小是依次比较，即如果第一个元素不相同，根据第一个元素的比较结果作为最终结果，否则比较第二个元素。</p>
<p><img src="https://i.loli.net/2018/11/28/5bfe21c741eb9.png" alt></p>
<h3 id="根据字典中的值排序" class="heading-control"><a href="#根据字典中的值排序" class="headerlink" title="根据字典中的值排序"></a>根据字典中的值排序<a class="heading-anchor" href="#根据字典中的值排序" aria-hidden="true"></a></h3><p>方法一：利用 zip 把字典转换为元组 (值在前，键在后)，然后 sorted 排序。</p>
<p><img src="https://i.loli.net/2018/11/28/5bfe2088135b1.png" alt></p>
<p>方法二：</p>
<p>利用 sorted 的 key 参数。字典的 items 返回由键值组成的元组列表（键在前，值在后），无法直接用 sorted 排序。我们可以用 key 指定使用列表里面每一个元组的第二个元素排序，这里使用 lambda 表达式。</p>
<p><img src="https://i.loli.net/2018/11/28/5bfe2346f11b7.png" alt></p>
<h3 id="多个字典的公共键" class="heading-control"><a href="#多个字典的公共键" class="headerlink" title="多个字典的公共键"></a>多个字典的公共键<a class="heading-anchor" href="#多个字典的公共键" aria-hidden="true"></a></h3><p><img src="https://i.loli.net/2018/11/28/5bfe67aacc470.png" alt></p>
<h3 id="有序字典" class="heading-control"><a href="#有序字典" class="headerlink" title="有序字典"></a>有序字典<a class="heading-anchor" href="#有序字典" aria-hidden="true"></a></h3><p><img src="https://i.loli.net/2018/11/28/5bfe68f632e28.png" alt></p>
<h3 id="历史记录功能" class="heading-control"><a href="#历史记录功能" class="headerlink" title="历史记录功能"></a>历史记录功能<a class="heading-anchor" href="#历史记录功能" aria-hidden="true"></a></h3><p><img src="https://i.loli.net/2018/11/28/5bfe69ad64e17.png" alt></p>
<h2 id="迭代器" class="heading-control"><a href="#迭代器" class="headerlink" title="迭代器"></a>迭代器<a class="heading-anchor" href="#迭代器" aria-hidden="true"></a></h2><h3 id="迭代器-1" class="heading-control"><a href="#迭代器-1" class="headerlink" title="迭代器"></a>迭代器<a class="heading-anchor" href="#迭代器-1" aria-hidden="true"></a></h3><p>迭代 (iteration) 指的是去获取元素的一种方式，一个接一个。当你显式或隐式的使用循环来遍历某个元素集的时候，那就是迭代。</p>
<p>在 Python 里面，可迭代对象 (iterable) 和迭代器 (iterator) 有着特殊的含义。</p>
<ul>
<li><code>iterable</code> 是实现了<code>__iter__()</code> 方法的对象，该方法会返回一个 <code>iterator</code> 对象</li>
<li><code>iterator</code> 是实现了<code>__iter__()</code> 和<code>__next__()</code> 方法的对象，<code>__iter__()</code> 方法返回的是 <code>iterator</code> 对象本身</li>
</ul>
<p>由此可见，<code>iterable</code> 和 <code>iterator</code> 的本质区别就是后者多了一个<code>__next__()</code> 方法。 也就是说一个 <code>iterator</code> 对象必定是一个 <code>iterable</code> 对象。</p>
<p> 当你使用一个 <code>for</code> 循环或者 <code>map</code>，或着一个列表推导，那么会先通过 iter () 获取相应的迭代器， 然后每次循环自动通过 <code>next</code> 方法调用这个迭代器 (iterator)，从中获取每一个元素，从而完成迭代过程。</p>
<p>凡是可作用于 for 循环的对象都是 Iterable 类型；</p>
<p>凡是可作用于 next () 函数的对象都是 Iterator 类型，它们表示一个惰性计算的序列；</p>
<p>集合数据类型如 list、dict、str 等是 Iterable 但不是 Iterator，不过可以通过 iter () 函数获得一个 Iterator 对象。</p>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="comment"># 首先获得Iterator对象:</span></span><br><span class="line">it = iter([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>])</span><br><span class="line"><span class="comment"># 循环:</span></span><br><span class="line"><span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        <span class="comment"># 获得下一个值:</span></span><br><span class="line">        x = next(it)</span><br><span class="line">    <span class="keyword">except</span> StopIteration:</span><br><span class="line">        <span class="comment"># 遇到StopIteration就退出循环</span></span><br><span class="line">        <span class="keyword">break</span></span><br></pre></td></tr></tbody></table></figure>
<h3 id="iteritem迭代大数据字典" class="heading-control"><a href="#iteritem迭代大数据字典" class="headerlink" title="iteritem迭代大数据字典"></a>iteritem 迭代大数据字典<a class="heading-anchor" href="#iteritem迭代大数据字典" aria-hidden="true"></a></h3><p>迭代大数据字典时，如果是使用 items () 方法，那么在迭代之前，迭代器迭代前需要把数据完整地加载到内存，这种方式不仅处理非常慢而且浪费内存，下面代码约占 1.6G 内存</p>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line">d = {i: i * <span class="number">2</span> <span class="keyword">for</span> i <span class="keyword">in</span> xrange(<span class="number">10000000</span>)}</span><br><span class="line"><span class="keyword">for</span> key, value <span class="keyword">in</span> d.items():</span><br><span class="line">    print(<span class="string">"{0} = {1}"</span>.format(key, value))</span><br></pre></td></tr></tbody></table></figure>
<p>而使用 iteritem () 方法替换 items () ，最终实现的效果一样，但是消耗的内存降低 50%，为什么差距那么大呢？因为 items () 返回的是一个 list，list 在迭代的时候会预先把所有的元素加载到内存，而 iteritem () 返回的一个迭代器 (iterators)，迭代器在迭代的时候，迭代元素逐个的生成。</p>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line">d = {i: i * <span class="number">2</span> <span class="keyword">for</span> i <span class="keyword">in</span> xrange(<span class="number">10000000</span>)}</span><br><span class="line"><span class="keyword">for</span> key, value <span class="keyword">in</span> d.iteritem():</span><br><span class="line">    print(<span class="string">"{0} = {1}"</span>.format(key, value))</span><br></pre></td></tr></tbody></table></figure>
<h2 id="生成器" class="heading-control"><a href="#生成器" class="headerlink" title="生成器"></a>生成器<a class="heading-anchor" href="#生成器" aria-hidden="true"></a></h2><p>当我们调用一个普通的函数时，执行过程从第一条语句开始，直到碰到一个 <code>return</code> 语句或者遇到一个异常抛出， 再或者到了函数最后一条语句 (实际上相对于一个隐式的 <code>return None</code>) 的时候结束。 一旦这个函数返回后将控制权交还给它的调用者，它里面所有的局部变量值都消失了，当你重新调用它的时候，一切又将重新开始。</p>
<p>这就是我们通常意义上面所认识的函数（或者说是子程序），但有时候我们需要创建某个函数，它并不简单的返回一个值， 而是可以不断的释放一个值的序列。那么这个特殊的函数就需要能够 “保存” 它的状态。</p>
<p>在 Python 中，有这种能力的 “函数” 被称为生成器，它们相当有用。生成器（yield 语句）刚开始被引入进来主要是用来方便的生成序列值。</p>
<h3 id="迭代器切片操作" class="heading-control"><a href="#迭代器切片操作" class="headerlink" title="迭代器切片操作"></a>迭代器切片操作<a class="heading-anchor" href="#迭代器切片操作" aria-hidden="true"></a></h3><p><img src="https://i.loli.net/2018/11/28/5bfe6c5f45dea.png" alt></p>
<h3 id="迭代器迭代多个对象" class="heading-control"><a href="#迭代器迭代多个对象" class="headerlink" title="迭代器迭代多个对象"></a>迭代器迭代多个对象<a class="heading-anchor" href="#迭代器迭代多个对象" aria-hidden="true"></a></h3><p><img src="https://i.loli.net/2018/11/28/5bfe6ce95f64a.png" alt></p>
<h2 id="字符串" class="heading-control"><a href="#字符串" class="headerlink" title="字符串"></a>字符串<a class="heading-anchor" href="#字符串" aria-hidden="true"></a></h2><h3 id="拆分多种分隔符的字符串" class="heading-control"><a href="#拆分多种分隔符的字符串" class="headerlink" title="拆分多种分隔符的字符串"></a>拆分多种分隔符的字符串<a class="heading-anchor" href="#拆分多种分隔符的字符串" aria-hidden="true"></a></h3><p><img src="/tmp/1543400851321.png" alt="1543400851321"></p>
<h2 id="类" class="heading-control"><a href="#类" class="headerlink" title="类"></a>类<a class="heading-anchor" href="#类" aria-hidden="true"></a></h2><h3 id="slots节省内存" class="heading-control"><a href="#slots节省内存" class="headerlink" title="slots节省内存"></a>slots 节省内存<a class="heading-anchor" href="#slots节省内存" aria-hidden="true"></a></h3><p>Python 允许在定义 class 的时候，定义一个特殊的 <strong>slots</strong> 变量，来限制该 class 实例能添加的属性</p>
<p><img src="https://i.loli.net/2018/11/28/5bfe74f6cd7c4.png" alt></p>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Student</span>(<span class="params">object</span>):</span></span><br><span class="line">    __slots__ = (<span class="string">'name'</span>, <span class="string">'age'</span>) <span class="comment"># 用tuple定义允许绑定的属性名称</span></span><br></pre></td></tr></tbody></table></figure>
<h3 id="使用-property" class="heading-control"><a href="#使用-property" class="headerlink" title="使用@property"></a>使用 @property<a class="heading-anchor" href="#使用-property" aria-hidden="true"></a></h3><p>python 最佳编程实践推荐我们不要像 java 那样去调用 getter 和 setter，而是使用装饰器 @property</p>
<p>Python 内置的 @property 装饰器就是负责把一个方法变成属性调用</p>
<p>把一个 getter 方法变成属性，只需要加上 @property 就可以了， 此时，@property 本身又创建了另一个装饰器 @score.setter，负责把一个 setter 方法变成属性赋值</p>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Student</span>(<span class="params">object</span>):</span></span><br><span class="line"><span class="meta">    @property</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">score</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">return</span> self._score</span><br><span class="line"></span><br><span class="line"><span class="meta">    @score.setter</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">score</span>(<span class="params">self, value</span>):</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> isinstance(value, int):</span><br><span class="line">            <span class="keyword">raise</span> ValueError(<span class="string">'score must be an integer!'</span>)</span><br><span class="line">        <span class="keyword">if</span> value < <span class="number">0</span> <span class="keyword">or</span> value > <span class="number">100</span>:</span><br><span class="line">            <span class="keyword">raise</span> ValueError(<span class="string">'score must between 0 ~ 100!'</span>)</span><br><span class="line">        self._score = value</span><br><span class="line">s = Student()</span><br><span class="line">s.score = <span class="number">60</span></span><br><span class="line">s.score</span><br></pre></td></tr></tbody></table></figure>
<p>还可以定义只读属性，只定义 getter 方法，不定义 setter 方法就是一个只读属性</p>
<h2 id="函数装饰器" class="heading-control"><a href="#函数装饰器" class="headerlink" title="函数装饰器"></a>函数装饰器<a class="heading-anchor" href="#函数装饰器" aria-hidden="true"></a></h2><h3 id="斐波那契数列" class="heading-control"><a href="#斐波那契数列" class="headerlink" title="斐波那契数列"></a>斐波那契数列<a class="heading-anchor" href="#斐波那契数列" aria-hidden="true"></a></h3><p>装饰器本质上是一个 Python 函数，它可以让其他函数在<strong>不需要做任何代码变动的前提下增加额外功能</strong>，装饰器的返回值也是一个函数对象。它经常用于有切面需求的场景，比如：插入日志、性能测试、事务处理、缓存、权限校验等场景。装饰器是解决这类问题的绝佳设计，有了装饰器，我们就可以抽离出大量与函数功能本身无关的雷同代码并继续重用。</p>
<p>下面是一个简单的求斐波那契数列的算法，用的递归，很简单：</p>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">fibonacci</span>(<span class="params">n</span>):</span></span><br><span class="line">    <span class="keyword">if</span> n <= <span class="number">1</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="number">1</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">return</span>  fibonacci(n - <span class="number">1</span>) + fibonacci(n - <span class="number">2</span>)</span><br></pre></td></tr></tbody></table></figure>
<h3 id="Memoization技术" class="heading-control"><a href="#Memoization技术" class="headerlink" title="Memoization技术"></a>Memoization 技术<a class="heading-anchor" href="#Memoization技术" aria-hidden="true"></a></h3><p>但是执行 fibonacci (50) 却需要花费很多时间。这是因为递归求解的时候计算了很多重复子序列。我们可以把求解斐波那契看成是一个二叉树，如下图所示：</p>
<p><img src="https://i.loli.net/2018/11/27/5bfd36ef08617.png" alt></p>
<p>一种想法是以空间换时间，计算一次，然后存储，下次需要的时候直接取出，不需要 redo 前面的计算，称之为 Memoization 技术。加入缓存后的程序如下：</p>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">fibonacci</span>(<span class="params">n, chche=None</span>):</span></span><br><span class="line">    <span class="keyword">if</span> chche <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">        chche = {}</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> n <span class="keyword">in</span> chche.keys():</span><br><span class="line">        <span class="keyword">return</span> chche[n]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> n <= <span class="number">1</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="number">1</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        chche[n] = fibonacci(n - <span class="number">1</span>, chche) + fibonacci(n - <span class="number">2</span>, chche)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> chche[n]</span><br></pre></td></tr></tbody></table></figure>
<h3 id="加入装饰器" class="heading-control"><a href="#加入装饰器" class="headerlink" title="加入装饰器"></a>加入装饰器<a class="heading-anchor" href="#加入装饰器" aria-hidden="true"></a></h3><p>这下就执行的非常快了。但是还有一个问题，就是加入我们有很多这样的函数，每个这样写很麻烦，这就引入了装饰器。加入装饰器后的代码如下：</p>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">memo</span>(<span class="params">func</span>):</span></span><br><span class="line">    cache = {}</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">wrap</span>(<span class="params">*args</span>):</span></span><br><span class="line">        <span class="keyword">if</span> args <span class="keyword">not</span> <span class="keyword">in</span> cache:</span><br><span class="line">            cache[args] = func(*args)</span><br><span class="line">        <span class="keyword">return</span> cache[args]</span><br><span class="line">    <span class="keyword">return</span> wrap</span><br><span class="line"></span><br><span class="line"><span class="meta">@memo</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">fibonacci</span>(<span class="params">n</span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> n <= <span class="number">1</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="number">1</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">return</span>  fibonacci(n - <span class="number">1</span>) + fibonacci(n - <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    print(fibonacci(<span class="number">50</span>))</span><br></pre></td></tr></tbody></table></figure>
<p>但是这个时候如果我们调用下面的这句代码：</p>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line">print(fibonacci.__name__)</span><br><span class="line"><span class="comment">#wrap</span></span><br></pre></td></tr></tbody></table></figure>
<h3 id="更新元数据" class="heading-control"><a href="#更新元数据" class="headerlink" title="更新元数据"></a>更新元数据<a class="heading-anchor" href="#更新元数据" aria-hidden="true"></a></h3><p>看来原函数的元数据被装饰器改变了。解决方法就是使用 functools 中的装饰器 wraps 装饰内部包裹函数，可以吧原函数的属性更新到包裹函数上。</p>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> functools <span class="keyword">import</span> update_wrapper</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">memo</span>(<span class="params">func</span>):</span></span><br><span class="line">    cache = {}</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">wrap</span>(<span class="params">*args</span>):</span></span><br><span class="line">        <span class="keyword">if</span> args <span class="keyword">not</span> <span class="keyword">in</span> cache:</span><br><span class="line">            cache[args] = func(*args)</span><br><span class="line">        <span class="keyword">return</span> cache[args]</span><br><span class="line">    update_wrapper(wrap,func)</span><br><span class="line">    <span class="keyword">return</span> wrap</span><br></pre></td></tr></tbody></table></figure>
<p>主要代码是：</p>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> functools <span class="keyword">import</span> update_wrapper</span><br><span class="line">update_wrapper(wrap,func)</span><br></pre></td></tr></tbody></table></figure>
<p>还有一种更简便的写法，和上面的代码效果相同，就是用装饰器去装饰我们写的装饰器：</p>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> functools <span class="keyword">import</span> wraps</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">memo</span>(<span class="params">func</span>):</span></span><br><span class="line">    cache = {}</span><br><span class="line"><span class="meta">    @wraps(func)</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">wrap</span>(<span class="params">*args</span>):</span></span><br><span class="line">        <span class="keyword">if</span> args <span class="keyword">not</span> <span class="keyword">in</span> cache:</span><br><span class="line">            cache[args] = func(*args)</span><br><span class="line">        <span class="keyword">return</span> cache[args]</span><br><span class="line">    <span class="keyword">return</span> wrap</span><br></pre></td></tr></tbody></table></figure>
<h3 id="带参数的装饰器" class="heading-control"><a href="#带参数的装饰器" class="headerlink" title="带参数的装饰器"></a>带参数的装饰器<a class="heading-anchor" href="#带参数的装饰器" aria-hidden="true"></a></h3><p>下面实现的是一个参数类型检查器。</p>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> functools <span class="keyword">import</span> wraps</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> inspect <span class="keyword">import</span> signature</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">typeassert</span>(<span class="params">*ty_args,**ty_kargs</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">decorator</span>(<span class="params">func</span>):</span></span><br><span class="line">        sig = signature(func)</span><br><span class="line">        btypes =  sig.bind_partial(*ty_args,**ty_kargs).arguments</span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">wrap</span>(<span class="params">*args,**kwargs</span>):</span></span><br><span class="line">            <span class="keyword">for</span> name,obj <span class="keyword">in</span> sig.bind(*args,**kwargs).arguments.items():</span><br><span class="line">                <span class="keyword">if</span> name <span class="keyword">in</span> btypes:</span><br><span class="line">                    <span class="keyword">if</span> <span class="keyword">not</span> isinstance(obj,btypes[name]):</span><br><span class="line">                        <span class="keyword">raise</span>  TypeError(<span class="string">'"%s" must be "%s"'</span> %(name,btypes[name]))</span><br><span class="line">            <span class="keyword">return</span> func(*args,**kwargs)</span><br><span class="line">        <span class="keyword">return</span> wrap</span><br><span class="line">    <span class="keyword">return</span> decorator</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">memo</span>(<span class="params">func</span>):</span></span><br><span class="line">    cache = {}</span><br><span class="line"><span class="meta">    @wraps(func)</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">wrap</span>(<span class="params">*args</span>):</span></span><br><span class="line">        <span class="keyword">if</span> args <span class="keyword">not</span> <span class="keyword">in</span> cache:</span><br><span class="line">            cache[args] = func(*args)</span><br><span class="line">        <span class="keyword">return</span> cache[args]</span><br><span class="line">    <span class="keyword">return</span> wrap</span><br><span class="line"></span><br><span class="line"><span class="meta">@typeassert(int)</span></span><br><span class="line"><span class="meta">@memo</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">fibonacci</span>(<span class="params">n</span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> n <= <span class="number">1</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="number">1</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">return</span>  fibonacci(n - <span class="number">1</span>) + fibonacci(n - <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    print(fibonacci(<span class="string">'a'</span>))</span><br><span class="line">    </span><br><span class="line"><span class="comment">#Traceback (most recent call last):</span></span><br><span class="line"><span class="comment">#  File "/home/sunyan/PycharmProjects/sunyan/sunyan.py", line 37, in <module></span></span><br><span class="line"><span class="comment">#    print(fibonacci('a'))</span></span><br><span class="line"><span class="comment">#  File "/home/sunyan/PycharmProjects/sunyan/sunyan.py", line 12, in wrap</span></span><br><span class="line"><span class="comment">#    raise  TypeError('"%s" must be "%s"' %(name,btypes[name]))</span></span><br><span class="line"><span class="comment">#TypeError: "n" must be "<class 'int'>"</span></span><br></pre></td></tr></tbody></table></figure>
<p>这里我们输入了字符型变量，但是要求输入是一个 int 变量，所以程序报错，提示应该输入 int 类型。</p>
<h3 id="属性可修改的函数装饰器" class="heading-control"><a href="#属性可修改的函数装饰器" class="headerlink" title="属性可修改的函数装饰器"></a>属性可修改的函数装饰器<a class="heading-anchor" href="#属性可修改的函数装饰器" aria-hidden="true"></a></h3><p>下面是一个测试函数运行时间的装饰器，并记录进入日志里面。</p>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> logging</span><br><span class="line">logging.basicConfig(level=logging.INFO)</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">runtime</span>(<span class="params">func</span>):</span></span><br><span class="line"><span class="meta">    @wraps(func)</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">wrap</span>(<span class="params">*args, **kwargs</span>):</span></span><br><span class="line">        start = time.time()</span><br><span class="line">        used = time.time()-start</span><br><span class="line">        msg = <span class="string">'%s used time: %s'</span> %(func.__name__,used)</span><br><span class="line">        logging.info(msg)</span><br><span class="line">    <span class="keyword">return</span> wrap</span><br></pre></td></tr></tbody></table></figure>
<h3 id="总体程序" class="heading-control"><a href="#总体程序" class="headerlink" title="总体程序"></a>总体程序<a class="heading-anchor" href="#总体程序" aria-hidden="true"></a></h3><figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> functools <span class="keyword">import</span> wraps</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> inspect <span class="keyword">import</span> signature</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">typeassert</span>(<span class="params">*ty_args,**ty_kargs</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">decorator</span>(<span class="params">func</span>):</span></span><br><span class="line">        sig = signature(func)</span><br><span class="line">        btypes =  sig.bind_partial(*ty_args,**ty_kargs).arguments</span><br><span class="line"><span class="meta">        @wraps(func)</span></span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">wrap</span>(<span class="params">*args,**kwargs</span>):</span></span><br><span class="line">            <span class="keyword">for</span> name,obj <span class="keyword">in</span> sig.bind(*args,**kwargs).arguments.items():</span><br><span class="line">                <span class="keyword">if</span> name <span class="keyword">in</span> btypes:</span><br><span class="line">                    <span class="keyword">if</span> <span class="keyword">not</span> isinstance(obj,btypes[name]):</span><br><span class="line">                        <span class="keyword">raise</span>  TypeError(<span class="string">'"%s" must be "%s"'</span> %(name,btypes[name]))</span><br><span class="line">            <span class="keyword">return</span> func(*args,**kwargs)</span><br><span class="line">        <span class="keyword">return</span> wrap</span><br><span class="line">    <span class="keyword">return</span> decorator</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> logging</span><br><span class="line">logging.basicConfig(level=logging.INFO)</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">runtime</span>(<span class="params">func</span>):</span></span><br><span class="line"><span class="meta">    @wraps(func)</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">wrap</span>(<span class="params">*args, **kwargs</span>):</span></span><br><span class="line">        start = time.time()</span><br><span class="line">        res = func(*args, **kwargs)</span><br><span class="line">        used = time.time()-start</span><br><span class="line">        msg = <span class="string">'%s used time: %s'</span> %(func.__name__,used)</span><br><span class="line">        logging.info(msg)</span><br><span class="line">        <span class="keyword">return</span> res</span><br><span class="line">    <span class="keyword">return</span> wrap</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">memo</span>(<span class="params">func</span>):</span></span><br><span class="line">    cache = {}</span><br><span class="line"><span class="meta">    @wraps(func)</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">wrap</span>(<span class="params">*args</span>):</span></span><br><span class="line">        <span class="keyword">if</span> args <span class="keyword">not</span> <span class="keyword">in</span> cache:</span><br><span class="line">            cache[args] = func(*args)</span><br><span class="line">        <span class="keyword">return</span> cache[args]</span><br><span class="line">    <span class="keyword">return</span> wrap</span><br><span class="line"></span><br><span class="line"><span class="meta">@runtime</span></span><br><span class="line"><span class="meta">@typeassert(int)</span></span><br><span class="line"><span class="meta">@memo</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">fibonacci</span>(<span class="params">n</span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> n <= <span class="number">1</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="number">1</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">return</span>  fibonacci(n - <span class="number">1</span>) + fibonacci(n - <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    print(fibonacci(<span class="number">500</span>))</span><br></pre></td></tr></tbody></table></figure>
<h2 id="正则表达式" class="heading-control"><a href="#正则表达式" class="headerlink" title="正则表达式"></a>正则表达式<a class="heading-anchor" href="#正则表达式" aria-hidden="true"></a></h2><p> <a href="https://www.xncoding.com/2016/05/20/python/pyfunny.html">正则表达式</a></p>
<h2 id="Reference" class="heading-control"><a href="#Reference" class="headerlink" title="Reference"></a>Reference<a class="heading-anchor" href="#Reference" aria-hidden="true"></a></h2><ul>
<li><a href="https://www.bilibili.com/video/av33736836">Python 进阶强化教学视频</a></li>
<li><a href="https://www.xncoding.com/2015/10/30/python/module.html">一篇写 python 的博客</a></li>
</ul>
</body></html>]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>语法</tag>
      </tags>
  </entry>
  <entry>
    <title>QA 综述</title>
    <url>/post/6322.html</url>
    <content><![CDATA[<html><head><link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script></head><body><h2 id="Memory-Networks" class="heading-control"><a href="#Memory-Networks" class="headerlink" title="Memory Networks"></a>Memory Networks<a class="heading-anchor" href="#Memory-Networks" aria-hidden="true"></a></h2><h3 id="论文简介" class="heading-control"><a href="#论文简介" class="headerlink" title="论文简介"></a>论文简介<a class="heading-anchor" href="#论文简介" aria-hidden="true"></a></h3><ol>
<li><a href="http://arxiv.org/pdf/1410.3916v11.pdf">Memory Networks</a> ，<strong>ICLR 2015</strong>，Facebook AI Research</li>
<li><a href="http://cs224d.stanford.edu/reports/KapashiDarshan.pdf">Answering Reading Comprehension Using Memory Networks</a>，Stanford</li>
</ol>
<p>(2018 年 12 月 3 日补充：第二篇不是论文，应该是斯坦福写的一个类似教程之类的东西，但是写的太像论文了 (ˇˍˇ)，我都搞混了 )</p>
<p>看名字就知道第一篇是原论文，第二篇是第一篇的实现。（这里必须吐槽一下，第一篇论文一个图都没有，让我这种看论文先看图的人瞬间丧失好感。第二篇就人性化的多，简单的一个模型架构图就能瞬间让人领悟许多。）</p>
<ul>
<li><strong>起因</strong>：作者认为 RNN、Attention 机制把很长的语句编码为定长向量 (Context Vector) 作为模型的记忆，会带来很大的信息压缩损失</li>
<li><strong>想法</strong>:   既然是因为向量太小带来的问题，那就直接加一个外部记忆模块，称之为 Memory</li>
<li><strong> 评价</strong>：开山之作，但是模型比较简单，也没有特别具体的说明。</li>
</ul>
<p>在第二篇论文里面的引言部分有一些比较精辟的话，我也摘录出来，不妨作为 NLP 的部分真理以供参考。</p>
<ol>
<li>QA 是最容易评估 AI 的标准。(这个容易理解，图灵测试不就是这样吗？)</li>
<li>AI 要想很好的完成 QA 任务，要在两个方面得到提高：检索和推理。</li>
<li>单纯的记忆是不够的，他们需要一些知识去检索。(人不也经常使用浏览器吗？)</li>
</ol>
<a id="more"></a>
<h3 id="具体实现" class="heading-control"><a href="#具体实现" class="headerlink" title="具体实现"></a>具体实现<a class="heading-anchor" href="#具体实现" aria-hidden="true"></a></h3><p>看下面这个图就很清楚，这个模型主要包括五个部分：Memory 单元和 I、G、O、R。</p>
<ul>
<li>Input 模块：输入的文本经过 Input 模块编码成特征向量 (各种方式都可以，最简单就是 wordvec)。</li>
<li>Generalization 模块：根据特征向量对 Memory 单元进行读写操作，即更新记忆。</li>
<li>Output 模块：根据 Question（也会进过 Input 模块进行编码）对 Memory 单元进行组合（比如加权），得到编码的输出向量</li>
<li> Response 模块：根据输出向量编码生成一个自然语言的答案出来。</li>
</ul>
<p><img src="https://i.loli.net/2018/12/03/5c050e6481611.png" alt></p>
<p>举个例子。假设有下面一段文字，针对文字可以提出几个问题，然后让模型去回答：</p>
<p><img src="https://i.loli.net/2018/12/03/5c05183c3962f.png" alt></p>
<p>这里我们首先使用 Input 模块对文档进行编码，Generalization 模块存储编码结果，然后使用 Input 对问题 where is the milk now？进行编码，Output 模块根据问题编码后的向量从 Memory 单元中选出最相关的一句话：Joe left the milk，然后再对剩下的记忆进行评分，找出与 where is the milk now？和 Joe left the milk 最相关的 memory。我们发现是 Joe travelled to the office。这样我们就找到了最相关的记忆，接下来使用 R 模块对所有的单词进行评分找到得分最高的单词作为答案即可。</p>
<h3 id="代码复现" class="heading-control"><a href="#代码复现" class="headerlink" title="代码复现"></a>代码复现<a class="heading-anchor" href="#代码复现" aria-hidden="true"></a></h3><ol>
<li><a href="https://github.com/pararthshah/qa-memnn/blob/master/memnn_theano_v3.py">Theano 版本的代码</a></li>
</ol>
<h2 id="End-To-End-Memory-Networks" class="heading-control"><a href="#End-To-End-Memory-Networks" class="headerlink" title="End-To-End Memory Networks"></a>End-To-End Memory Networks<a class="heading-anchor" href="#End-To-End-Memory-Networks" aria-hidden="true"></a></h2><h3 id="论文简介-1" class="heading-control"><a href="#论文简介-1" class="headerlink" title="论文简介"></a>论文简介<a class="heading-anchor" href="#论文简介-1" aria-hidden="true"></a></h3><ul>
<li><a href="https://arxiv.org/pdf/1503.08895v5.pdf">End-To-End Memory Networks</a>，Facebook AI Research</li>
</ul>
<p>这是 Facebook AI 在 Memory networks 后的续作。上文记忆网络介绍模型并非端到端的 QA 训练，该论文 End-To-End Memory Networks 就在上文的基础上进行端到端的模型构建，减少生成答案时需要事实依据的监督项，在实际应用中应用意义更大。</p>
<p><strong>End to end</strong>：一端输入我的原始数据，一端输出我想得到的结果。只关心输入和输出，中间的步骤全部都不管。</p>
<h3 id="具体实现-1" class="heading-control"><a href="#具体实现-1" class="headerlink" title="具体实现"></a>具体实现<a class="heading-anchor" href="#具体实现-1" aria-hidden="true"></a></h3><p><img src="https://i.loli.net/2018/12/03/5c051a6d2d277.png" alt></p>
<p>这一篇文章提到一个更加具体但是复杂一点的模型如上图所示。</p>
<p>模型主要的参数包括 A,B,C,W 四个矩阵，其中 A,B,C 三个矩阵就是 embedding 矩阵，主要是将输入文本和 Question 编码成词向量，W 是最终的输出矩阵。从上图可以看出，对于输入的句子 s 分别会使用 A 和 C 进行编码得到 Input 和 Output 的记忆模块，Input 用来跟 Question 编码得到的向量相乘得到每句话跟 q 的相关性，Output 则与该相关性进行加权求和得到输出向量。然后再加上 q 并传入最终的输出层。</p>
<h4 id="输入输出模块" class="heading-control"><a href="#输入输出模块" class="headerlink" title="输入输出模块"></a>输入输出模块<a class="heading-anchor" href="#输入输出模块" aria-hidden="true"></a></h4><p>通过把每句话压缩成一个向量对应到 memory 中的一个 slot（上图中的蓝色或者黄色竖条），将输入的文本转化成向量并保存在 memory 中 (通过词向量得到句向量)。论文中提出了两种编码方式，BoW 和位置编码：</p>
<ul>
<li>BoW：直接把词向量加起来，会丢失位置关系。</li>
<li>位置编码：认为不同位置的单词的权重是不一样的，然后对各个单词的词向量按照不同位置权重进行加权求和得到句子表示。</li>
</ul>
<p>输入模块把输入文本编码为向量，保存在 Input 和 Output 两个模块中，Input 模块用于跟 Question 相互作用得到各个 memory slot 与问题的相关程度，使用 Output 模块的信息产生输出。</p>
<ul>
<li>Input 模块：将 Question 经过输入模块编码成一个向量 u，与 $m<em>{i}$ 维度相同，然后将其与每个 $m</em>{i}$ 点积得到两个向量的相似度，在通过一个 softmax 函数进行归一化得到 $p<em>{i}$，$p</em>{i}$ 就是 q 与 $m_{i}$ 的相关性指标。</li>
<li>Output 模块：对其中各个记忆 ci 按照 pi 进行加权求和即可得到模型的输出向量 o。</li>
</ul>
<h4 id="Response模块" class="heading-control"><a href="#Response模块" class="headerlink" title="Response模块"></a>Response 模块<a class="heading-anchor" href="#Response模块" aria-hidden="true"></a></h4><p>Response 模块主要是根据输出向量 o 和问题向量 q 产生最终的答案。其结合 o 和 q 两个向量的和与 W 相乘在经过一个 softmax 函数产生各个单词是答案的概率，值最高的单词就是答案。并且使用交叉熵损失函数最为目标函数进行训练。</p>
<h4 id="多层模型" class="heading-control"><a href="#多层模型" class="headerlink" title="多层模型"></a>多层模型<a class="heading-anchor" href="#多层模型" aria-hidden="true"></a></h4><p>将多个单层模型进行 stack 在一块，结构图如下所示：</p>
<p><img src="https://i.loli.net/2018/12/03/5c052a23169f2.png" alt></p>
<p>上面几层的输入就是下层 o 和 u 的和。至于各层的参数选择，论文中提出了两种方法（主要是为了减少参数量，如果每层参数都不同的话会导致参数很多难以训练）。</p>
<ul>
<li><strong>Adjacent</strong>：这种方法让相邻层之间的 A=C。也就是说 $A {k}+1=C_{k}$，此外 W 等于顶层的 C，B 等于底层的 A，这样就减少了一半的参数量。</li>
<li><strong>Layer-wise（RNN-like)</strong>：与 RNN 相似，采用完全共享参数的方法，即各层之间参数均相等。由于这样会大大的减少参数量导致模型效果变差，所以提出一种改进方法，即令 $u<em>{k+1}=u</em>{k}+o_{k}$，也就是在每一层之间加一个线性映射矩阵 H。</li>
</ul>
<h4 id="论文公式" class="heading-control"><a href="#论文公式" class="headerlink" title="论文公式"></a>论文公式<a class="heading-anchor" href="#论文公式" aria-hidden="true"></a></h4><p>具体的公式如下：</p>
<p><img src="https://i.loli.net/2018/12/03/5c051dd1571df.png" alt></p>
<h3 id="代码实现" class="heading-control"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现<a class="heading-anchor" href="#代码实现" aria-hidden="true"></a></h3><ol>
<li><a href="https://github.com/domluna/memn2n">End-To-End Memory Network using Tensorflow</a></li>
</ol>
<h2 id="Dynamic-Memory-Networks" class="heading-control"><a href="#Dynamic-Memory-Networks" class="headerlink" title="Dynamic Memory Networks"></a>Dynamic Memory Networks<a class="heading-anchor" href="#Dynamic-Memory-Networks" aria-hidden="true"></a></h2><h3 id="论文简介-2" class="heading-control"><a href="#论文简介-2" class="headerlink" title="论文简介"></a>论文简介<a class="heading-anchor" href="#论文简介-2" aria-hidden="true"></a></h3><ul>
<li><a href="https://arxiv.org/pdf/1506.07285v3.pdf">Ask Me Anything: Dynamic Memory Networks for Natural Language Processing</a></li>
</ul>
<p>论文中说 NLP 中很多任务都可以归结为 QA 问题，所以本文的 DMN 模型以 QA 为基础进行训练，但是可以扩展到很多别的任务中，包括序列标注、分类、翻译等等。</p>
<h3 id="具体实现-2" class="heading-control"><a href="#具体实现-2" class="headerlink" title="具体实现"></a>具体实现<a class="heading-anchor" href="#具体实现-2" aria-hidden="true"></a></h3><p><img src="https://i.loli.net/2018/12/03/5c0531196f1d0.png" alt></p>
</body></html>]]></content>
      <categories>
        <category>项目</category>
      </categories>
      <tags>
        <tag>NLP</tag>
        <tag>QA</tag>
      </tags>
  </entry>
  <entry>
    <title>ReadDocs</title>
    <url>/post/41605.html</url>
    <content><![CDATA[<html><head><link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script></head><body><p><img src="https://i.loli.net/2018/08/18/5b777783c90fb.png" alt></p>
<h2 id="搭建工具" class="heading-control"><a href="#搭建工具" class="headerlink" title="搭建工具"></a>搭建工具<a class="heading-anchor" href="#搭建工具" aria-hidden="true"></a></h2><p>Sphinx 是一个基于 Python 的文档生成工具，最早只是用来生成 Python 官方文档，随着工具的完善，越来越多的知名的项目也用他来生成文档，甚至完全可以用他来写书。例如我最近看到 tensorly 等库都有包括 Github 主页，Jupyter Notebook, 以及 Read the Docs 代码 API 说明。<br><a id="more"></a> </p>
<h2 id="搭建步骤" class="heading-control"><a href="#搭建步骤" class="headerlink" title="搭建步骤"></a>搭建步骤<a class="heading-anchor" href="#搭建步骤" aria-hidden="true"></a></h2><ol>
<li><code>pip install sphinx sphinx-autobuild sphinx_rtd_theme</code> </li>
<li>新建一个 Github 仓库，并拉到本地，仓库名设为项目名。 </li>
<li>命令行进入仓库本地目录，输入 <code>sphinx-quickstart</code>   <img src="https://i.loli.net/2018/08/18/5b7779ccd6682.png" alt>   这个是项目的配置文件，这里要改动的是项目名，版本，以及语言。其他的默认即可。生成下面目录结构。   <img src="https://i.loli.net/2018/08/18/5b777a3abcaba.png" alt> </li>
<li>进入目录下面的 conf.py，可以看到我们刚才的配置的内容就是在配置这个文件。下面继续修改。   首先把源文件改为使用习惯的 Markdown 文件，<code>source_suffix = \'.md\'</code>   然后把主题换了，<code>html_theme = \'sphinx_rtd_theme\'。</code>   最后把 LaTeX 内容配置一下。   <img src="https://i.loli.net/2018/08/18/5b777b951d64b.png" alt> </li>
<li>进入命令行 make html   <img src="https://i.loli.net/2018/08/18/5b777bdb70e1a.png" alt> </li>
<li>提交目录到 Github。 </li>
<li>打开 Read the Docs, 并使用 Github 注册，导入项目并点击阅读文档即可。   也可以在 GitHub 里选择仓库，然后依次点击 Setting => Webhooks & Service => Add service => ReadTheDocs, 激活这个选项。</li>
</ol>
<h2 id="参考文章" class="heading-control"><a href="#参考文章" class="headerlink" title="参考文章"></a>参考文章<a class="heading-anchor" href="#参考文章" aria-hidden="true"></a></h2><ol>
<li><a href="https://zh-sphinx-doc.readthedocs.io/en/latest/contents.html">sphinx 中文翻译手册</a> </li>
<li><a href="http://dwz.cn/wEwYNed3">http://dwz.cn/wEwYNed3</a> </li>
<li><a href="https://www.jianshu.com/p/78e9e1b8553a">https://www.jianshu.com/p/78e9e1b8553a</a></li>
</ol>
</body></html>]]></content>
      <categories>
        <category>工具</category>
      </categories>
      <tags>
        <tag>ReadDocs</tag>
      </tags>
  </entry>
  <entry>
    <title>《Retrieve-and-Read,Multi-task Learning of Information Retrieval and Reading Comprehension》的 References 和 Citations 梳理</title>
    <url>/post/37274.html</url>
    <content><![CDATA[<html><head><link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script></head><body><h3 id="Citations" class="heading-control"><a href="#Citations" class="headerlink" title="Citations"></a>Citations<a class="heading-anchor" href="#Citations" aria-hidden="true"></a></h3><ol>
<li><p><a href="https://www.semanticscholar.org/paper/Retrieval-Based-Open-Domain-Question-Answering%3A-The-Jiang/77c55d771bca41ee7361dba3a27fbc883bba65bf">Retrieval-Based Open-Domain Question Answering: Exploring The Impact on The Retrieval Component across Datasets》</a><br> 论文动机：主要探讨的是数据集对 IR 组件的影响，有一些比较好的综述性的内容：</p>
<p> <img src="https://s2.ax1x.com/2019/11/25/MjZU9P.png" alt="MjZU9P.png" style="zoom:67%;"></p>
 <a id="more"></a>
<p> <img src="https://s2.ax1x.com/2019/11/25/MjZR3V.png" alt="MjZR3V.png" style="zoom:67%;"></p>
<p> <img src="https://s2.ax1x.com/2019/11/25/MjZOgK.png" alt="MjZOgK.png" style="zoom:67%;"></p>
<p> Text Span 的评估指标：</p>
<blockquote>
<p>For text-span questions whose answer is string(s), we need to compare the predicted string(s) with the ground truth answer string(s) (i.e., the correct answer). RCstyle QA task generally uses evaluation metrics Exact Match (EM) and F1 score (F1) proposed by Rajpurkar et al. [94] for text-span questions [104, 116]. EM assigns credit 1.0 to questions whose predicted answer is exactly the same as the ground truth answer and 0.0 otherwise, so the computation of EM is the same as the metric Accuracy but for different categories of RC-style QA. F1 measures the average word overlap between the predicted answer and the ground truth answer. These two answers are both considered as bag of words with lower cases and ignored the punctuation and articles “a”, “an” and “the”. For example, the answer “The Question Answering System” is treated as a set of words {question, answering, system}. Therefore, F1 of each text-span question can be computed at word-level by Equation 2.2  </p>
<script type="math/tex; mode=display">
F 1=\frac{2 \times \text {Precision} \times \text {Recall}}{\text {Precision}+\text {Recall}}</script><script type="math/tex; mode=display">
\begin{array}{l}{\text { Precision }=\frac{\#\{\text { predicted words }\} \cap\{\text { ground truth words }\}}{\text { # predicted words }}} \\ {\text { Recall }=\frac{\#\{\text { predicted words }\} \cap\{\text { ground truth words }\}}{\# \text { ground truth words }}}\end{array}</script></blockquote>
</li>
<li><p><a href="https://arxiv.org/abs/1910.07000">《Answering Complex Open-domain Questions Through Iterative Query Generation》</a><br><strong>论文信息</strong>：EMNLP-IJCNLP 2019. Xiaowen Lin, Leo Mehr, and Zijian Wang contributed equally. <a href="https://github.com/qipeng/golden-retriever">GitHub</a><br><strong>论文动机</strong>：对于当前的单步检索和问答系统（QA）来说，回答 “Armada 的作者的哪部小说将改编为 Steven Spielberg 的故事片？” 等问题具有挑战性。因为该问题很少包含有关缺失实体（此处为作者）的可检索线索。要回答这一问题，需要进行多跳推理，其中必须收集有关缺失实体（或事实）的信息才能继续进行推理。<br><strong>论文主要实现方法</strong>：设计了一个 IR，在读取上下文和检索更多支持文档之间进行迭代，以回答开放域多跳问题。主要是对问题进行分解，涉及到新的问题的生成。<br><img src="https://s2.ax1x.com/2019/11/12/M81WEq.md.png" alt="M81WEq.md.png"></p>
</li>
<li><p>《Answering while Summarizing: Multi-task Learning for Multi-hop QA with Evidence Extraction》</p>
<p><strong>论文信息</strong>：ACL2019<br><strong>论文动机</strong>： 使用阅读理解（RC）进行的问答（QA）引起了广泛的关注。这项研究的重点是可解释的多跳问答的解释性，该任务要求系统通过推理和收集不连贯的参考文本来返回带有证据句的答案。本文提出了用于查询证据的查询集中提取器（QFE）模型，并将多任务学习与 QA 模型结合使用。QFE 模型是受到提取摘要模型的启发，与现有的独立提取每个证据语句的方法相比，该方法使用带有注意机制的 RNN 对问题语句进行顺序提取证据语句，因此使得 QFE 能够考虑证据句子之间的依存关系，并覆盖问题句子中的重要信息。实验结果表明，简单 RC 基线模型的 QFE 在 HotpotQA 上获得了最高的证据提取得分。<br><strong>论文主要实现方法</strong>：第一张图讲的是整体的模型设计，重点是添加了一个 QFE 模块。模型设计包括首先做 Q 和 CEmbedding，之后分别输入 Bi RNN 编码，编码的信息进行 Bi Attention，再输入 Bi RNN，经过 self Attention 之后，输出经过 Bi RNN 和全连接层输出。(这里我怀疑他这个模型可能会 Train 不动，堆了太多层 RNN，训练时间大大增加)。第二张图是 QFE 模块，说是来自于一篇生成的文章，看不太懂，跳过。</p>
<p><img src="https://s2.ax1x.com/2019/11/25/MXjiLT.md.png" alt="MXjiLT.md.png" style="zoom:67%;"></p>
<p><img src="https://s2.ax1x.com/2019/11/25/MXjW60.md.png" alt="MXjW60.md.png" style="zoom:67%;"></p>
</li>
<li><p>《Context Attentive Document Ranking and Query Suggestion》</p>
<p><strong>论文信息</strong>：  SIGIR 2019 </p>
<p><strong>论文动机</strong>： 提出了一种上下文感知的 Ranking 模型，用于用户的搜索并增强检索性能。引入了两级分层递归神经网络，通过联合优化两个伴随检索任务：文档排名和查询建议，来学习单个查询，搜索任务和相应的依存关系的搜索上下文表示。为了确定搜索上下文和用户正在进行的搜索活动之间的变量依赖关系结构，在递归状态的两个级别上都引入了注意力机制。针对基线方法进行了很多实验比较，并进行了消融分析，证实了提出的方法在搜索任务中非常有价值。</p>
<p><strong>论文主要实现方法</strong>： </p>
<p><img src="https://s2.ax1x.com/2019/11/25/Mj98Tf.png" alt="Mj98Tf.png" style="zoom:67%;"></p>
</li>
<li><p>《 Effective Subword Segmentation for Text Comprehension 》</p>
<p><strong>论文信息</strong>：IEEE/ACM Transactions On Audio, Speech, And Language Processing2018</p>
<p><strong>论文动机</strong>：表征学习是机器阅读理解和推理的基础。在最新模型中（应该指的是 BERT 系列），字符级表示已被广泛采用，用来缓解有效表示稀有或复杂单词的问题。但是，由于忽略单词内部连续字符的语言连贯性，字符本身并不是用于表示或者叫词嵌入的自然最小语言单元。本文提出了一个通用的子词增强嵌入框架，用于学习和组成计算派生的子词级表示形式。</p>
<p><strong>论文主要实现方法</strong>：<img src="https://s2.ax1x.com/2019/11/25/MjCL5T.png" alt="MjCL5T.png" style="zoom:67%;"></p>
</li>
<li><p>《Learning to Attend On Essential Terms: An Enhanced Retriever-Reader Model for Open-domain Question Answering 》</p>
<p><strong>论文信息</strong>：NAACL-HLT2018</p>
<p><strong>论文动机</strong>：</p>
<p><strong>论文主要实现方法</strong>：</p>
</li>
<li><p>《 Multi-style Generative Reading Comprehension》</p>
<p><strong>论文信息</strong>：ACL2019</p>
<p><strong>论文动机</strong>：</p>
<p><strong>论文主要实现方法</strong>：</p>
</li>
<li><p>《Real-Time Open-Domain Question Answering with Dense-Sparse Phrase Index》</p>
<p><strong>论文信息</strong>：ACL2019</p>
<p><strong>论文动机</strong>：</p>
<p><strong>论文主要实现方法</strong>：</p>
</li>
<li><p>《Regularization Advantages of Multilingual Neural Language Models for Low Resource Domains》</p>
<p><strong>论文信息</strong>：</p>
<p><strong>论文动机</strong>：</p>
<p><strong>论文主要实现方法</strong>：</p>
</li>
<li><p>《Controlling Risk of Web Question Answering》</p>
<p><strong>论文信息</strong>： SIGIR2019</p>
<p><strong>论文动机</strong>： 问答（QA）已成为现代搜索系统中必不可少的组件，它可以通过提供对用户信息需求的直接答案来显着改善用户的搜索体验。可以通过在检索的段落上应用机器阅读理解（MRC）模型以提取有关搜索查询的答案来实现。随着深度学习技术的发展，最新的深度方法已实现了最先进的 MRC 性能。但是，现有的关于 MRC 的研究很少涉及预测不确定性问题，即 MRC 模型的预测错误的可能性有多大，从而导致现实 Web QA 应用程序中的风险不可控制。在这项工作中，我们首先对 Web 质量检查的风险进行了深入的调查。然后，我们介绍一个新颖的风险控制框架，它由使用探查思路进行不确定性估计的合格模型和用于选择性输出的决策模型组成。为了进行评估，我们引入了与风险相关的指标，而不是 MRC 中的传统 EM 和 F1 来评估具有风险意识的 Web 质量检查。实际的 Web 质量检查数据集和 MRC 学术基准收集的经验结果证明了我们方法的有效性。 </p>
<p><strong>论文主要实现方法</strong>：<img src="https://s2.ax1x.com/2019/11/25/MjPQdP.png" alt="MjPQdP.png"></p>
<p><img src="https://s2.ax1x.com/2019/11/25/MjiPyj.png" alt="MjiPyj.png"></p>
<p><img src="https://s2.ax1x.com/2019/11/25/Mji8Tx.png" alt="Mji8Tx.png" style="zoom:50%;"></p>
</li>
</ol>
</body></html>]]></content>
      <tags>
        <tag>论文阅读</tag>
      </tags>
  </entry>
  <entry>
    <title>Seq2Seq 模型的构建</title>
    <url>/post/33231.html</url>
    <content><![CDATA[<html><head><link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script></head><body><p><img src="https://i.loli.net/2018/10/29/5bd707b5b65d4.png" alt="1_1I2tTjCkMHlQ-r73eRn4ZQ.png"><br>Seq2Seq 是指一般的序列到序列的转换任务，特点是输入序列和输出序列是不对齐的，比如机器翻译、自动文摘等等。</p>
<a id="more"></a>
<p>假如原句子为 X=(a,b,c,d,e,f)，目标输出为 Y=(P,Q,R,S,T), 则 Seq2Seq 模型如下：</p>
<p><img src="https://spaces.ac.cn/usr/uploads/2018/09/3140019013.png" alt="seq2seq"></p>
<p>模型的工作原理如下；</p>
<ol>
<li><p>Encoder 部分首先通过 RNN 及其变种 (LSTM、GRU) 等进行编码，讲输入序列编码成一个<strong>定长向量</strong> c，认为这个向量包含了句子的所有信息。得到 c 有多种方式，最简单的方法就是把 Encoder 的最后一个隐状态赋值给 c，还可以对最后的隐状态做一个变换得到 c，也可以对所有的隐状态做变换。</p>
<p><img src="https://i.loli.net/2018/10/24/5bcfdae375792.png" alt="yKJ3iJU.png"></p>
</li>
<li><p>Decoder 的任务就是把这个<strong>定长向量</strong>进行解码：在给定 Target 序列的前一个字符，通过训练来预测下一个字符。</p>
</li>
</ol>
<p><img src="https://i.loli.net/2018/10/24/5bcfdae3d0915.png" alt="TfGooCw.png"></p>
<p>还有一种做法是将 c 当做每一步的输入：</p>
<p><img src="https://i.loli.net/2018/10/24/5bcfdb22cda92.jpg" alt="3.jpg"></p>
<ol>
<li>对于问答系统来说输入包括 Questions 和 Documents 两部分，所以要在输入进 Decoder 的时候要进行融合，可以选择 Concatenate。</li>
</ol>
<h3 id="Input准备" class="heading-control"><a href="#Input准备" class="headerlink" title="Input准备"></a>Input 准备<a class="heading-anchor" href="#Input准备" aria-hidden="true"></a></h3><h3 id="Embedding层" class="heading-control"><a href="#Embedding层" class="headerlink" title="Embedding层"></a>Embedding 层<a class="heading-anchor" href="#Embedding层" aria-hidden="true"></a></h3><figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> Sequential</span><br><span class="line"><span class="keyword">from</span> keras.layers.embeddings <span class="keyword">import</span> Embedding</span><br><span class="line"></span><br><span class="line">model = Sequential()</span><br><span class="line">model.add(Embedding(input_dim,output_dim, init=<span class="string">'uniform'</span>, input_length=<span class="literal">None</span>, weights=<span class="literal">None</span>, W_regularizer=<span class="literal">None</span>, W_constraint=<span class="literal">None</span>, mask_zero=<span class="literal">False</span>))</span><br></pre></td></tr></tbody></table></figure>
<p>Embedding 有一个参数 mask_zero, 参数的含义是当输入样本的长度不一样时候，首先对数据进行 padding 补 0，然后引入 keras 的 Masking 层，它能自动对 0 值进行过滤。 </p>
<p><img src="https://i.loli.net/2018/10/22/5bcd7c2573733.jpeg" alt="20180509155008234.jpeg"></p>
<p>比如上面这个 3x4 大小的张量，是经过补零 padding 的。我希望做 axis=1 的 meanpooling，则第一行应该是 (10+20)/2，第二行应该是 (10+20+30)/3，第三行应该是 (10+20+30+40)/4。这个时候应该是 mask_zero=True 的，过滤掉 0 值。</p>
<h3 id="Dropout" class="heading-control"><a href="#Dropout" class="headerlink" title="Dropout"></a>Dropout<a class="heading-anchor" href="#Dropout" aria-hidden="true"></a></h3><p>SpatialDropout1D 和 Dropout 的比较。</p>
<h3 id="Encoder层" class="heading-control"><a href="#Encoder层" class="headerlink" title="Encoder层"></a>Encoder 层<a class="heading-anchor" href="#Encoder层" aria-hidden="true"></a></h3><figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line">keras.layers.recurrent.LSTM(units, activation=<span class="string">'tanh'</span>, recurrent_activation=<span class="string">'hard_sigmoid'</span>, use_bias=<span class="literal">True</span>, kernel_initializer=<span class="string">'glorot_uniform'</span>, recurrent_initializer=<span class="string">'orthogonal'</span>, bias_initializer=<span class="string">'zeros'</span>, unit_forget_bias=<span class="literal">True</span>, kernel_regularizer=<span class="literal">None</span>, recurrent_regularizer=<span class="literal">None</span>, bias_regularizer=<span class="literal">None</span>, activity_regularizer=<span class="literal">None</span>, kernel_constraint=<span class="literal">None</span>, recurrent_constraint=<span class="literal">None</span>, bias_constraint=<span class="literal">None</span>, dropout=<span class="number">0.0</span>, recurrent_dropout=<span class="number">0.0</span>)</span><br></pre></td></tr></tbody></table></figure>
<p>在 Keras 所有的 RNN 中，包括 simpleRNN, LSTM, GRU 等等，输入输出数据格式如下：</p>
<p><img src="https://i.loli.net/2018/10/24/5bd0659510862.png" alt="605010.png"></p>
<p>例如这样一个数据，总共 100 条句子，每个句子 20 个词，每个词都由一个 80 维的向量表示，输入数据的大小应当是（100, 20, 80）。因此各个维度的含义如下 ：</p>
<ul>
<li>samples 为样本数目</li>
<li> timesteps 为句子长度（padding 后的 max_len）</li>
<li>input_dim 为数据的维度</li>
</ul>
<p>下面的三个代码写法是等价的。</p>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="comment">#model.add(LSTM(input_dim=1, output_dim=6,input_length=10, return_sequences=True))</span></span><br><span class="line"><span class="comment">#model.add(LSTM(6, input_dim=1, input_length=10, return_sequences=True))</span></span><br><span class="line">model.add(LSTM(<span class="number">6</span>, input_shape=(<span class="number">10</span>, <span class="number">1</span>),return_sequences=<span class="literal">True</span>))</span><br></pre></td></tr></tbody></table></figure>
<p><img src="https://i.loli.net/2018/10/21/5bcc44890bbdf.png" alt="20170828113807895.png"></p>
<p>return_sequences 的含义是每个 LSTM 单元是否返回输出，我们可以通过上面的图来解释 return_sequences：</p>
<ul>
<li>return_sequences=True，我们可以获得 5 个 128 维的词向量 V1’..V5’ </li>
<li>return_sequences=False，只输出最后一个红色的词向量 </li>
</ul>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line">model = Sequential()</span><br><span class="line">model.add(LSTM(<span class="number">128</span>, input_dim=<span class="number">64</span>, input_length=<span class="number">5</span>, return_sequences=<span class="literal">True</span>))</span><br></pre></td></tr></tbody></table></figure>
<h4 id="Concatenate" class="heading-control"><a href="#Concatenate" class="headerlink" title="Concatenate"></a>Concatenate<a class="heading-anchor" href="#Concatenate" aria-hidden="true"></a></h4><p>作用是把两个张量在某个维度级联起来。参考下面这个链接。<a href="https://nbviewer.jupyter.org/github/anhhh11/DeepLearning/blob/master/Concanate_two_layer_keras.ipynb">https://nbviewer.jupyter.org/github/anhhh11/DeepLearning/blob/master/Concanate_two_layer_keras.ipynb</a></p>
<h4 id="TimeDistributed" class="heading-control"><a href="#TimeDistributed" class="headerlink" title="TimeDistributed"></a>TimeDistributed<a class="heading-anchor" href="#TimeDistributed" aria-hidden="true"></a></h4><p>考虑一批 32 个样本，其中每个样本是一个由 16 个维度组成的 10 个向量的序列。该层的批输入形状然后 <code>(32, 10, 16)</code>。TimeDistributed 层的作用就是把 Dense 层应用到这 10 个具体的向量上，对每一个向量进行了一个 Dense 操作，假设是下面这段代码：</p>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line">model = Sequential()</span><br><span class="line">model.add(TimeDistributed(Dense(<span class="number">8</span>), input_shape=(<span class="number">10</span>, <span class="number">16</span>)))</span><br></pre></td></tr></tbody></table></figure>
<p>输出还是 10 个向量，但是输出的维度由 16 变成了 8，也就是（32,10,8）。</p>
<h3 id="LSTM模型分析" class="heading-control"><a href="#LSTM模型分析" class="headerlink" title="LSTM模型分析"></a>LSTM 模型分析<a class="heading-anchor" href="#LSTM模型分析" aria-hidden="true"></a></h3><p>下图是 LSTM 的一个典型内部示意图，有三个门：输入门、输出门和遗忘门。</p>
<p><img src="http://file.elecfans.com/web1/M00/63/24/pIYBAFuQetKACYz6AAAv-m33kc8472.png" alt="img"></p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">符号</th>
<th style="text-align:center">含义</th>
<th style="text-align:center">符号</th>
<th style="text-align:center">含义</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center"> C(t-1)</td>
<td style="text-align:center"> 上一个 LSTM 单元的记忆</td>
<td style="text-align:center"> C(t)</td>
<td style="text-align:center"> 新更新的记忆</td>
</tr>
<tr>
<td style="text-align:center"> h(t-1)</td>
<td style="text-align:center"> 上一个 LSTM 单元的输出</td>
<td style="text-align:center"> h(t)</td>
<td style="text-align:center"> 当前输出</td>
</tr>
<tr>
<td style="text-align:center"> σ</td>
<td style="text-align:center">Sigmoid 层</td>
<td style="text-align:center"> X</td>
<td style="text-align:center"> 信息</td>
</tr>
<tr>
<td style="text-align:center"> tanh</td>
<td style="text-align:center">tanh 层</td>
<td style="text-align:center"> +</td>
<td style="text-align:center"> 增加信息</td>
</tr>
</tbody>
</table>
</div>
<h3 id="Attention" class="heading-control"><a href="#Attention" class="headerlink" title="Attention"></a>Attention<a class="heading-anchor" href="#Attention" aria-hidden="true"></a></h3><p><img src="https://spaces.ac.cn/usr/uploads/2018/09/494964564.png" alt="å¸¦Attentionçseq2seq"></p>
<p>Attention 的思想是：每一步解码时，不仅仅要结合 encoder 编码出来的固定大小的向量（通读全文），还要往回查阅原来的每一个字词（精读局部），两者配合来决定当前步的输出。</p>
<p><img src="https://i.loli.net/2018/10/24/5bcfdb4b02304.png" alt="L21aLHb.png"></p>
<h3 id="对话系统" class="heading-control"><a href="#对话系统" class="headerlink" title="对话系统"></a>对话系统<a class="heading-anchor" href="#对话系统" aria-hidden="true"></a></h3><p><img src="https://i.loli.net/2018/10/21/5bcc76f857700.jpg" alt="20170912103504059.jpg"></p>
<h3 id="训练技巧" class="heading-control"><a href="#训练技巧" class="headerlink" title="训练技巧"></a>训练技巧<a class="heading-anchor" href="#训练技巧" aria-hidden="true"></a></h3><p>1. 刚开始内存跑满了，分析了一下原因主要是词典太大，所以对词典进行了词频分析，选出指定大小的常用词，其他低频词语用 <code><UNK></code> 替换，这样就可以大大减少模型的参数量。<br><img src="https://i.loli.net/2018/10/24/5bcfdb856b444.png" alt="深度截图_deepin-terminal_20181023130415.png"></p>
<p>2. 采用 pickle 序列化中间结果，一般来说生成的二进制数据比较大，但是能大大加快读取速度。</p>
<p>3. 代码结构函数化，使用面向对象的方式编程，增强代码的可复用性。</p>
<p>4. 通过小批量数据验证代码的正确性，方便程序的调试。</p>
<p>5. 使用 Pycharm 远程连接服务器来跑代码，结合计算资源和开发工具，提升开发效率。</p>
<h3 id="存在的问题" class="heading-control"><a href="#存在的问题" class="headerlink" title="存在的问题"></a>存在的问题<a class="heading-anchor" href="#存在的问题" aria-hidden="true"></a></h3><p>1. 没有使用 batch 来小批量输入数据。</p>
<p>2. 训练和预测使用的 decoder 结果不同，编写循环的预测 decoder。</p>
<p>3. 前端的 word2vec 词向量和最新的 ElMo 模型的对比实验。</p>
<p>4. 对比不同的 decoder 结构对模型的影响程度。</p>
<p>5. 了解 Attention 原理，在模型中加入 Attention 来提高准确率。</p>
</body></html>]]></content>
      <categories>
        <category>项目</category>
      </categories>
      <tags>
        <tag>Seq2Seq</tag>
      </tags>
  </entry>
  <entry>
    <title>TFIDF 做文档检索</title>
    <url>/post/50690.html</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>一个简单的 TFIDF 做文档检索，还可以继续加一些功能：</p>
<ul>
<li>[ ] 增加评估指标</li>
<li> [ ] 增加新的模型，例如 BM25</li>
</ul>
<p>实现效果：<br><img src="https://i.loli.net/2020/08/29/6QkVe9hKGjo8Hx5.png" alt="image-20200829163450810"><br><a id="more"></a><br></p><figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">TF_IDF_Model</span>(<span class="params">object</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, documents_list</span>):</span></span><br><span class="line">        self.documents_list = documents_list</span><br><span class="line">        self.token_documents_list = [jieba.lcut(doc) <span class="keyword">for</span> doc <span class="keyword">in</span> document_list]</span><br><span class="line">        <span class="comment"># 文本总个数</span></span><br><span class="line">        self.documents_number = len(self.token_documents_list)</span><br><span class="line">        <span class="comment"># 存储每个文本中没个词的词频</span></span><br><span class="line">        self.tf = []</span><br><span class="line">        <span class="comment"># 存储每个词汇的逆文档频率</span></span><br><span class="line">        self.idf = {}</span><br><span class="line">        <span class="comment"># 类初始化</span></span><br><span class="line">        self.init()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">init</span>(<span class="params">self</span>):</span></span><br><span class="line">        df = {}</span><br><span class="line">        <span class="keyword">for</span> document <span class="keyword">in</span> self.token_documents_list:</span><br><span class="line">            temp = {}</span><br><span class="line">            <span class="keyword">for</span> word <span class="keyword">in</span> document:</span><br><span class="line">                <span class="comment"># 存储每个文档中每个词的词频</span></span><br><span class="line">                temp[word] = temp.get(word, <span class="number">0</span>) + <span class="number">1</span> / len(document)</span><br><span class="line">            self.tf.append(temp)</span><br><span class="line">            <span class="keyword">for</span> key <span class="keyword">in</span> temp.keys():</span><br><span class="line">                df[key] = df.get(key, <span class="number">0</span>) + <span class="number">1</span></span><br><span class="line">        <span class="keyword">for</span> key, value <span class="keyword">in</span> df.items():</span><br><span class="line">            <span class="comment"># 每个词的逆文档频率</span></span><br><span class="line">            self.idf[key] = np.log(self.documents_number / (value + <span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_score</span>(<span class="params">self, index, query</span>):</span></span><br><span class="line">        score = <span class="number">0.0</span></span><br><span class="line">        <span class="keyword">for</span> q <span class="keyword">in</span> query:</span><br><span class="line">            <span class="keyword">if</span> q <span class="keyword">not</span> <span class="keyword">in</span> self.tf[index]:</span><br><span class="line">                <span class="keyword">continue</span></span><br><span class="line">            score += self.tf[index][q] * self.idf[q]</span><br><span class="line">        <span class="keyword">return</span> score</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_documents_score</span>(<span class="params">self, query</span>):</span></span><br><span class="line">        score_list = []</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(self.documents_number):</span><br><span class="line">            score_list.append(self.get_score(i, query))</span><br><span class="line">        <span class="keyword">return</span> score_list</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_rank_documents</span>(<span class="params">self, query</span>):</span></span><br><span class="line">        query = jieba.lcut(query)</span><br><span class="line">        score_list = []</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(self.documents_number):</span><br><span class="line">            score_list.append(self.get_score(i, query))</span><br><span class="line">        rank_score = list(np.sort(score_list))</span><br><span class="line">        rank_index = np.argsort(score_list)</span><br><span class="line">        rank_documents = [self.documents_list[i] <span class="keyword">for</span> i <span class="keyword">in</span> rank_index]</span><br><span class="line">        <span class="keyword">return</span> list(zip(rank_documents, rank_score))[::<span class="number">-1</span>]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    <span class="keyword">import</span> jieba_fast <span class="keyword">as</span> jieba  <span class="comment"># 使用jieba cpython 版本, 加快分词速度</span></span><br><span class="line">    <span class="keyword">from</span> pprint <span class="keyword">import</span> pprint</span><br><span class="line">    <span class="keyword">import</span> logging</span><br><span class="line"></span><br><span class="line">    jieba.setLogLevel(logging.INFO)  <span class="comment"># 关闭jieba分词log</span></span><br><span class="line"></span><br><span class="line">    document_list = [<span class="string">"行政机关强行解除行政协议造成损失，如何索取赔偿？"</span>,</span><br><span class="line">                     <span class="string">"借钱给朋友到期不还得什么时候可以起诉？怎么起诉？"</span>,</span><br><span class="line">                     <span class="string">"我在微信上被骗了，请问被骗多少钱才可以立案？"</span>,</span><br><span class="line">                     <span class="string">"公民对于选举委员会对选民的资格申诉的处理决定不服，能不能去法院起诉吗？"</span>,</span><br><span class="line">                     <span class="string">"有人走私两万元，怎么处置他？"</span>,</span><br><span class="line">                     <span class="string">"法律上餐具、饮具集中消毒服务单位的责任是不是对消毒餐具、饮具进行检验？"</span>]</span><br><span class="line">    tf_idf_model = TF_IDF_Model(document_list)</span><br><span class="line"></span><br><span class="line">    query = <span class="string">"走私了两万元，在法律上应该怎么量刑？"</span></span><br><span class="line">    scores = tf_idf_model.get_documents_score(query)</span><br><span class="line">    print(<span class="string">"query: "</span>, query)</span><br><span class="line">    print(<span class="string">"score: "</span>, scores)</span><br><span class="line">    rank_result = tf_idf_model.get_rank_documents(query)</span><br><span class="line">    pprint(rank_result)</span><br><span class="line"></span><br></pre></td></tr></tbody></table></figure><p></p>
]]></content>
      <tags>
        <tag>TFIDF</tag>
      </tags>
  </entry>
  <entry>
    <title>THU 深圳研究院：大数据机器学习</title>
    <url>/post/64988.html</url>
    <content><![CDATA[<html><head><link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script></head><body><h2 id="课程介绍" class="heading-control"><a href="#课程介绍" class="headerlink" title="课程介绍"></a>课程介绍<a class="heading-anchor" href="#课程介绍" aria-hidden="true"></a></h2><p><img src="https://i.loli.net/2019/09/24/RAgXiHG8ZdlDSek.png" alt><br>B 站视频：<a href="https://www.bilibili.com/video/av67224054">https://www.bilibili.com/video/av67224054</a><br><a id="more"></a></p>
<h2 id="Lecture-1：引言" class="heading-control"><a href="#Lecture-1：引言" class="headerlink" title="Lecture 1：引言"></a>Lecture 1：引言<a class="heading-anchor" href="#Lecture-1：引言" aria-hidden="true"></a></h2><ul>
<li>2012 年 Alnet 在 ImageNet 上错误率大幅度下降</li>
<li> 2016 年 3 月 Alphgo 战胜人类围棋高手</li>
<li>机器学习设计概率论，凸分析，统计学等</li>
<li>数据挖掘主要使用机器学习进行分析数据，并使用数据库来管理数据</li>
<li> 1980 年，在 CMU 召开了第一次 ICML 会议，标志着机器学习的诞生</li>
</ul>
<p>五本推荐的书：</p>
<ul>
<li>统计学习方法</li>
<li>深度学习（花书）</li>
<li>模式识别与机器学习（PRML）</li>
<li>机器学习实战</li>
<li>机器学习（西瓜书）</li>
</ul>
<h2 id="Lecture-2：机器学习基本概念" class="heading-control"><a href="#Lecture-2：机器学习基本概念" class="headerlink" title="Lecture 2：机器学习基本概念"></a>Lecture 2：机器学习基本概念<a class="heading-anchor" href="#Lecture-2：机器学习基本概念" aria-hidden="true"></a></h2><h3 id="监督学习和假设空间" class="heading-control"><a href="#监督学习和假设空间" class="headerlink" title="监督学习和假设空间"></a>监督学习和假设空间<a class="heading-anchor" href="#监督学习和假设空间" aria-hidden="true"></a></h3><p>监督学习目的是学习一个由输入到输出的映射，称为模型，模型集合就是假设空间。<br><img src="https://i.loli.net/2019/09/24/cLwgkd5h2BQVpx8.png" alt></p>
<h3 id="学习三要素" class="heading-control"><a href="#学习三要素" class="headerlink" title="学习三要素"></a>学习三要素<a class="heading-anchor" href="#学习三要素" aria-hidden="true"></a></h3><p>三要素：模型 + 策略 + 最优化方法</p>
<h4 id="策略" class="heading-control"><a href="#策略" class="headerlink" title="策略"></a>策略<a class="heading-anchor" href="#策略" aria-hidden="true"></a></h4><p>详细数据推导可参考<a href="https://www.cnblogs.com/jeromeblog/p/3749193.html">这篇文章</a></p>
<ul>
<li><strong>损失函数</strong>：定义在单个训练样本的损失，也就是就算一个样本的损失</li>
<li><strong>代价函数</strong>：定义在整个训练集整体的误差描述，也就是所有样本的误差的总和，也就是损失函数的总和。</li>
<li><strong>经验风险</strong>：代价函数的平均，定义在训练集上，是局部的，是现实的，可求的。</li>
<li><strong>期望风险</strong>：表示的是决策函数对所有的样本的预测能力的大小，是全局的，是理想化的，不可求的。</li>
<li><strong>经验风险最小化</strong>：极大似然估计是经验风险最小化的一个例子，当模型是条件概率分布，损失函数是对数损失函数的时候，经验风险最小化等价于极大似然估计。样本容量很小，经验风险最小化的效果未必好，会产生过拟合。</li>
<li><strong>结构风险最小化</strong>：经验风险＋正则化项表示结构风险，是防止过拟合的策略。。贝叶斯的最大后验概率估计就是结构风险最小化的例子。当模型是条件概率分布，损失函数是对数损失函数、模型复杂度由模型的先验概率表示时，结构风险最小化等价于最大后验概率估计。</li>
</ul>
<p><img src="https://i.loli.net/2019/09/24/123ZRoyMVwJEUeO.png" alt></p>
<h3 id="奥卡姆剃刀定理" class="heading-control"><a href="#奥卡姆剃刀定理" class="headerlink" title="奥卡姆剃刀定理"></a>奥卡姆剃刀定理<a class="heading-anchor" href="#奥卡姆剃刀定理" aria-hidden="true"></a></h3><p><strong>定理</strong>：简单的是最好的</p>
<h3 id="没有免费的午餐定理" class="heading-control"><a href="#没有免费的午餐定理" class="headerlink" title="没有免费的午餐定理"></a>没有免费的午餐定理<a class="heading-anchor" href="#没有免费的午餐定理" aria-hidden="true"></a></h3><p><strong>定理</strong>：没有一种机器学习算法是适用于所有情况的。<br>这个定理本质上就是告诉我们不要奢望能找到一种算法对所有问题都适用。注意，这个定理有个前提：“对于所有机器学习问题，且所有问题同等重要”。而我们实际情况不是这样，我们在实际中往往更关心的是一个特定的机器学习问题，对于特定的问题，特定的机器学习算法效果自然比瞎猜更好。</p>
<h3 id="训练误差和测试误差" class="heading-control"><a href="#训练误差和测试误差" class="headerlink" title="训练误差和测试误差"></a>训练误差和测试误差<a class="heading-anchor" href="#训练误差和测试误差" aria-hidden="true"></a></h3><p>机器学习模型在训练数据集上表现出的误差叫做<strong>训练误差</strong>，在任意一个测试数据样本上表现出的误差的期望值叫做<strong>泛化误差</strong>。<br>统计学习理论的一个假设是：训练数据集和测试数据集里的每一个数据样本都是从同一个概率分布中相互独立地生成出的（独立同分布假设）。<br>一个重要结论是：训练误差的降低不一定意味着泛化误差的降低。机器学习既需要降低训练误差，又需要降低泛化误差。</p>
<h3 id="过拟合" class="heading-control"><a href="#过拟合" class="headerlink" title="过拟合"></a>过拟合<a class="heading-anchor" href="#过拟合" aria-hidden="true"></a></h3><p><strong>欠拟合</strong>：模型无法得到较低的训练误差<br><strong>过拟合</strong>：机器学习模型的训练误差远小于其在测试数据集上的误差。<br><img src="https://i.loli.net/2019/09/24/FOnkSqRUK6wDhH8.png" alt></p>
<h3 id="正则化" class="heading-control"><a href="#正则化" class="headerlink" title="正则化"></a>正则化<a class="heading-anchor" href="#正则化" aria-hidden="true"></a></h3><p>虽然增大训练数据集可能会减轻过拟合，但是获取额外的训练数据往往代价高昂。这里介绍过拟合问题的常用方法：正则化。<br>L1 和 L2 正则化在神经网络中的运用和其他机器学习方法一样，通过约束权重的 L1 范数或者 L2 范数，对模型的复杂度进行惩罚，来减小模型在训练数据集上的过拟合问题。<br><img src="https://i.loli.net/2019/09/24/ZjnQIlq4uPr2XBz.png" alt></p>
<h3 id="生成模型和判别模型" class="heading-control"><a href="#生成模型和判别模型" class="headerlink" title="生成模型和判别模型"></a>生成模型和判别模型<a class="heading-anchor" href="#生成模型和判别模型" aria-hidden="true"></a></h3><p><strong>判别式模型举例</strong>：要确定一个羊是山羊还是绵羊，用判别模型的方法是从历史数据中学习到模型，然后通过提取这只羊的特征来预测出这只羊是山羊的概率，是绵羊的概率。</p>
<p><strong>生成式模型举例</strong>：利用生成模型是根据山羊的特征首先学习出一个山羊的模型，然后根据绵羊的特征学习出一个绵羊的模型，然后从这只羊中提取特征，放到山羊模型中看概率是多少，在放到绵羊模型中看概率是多少，哪个大就是哪个。</p>
<p>上面例子说明，判别式模型是根据一只羊的特征可以直接给出这只羊的概率（比如 logistic regression，这概率大于 0.5 时则为正例，否则为反例），而生成式模型是要都试一试，最大的概率的那个就是最后结果。</p>
<p><strong>比较</strong><br><img src="https://i.loli.net/2019/09/24/Qy3GlTKCi8EzIBX.png" alt><br><strong>生成模型</strong><br><img src="https://i.loli.net/2019/09/24/yqS2Hk8jDr9hiAB.png" alt><br><strong>判别模型</strong><br><img src="https://i.loli.net/2019/09/24/YoVuQwlHKZ4hic6.png" alt></p>
</body></html>]]></content>
      <tags>
        <tag>大数据机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title>TensorFlow 2.0 Question Answering</title>
    <url>/post/24791.html</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><ol>
<li><strong>GPT-2 and BERT Pretrained Weights (pytorch)</strong><br>You can find weights for BERT and GPT-2 models (pytorch), ready to be used with HuggingFace’s Transformers or your own models：<br> <a href="https://www.kaggle.com/abhishek/bert-pytorch">https://www.kaggle.com/abhishek/bert-pytorch</a><br> <a href="https://www.kaggle.com/abhishek/gpt2-pytorch">https://www.kaggle.com/abhishek/gpt2-pytorch</a></li>
<li><strong> 一个 NLP 数据增广的库</strong>：<a href="https://github.com/makcedward/nlpaug">nlpaug</a></li>
<li><strong>One of the best collection of papers about BERT</strong><br><a href="https://github.com/thunlp/PLMpapers">https://github.com/thunlp/PLMpapers</a></li>
</ol>
]]></content>
      <tags>
        <tag>学习</tag>
      </tags>
  </entry>
  <entry>
    <title>TensorFlow 内核剖析</title>
    <url>/post/36490.html</url>
    <content><![CDATA[<html><head><link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script></head><body><p>这是我找的一个 Tensorflow 的书，作者是<a href="https://www.jianshu.com/p/fda4ae1e2547">刘光聪</a>。书写的非常不错，我也借此机会学习一波。书中的 TensorFlow 使用的是 1.2 版本，目前来说算是很新的。<br>作者在前言里面写到：</p>
<blockquote>
<p>这是一本剖析 TensorFlow 内核工作原理的书籍，并非讲述如何使用 TensorFlow 构建机器学习模型，也不会讲述应用 TensorFlow 的最佳实践。本书将通过剖析 TensorFlow 源代码的方式，揭示 TensorFlow 的系统架构、领域模型、工作原理、及其实现模式等相关内容，以便揭示内在的知识。</p>
</blockquote>
<p>可以看出，这必定是一本干货满满的书。<a href="https://github.com/horance-liu/tensorflow-internals-errors">Github</a>。<br><a id="more"></a></p>
<h1 id="基础知识" class="heading-control"><a href="#基础知识" class="headerlink" title="基础知识"></a>基础知识<a class="heading-anchor" href="#基础知识" aria-hidden="true"></a></h1><h2 id="基础知识-1" class="heading-control"><a href="#基础知识-1" class="headerlink" title="基础知识"></a>基础知识<a class="heading-anchor" href="#基础知识-1" aria-hidden="true"></a></h2><h3 id="前身" class="heading-control"><a href="#前身" class="headerlink" title="前身"></a>前身<a class="heading-anchor" href="#前身" aria-hidden="true"></a></h3><p>Tensorflow 的前身是 DistBelief。DistBelief 使用参数服务器 (Parameter Server, 常称为 PS) 的系统架构，训练作业包括两个分离的进程：无状态的 Worker 进程，用于模型的训练；有状态的 PS 进程，用于维护模型的参数。如图 1-1 所示，在分布式训练过程中，各个模型副本异步地从 PS 上拉取训练参数 w，当完成一步迭代运算后，推送参数的梯度 ∆w 到 PS 上去，并完成参数的更新。<br><img src="/TensorFlow-内核剖析/20181206081413795.png" alt><br>由于其缺乏足够的灵活性和可扩展性，TensorFlow 应运而生，开创了深度学习领域的新纪元。</p>
<h3 id="设计原则" class="heading-control"><a href="#设计原则" class="headerlink" title="设计原则"></a>设计原则<a class="heading-anchor" href="#设计原则" aria-hidden="true"></a></h3><ul>
<li>延迟计算：图的构造与执行分离，并推迟计算图的执行过程；</li>
<li>原子 OP：OP 是最小的抽象计算单元，支持构造复杂的网络模型；</li>
<li>抽象设备：支持 CPU, GPU, ASIC 多种异构计算设备类型；</li>
<li>抽象任务：基于任务的 PS，对新的优化算法和网络模型具有良好的可扩展性。</li>
</ul>
<h3 id="优势" class="heading-control"><a href="#优势" class="headerlink" title="优势"></a>优势<a class="heading-anchor" href="#优势" aria-hidden="true"></a></h3><p><img src="/TensorFlow-内核剖析/20181206081721146.png" alt></p>
<h3 id="开源" class="heading-control"><a href="#开源" class="headerlink" title="开源"></a>开源<a class="heading-anchor" href="#开源" aria-hidden="true"></a></h3><p>2015.11 正式开源，并产生巨大影响。<br><img src="/TensorFlow-内核剖析/20181206081832279.png" alt></p>
<h2 id="编程环境" class="heading-control"><a href="#编程环境" class="headerlink" title="编程环境"></a>编程环境<a class="heading-anchor" href="#编程环境" aria-hidden="true"></a></h2><h3 id="代码统计" class="heading-control"><a href="#代码统计" class="headerlink" title="代码统计"></a>代码统计<a class="heading-anchor" href="#代码统计" aria-hidden="true"></a></h3><p>截止当前最新发布的 1.4 版本，TensorFlow 代码库拥有大约 100 万代码。其中，包括 53 万行 C/C++ 代码，37 万行 Python 代码，而且代码规模在不断膨胀之中。其中，Python 提供的 API 是最完善的；相比之下，其他编程语言的 API 尚未成熟，甚至处于起步阶段。<br><img src="/TensorFlow-内核剖析/20181206081932974.png" alt></p>
<h3 id="技术栈" class="heading-control"><a href="#技术栈" class="headerlink" title="技术栈"></a>技术栈<a class="heading-anchor" href="#技术栈" aria-hidden="true"></a></h3><p><img src="/TensorFlow-内核剖析/20181206082100122.png" alt></p>
<h2 id="基础概念" class="heading-control"><a href="#基础概念" class="headerlink" title="基础概念"></a>基础概念<a class="heading-anchor" href="#基础概念" aria-hidden="true"></a></h2><h3 id="Softmax" class="heading-control"><a href="#Softmax" class="headerlink" title="Softmax"></a>Softmax<a class="heading-anchor" href="#Softmax" aria-hidden="true"></a></h3><h3 id="交叉熵" class="heading-control"><a href="#交叉熵" class="headerlink" title="交叉熵"></a>交叉熵<a class="heading-anchor" href="#交叉熵" aria-hidden="true"></a></h3><h3 id="Placeholder" class="heading-control"><a href="#Placeholder" class="headerlink" title="Placeholder"></a>Placeholder<a class="heading-anchor" href="#Placeholder" aria-hidden="true"></a></h3></body></html>]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>Tensorflow</tag>
      </tags>
  </entry>
  <entry>
    <title>20190730180327</title>
    <url>/post/35857.html</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script>]]></content>
  </entry>
  <entry>
    <title>Tensorflow Object_Detection</title>
    <url>/post/43522.html</url>
    <content><![CDATA[<html><head><link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script></head><body><p><img src="https://i.loli.net/2018/10/28/5bd5c32f8f6ef.png" alt="下载 (1).png"></p>
<h2 id="准备" class="heading-control"><a href="#准备" class="headerlink" title="准备"></a>准备<a class="heading-anchor" href="#准备" aria-hidden="true"></a></h2><p>准备大体按照官方<a href="https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/installation.md">文档</a>进行。<br><a id="more"></a></p>
<h3 id="检查库" class="heading-control"><a href="#检查库" class="headerlink" title="检查库"></a>检查库<a class="heading-anchor" href="#检查库" aria-hidden="true"></a></h3><figure class="highlight shell"><table><tbody><tr><td class="code"><pre><span class="line">sudo apt-get install protobuf-compiler python-pil python-lxml python-tk</span><br><span class="line">pip install --user Cython</span><br><span class="line">pip install --user contextlib2</span><br><span class="line">pip install --user jupyter</span><br><span class="line">pip install --user matplotlib</span><br></pre></td></tr></tbody></table></figure>
<h3 id="COCO-API-installation" class="heading-control"><a href="#COCO-API-installation" class="headerlink" title="COCO API installation"></a>COCO API installation<a class="heading-anchor" href="#COCO-API-installation" aria-hidden="true"></a></h3><figure class="highlight shell"><table><tbody><tr><td class="code"><pre><span class="line">pip install git+https://github.com/philferriere/cocoapi.git#subdirectory=PythonAPI</span><br></pre></td></tr></tbody></table></figure>
<h3 id="下载Object-Detection" class="heading-control"><a href="#下载Object-Detection" class="headerlink" title="下载Object_Detection"></a>下载 Object_Detection<a class="heading-anchor" href="#下载Object-Detection" aria-hidden="true"></a></h3><p><a href="https://github.com/tensorflow/models/tree/master/research/object_detection?1540622178700">官方链接</a>在这里。这里我没有下载整个 models，在 linux 下面只下载了 Object_Detection。方法如下：</p>
<ol>
<li><p>首先安装 svn</p>
<figure class="highlight shell"><table><tbody><tr><td class="code"><pre><span class="line">sudo apt-get install subversion</span><br></pre></td></tr></tbody></table></figure>
</li>
<li><p>确定导出的文件夹 URL, 比如 <a href="https://github.com/tensorflow/models/tree/master/research/object_detection?1540622178700">https://github.com/tensorflow/models/tree/master/research/object_detection?1540622178700</a> 。</p>
</li>
<li>首先改为：<a href="https://github.com/tensorflow/models/tree/master/research/object_detection">https://github.com/tensorflow/models/tree/master/research/object_detection</a><br>然后把其中的 tree/master 替换成 trunk。</li>
<li>导出 <figure class="highlight shell"><table><tbody><tr><td class="code"><pre><span class="line">svn checkout https://github.com/tensorflow/models/trunk/research/object_detection</span><br></pre></td></tr></tbody></table></figure>
Reference：<a href="https://blog.csdn.net/why19940926/article/details/78580067">https://blog.csdn.net/why19940926/article/details/78580067</a><h3 id="Protobuf-Compilation" class="heading-control"><a href="#Protobuf-Compilation" class="headerlink" title="Protobuf Compilation"></a>Protobuf Compilation<a class="heading-anchor" href="#Protobuf-Compilation" aria-hidden="true"></a></h3>文档里面有详细说明。这里我把 Protobuf 直接加入了路径，执行下面的操作：<figure class="highlight shell"><table><tbody><tr><td class="code"><pre><span class="line">protoc object_detection/protos/*.proto --python_out=.</span><br></pre></td></tr></tbody></table></figure>
最后看到 protos 文件夹下有 python 文件生成，如图；<br><img src="https://i.loli.net/2018/10/27/5bd40b533b996.png" alt><h3 id="Add-Libraries-to-PYTHONPATH" class="heading-control"><a href="#Add-Libraries-to-PYTHONPATH" class="headerlink" title="Add Libraries to PYTHONPATH"></a>Add Libraries to PYTHONPATH<a class="heading-anchor" href="#Add-Libraries-to-PYTHONPATH" aria-hidden="true"></a></h3>在 Object_Detection 的上一级目录下执行下面代码：<figure class="highlight shell"><table><tbody><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> From tensorflow/models/research/</span></span><br><span class="line">export PYTHONPATH=$PYTHONPATH:`pwd`:`pwd`/slim</span><br></pre></td></tr></tbody></table></figure>
注意这种方式只对当前命令窗口有效，关掉窗口还是要重新输入，最好的方案是直接把包放到目录下去，比如我的：<code>/home/sunyan/anaconda3/lib/python3.6/site-packages/object_detection</code><h3 id="Testing-the-Installation" class="heading-control"><a href="#Testing-the-Installation" class="headerlink" title="Testing the Installation"></a>Testing the Installation<a class="heading-anchor" href="#Testing-the-Installation" aria-hidden="true"></a></h3>还是在 Object_Detection 的上一级目录下执行下面代码 <figure class="highlight shell"><table><tbody><tr><td class="code"><pre><span class="line">python object_detection/builders/model_builder_test.py</span><br></pre></td></tr></tbody></table></figure>
果不其然，报错了。我就知道没那么容易装好 (┑(￣Д ￣)┍)。<br><img src="https://i.loli.net/2018/10/27/5bd40d9a38c15.png" alt><br>说是 TF 里面没有 keras 模块，但我知道最新的是有的，所以检查一下 TF 的版本:<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line">print(tf.__versin__)</span><br><span class="line"><span class="comment">#1.3.0</span></span><br></pre></td></tr></tbody></table></figure>
查了一下 TF1.4 版本才有的 keras, 所以通过 pip 升级到最新的版本，这里我选择 TF==1.5：<figure class="highlight shell"><table><tbody><tr><td class="code"><pre><span class="line">pip install tensorflow-gpu==1.5</span><br></pre></td></tr></tbody></table></figure>
重新执行，依旧有报错；<br><img src="https://i.loli.net/2018/10/27/5bd40f111f18d.png" alt><br>然而我使用 pycharm 打开后运行通过了，有点奇怪。<h3 id="运行notebook测试" class="heading-control"><a href="#运行notebook测试" class="headerlink" title="运行notebook测试"></a>运行 notebook 测试<a class="heading-anchor" href="#运行notebook测试" aria-hidden="true"></a></h3>因为我装的是 TF1.5，所以首先把里面的这句话删掉：<figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">if StrictVersion(tf.__version__) < StrictVersion('1.9.0'):</span><br><span class="line">  raise ImportError('Please upgrade your TensorFlow installation to v1.9.* or later!')</span><br></pre></td></tr></tbody></table></figure>
第一次运行需要下载模型，下载时间比较久，第二次就不需要了，可以把下载的代码注释掉。<figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line"># opener = urllib.request.URLopener()</span><br><span class="line"># opener.retrieve(DOWNLOAD_BASE + MODEL_FILE, MODEL_FILE)</span><br></pre></td></tr></tbody></table></figure>
当然也可以自己下载，<a class="btn" href="https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md">
            <i class="fa fa-download fa-lg fa-fw"></i>点击下载模型
          </a>，经测试，自己下载的速度还快一点。<br>(2018.10.28 Update: 我电脑的 GPU 环境被我搞乱了，目前只能在 CPU 上运行了)<br>(2018.10.28 Update: 问题找到了，conda 安装 TF GPU 版本的会自动下载 cuda 和 cudnn，不需要额外安装了)</li>
</ol>
</body></html>]]></content>
      <categories>
        <category>项目</category>
      </categories>
      <tags>
        <tag>目标检测</tag>
      </tags>
  </entry>
  <entry>
    <title>Tqdm 实时显示 Loss 和 Acc</title>
    <url>/post/61076.html</url>
    <content><![CDATA[<html><head><link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script></head><body><h3 id="代码示例" class="heading-control"><a href="#代码示例" class="headerlink" title="代码示例"></a>代码示例<a class="heading-anchor" href="#代码示例" aria-hidden="true"></a></h3><figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> random <span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">from</span> time <span class="keyword">import</span> sleep</span><br><span class="line"><span class="keyword">from</span> tqdm <span class="keyword">import</span> tqdm</span><br><span class="line"></span><br><span class="line">epochs = <span class="number">2</span></span><br><span class="line">train_data_num = <span class="number">10</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(epochs):</span><br><span class="line">    <span class="keyword">with</span> tqdm(total=train_data_num) <span class="keyword">as</span> t:</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> range(<span class="number">10</span>):</span><br><span class="line">            <span class="comment"># Description will be displayed on the left</span></span><br><span class="line">            t.set_description(<span class="string">'Epoch %i'</span> % i)</span><br><span class="line">            <span class="comment"># Postfix will be displayed on the right,</span></span><br><span class="line">            <span class="comment"># formatted automatically based on argument's datatype</span></span><br><span class="line">            t.set_postfix(loss=random(),acc=random())</span><br><span class="line">            sleep(<span class="number">0.1</span>)</span><br><span class="line">            t.update(<span class="number">1</span>)</span><br></pre></td></tr></tbody></table></figure>
<p>输出结果：<br></p><figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line">Epoch <span class="number">0</span>: <span class="number">100</span>%|██████████| <span class="number">10</span>/<span class="number">10</span> [<span class="number">00</span>:<span class="number">01</span><<span class="number">00</span>:<span class="number">00</span>,  <span class="number">9.94</span>it/s, acc=<span class="number">0.0863</span>, loss=<span class="number">0.999</span>]</span><br><span class="line">Epoch <span class="number">1</span>: <span class="number">100</span>%|██████████| <span class="number">10</span>/<span class="number">10</span> [<span class="number">00</span>:<span class="number">01</span><<span class="number">00</span>:<span class="number">00</span>,  <span class="number">9.93</span>it/s, acc=<span class="number">0.459</span>, loss=<span class="number">0.921</span>]</span><br></pre></td></tr></tbody></table></figure><p></p>
</body></html>]]></content>
      <tags>
        <tag>Tqdm</tag>
      </tags>
  </entry>
  <entry>
    <title>ULMFiT 进行文本分类</title>
    <url>/post/61903.html</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script>]]></content>
  </entry>
  <entry>
    <title>VSCode 配置远程开发</title>
    <url>/post/22891.html</url>
    <content><![CDATA[<html><head><link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script></head><body><h2 id="通过-PowerShell-安装-OpenSSH" class="heading-control"><a href="#通过-PowerShell-安装-OpenSSH" class="headerlink" title="通过 PowerShell 安装 OpenSSH"></a>通过 PowerShell 安装 OpenSSH<a class="heading-anchor" href="#通过-PowerShell-安装-OpenSSH" aria-hidden="true"></a></h2><p><a href="https://docs.microsoft.com/zh-cn/windows-server/administration/openssh/openssh_install_firstuse">来自微软官方文档</a>。 若要使用 PowerShell 安装 OpenSSH，请首先以管理员身份启动 PowerShell。 若要确保 OpenSSH 功能可以安装，请执行以下操作：</p>
<figure class="highlight powershell"><table><tbody><tr><td class="code"><pre><span class="line"><span class="comment"># 输入这句话</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">Get-WindowsCapability</span> <span class="literal">-Online</span> | ? Name <span class="operator">-like</span> <span class="string">'OpenSSH*'</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># This should return the following output:</span></span><br><span class="line"></span><br><span class="line">Name  : OpenSSH.Client~~~~<span class="number">0.0</span>.<span class="number">1.0</span></span><br><span class="line">State : NotPresent</span><br><span class="line">Name  : OpenSSH.Server~~~~<span class="number">0.0</span>.<span class="number">1.0</span></span><br><span class="line">State : NotPresent</span><br></pre></td></tr></tbody></table></figure>
<a id="more"></a>
<p>然后安装服务器和 / 或客户端功能：</p>
<figure class="highlight powershell"><table><tbody><tr><td class="code"><pre><span class="line"><span class="comment"># Install the OpenSSH Client</span></span><br><span class="line"><span class="built_in">Add-WindowsCapability</span> <span class="literal">-Online</span> <span class="literal">-Name</span> OpenSSH.Client~~~~<span class="number">0.0</span>.<span class="number">1.0</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Install the OpenSSH Server</span></span><br><span class="line"><span class="built_in">Add-WindowsCapability</span> <span class="literal">-Online</span> <span class="literal">-Name</span> OpenSSH.Server~~~~<span class="number">0.0</span>.<span class="number">1.0</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Both of these should return the following output:</span></span><br><span class="line"></span><br><span class="line">Path          :</span><br><span class="line">Online        : True</span><br><span class="line">RestartNeeded : False</span><br></pre></td></tr></tbody></table></figure>
<p>命令行中输入 <code>ssh</code> 命令验证：</p>
<figure class="highlight powershell"><table><tbody><tr><td class="code"><pre><span class="line">[<span class="type">input</span>]: ssh</span><br><span class="line">[<span class="type">out</span>]: usage: ssh [-<span class="number">46</span><span class="type">sdasdsfsf</span>] [-<span class="type">B</span> <span class="type">bind_interface</span>]</span><br><span class="line">           [-<span class="type">b</span> <span class="type">bind_address</span>] [-<span class="type">c</span> <span class="type">cipher_spec</span>] [-<span class="type">D</span> [<span class="type">bind_address</span>:]<span class="type">port</span>]</span><br><span class="line">           [-<span class="type">E</span> <span class="type">log_file</span>] [-<span class="type">e</span> <span class="type">escape_char</span>] [-<span class="type">F</span> <span class="type">configfile</span>] [-<span class="type">I</span> <span class="type">pkcs11</span>]</span><br><span class="line">           [-<span class="type">i</span> <span class="type">identity_file</span>] [-<span class="type">J</span> [<span class="type">user</span><span class="selector-tag">@</span>]<span class="type">host</span>[:<span class="type">port</span>]] [-<span class="type">L</span> <span class="type">address</span>]</span><br><span class="line">           [-<span class="type">l</span> <span class="type">login_name</span>] [-<span class="type">m</span> <span class="type">mac_spec</span>] [-<span class="type">O</span> <span class="type">ctl_cmd</span>] [-<span class="type">o</span> <span class="type">option</span>] [-<span class="type">p</span> <span class="type">port</span>]</span><br><span class="line">           [-<span class="type">Q</span> <span class="type">query_option</span>] [-<span class="type">R</span> <span class="type">address</span>] [-<span class="type">S</span> <span class="type">ctl_path</span>] [-<span class="type">W</span> <span class="type">host</span>:<span class="type">port</span>]</span><br><span class="line">           [-<span class="type">w</span> <span class="type">local_tun</span>[:<span class="type">remote_tun</span>]] destination [<span class="type">command</span>]</span><br></pre></td></tr></tbody></table></figure>
<p>查看 openssh 路径</p>
<p><img src="https://i.loli.net/2020/08/29/UNowsM7Ky9BPb2j.png" alt="image-20200829152810966"></p>
<blockquote>
<p>这里显示了两个路径，使用 openssh 的那个</p>
</blockquote>
<h2 id="SSH-服务器的初始配置" class="heading-control"><a href="#SSH-服务器的初始配置" class="headerlink" title="SSH 服务器的初始配置"></a>SSH 服务器的初始配置<a class="heading-anchor" href="#SSH-服务器的初始配置" aria-hidden="true"></a></h2><figure class="highlight powershell"><table><tbody><tr><td class="code"><pre><span class="line"><span class="built_in">Set-Service</span> ssh<span class="literal">-agent</span> <span class="literal">-StartupType</span> Automatic</span><br><span class="line"><span class="built_in">Start-Service</span> ssh<span class="literal">-agent</span></span><br><span class="line"><span class="built_in">Get-Service</span> ssh<span class="literal">-agent</span></span><br></pre></td></tr></tbody></table></figure>
<h2 id="配置VScode-Remote-SSH" class="heading-control"><a href="#配置VScode-Remote-SSH" class="headerlink" title="配置VScode Remote-SSH"></a>配置 VScode Remote-SSH<a class="heading-anchor" href="#配置VScode-Remote-SSH" aria-hidden="true"></a></h2><h3 id="安装插件" class="heading-control"><a href="#安装插件" class="headerlink" title="安装插件"></a>安装插件<a class="heading-anchor" href="#安装插件" aria-hidden="true"></a></h3><p>在界面左边的 Extensions 里搜索 ssh，找到 Remote-SSH 插件安装。</p>
<p><img src="https://i.loli.net/2020/08/29/kOMhLKCsIqfNoz3.png" alt="image-20200829153839323"></p>
<h3 id="编辑配置" class="heading-control"><a href="#编辑配置" class="headerlink" title="编辑配置"></a>编辑配置<a class="heading-anchor" href="#编辑配置" aria-hidden="true"></a></h3><p>安装完成后，选择左边的 SSH 插件按钮，点击 Connections 的齿轮选择 ssh_config 的路径，选择第一项的.ssh/config 就可以，回车即可编辑此文件。</p>
<p><img src="https://i.loli.net/2020/08/29/4mHNFvrS9MfOjpJ.png" alt="image-20200829153930281"></p>
<p>假设你的跳板机的 ip 地址为 A，目标机器的地址为 B，那么在你的 config 中写下如下配置并保存：</p>
<figure class="highlight shell"><table><tbody><tr><td class="code"><pre><span class="line">Host JumpMachine</span><br><span class="line">    # 跳板机的ip地址</span><br><span class="line">    HostName A</span><br><span class="line">    # 你跳板机的用户名</span><br><span class="line">    User username</span><br><span class="line">    # 跳板机登录端口 </span><br><span class="line">    Port 22</span><br><span class="line"></span><br><span class="line">Host TargetMachine</span><br><span class="line">    # 目标机的ip地址</span><br><span class="line">    HostName B</span><br><span class="line">    # 你目标机的用户名</span><br><span class="line">    User username</span><br><span class="line">    # 目标机登录端口 </span><br><span class="line">    Port 8080</span><br><span class="line">    IdentityFile ~/.ssh/jump_rsa</span><br><span class="line">    ProxyCommand "openssh的安装路径"\ssh.exe -W %h:%p JumpMachine</span><br></pre></td></tr></tbody></table></figure>
<p>其中”openssh 的安装路径” 因人而异（我的 openssh 的安装路径为 <code>C:\Windows\System32\OpenSSH\ssh.exe</code>）, IdentityFile 是公司给的私钥，原始名称为 id_rsa，可以复制到.ssh，若不想覆盖原 private key,  重命名为 jump_rsa。</p>
<p>如果一切正常的话，此时你在 SSH Targets 里就可以找到 TargetMachine 啦！点击旁边的小加号就可以开始远程连接啦！</p>
<p><img src="https://i.loli.net/2020/08/29/aoPCzh8wYBML4VA.jpg" alt="img"></p>
<h2 id="私钥文件权限太高" class="heading-control"><a href="#私钥文件权限太高" class="headerlink" title="私钥文件权限太高"></a>私钥文件权限太高<a class="heading-anchor" href="#私钥文件权限太高" aria-hidden="true"></a></h2><p>如果 SSH 连接时提示私钥文件权限太高，可以按如下方式修改文件属性。</p>
<p>右击 <code>jump_rsa</code>, 中文系统：属性→安全→高级→禁止继承→删除所有继承→确定<br>如果系统是英文：<br>Properties -> Security -> Advanced -> Disable Inheritance -> Remove all inherited permissions from this object。</p>
<p><img src="https://i.loli.net/2020/08/29/baMv6uTHQqGWyDc.png" alt="image-20200829160306077"></p>
<p>然后重新添加用户，可以设置如下 3 项：</p>
<p><img src="https://i.loli.net/2020/08/29/2Zl6yFC9mLjw7Kh.png" alt="image-20200829160749900"></p>
<p>设置方式：</p>
<p><img src="https://i.loli.net/2020/08/29/Wap6ubrSYLvy43g.png" alt="image-20200829160902719"></p>
<h2 id="免密登录" class="heading-control"><a href="#免密登录" class="headerlink" title="免密登录"></a>免密登录<a class="heading-anchor" href="#免密登录" aria-hidden="true"></a></h2><p>若不想每次输入 passphrase 可以通过 openssl 指令生成解密之后的 id_rsa 并且修改 IdentityFile 成解密之后的文件即可 </p>
<p><code>openssl rsa -in ~/.ssh/jump_rsa -out ~/.ssh/jump_rsa_new</code></p>
<blockquote>
<p>注意需要输入密码，然后替换掉 ssh 配置里面的 jump_rsa</p>
</blockquote>
<h2 id="C-开发和软连接" class="heading-control"><a href="#C-开发和软连接" class="headerlink" title="C++开发和软连接"></a>C++ 开发和软连接<a class="heading-anchor" href="#C-开发和软连接" aria-hidden="true"></a></h2><p>安装插件 C/C++</p>
<p><img src="https://i.loli.net/2020/08/29/4PasoT1e79fwtNj.png" alt="image-20200829161219572"></p>
<p>vscode 的 cpp 解析文件默认放在～/.vscode-cpptools 目录，由于开发机上的 /home 目录分区空间非常小，vscode 生成的文件比较大，很容易导致空间占满，可以软连接到其他目录。</p>
<p>主要转移两个，一个是.vscode-server，另一个是.cache，这占用两个空间比较大。</p>
<ol>
<li>首先把这两个文件 mv 到新的存储区域，例如新建目录 <code>/data1/sunyan/work</code>, 然后 <code>mv /home/sunyan/.cache /data1/sunyan/work/</code>，然后 <code>mv /home/sunyan/.vscode-server /data1/sunyan/work/</code>。(注意不要关闭 vscode)</li>
<li><p> 然后建立软连接：</p>
<figure class="highlight shell"><table><tbody><tr><td class="code"><pre><span class="line">ln -s  /data1/sunyan/work/.vscode-server /home/sunyan/.vscode-server</span><br><span class="line">ln -s  /data1/sunyan/work/.cache /home/sunyan/.cache </span><br></pre></td></tr></tbody></table></figure>
</li>
<li><p>建立好之后：</p>
<p><img src="https://i.loli.net/2020/08/29/BpV9CfoP8Dzm62k.png" alt="image-20200829175456795"></p>
</li>
</ol>
<blockquote>
<p>小技巧 1：<code>du -sh .[!.]** ** | sort -hr</code>，显示所有隐藏文件和非隐藏文件的大小并根据占用空间排序</p>
<p>小技巧 2：<code>ls -lah</code> , 显示目录信息，-a 显示所有文件及目录 (ls 内定将文件名或目录名称开头为”.” 的视为隐藏档，不会列出)，-l 除文件名称外，亦将文件型态、权限、拥有者、文件大小等资讯详细列出，h 选项的意思是生成的结果有利于人看，也就是不是用默认的 byte 做单位，而是根据实际情况调整。</p>
</blockquote>
</body></html>]]></content>
      <tags>
        <tag>远程开发</tag>
      </tags>
  </entry>
  <entry>
    <title>cdqa 使用方法</title>
    <url>/post/37942.html</url>
    <content><![CDATA[<html><head><link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script></head><body><p>文档：<a href="https://github.com/cdqa-suite/cdQA">Closed Domain Question Answering</a></p>
<h2 id="使用CSV文件数据" class="heading-control"><a href="#使用CSV文件数据" class="headerlink" title="使用CSV文件数据"></a>使用 CSV 文件数据<a class="heading-anchor" href="#使用CSV文件数据" aria-hidden="true"></a></h2><figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> ast <span class="keyword">import</span> literal_eval</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> cdqa.utils.filters <span class="keyword">import</span> filter_paragraphs</span><br><span class="line"><span class="keyword">from</span> cdqa.pipeline <span class="keyword">import</span> QAPipeline</span><br><span class="line"></span><br><span class="line"><span class="comment">#Download pre-trained reader model and example dataset</span></span><br><span class="line"><span class="keyword">from</span> cdqa.utils.download <span class="keyword">import</span> download_model, download_bnpp_data</span><br><span class="line">download_bnpp_data(dir=<span class="string">'./data/bnpp_newsroom_v1.1/'</span>)</span><br><span class="line">download_model(model=<span class="string">'bert-squad_1.1'</span>, dir=<span class="string">'./models'</span>)</span><br><span class="line"><span class="comment">#Visualize the dataset</span></span><br><span class="line">df = pd.read_csv(<span class="string">'./data/bnpp_newsroom_v1.1/bnpp_newsroom-v1.1.csv'</span>, converters={<span class="string">'paragraphs'</span>: literal_eval})</span><br><span class="line">df = filter_paragraphs(df)</span><br><span class="line">print(df.head())</span><br><span class="line"><span class="comment">#Instantiate the cdQA pipeline from a pre-trained CPU reader</span></span><br><span class="line">cdqa_pipeline = QAPipeline(reader=<span class="string">'./models/bert_qa_vCPU-sklearn.joblib'</span>)</span><br><span class="line">cdqa_pipeline.fit_retriever(df=df)</span><br><span class="line"><span class="comment">#Execute a query</span></span><br><span class="line">query = <span class="string">'Since when does the Excellence Program of BNP Paribas exist?'</span></span><br><span class="line">prediction = cdqa_pipeline.predict(query)</span><br><span class="line"><span class="comment">#Explore predictions</span></span><br><span class="line">print(<span class="string">'query: {}'</span>.format(query))</span><br><span class="line">print(<span class="string">'answer: {}'</span>.format(prediction[<span class="number">0</span>]))</span><br><span class="line">print(<span class="string">'title: {}'</span>.format(prediction[<span class="number">1</span>]))</span><br><span class="line">print(<span class="string">'paragraph: {}'</span>.format(prediction[<span class="number">2</span>]))</span><br></pre></td></tr></tbody></table></figure>
<a id="more"></a>
<h2 id="PDF文档数据" class="heading-control"><a href="#PDF文档数据" class="headerlink" title="PDF文档数据"></a>PDF 文档数据<a class="heading-anchor" href="#PDF文档数据" aria-hidden="true"></a></h2><figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> ast <span class="keyword">import</span> literal_eval</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> cdqa.utils.converters <span class="keyword">import</span> pdf_converter</span><br><span class="line"><span class="keyword">from</span> cdqa.utils.filters <span class="keyword">import</span> filter_paragraphs</span><br><span class="line"><span class="keyword">from</span> cdqa.pipeline <span class="keyword">import</span> QAPipeline</span><br><span class="line"><span class="keyword">from</span> cdqa.utils.download <span class="keyword">import</span> download_model</span><br><span class="line"></span><br><span class="line"><span class="comment"># Download model</span></span><br><span class="line">download_model(model=<span class="string">'bert-squad_1.1'</span>, dir=<span class="string">'./models'</span>)</span><br><span class="line"><span class="comment"># Download pdf files from BNP Paribas public news</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">download_pdf</span>():</span></span><br><span class="line">    <span class="keyword">import</span> os</span><br><span class="line">    <span class="keyword">import</span> wget</span><br><span class="line">    directory = <span class="string">'./data/pdf/'</span></span><br><span class="line">    models_url = [</span><br><span class="line">      <span class="string">'https://invest.bnpparibas.com/documents/1q19-pr-12648'</span>,</span><br><span class="line">      <span class="string">'https://invest.bnpparibas.com/documents/4q18-pr-18000'</span>,</span><br><span class="line">      <span class="string">'https://invest.bnpparibas.com/documents/4q17-pr'</span></span><br><span class="line">    ]</span><br><span class="line"></span><br><span class="line">    print(<span class="string">'\nDownloading PDF files...'</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(directory):</span><br><span class="line">        os.makedirs(directory)</span><br><span class="line">    <span class="keyword">for</span> url <span class="keyword">in</span> models_url:</span><br><span class="line">        wget.download(url=url, out=directory)</span><br><span class="line"></span><br><span class="line">download_pdf()</span><br><span class="line">df = pdf_converter(directory_path=<span class="string">'./data/pdf/'</span>)</span><br><span class="line">print(df.head())</span><br><span class="line"></span><br><span class="line">cdqa_pipeline = QAPipeline(reader=<span class="string">'./models/bert_qa_vCPU-sklearn.joblib'</span>, max_df=<span class="number">1.0</span>)</span><br><span class="line"><span class="comment"># Send model to GPU</span></span><br><span class="line">cdqa_pipeline.cuda()</span><br><span class="line"><span class="comment"># Fit Retriever to documents</span></span><br><span class="line">cdqa_pipeline.fit_retriever(df)</span><br><span class="line"><span class="comment">#Execute a query</span></span><br><span class="line">query = <span class="string">'How many contracts did BNP Paribas Cardif sell in 2019?'</span></span><br><span class="line">prediction = cdqa_pipeline.predict(query)</span><br><span class="line"><span class="comment">#Explore predictions</span></span><br><span class="line">print(<span class="string">'query: {}'</span>.format(query))</span><br><span class="line">print(<span class="string">'answer: {}'</span>.format(prediction[<span class="number">0</span>]))</span><br><span class="line">print(<span class="string">'title: {}'</span>.format(prediction[<span class="number">1</span>]))</span><br><span class="line">print(<span class="string">'paragraph: {}'</span>.format(prediction[<span class="number">2</span>]))</span><br></pre></td></tr></tbody></table></figure>
<h2 id="训练模型" class="heading-control"><a href="#训练模型" class="headerlink" title="训练模型"></a>训练模型<a class="heading-anchor" href="#训练模型" aria-hidden="true"></a></h2><figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> joblib</span><br><span class="line"><span class="keyword">from</span> cdqa.reader <span class="keyword">import</span> BertProcessor, BertQA</span><br><span class="line"><span class="keyword">from</span> cdqa.utils.download <span class="keyword">import</span> download_squad</span><br><span class="line">download_squad(dir=<span class="string">'./data'</span>)</span><br><span class="line">train_processor = BertProcessor(do_lower_case=<span class="literal">True</span>, is_training=<span class="literal">True</span>, n_jobs=<span class="number">-1</span>)</span><br><span class="line">train_examples, train_features = train_processor.fit_transform(X=<span class="string">'./data/SQuAD_1.1/train-v1.1.json'</span>)</span><br><span class="line"><span class="comment">#Train the model</span></span><br><span class="line">reader = BertQA(train_batch_size=<span class="number">12</span>,</span><br><span class="line">                learning_rate=<span class="number">3e-5</span>,</span><br><span class="line">                num_train_epochs=<span class="number">2</span>,</span><br><span class="line">                do_lower_case=<span class="literal">True</span>,</span><br><span class="line">                output_dir=<span class="string">'models'</span>)</span><br><span class="line"></span><br><span class="line">reader.fit(X=(train_examples, train_features))</span><br><span class="line"><span class="comment">#Send model to CPU</span></span><br><span class="line">reader.model.to(<span class="string">'cpu'</span>)</span><br><span class="line">reader.device = torch.device(<span class="string">'cpu'</span>)</span><br><span class="line"><span class="comment">#Save CPU model locally</span></span><br><span class="line">joblib.dump(reader, os.path.join(reader.output_dir, <span class="string">'bert_qa_vCPU.joblib'</span>))</span><br></pre></td></tr></tbody></table></figure></body></html>]]></content>
      <tags>
        <tag>cdqa</tag>
      </tags>
  </entry>
  <entry>
    <title>kashgari 学习</title>
    <url>/post/10170.html</url>
    <content><![CDATA[<html><head><link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script></head><body><h2 id="文本分类" class="heading-control"><a href="#文本分类" class="headerlink" title="文本分类"></a>文本分类<a class="heading-anchor" href="#文本分类" aria-hidden="true"></a></h2><h3 id="训练和保存模型代码" class="heading-control"><a href="#训练和保存模型代码" class="headerlink" title="训练和保存模型代码"></a>训练和保存模型代码<a class="heading-anchor" href="#训练和保存模型代码" aria-hidden="true"></a></h3><figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> kashgari</span><br><span class="line"><span class="keyword">from</span> kashgari.corpus <span class="keyword">import</span> SMP2018ECDTCorpus</span><br><span class="line"><span class="keyword">from</span> kashgari.tasks.classification <span class="keyword">import</span> BiLSTM_Model</span><br><span class="line"><span class="keyword">from</span> kashgari.embeddings <span class="keyword">import</span> BERTEmbedding</span><br><span class="line"><span class="keyword">from</span> kashgari.callbacks <span class="keyword">import</span> EvalCallBack</span><br><span class="line"><span class="keyword">from</span> tensorflow.python <span class="keyword">import</span> keras</span><br><span class="line"><span class="keyword">from</span> kashgari <span class="keyword">import</span> utils</span><br><span class="line"></span><br><span class="line"><span class="comment"># 有GPU的话</span></span><br><span class="line">kashgari.config.use_cudnn_cell = <span class="literal">True</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 数据集</span></span><br><span class="line">train_x, train_y = SMP2018ECDTCorpus.load_data(<span class="string">'train'</span>)</span><br><span class="line">valid_x, valid_y = SMP2018ECDTCorpus.load_data(<span class="string">'valid'</span>)</span><br><span class="line">test_x, test_y = SMP2018ECDTCorpus.load_data(<span class="string">'test'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># '<PRE_TRAINED_BERT_MODEL_FOLDER>'：BERT模型路径</span></span><br><span class="line">bert_embed = BERTEmbedding(<span class="string">'/home/new/Toxicity/bert_model/models/chinese_L-12_H-768_A-12'</span>,</span><br><span class="line">                           task=kashgari.CLASSIFICATION,</span><br><span class="line">                           sequence_length=<span class="number">100</span>)</span><br><span class="line"></span><br><span class="line">model = BiLSTM_Model(bert_embed)</span><br><span class="line">tf_board_callback = keras.callbacks.TensorBoard(log_dir=<span class="string">'./logs'</span>, update_freq=<span class="number">1000</span>)</span><br><span class="line"></span><br><span class="line">eval_callback = EvalCallBack(kash_model=model,</span><br><span class="line">                             valid_x=valid_x,</span><br><span class="line">                             valid_y=valid_y,</span><br><span class="line">                             step=<span class="number">5</span>)</span><br><span class="line"></span><br><span class="line">model.fit(train_x,</span><br><span class="line">          train_y,</span><br><span class="line">          valid_x,</span><br><span class="line">          valid_y,</span><br><span class="line">          batch_size=<span class="number">100</span>,</span><br><span class="line">          callbacks=[eval_callback, tf_board_callback])</span><br><span class="line"></span><br><span class="line">model.evaluate(test_x, test_y)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 保存模型到 `saved_classification_model` 目录下</span></span><br><span class="line">model.save(<span class="string">'saved_classification_model'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 加载保存模型</span></span><br><span class="line">loaded_model = kashgari.utils.load_model(<span class="string">'saved_classification_model'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用模型进行预测</span></span><br><span class="line">loaded_model.predict(test_x[:<span class="number">10</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># Save model</span></span><br><span class="line">utils.convert_to_saved_model(model, </span><br><span class="line">                             model_path=<span class="string">'saved_model/blstm'</span>, </span><br><span class="line">                             version=<span class="number">1</span>)</span><br><span class="line"></span><br></pre></td></tr></tbody></table></figure>
<a id="more"></a>
<h3 id="模型部署" class="heading-control"><a href="#模型部署" class="headerlink" title="模型部署"></a>模型部署<a class="heading-anchor" href="#模型部署" aria-hidden="true"></a></h3><h3 id="多标签" class="heading-control"><a href="#多标签" class="headerlink" title="多标签"></a>多标签<a class="heading-anchor" href="#多标签" aria-hidden="true"></a></h3><h2 id="命名实体识别" class="heading-control"><a href="#命名实体识别" class="headerlink" title="命名实体识别"></a>命名实体识别<a class="heading-anchor" href="#命名实体识别" aria-hidden="true"></a></h2></body></html>]]></content>
      <tags>
        <tag>kashgari</tag>
      </tags>
  </entry>
  <entry>
    <title>leetcode top100 - 整数反转</title>
    <url>/post/51747.html</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>思路:</p>
<ol>
<li>先判断正负数</li>
<li>将这个数转成字符串再转成字符数组</li>
<li>将数组的首尾元素交换（注意正负）</li>
<li>将字符数组转成字符串再转成整数（注意转换后的数是否超出 int 的取值范围）</li>
<li>将这个整数返回 </li>
</ol>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">reverse</span>(<span class="params">self, x: int</span>) -&gt; int:</span></span><br><span class="line">        <span class="keyword">if</span> x &lt;<span class="number">0</span>:</span><br><span class="line">            res = -int(<span class="string">""</span>.join(list(str(-x))[::<span class="number">-1</span>]))</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            res = int(<span class="string">""</span>.join(list(str(x))[::<span class="number">-1</span>]))</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> <span class="number">-2</span>**<span class="number">31</span>&lt;=res&lt;<span class="number">2</span>**<span class="number">31</span><span class="number">-1</span>:</span><br><span class="line">            <span class="keyword">return</span> res</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="number">0</span></span><br></pre></td></tr></tbody></table></figure>
]]></content>
  </entry>
  <entry>
    <title>leetcode226— 翻转二叉树</title>
    <url>/post/26095.html</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p><img src="https://i.loli.net/2019/08/12/nb9EH4gKTdricY8.png" alt=""><br><a id="more"></a><br></p><figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">TreeNode</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        self.val = x</span><br><span class="line">        self.left = <span class="literal">None</span></span><br><span class="line">        self.right = <span class="literal">None</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">invertTree</span>(<span class="params">root: TreeNode</span>) -&gt; TreeNode:</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> root:</span><br><span class="line">        <span class="keyword">return</span> </span><br><span class="line">    root.right, root.left = invertTree(root.left), invertTree(root.right)</span><br><span class="line">    <span class="keyword">return</span> root</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    root = TreeNode(<span class="number">1</span>)</span><br><span class="line">    root.left = TreeNode(<span class="number">2</span>)</span><br><span class="line">    root.right = TreeNode(<span class="number">3</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">print_tree</span>(<span class="params">root</span>):</span></span><br><span class="line">        <span class="keyword">if</span> root:</span><br><span class="line">            print(root.val)</span><br><span class="line">            print(root.left.val)</span><br><span class="line">            print(root.right.val)</span><br><span class="line"></span><br><span class="line">    print_tree(root)</span><br><span class="line">    </span><br><span class="line">    print(<span class="string">"\n"</span>)</span><br><span class="line"></span><br><span class="line">    root = invertTree(root)</span><br><span class="line">    print_tree(root)</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></tbody></table></figure><p></p>
]]></content>
      <tags>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title>nohup 详解</title>
    <url>/post/48347.html</url>
    <content><![CDATA[<html><head><link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script></head><body><p>功能：使程序在后台运行，当连接服务器终端时，程序还在运行</p>
<h3 id="后台运行的命令" class="heading-control"><a href="#后台运行的命令" class="headerlink" title="后台运行的命令"></a>后台运行的命令<a class="heading-anchor" href="#后台运行的命令" aria-hidden="true"></a></h3><figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line">nohup python 文件名.py &</span><br><span class="line"><span class="comment"># 会出现一个进程后，记住这是该程序的进程号，</span></span><br><span class="line"><span class="comment"># 后期如果想要停止，可以使用该命令：kill -9 进程号</span></span><br></pre></td></tr></tbody></table></figure>
<h3 id="查看后台运行的进程" class="heading-control"><a href="#查看后台运行的进程" class="headerlink" title="查看后台运行的进程"></a>查看后台运行的进程<a class="heading-anchor" href="#查看后台运行的进程" aria-hidden="true"></a></h3><figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="comment"># 如果发现没记nohup运行的进程，可以使用以下的命令来查看进程号</span></span><br><span class="line"><span class="number">1.</span> jobs -l <span class="comment"># 查看后台运行的进程，如果后台运行的进程很多，可以使用下面的命令</span></span><br><span class="line"><span class="number">2.</span> ps aux | grep nohup 查看nohup 的进程，然后使用 kill <span class="number">-9</span> 进程号杀死该进程</span><br></pre></td></tr></tbody></table></figure>
<h3 id="nohup的输出重定向问题" class="heading-control"><a href="#nohup的输出重定向问题" class="headerlink" title="nohup的输出重定向问题"></a>nohup 的输出重定向问题<a class="heading-anchor" href="#nohup的输出重定向问题" aria-hidden="true"></a></h3><p>如果后台同时运行多个程序，它们的输出全都在 nohup.out 中，阅读起来很不方便。可通过重定向到不同文件中来解决这个问题；也可以通过在不同的文件下，运行 nohup 来避免这种情况。<br>linux 启动后，会默认打开 3 个文件描述符，0 表示标准输入，1 表示正确输出，2 表示错误输出。<br></p><figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line">nohup python 文件名.py <span class="number">1</span>>result.out <span class="number">2</span>>result.out & </span><br><span class="line"><span class="comment"># 将正确输出和错误输出均写入result.out文件</span></span><br></pre></td></tr></tbody></table></figure><p></p>
<h3 id="查看运行输出" class="heading-control"><a href="#查看运行输出" class="headerlink" title="查看运行输出"></a>查看运行输出<a class="heading-anchor" href="#查看运行输出" aria-hidden="true"></a></h3><figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="comment">#实时查看</span></span><br><span class="line">tailf result.out</span><br><span class="line"><span class="comment">#查看几行</span></span><br><span class="line">head <span class="number">10</span> result.out <span class="comment">#查看文件的前面10行</span></span><br><span class="line">tail <span class="number">10</span> result.out <span class="comment"># 查看文件的后面10行</span></span><br></pre></td></tr></tbody></table></figure></body></html>]]></content>
      <tags>
        <tag>nohup</tag>
      </tags>
  </entry>
  <entry>
    <title>nvidia-smi 指令报错</title>
    <url>/post/19880.html</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>最近装深度学习环境的时候遇见 nvidia-smi 指令报错：<code>Failed to initialize NVML: Driver</code>，主要原因是旧的显卡驱动没卸载。<br>首先需要卸载驱动<br></p><figure class="highlight shell"><table><tbody><tr><td class="code"><pre><span class="line">sudo apt-get purge nvidia*</span><br></pre></td></tr></tbody></table></figure><br>然后重新安装新的驱动即可。<br>参考文章：<a href="https://www.zhihu.com/people/sun-yan-90-29">https://www.zhihu.com/people/sun-yan-90-29</a><p></p>
]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>bug</tag>
      </tags>
  </entry>
  <entry>
    <title>python 的二分查找库：bisect</title>
    <url>/post/9806.html</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>具体参考 <a href="http://kuanghy.github.io/2016/06/14/python-bisect">文章</a><br></p><figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> bisect</span><br><span class="line"></span><br><span class="line"><span class="comment">#查找指定区间中包含的元素个数</span></span><br><span class="line">A = [<span class="number">1</span>,<span class="number">2</span>,<span class="number">2.5</span>,<span class="number">3</span>,<span class="number">3.5</span>,<span class="number">4</span>,<span class="number">5</span>]</span><br><span class="line">lindex = bisect.bisect_left(A,<span class="number">2.5</span>)</span><br><span class="line">rindex = bisect.bisect_right(A,<span class="number">3.5</span>)</span><br><span class="line">print(lindex, rindex, rindex-lindex)</span><br><span class="line"></span><br><span class="line"><span class="comment">#分数等级</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">grade</span>(<span class="params">score,breakpoints=[<span class="number">60</span>, <span class="number">70</span>, <span class="number">80</span>, <span class="number">90</span>], grades=<span class="string">'FDCBA'</span></span>):</span></span><br><span class="line">    i = bisect.bisect(breakpoints, score)</span><br><span class="line">    <span class="keyword">return</span> grades[i]</span><br><span class="line"></span><br><span class="line">print([grade(score) <span class="keyword">for</span> score <span class="keyword">in</span> [<span class="number">33</span>, <span class="number">99</span>, <span class="number">77</span>, <span class="number">70</span>, <span class="number">89</span>, <span class="number">90</span>, <span class="number">100</span>]])</span><br><span class="line"></span><br><span class="line"><span class="comment">#二分查找</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">binary_search_bisect</span>(<span class="params">lst, x</span>):</span></span><br><span class="line">    <span class="keyword">from</span> bisect <span class="keyword">import</span> bisect_left</span><br><span class="line">    i = bisect_left(lst, x)</span><br><span class="line">    <span class="keyword">if</span> i != len(lst) <span class="keyword">and</span> lst[i] == x:</span><br><span class="line">        <span class="keyword">return</span> i</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">print(binary_search_bisect(A,<span class="number">4</span>))</span><br></pre></td></tr></tbody></table></figure><p></p>
]]></content>
      <tags>
        <tag>二分</tag>
      </tags>
  </entry>
  <entry>
    <title>leetcode top 100 1—two sum</title>
    <url>/post/47969.html</url>
    <content><![CDATA[<html><head><link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script></head><body><p>这道题本身如果通过暴力遍历的话也是很容易解决的，时间复杂度在 O (n2)，由于哈希查找的时间复杂度为 O (1)，所以可以利用哈希容器 map 降低时间复杂度 (这里使用 python 的字典)。</p>
<h3 id="方法1：两重循环" class="heading-control"><a href="#方法1：两重循环" class="headerlink" title="方法1：两重循环"></a>方法 1：两重循环<a class="heading-anchor" href="#方法1：两重循环" aria-hidden="true"></a></h3><p>会报超时错误<br></p><figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">two_sum</span>(<span class="params">nums, target</span>):</span></span><br><span class="line">    <span class="keyword">for</span> i, n <span class="keyword">in</span> enumerate(nums):</span><br><span class="line">        <span class="keyword">for</span> j, m <span class="keyword">in</span> enumerate(nums):</span><br><span class="line">            <span class="keyword">if</span> target - n == m <span class="keyword">and</span> i!=j:</span><br><span class="line">                <span class="keyword">return</span> [i,j]</span><br></pre></td></tr></tbody></table></figure><br>时间复杂度：O(n2)<br>空间复杂度：O(n)<p></p>
<h3 id="方法2：两遍Hash" class="heading-control"><a href="#方法2：两遍Hash" class="headerlink" title="方法2：两遍Hash"></a>方法 2：两遍 Hash<a class="heading-anchor" href="#方法2：两遍Hash" aria-hidden="true"></a></h3><figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">two_sum</span>(<span class="params">nums, target</span>):</span></span><br><span class="line">    dct = dict(zip(nums, range(len(nums))))</span><br><span class="line">    <span class="keyword">for</span> i, n <span class="keyword">in</span> enumerate(nums) <span class="keyword">and</span> i!=dct[target - n]:</span><br><span class="line">        <span class="keyword">if</span> target - n <span class="keyword">in</span> dct:</span><br><span class="line">            <span class="keyword">return</span> [dct[target - n], i]</span><br></pre></td></tr></tbody></table></figure>
<p>时间复杂度：O (n2)<br>空间复杂度：O (n)</p>
<h3 id="方法2：一遍Hash-边循环边查字典" class="heading-control"><a href="#方法2：一遍Hash-边循环边查字典" class="headerlink" title="方法2：一遍Hash(边循环边查字典)"></a>方法 2：一遍 Hash (边循环边查字典)<a class="heading-anchor" href="#方法2：一遍Hash-边循环边查字典" aria-hidden="true"></a></h3><figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">two_sum</span>(<span class="params">nums, target</span>):</span></span><br><span class="line">    dct = {}</span><br><span class="line">    <span class="keyword">for</span> i, n <span class="keyword">in</span> enumerate(nums):</span><br><span class="line">        <span class="keyword">if</span> target - n <span class="keyword">in</span> dct:</span><br><span class="line">            <span class="keyword">return</span> [dct[target - n], i]</span><br><span class="line">        dct[n] = i</span><br></pre></td></tr></tbody></table></figure>
<p>时间复杂度：O (n2)<br>空间复杂度：O (n)</p>
</body></html>]]></content>
      <tags>
        <tag>leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title>一些 NLP 的会议</title>
    <url>/post/29015.html</url>
    <content><![CDATA[<html><head><link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script></head><body><p><img src="https://s2.ax1x.com/2019/07/23/ekiH9e.png" alt="ekiH9e.png"><br><a id="more"></a></p>
<h5 id="ICONIP-2019-International-Conference-on-Neural-Information-Processing" class="heading-control"><a href="#ICONIP-2019-International-Conference-on-Neural-Information-Processing" class="headerlink" title="ICONIP 2019: International Conference on Neural Information Processing"></a>ICONIP 2019: International Conference on Neural Information Processing<a class="heading-anchor" href="#ICONIP-2019-International-Conference-on-Neural-Information-Processing" aria-hidden="true"></a></h5><div class="table-container">
<table>
<thead>
<tr>
<th>截稿日期:</th>
<th>2019-06-15</th>
</tr>
</thead>
<tbody>
<tr>
<td> 通知日期:</td>
<td>2019-08-01</td>
</tr>
<tr>
<td> 会议日期:</td>
<td>2019-12-12</td>
</tr>
<tr>
<td> 会议地点:</td>
<td>Sydney, Australia</td>
</tr>
<tr>
<td> 网 </td>
<td><a href="http://ajiips.com.au/iconip2019">http://ajiips.com.au/iconip2019</a></td>
</tr>
</tbody>
</table>
</div>
<h5 id="CoNLL-2019-The-SIGNLL-Conference-on-Computational-Natural-Language-Learning" class="heading-control"><a href="#CoNLL-2019-The-SIGNLL-Conference-on-Computational-Natural-Language-Learning" class="headerlink" title="CoNLL 2019: The SIGNLL Conference on Computational Natural Language Learning"></a>CoNLL 2019: The SIGNLL Conference on Computational Natural Language Learning<a class="heading-anchor" href="#CoNLL-2019-The-SIGNLL-Conference-on-Computational-Natural-Language-Learning" aria-hidden="true"></a></h5><div class="table-container">
<table>
<thead>
<tr>
<th>截稿日期:</th>
<th>2019-05-31</th>
</tr>
</thead>
<tbody>
<tr>
<td> 通知日期:</td>
<td>2019-07-27</td>
</tr>
<tr>
<td> 会议日期:</td>
<td>2019-11-03</td>
</tr>
<tr>
<td> 会议地点:</td>
<td>Hong Kong, China</td>
</tr>
<tr>
<td> 网站 </td>
<td><a href="http://www.conll.org/">http://www.conll.org/</a></td>
</tr>
</tbody>
</table>
</div>
</body></html>]]></content>
      <tags>
        <tag>会议</tag>
      </tags>
  </entry>
  <entry>
    <title>一些面试的经验帖子</title>
    <url>/post/38161.html</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p><img src="https://i.loli.net/2020/09/01/c7XbUfRHptE3ZyG.png" alt="bg.png"><br><a id="more"></a></p>
<ul>
<li><a href="https://www.nowcoder.com/discuss/487035?type=2&amp;channel=666&amp;source_id=discuss_center_discuss_jinghua">小米算法面经</a></li>
<li><a href="https://www.nowcoder.com/discuss/464485?source_id=profile_create&amp;channel=1009">猿辅导算法面经</a></li>
</ul>
]]></content>
      <categories>
        <category>面试</category>
      </categories>
      <tags>
        <tag>面试</tag>
      </tags>
  </entry>
  <entry>
    <title>中文分词算法总结</title>
    <url>/post/44202.html</url>
    <content><![CDATA[<html><head><link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script></head><body><h2 id="最大匹配算法" class="heading-control"><a href="#最大匹配算法" class="headerlink" title="最大匹配算法"></a>最大匹配算法<a class="heading-anchor" href="#最大匹配算法" aria-hidden="true"></a></h2><p>基于词典的双向匹配算法的中文分词算法的实现。<br>例子：[我们经常有意见分歧]<br>词典：[我们，经常，有，有意见，意见，分歧]</p>
<h3 id="前向最大匹配" class="heading-control"><a href="#前向最大匹配" class="headerlink" title="前向最大匹配"></a>前向最大匹配<a class="heading-anchor" href="#前向最大匹配" aria-hidden="true"></a></h3><p>先设定扫描的窗口大小 maxLen（最好是字典最长的单词长度），从左向右取待切分汉语句的 maxLen 个字符作为匹配字段。查找词典并进行匹配。若匹配成功，则将这个匹配字段作为一个词切分出来，并将窗口向右移动这个单词的长度。若匹配不成功，则将这个匹配字段的最后一个字去掉，剩下的字符串作为新的匹配字段，进行再次匹配，重复以上过程，直到切分出所有词为止。</p>
<h3 id="后向最大匹配" class="heading-control"><a href="#后向最大匹配" class="headerlink" title="后向最大匹配"></a>后向最大匹配<a class="heading-anchor" href="#后向最大匹配" aria-hidden="true"></a></h3><p>该算法是正向的逆向算法，区别是窗口是从后向左扫描，若匹配不成功，则去掉第一个字符，重复上述的匹配步骤。</p>
<h3 id="双向最大匹配" class="heading-control"><a href="#双向最大匹配" class="headerlink" title="双向最大匹配"></a>双向最大匹配<a class="heading-anchor" href="#双向最大匹配" aria-hidden="true"></a></h3><p>双向最大匹配法是将正向最大匹配法得到的分词结果和逆向最大匹配法的到的结果进行比较，从而决定正确的分词方法。定义的匹配规则如下：</p>
<ol>
<li>如果正反向匹配算法得到的结果相同，我们则认为分词正确，返回任意一个结果即可。</li>
<li>如果正反向匹配算法得到的结果不同，则考虑单字词、非字典词、总词数数量的数量，三者的数量越少，认为分词的效果越好。我们设定一个惩罚分数（score_fmm /score_bmm = 0），例如：正向匹配中单字词数量多于反向匹配，则正向匹配的分值 score_fmm += 1。其他两个条件相同。可以根据实际的分词效果调整惩罚分数的大小，但由于没有正确分词的数据，因此惩罚分数都设为 1。最后比较惩罚分数，返回较小的匹配结果。</li>
</ol>
</body></html>]]></content>
      <tags>
        <tag>中文分词</tag>
      </tags>
  </entry>
  <entry>
    <title>中秋</title>
    <url>/post/13085.html</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>2019 年的夏天很快的过去了。今天是中秋，在古代诗歌中中秋都是思念的代名词，虽然逢人便道中秋快乐，但是自己却快乐不起来呢。<br>从 6 月底到现在陆陆续续找了快 3 个月的工作，属实有点累了。每逢一个休息日都想要静静的躺着。这段时间焦虑，等待，兴奋以及各种失败，其实蛮痛苦的。希望自己能挺过这段时间，有个好的结尾吧。<br>晚上没吃月饼，心里好怀念小时候的五仁月饼，但是也不想故意去买个吃了，就让这段时间安静的溜走吧，仿佛从来没有来过一样。</p>
<p><img src="https://i.loli.net/2019/09/13/L6RsEIFqrgcVknB.png" alt=""></p>
]]></content>
      <tags>
        <tag>中秋</tag>
      </tags>
  </entry>
  <entry>
    <title>从香农说起</title>
    <url>/post/16530.html</url>
    <content><![CDATA[<html><head><link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script></head><body><div class="tip">
我在大学上量子物理的时候，觉得这门课公式繁多，一度不愿意去学习。直到后来我看到近代量子物理的发展简史，才感受到其中的美妙。那是一种人文与科学的交织，我深深陶醉其中，也对量子物理兴趣大发。我觉得深度学习也是这样，我们应该了解公式背后的历史。跟随着那些有趣灵魂的脚步，才会明白是这一切将去往何方。
</div>

<p><img src="https://s2.ax1x.com/2019/07/18/ZXFwXd.png" alt="ZXFwXd.png"></p>
<p>香农（1916 年 4 月 30 日－2001 年 2 月 26 日），美国数学家、电子工程师和密码学家，被誉为信息论的创始人。1948 年，香农发表了划时代的论文 —— 通信的数学原理，在这部著作中，他提出了比特数据，证明了信息是可以被量化的，并阐述了如何在保证准确率的前提下用数字编码对信息进行压缩和传输。<br><a id="more"></a></p>
<h1 id="信息量和信息熵" class="heading-control"><a href="#信息量和信息熵" class="headerlink" title="信息量和信息熵"></a>信息量和信息熵<a class="heading-anchor" href="#信息量和信息熵" aria-hidden="true"></a></h1><p>我们都知道，物质、能量、信息是构成现实世界的三大要素。其中物质和能量的度量由物理学和化学中的牛顿定律、热力学定律和质能方程解释的很好了。唯独剩下信息，如何度量信息呢？</p>
<h4 id="信息量" class="heading-control"><a href="#信息量" class="headerlink" title="信息量"></a>信息量<a class="heading-anchor" href="#信息量" aria-hidden="true"></a></h4><p>我们常说信息的多少，这其实就是一种粗略的度量。举个例子</p>
<ul>
<li>太阳从东方升起了 —— 没有什么信息</li>
<li>李彦宏被泼水了，还问了”what’s your problem”—— 信息量很大，开始吃瓜</li>
</ul>
<p>为什么说第二个事情信息量大呢？本质上是因为第二个时间出现的概率低。由此我们把事件出现的概率和时间的信息关联起来了：<strong>事情的概率越低，事件的信息量越大</strong>。</p>
<h4 id="信息熵" class="heading-control"><a href="#信息熵" class="headerlink" title="信息熵"></a>信息熵<a class="heading-anchor" href="#信息熵" aria-hidden="true"></a></h4><p></p><div class="tip">
凡是可能出错的事必定会出错 ———— 墨菲定律
</div><br>这就话的意思是说生活中的事情总会朝着最坏的方向发展。生活不但不会自行解决问题，甚至还会逐渐变得更糟糕和复杂。这背后的原因就是：熵。<br>信息熵其实是信息量的期望。<p></p>
<h1 id="二分类交叉熵" class="heading-control"><a href="#二分类交叉熵" class="headerlink" title="二分类交叉熵"></a>二分类交叉熵<a class="heading-anchor" href="#二分类交叉熵" aria-hidden="true"></a></h1><p>我们假设要训练一个拥有多个输入变量的神经元：输入 $x_1, x_2, \ldots$ ，权重 $w_1, w_2, \ldots$ ，偏置为 $b$ ：<br><img src="https://i.loli.net/2019/07/18/5d30776ad28ce81358.png" alt><br>神经元的输出为 $a = \sigma (z)$ ，这里 $z = \sum_j w_j x_j+b$ ，我们定义这个神经元的交叉熵代价函数为：</p>
<script type="math/tex; mode=display">
\begin{eqnarray} C = -\frac{1}{n} \sum_x \left[y \ln a + (1-y ) \ln (1-a) \right]\end{eqnarray}</script><p>这里 $n$ 是训练数据的个数，这个加和覆盖了所有的训练输入 $x$ ， $y$ 是期望输出。注意这里用于计算的 $a$ 也是经过 $sigmoid$ 激活的，取值范围在 0 到 1 之间。</p>
<p>当输出 y 为 0 的时候，上面的式子变为： $-\ln (1-a)$ , 图像如下。可以看出当神经网络的输出也为 0 的时候 loss 最小，趋向于 1 的时候 loss 变大。<br><img src="https://i.loli.net/2019/07/18/5d30776add5b376894.png" alt><br>当输出 y 为 1 的时候，上面的式子变为：$-\ln (a)$ , 图像如下。可以看出当神经网络的输出也为 1 的时候 loss 最小，趋向于 0 的时候 loss 变大。<br><img src="https://i.loli.net/2019/07/18/5d30776adf1bc91779.png" alt></p>
<h1 id="多分类交叉熵" class="heading-control"><a href="#多分类交叉熵" class="headerlink" title="多分类交叉熵"></a>多分类交叉熵<a class="heading-anchor" href="#多分类交叉熵" aria-hidden="true"></a></h1><script type="math/tex; mode=display">softmax(s_i) = \frac{e^{s_i} }{\sum_{j=1}^{N}e^{s_j} }  \qquad  (i=1,\cdots,N)</script><script type="math/tex; mode=display">
\frac{\partial L}{\partial y_{j}}=-\sum_{j} \frac{\hat{y}_{j}}{y_{j}}</script></body></html>]]></content>
      <tags>
        <tag>AI历史</tag>
      </tags>
  </entry>
  <entry>
    <title>关于读书</title>
    <url>/post/60043.html</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>记得有一幅漫画我看见过几次，漫画上画的是三个人：第一个人在凡间地上鸟语花香，第二个人站在一摞书上，伸入云霄看见满世界压抑的乌云，第三个人则站在更高的一摞书上，看到了九霄层云之上的灿烂千阳。<br>不读书的人，无所得无所失，反正就那样凑合着过；开始读书的人，可能会感受到繁杂阴暗的痛苦；而咬牙读下去的人，终能圆融贯通，看到金光乍现。</p>
<p><img src="https://s2.ax1x.com/2019/09/24/uAEKFP.png" alt="uAEKFP.png"></p>
]]></content>
      <tags>
        <tag>生活</tag>
      </tags>
  </entry>
  <entry>
    <title>分类样本不均衡的解决方案</title>
    <url>/post/5534.html</url>
    <content><![CDATA[<html><head><link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script></head><body><p><img src="https://s2.ax1x.com/2019/07/23/eknXuD.md.png" alt><br><a id="more"></a></p>
<h2 id="更改评价指标" class="heading-control"><a href="#更改评价指标" class="headerlink" title="更改评价指标"></a>更改评价指标<a class="heading-anchor" href="#更改评价指标" aria-hidden="true"></a></h2><p>准确率肯定是不行的，一般会选择 F1 值或者 AUC_ROC 来作为评价指标</p>
<h2 id="数据层面" class="heading-control"><a href="#数据层面" class="headerlink" title="数据层面"></a>数据层面<a class="heading-anchor" href="#数据层面" aria-hidden="true"></a></h2><p>数据的采样，过采样或者欠采样</p>
<ul>
<li>过采样是从少数类样本集 Smin 中随机重复抽取样本（ 有放回）</li>
<li>欠采样是从多数类样本集 Smaj 中随机选取较少的样本（ 有放回或无放回）</li>
</ul>
<p>直接的随机采样虽然可以使样本集变得均衡，但会带来一些问题，比如，过采样对少数类样本进行了多次复制，扩大了数据规模，增加了模型训练的复杂度，同时也容易造成过拟合； 欠采样会丢弃一些样本，可能会损失部分有用信息， 造成模型只学到了整体模式的一部分。</p>
<h2 id="模型方法" class="heading-control"><a href="#模型方法" class="headerlink" title="模型方法"></a>模型方法<a class="heading-anchor" href="#模型方法" aria-hidden="true"></a></h2><p>更改损失函数，例如类别加权损失或者 Focal Loss<br>Focal loss 主要是为了解决 one-stage 目标检测中正负样本比例严重失衡的问题。该损失函数降低了大量简单负样本在训练中所占的权重。<br>回顾二分类交叉上损失：<br><img src="https://i.loli.net/2019/07/23/5d36aab50d2ce67048.png" alt><br>普通的交叉熵对于正样本而言，输出概率越大损失越小。对于负样本而言，输出概率越小则损失越小。<br>现在记：</p>
<script type="math/tex; mode=display">
p_{\mathrm{t}}=\left\{\begin{array}{ll}{p} & {\text { if } y=1} \\ {1-p} & {\text { otherwise }}\end{array}\right.</script><p>这样 $p_t$ 实际上就是反映了 p 与 y 的接近程度。$p_t$ 越大，说明分类越好。交叉熵损失函数的最终形式为： </p>
<script type="math/tex; mode=display">
\operatorname{CE}(p, y)=\operatorname{CE}\left(p_{\mathrm{t}}\right)=-\log \left(p_{\mathrm{t}}\right)</script><p>通过实验发现，即使是 easy examples，由于它们数量很多，它的 loss 也很高，如下图蓝线。这些 loss 会主导梯度下降的方向，淹没少量的正样本的影响。$p_t$ 越大，FL 越小，总体 Loss 越小。增加了误分类的重要性。<br><img src="https://i.loli.net/2019/07/23/5d36aae36f66e92180.png" alt></p>
<p>参数为 0 的时候，Focal Loss 退化为交叉熵 CE。从图中我们可以很直观地看到，</p>
<h2 id="集成方法" class="heading-control"><a href="#集成方法" class="headerlink" title="集成方法"></a>集成方法<a class="heading-anchor" href="#集成方法" aria-hidden="true"></a></h2><p>每次生成训练集时使用所有分类中的小样本量，同时从分类中的大样本量中随机抽取数据来与小样本量合并构成训练集，这样反复多次会得到很多训练集和训练模型。最后在应用时，使用组合方法（例如投票、加权投票等）产生分类预测结果。<br>这种解决问题的思路类似于随机森林。在随机森林中，虽然每个小决策树的分类能力很弱，但是通过大量的 “小树” 组合形成的 “森林” 具有良好的模型预测能力。</p>
</body></html>]]></content>
      <tags>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title>刷题日记</title>
    <url>/post/38454.html</url>
    <content><![CDATA[<html><head><link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script></head><body><h2 id="赛马问题" class="heading-control"><a href="#赛马问题" class="headerlink" title="赛马问题"></a>赛马问题<a class="heading-anchor" href="#赛马问题" aria-hidden="true"></a></h2><p></p><div class="tip">
25 匹马，找出最快的 3 匹，只有 5 个赛道，每次比赛只能得到 5 匹马的速度排序，最少需要多少次比赛
</div><br>答案是7次。<a href="https://blog.csdn.net/qq_29519041/article/details/85319046">题解</a><p></p>
<ul>
<li>分五组进行小组赛，5 次；</li>
<li>小组头名进行冠军赛，确定第一名，1 次；</li>
<li>最后决出第二三名，1 次</li>
</ul>
<h2 id="量水" class="heading-control"><a href="#量水" class="headerlink" title="量水"></a>量水<a class="heading-anchor" href="#量水" aria-hidden="true"></a></h2><p></p><div class="tip">
有一个 5L 和一个 3l 的无刻度水杯，还有一个水池。如何量出 4L 水
</div><p></p>
<ul>
<li>先接满 5L 的杯子，然后倒入 3L 的杯子，留 2L</li>
<li> 然后把 3L 的杯子倒了，把 2L 倒进 3L 杯子里面</li>
<li>然后接 5L 水，最后把 3L 倒满，5L 杯子里面留下 4L</li>
</ul>
<h2 id="拿球" class="heading-control"><a href="#拿球" class="headerlink" title="拿球"></a>拿球<a class="heading-anchor" href="#拿球" aria-hidden="true"></a></h2><p></p><div class="tip">
1001 个球，两个人轮流拿球，且每次只能拿 1、2、4 个球，规定拿到最后一个球的人为输。如果让你先拿，你是否有必胜的把握。如果有，该如何操作？
</div><p></p>
<ul>
<li>先拿 4 个，然后每轮保证两个人所拿球数之和为 3 或 6。</li>
</ul>
<h2 id="送礼物" class="heading-control"><a href="#送礼物" class="headerlink" title="送礼物"></a>送礼物<a class="heading-anchor" href="#送礼物" aria-hidden="true"></a></h2><p></p><div class="tip">
N 个人，互相交换礼物，每个人不能拿到自己的礼物。设计一种算法
</div><br>第N个人在[1，N]中随机选择一个数，提前想好。然后前面的人按照这个随机数站好。比如，第一个人，只能傻乎乎站在那里。第二个人，提前在[1,2]这两个数中选一个，比如选1就站在第一个人左边，选2就站在第二个人右边。那第三个人呢，这时候场上已经有两个人了，也就是说有三个空位置，左边，右边和两个人中间。第三个人提前在[1,3]中选择一个数，如果是1就最左边，2就是在前两个人中间，3就是最右边。以此类推，直到第50个人，前面49个人已经站好了，最后一个人就有50个空儿可以插入。当所有人站好后，每个人把自己的礼物给后面那个人。<p></p>
</body></html>]]></content>
      <tags>
        <tag>刷题</tag>
      </tags>
  </entry>
  <entry>
    <title>动态规划</title>
    <url>/post/55046.html</url>
    <content><![CDATA[<html><head><link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script></head><body><h2 id="从青蛙跳台阶说起" class="heading-control"><a href="#从青蛙跳台阶说起" class="headerlink" title="从青蛙跳台阶说起"></a>从青蛙跳台阶说起<a class="heading-anchor" href="#从青蛙跳台阶说起" aria-hidden="true"></a></h2><p>这个问题和斐波纳契数字问题是一样的。题目描述如下：</p>
<blockquote>
<p>一只青蛙一次可以跳上 1 级台阶，也可以跳上 2 级。求该青蛙跳上一个 n 级的台阶总共有多少种跳法（先后次序不同算不同的结果）。</p>
</blockquote>
<h3 id="考虑递归" class="heading-control"><a href="#考虑递归" class="headerlink" title="考虑递归"></a>考虑递归<a class="heading-anchor" href="#考虑递归" aria-hidden="true"></a></h3><p>首先用递归的思路来考虑。递归是倒着分析的。</p>
<p>假如只差一步就能走完整个台阶，要分为几种情况？因为每一步能走一级或者两级台阶，所以有如下两种情况：</p>
<ul>
<li>最后一步走 2 级台阶，也就是从 n-2 级到 n 级</li>
<li>最后一步走 1 级台阶，也就是从 n-1 级到 n 级</li>
</ul>
<p>所以第 n 步的走法由两种方法的和构成。如果定义 F (n) 为第 n 步的走法，那么 F (n)=F (n-1)+F (n-2)。这个公式称之为<strong>递推公式</strong>。<br>当只有 1 级台阶和 2 级台阶时走法很明显，即 F (1)=1、F (2)=2。称之为<strong>边界条件</strong>。<br>两部分具备之后，很容易可以写出代码：<br></p><figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">fun</span>(<span class="params">n</span>):</span></span><br><span class="line">    <span class="keyword">if</span> n==<span class="number">2</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="number">2</span></span><br><span class="line">    <span class="keyword">if</span> n==<span class="number">1</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="number">1</span></span><br><span class="line">    <span class="keyword">return</span> fun(n<span class="number">-1</span>)+fun(n<span class="number">-2</span>)</span><br></pre></td></tr></tbody></table></figure><br>验证的时候会发现一个问题，如果n比较大，那么会导致计算机栈的溢出，即便是n=100的时候也需要相当长的计算时间。那么问题出在哪里呢？<p></p>
<h2 id="重叠子问题" class="heading-control"><a href="#重叠子问题" class="headerlink" title="重叠子问题"></a>重叠子问题<a class="heading-anchor" href="#重叠子问题" aria-hidden="true"></a></h2><p>我们不妨把上面的递归式子以树的形式表示出来，结果如下：<br></p><figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line">                       F(<span class="number">5</span>)</span><br><span class="line">                  /             \</span><br><span class="line">             F(<span class="number">4</span>)                  F(<span class="number">3</span>)</span><br><span class="line">          /      \                /     \</span><br><span class="line">      F(<span class="number">3</span>)       F(<span class="number">2</span>)         F(<span class="number">2</span>)     F(<span class="number">1</span>)</span><br><span class="line">     /     \     /    \       /    \</span><br><span class="line">   F(<span class="number">2</span>)   F(<span class="number">1</span>) F(<span class="number">1</span>)  F(<span class="number">0</span>)  F(<span class="number">1</span>)   F(<span class="number">0</span>)</span><br><span class="line">  /    \</span><br><span class="line">F(<span class="number">1</span>)  F(<span class="number">0</span>)</span><br></pre></td></tr></tbody></table></figure><br>可以看到这其中有很多重复求解部分，称之为重叠子问题。<br>一种想到的改进方法是我们可不可以把递归计算中某些计算过的结果存起来，来避免这个问题。下面介绍记忆化搜索和LRU 缓存策略实现这种改进方法。<p></p>
<h3 id="记忆化搜索" class="heading-control"><a href="#记忆化搜索" class="headerlink" title="记忆化搜索"></a>记忆化搜索<a class="heading-anchor" href="#记忆化搜索" aria-hidden="true"></a></h3><p>记忆化搜索的思路如下：每当我们需要解决子问题时，我们首先查找查找表。如果预先计算的值存在，那么我们返回该值，否则我们计算值，并将结果放在查找表中，以便以后可以重复使用。<br></p><figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line">lookup = [<span class="number">0</span>,<span class="number">1</span>,<span class="number">2</span>]+[<span class="number">0</span>]*<span class="number">100</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">fun</span>(<span class="params">n</span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> lookup[n] == <span class="number">0</span>:</span><br><span class="line">        lookup[n] = fun(n<span class="number">-1</span>)+fun(n<span class="number">-2</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> lookup[n]</span><br></pre></td></tr></tbody></table></figure><p></p>
<h3 id="LRU缓存" class="heading-control"><a href="#LRU缓存" class="headerlink" title="LRU缓存"></a>LRU 缓存<a class="heading-anchor" href="#LRU缓存" aria-hidden="true"></a></h3><p>LRU（Least recently used，最近最少使用），其核心思想是 “如果数据最近被访问过，那么将来被访问的几率也更高”。对于本题目，如果是高频出现的计算函数的结果会被放到缓存中，再次出现只需要在缓存中读取即可，和记忆化搜索类似。python 有 LRU 的内置函数：<br></p><figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> functools <span class="keyword">import</span> lru_cache</span><br><span class="line"><span class="meta">@lru_cache(None)</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">fun</span>(<span class="params">n</span>):</span></span><br><span class="line">    <span class="keyword">if</span> n==<span class="number">2</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="number">2</span></span><br><span class="line">    <span class="keyword">if</span> n==<span class="number">1</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="number">1</span></span><br><span class="line">    <span class="keyword">return</span> fun(n<span class="number">-1</span>)+fun(n<span class="number">-2</span>)</span><br></pre></td></tr></tbody></table></figure><p></p>
<p>有了上诉方法，n=100 已经可以计算了。但是虽然有这两个缓解的方法，但是仍存在问题。当 n=1000 的时候仍然会存在堆栈溢出的问题。</p>
<h2 id="一维动态规划" class="heading-control"><a href="#一维动态规划" class="headerlink" title="一维动态规划"></a>一维动态规划<a class="heading-anchor" href="#一维动态规划" aria-hidden="true"></a></h2><p>上面的思考都是基于递归的，即自顶而下的计算方法。如果我们换个思路，自底而上呢？</p>
<p>其实和上面的记忆化搜索很像了。首选记录 n=1 的情况和 n=2 的情况，然后依次向上计算，每次计算都存表即可。</p>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line">N = <span class="number">10</span></span><br><span class="line"></span><br><span class="line">dp  = [<span class="number">0</span>]*(N+<span class="number">1</span>)</span><br><span class="line">dp[<span class="number">1</span>] = <span class="number">1</span></span><br><span class="line">dp[<span class="number">2</span>] = <span class="number">2</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">fun</span>(<span class="params">n</span>):</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(n+<span class="number">1</span>):</span><br><span class="line">        <span class="keyword">if</span> i><span class="number">2</span>:</span><br><span class="line">            dp[i] = dp[i<span class="number">-1</span>] + dp[i<span class="number">-2</span>]</span><br><span class="line">    <span class="keyword">return</span> dp[<span class="number">-1</span>]    </span><br></pre></td></tr></tbody></table></figure>
<p>这种方法存的表称之为 DP Table, 这种解决思路称之为动态规划。本题目的 DP Table 是一维的，所以称之为一维动态规划。</p>
<p>当然针对这个问题，对空间还可以进一步优化：<br></p><figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">fun</span>(<span class="params">n</span>):</span></span><br><span class="line">    <span class="keyword">if</span> n == <span class="number">1</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="number">1</span></span><br><span class="line">    <span class="keyword">if</span> n == <span class="number">2</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="number">2</span></span><br><span class="line">    pre,prepre = <span class="number">2</span>,<span class="number">1</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(n - <span class="number">2</span>):</span><br><span class="line">         prepre, pre = pre, pre + prepre</span><br><span class="line">    <span class="keyword">return</span> pre</span><br></pre></td></tr></tbody></table></figure><p></p>
<h3 id="动态规划和递归" class="heading-control"><a href="#动态规划和递归" class="headerlink" title="动态规划和递归"></a>动态规划和递归<a class="heading-anchor" href="#动态规划和递归" aria-hidden="true"></a></h3><p>上面我们已经见到过了：递归采用的是 “由上而下” 的解题策略并带有可能的” 子问题 “重复调用，时间复杂度自然高，而且容易造成堆栈的溢出。</p>
<h3 id="动态规划和分治" class="heading-control"><a href="#动态规划和分治" class="headerlink" title="动态规划和分治"></a>动态规划和分治<a class="heading-anchor" href="#动态规划和分治" aria-hidden="true"></a></h3><p>两者的区别在于：动态规划的下一个子阶段的求解是建立在上一个子阶段的解的基础上，进行进一步的求解。</p>
<h3 id="动态规划和贪心" class="heading-control"><a href="#动态规划和贪心" class="headerlink" title="动态规划和贪心"></a>动态规划和贪心<a class="heading-anchor" href="#动态规划和贪心" aria-hidden="true"></a></h3><p>贪心算法每走一步都是不可撤回的，而动态规划是在一个问题的多种策略中寻找最优策略，所以动态规划中前一种策略可能会被后一种策略推翻。</p>
<h3 id="一维动态规划Leetcode题目" class="heading-control"><a href="#一维动态规划Leetcode题目" class="headerlink" title="一维动态规划Leetcode题目"></a>一维动态规划 Leetcode 题目<a class="heading-anchor" href="#一维动态规划Leetcode题目" aria-hidden="true"></a></h3><ul>
<li><a href="http://oj.leetcode.com/problems/climbing-stairs/">Climbing Stairs</a></li>
<li><a href="http://oj.leetcode.com/problems/decode-ways/">Decode Ways</a></li>
<li><a href="http://oj.leetcode.com/problems/unique-binary-search-trees/">Unique Binary Search Trees</a></li>
<li><a href="http://oj.leetcode.com/problems/maximum-subarray/">Maximum Subarray</a></li>
<li><a href="https://leetcode.com/problems/maximum-product-subarray/">Maximum Product Subarray</a></li>
<li><a href="http://oj.leetcode.com/problems/best-time-to-buy-and-sell-stock/">Best Time to Buy and Sell Stock</a></li>
</ul>
<h2 id="二维动态规划" class="heading-control"><a href="#二维动态规划" class="headerlink" title="二维动态规划"></a>二维动态规划<a class="heading-anchor" href="#二维动态规划" aria-hidden="true"></a></h2></body></html>]]></content>
      <tags>
        <tag>DP</tag>
      </tags>
  </entry>
  <entry>
    <title>卷积神经网络复习</title>
    <url>/post/48895.html</url>
    <content><![CDATA[<html><head><link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script></head><body><p><img src="https://i.loli.net/2019/01/19/5c42b8b0d6f16.png" alt></p>
<h2 id="卷积神经网络" class="heading-control"><a href="#卷积神经网络" class="headerlink" title="卷积神经网络"></a>卷积神经网络<a class="heading-anchor" href="#卷积神经网络" aria-hidden="true"></a></h2><p>卷积神经网络主要包括 3 层，即：卷积层、池化层以及全连接层。本文讲分别细致介绍这三层的作用和计算来复习一下卷积神经网络。本文采用简单的 LeNet 来讨论这些问题，模型的结构如下。<br><img src="https://i.loli.net/2018/10/25/5bd1c482c424a.png" alt><br><a id="more"></a></p>
<h2 id="卷积层" class="heading-control"><a href="#卷积层" class="headerlink" title="卷积层"></a>卷积层<a class="heading-anchor" href="#卷积层" aria-hidden="true"></a></h2><p>卷积层的功能是特征提取。我们先设定下面的符号：</p>
<ul>
<li>H：图片高度；</li>
<li>W：图片宽度；</li>
<li>D：原始图片通道数，也是卷积核个数；</li>
<li>F：卷积核高宽大小；</li>
<li>P：图像边扩充大小；</li>
<li>S：滑动步长</li>
<li> K：卷积核的个数</li>
</ul>
<p>在卷积操作中卷积核是可学习的参数，每层卷积的参数大小为 D×F×F×K。这样看来卷积层的参数还是比较少的，主要原因是采用了两个重要的特性：局部连接和权值共享。</p>
<ul>
<li>局部连接<br>从神经网络连接结构的角度，CNN 的底层与隐藏不再是全连接，而是局部区域的成块连接:<br><img src="https://i.loli.net/2018/11/14/5bec277000545.png" alt="Untitled-28.png"><br>成块连接后，那些小块，还能在上层聚集成更大的块:<br><img src="https://i.loli.net/2018/11/14/5bec27d86614a.png" alt="Untitled-29.png"></li>
<li>权值共享<br>给一张输入图片，用一个 filter 去扫这张图，filter 里面的数就叫权重，这张图每个位置就是被同样的 filter 扫的，所以权重是一样的，也就是共享。</li>
</ul>
<h2 id="池化层" class="heading-control"><a href="#池化层" class="headerlink" title="池化层"></a>池化层<a class="heading-anchor" href="#池化层" aria-hidden="true"></a></h2><p>如果用上面的方法堆砌 CNN 网络，隐藏层的参数还是太多了，不是吗？每个相邻块都要在上层生成一个大的块。所以有时我们为了减少参数复杂度，不严格把相邻的块都至少聚合成一个上层块，我们可以把下层块分一些区域，在这些区域中聚合:<br><img src="https://i.loli.net/2018/11/14/5bec281a938de.png" alt="Untitled-30.png"><br>所以池化层的功能主要是对输入的特征图进行压缩，一方面使特征图变小，简化网络计算复杂度；另一方面进行特征压缩，提取主要特征。<br>最常见的池化操作为平均池化 mean pooling 和最大池化 max pooling：</p>
<ul>
<li>平均池化：计算图像区域的平均值作为该区域池化后的值。 </li>
<li>最大池化：选图像区域的最大值作为该区域池化后的值。</li>
</ul>
<p>3D 的卷积和池化如图所示：<br><img src="https://i.loli.net/2018/11/14/5bec287a44825.png" alt="Untitled-34.png"></p>
<h2 id="全连接层" class="heading-control"><a href="#全连接层" class="headerlink" title="全连接层"></a>全连接层<a class="heading-anchor" href="#全连接层" aria-hidden="true"></a></h2><p>卷积取的是局部特征，全连接就是把以前的局部特征重新通过权值矩阵组装成完整的图，将输出值送给分类器（如 softmax 分类器）。</p>
<h2 id="LeNet" class="heading-control"><a href="#LeNet" class="headerlink" title="LeNet"></a>LeNet<a class="heading-anchor" href="#LeNet" aria-hidden="true"></a></h2><h3 id="第一层，卷积层" class="heading-control"><a href="#第一层，卷积层" class="headerlink" title="第一层，卷积层"></a>第一层，卷积层<a class="heading-anchor" href="#第一层，卷积层" aria-hidden="true"></a></h3><p>输入图像的大小 32x32x1, 卷积核尺寸为 5x5，深度为 6，不使用全 0 填充，步长为 1。所以这一层的输出：28x28x6，卷积层共有 5x5x1x6+6=156 个参数。</p>
<h3 id="第二层，池化层" class="heading-control"><a href="#第二层，池化层" class="headerlink" title="第二层，池化层"></a>第二层，池化层<a class="heading-anchor" href="#第二层，池化层" aria-hidden="true"></a></h3><p>这一层的输入为第一层的输出，是一个 28x28x6 的节点矩阵。本层采用的过滤器大小为 2x2，长和宽的步长均为 2，所以本层的输出矩阵大小为 14x14x6。</p>
<h3 id="第三层，卷积层" class="heading-control"><a href="#第三层，卷积层" class="headerlink" title="第三层，卷积层"></a>第三层，卷积层<a class="heading-anchor" href="#第三层，卷积层" aria-hidden="true"></a></h3><p>本层的输入矩阵大小为 14x14x6，使用的过滤器大小为 5x5，深度为 16. 本层不使用全 0 填充，步长为 1。本层的输出矩阵大小为 10x10x16。本层有 5x5x6x16+16=2416 个参数。</p>
<h3 id="第四层，池化层" class="heading-control"><a href="#第四层，池化层" class="headerlink" title="第四层，池化层"></a>第四层，池化层<a class="heading-anchor" href="#第四层，池化层" aria-hidden="true"></a></h3><p>本层的输入矩阵大小 10x10x16。本层采用的过滤器大小为 2x2，长和宽的步长均为 2，所以本层的输出矩阵大小为 5x5x16。</p>
<h3 id="第五层，全连接层" class="heading-control"><a href="#第五层，全连接层" class="headerlink" title="第五层，全连接层"></a>第五层，全连接层<a class="heading-anchor" href="#第五层，全连接层" aria-hidden="true"></a></h3><p>本层的输入矩阵大小为 5x5x16，在 LeNet-5 论文中将这一层成为卷积层，但是因为过滤器的大小就是 5x5，所以和全连接层没有区别。如果将 5x5x16 矩阵中的节点拉成一个向量，那么这一层和全连接层就一样了。本层的输出节点个数为 120，总共有 5x5x16x120+120=48120 个参数。</p>
<h3 id="第六层，全连接层" class="heading-control"><a href="#第六层，全连接层" class="headerlink" title="第六层，全连接层"></a>第六层，全连接层<a class="heading-anchor" href="#第六层，全连接层" aria-hidden="true"></a></h3><p>本层的输入节点个数为 120 个，输出节点个数为 84 个，总共参数为 120x84+84=10164 个。</p>
<h3 id="第七层，全连接层" class="heading-control"><a href="#第七层，全连接层" class="headerlink" title="第七层，全连接层"></a>第七层，全连接层<a class="heading-anchor" href="#第七层，全连接层" aria-hidden="true"></a></h3><p>本层的输入节点个数为 84 个，输出节点个数为 10 个，总共参数为 84x10+10=850</p>
<h2 id="一些有用的代码" class="heading-control"><a href="#一些有用的代码" class="headerlink" title="一些有用的代码"></a>一些有用的代码<a class="heading-anchor" href="#一些有用的代码" aria-hidden="true"></a></h2><h3 id="在NoteBook里面显示训练用到的图片" class="heading-control"><a href="#在NoteBook里面显示训练用到的图片" class="headerlink" title="在NoteBook里面显示训练用到的图片"></a>在 NoteBook 里面显示训练用到的图片<a class="heading-anchor" href="#在NoteBook里面显示训练用到的图片" aria-hidden="true"></a></h3><figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line">%matplotlib inline</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> matplotlib.image <span class="keyword">as</span> mpimg</span><br><span class="line"><span class="comment"># Parameters for our graph; we'll output images in a 4x4 configuration</span></span><br><span class="line">nrows = <span class="number">4</span></span><br><span class="line">ncols = <span class="number">4</span></span><br><span class="line"><span class="comment"># Index for iterating over images</span></span><br><span class="line">pic_index = <span class="number">0</span></span><br><span class="line"><span class="comment"># Set up matplotlib fig, and size it to fit 4x4 pics</span></span><br><span class="line">fig = plt.gcf()</span><br><span class="line">fig.set_size_inches(ncols * <span class="number">4</span>, nrows * <span class="number">4</span>)</span><br><span class="line">pic_index += <span class="number">8</span></span><br><span class="line">next_cat_pix = [os.path.join(train_cats_dir, fname) </span><br><span class="line">                <span class="keyword">for</span> fname <span class="keyword">in</span> train_cat_fnames[pic_index<span class="number">-8</span>:pic_index]]</span><br><span class="line">next_dog_pix = [os.path.join(train_dogs_dir, fname) </span><br><span class="line">                <span class="keyword">for</span> fname <span class="keyword">in</span> train_dog_fnames[pic_index<span class="number">-8</span>:pic_index]]</span><br><span class="line"><span class="keyword">for</span> i, img_path <span class="keyword">in</span> enumerate(next_cat_pix+next_dog_pix):</span><br><span class="line">  <span class="comment"># Set up subplot; subplot indices start at 1</span></span><br><span class="line">  sp = plt.subplot(nrows, ncols, i + <span class="number">1</span>)</span><br><span class="line">  sp.axis(<span class="string">'Off'</span>) <span class="comment"># Don't show axes (or gridlines)</span></span><br><span class="line">  img = mpimg.imread(img_path)</span><br><span class="line">  plt.imshow(img)</span><br><span class="line">plt.show()</span><br></pre></td></tr></tbody></table></figure>
<p>主要使用 matplotlib 画一个 4x4 的图，代码效果如下：<br><img src="/卷积神经网络复习/20190119015827918.png" alt></p>
<h3 id="Keras图像增强" class="heading-control"><a href="#Keras图像增强" class="headerlink" title="Keras图像增强"></a>Keras 图像增强<a class="heading-anchor" href="#Keras图像增强" aria-hidden="true"></a></h3><p>通过对现有图像执行随机变换来人为地增加训练样例的多样性和数量，以创建一组新变体。当原始训练数据集相对较小时，数据增加特别有用。<br></p><figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> tensorflow.keras.preprocessing.image <span class="keyword">import</span> ImageDataGenerator</span><br><span class="line"></span><br><span class="line"><span class="comment"># All images will be rescaled by 1./255</span></span><br><span class="line">train_datagen = ImageDataGenerator(rescale=<span class="number">1.</span>/<span class="number">255</span>)</span><br><span class="line">test_datagen = ImageDataGenerator(rescale=<span class="number">1.</span>/<span class="number">255</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># datagen = ImageDataGenerator(</span></span><br><span class="line"><span class="comment">#       rotation_range=40,</span></span><br><span class="line"><span class="comment">#       width_shift_range=0.2,</span></span><br><span class="line"><span class="comment">#       height_shift_range=0.2,</span></span><br><span class="line"><span class="comment">#       shear_range=0.2,</span></span><br><span class="line"><span class="comment">#       zoom_range=0.2,</span></span><br><span class="line"><span class="comment">#       horizontal_flip=True,</span></span><br><span class="line"><span class="comment">#       fill_mode='nearest')</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Flow training images in batches of 20 using train_datagen generator</span></span><br><span class="line">train_generator = train_datagen.flow_from_directory(</span><br><span class="line">        train_dir,  <span class="comment"># This is the source directory for training images</span></span><br><span class="line">        target_size=(<span class="number">150</span>, <span class="number">150</span>),  <span class="comment"># All images will be resized to 150x150</span></span><br><span class="line">        batch_size=<span class="number">20</span>,</span><br><span class="line">        <span class="comment"># Since we use binary_crossentropy loss, we need binary labels</span></span><br><span class="line">        class_mode=<span class="string">'binary'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Flow validation images in batches of 20 using test_datagen generator</span></span><br><span class="line">validation_generator = test_datagen.flow_from_directory(</span><br><span class="line">        validation_dir,</span><br><span class="line">        target_size=(<span class="number">150</span>, <span class="number">150</span>),</span><br><span class="line">        batch_size=<span class="number">20</span>,</span><br><span class="line">        class_mode=<span class="string">'binary'</span>)</span><br><span class="line">history = model.fit_generator(</span><br><span class="line">      train_generator,</span><br><span class="line">      steps_per_epoch=<span class="number">100</span>,  <span class="comment"># 2000 images = batch_size * steps</span></span><br><span class="line">      epochs=<span class="number">15</span>,</span><br><span class="line">      validation_data=validation_generator,</span><br><span class="line">      validation_steps=<span class="number">50</span>,  <span class="comment"># 1000 images = batch_size * steps</span></span><br><span class="line">      verbose=<span class="number">2</span>)</span><br></pre></td></tr></tbody></table></figure><br>ImageDataGenerator的一些参数介绍：<p></p>
<ul>
<li>rotation_range is a value in degrees (0–180), a range within which to randomly rotate pictures.</li>
<li>width_shift and height_shift are ranges (as a fraction of total width or height) within which to randomly translate pictures vertically or horizontally.</li>
<li>shear_range is for randomly applying shearing transformations.</li>
<li>zoom_range is for randomly zooming inside pictures.</li>
<li>horizontal_flip is for randomly flipping half of the images horizontally. This is relevant when there are no assumptions of horizontal assymmetry (e.g. real-world pictures).</li>
<li>fill_mode is the strategy used for filling in newly created pixels, which can appear after a rotation or a width/height shift.</li>
</ul>
<p><img src="/卷积神经网络复习/20190119020156227.png" alt></p>
<h3 id="可视化中间层" class="heading-control"><a href="#可视化中间层" class="headerlink" title="可视化中间层"></a>可视化中间层<a class="heading-anchor" href="#可视化中间层" aria-hidden="true"></a></h3><figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras.preprocessing.image <span class="keyword">import</span> img_to_array, load_img</span><br><span class="line"></span><br><span class="line"><span class="comment"># Let's define a new Model that will take an image as input, and will output</span></span><br><span class="line"><span class="comment"># intermediate representations for all layers in the previous model after</span></span><br><span class="line"><span class="comment"># the first.</span></span><br><span class="line">successive_outputs = [layer.output <span class="keyword">for</span> layer <span class="keyword">in</span> model.layers[<span class="number">1</span>:]]</span><br><span class="line">visualization_model = Model(img_input, successive_outputs)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Let's prepare a random input image of a cat or dog from the training set.</span></span><br><span class="line">cat_img_files = [os.path.join(train_cats_dir, f) <span class="keyword">for</span> f <span class="keyword">in</span> train_cat_fnames]</span><br><span class="line">dog_img_files = [os.path.join(train_dogs_dir, f) <span class="keyword">for</span> f <span class="keyword">in</span> train_dog_fnames]</span><br><span class="line">img_path = random.choice(cat_img_files + dog_img_files)</span><br><span class="line"></span><br><span class="line">img = load_img(img_path, target_size=(<span class="number">150</span>, <span class="number">150</span>))  <span class="comment"># this is a PIL image</span></span><br><span class="line">x = img_to_array(img)  <span class="comment"># Numpy array with shape (150, 150, 3)</span></span><br><span class="line">x = x.reshape((<span class="number">1</span>,) + x.shape)  <span class="comment"># Numpy array with shape (1, 150, 150, 3)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Rescale by 1/255</span></span><br><span class="line">x /= <span class="number">255</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Let's run our image through our network, thus obtaining all</span></span><br><span class="line"><span class="comment"># intermediate representations for this image.</span></span><br><span class="line">successive_feature_maps = visualization_model.predict(x)</span><br><span class="line"></span><br><span class="line"><span class="comment"># These are the names of the layers, so can have them as part of our plot</span></span><br><span class="line">layer_names = [layer.name <span class="keyword">for</span> layer <span class="keyword">in</span> model.layers]</span><br><span class="line"></span><br><span class="line"><span class="comment"># Now let's display our representations</span></span><br><span class="line"><span class="keyword">for</span> layer_name, feature_map <span class="keyword">in</span> zip(layer_names, successive_feature_maps):</span><br><span class="line">  <span class="keyword">if</span> len(feature_map.shape) == <span class="number">4</span>:</span><br><span class="line">    <span class="comment"># Just do this for the conv / maxpool layers, not the fully-connected layers</span></span><br><span class="line">    n_features = feature_map.shape[<span class="number">-1</span>]  <span class="comment"># number of features in feature map</span></span><br><span class="line">    <span class="comment"># The feature map has shape (1, size, size, n_features)</span></span><br><span class="line">    size = feature_map.shape[<span class="number">1</span>]</span><br><span class="line">    <span class="comment"># We will tile our images in this matrix</span></span><br><span class="line">    display_grid = np.zeros((size, size * n_features))</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(n_features):</span><br><span class="line">      <span class="comment"># Postprocess the feature to make it visually palatable</span></span><br><span class="line">      x = feature_map[<span class="number">0</span>, :, :, i]</span><br><span class="line">      x -= x.mean()</span><br><span class="line">      x /= x.std()</span><br><span class="line">      x *= <span class="number">64</span></span><br><span class="line">      x += <span class="number">128</span></span><br><span class="line">      x = np.clip(x, <span class="number">0</span>, <span class="number">255</span>).astype(<span class="string">'uint8'</span>)</span><br><span class="line">      <span class="comment"># We'll tile each filter into this big horizontal grid</span></span><br><span class="line">      display_grid[:, i * size : (i + <span class="number">1</span>) * size] = x</span><br><span class="line">    <span class="comment"># Display the grid</span></span><br><span class="line">    scale = <span class="number">20.</span> / n_features</span><br><span class="line">    plt.figure(figsize=(scale * n_features, scale))</span><br><span class="line">    plt.title(layer_name)</span><br><span class="line">    plt.grid(<span class="literal">False</span>)</span><br><span class="line">    plt.imshow(display_grid, aspect=<span class="string">'auto'</span>, cmap=<span class="string">'viridis'</span>)</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/卷积神经网络复习/20190119020442527.png" alt><br>可以看出，从浅到深模型学习到的特征越来越抽象，图像的原始像素的信息越来越少，但是关于图像类别的信息越来越精细。</p>
<h3 id="Loss和Acc可视化" class="heading-control"><a href="#Loss和Acc可视化" class="headerlink" title="Loss和Acc可视化"></a>Loss 和 Acc 可视化<a class="heading-anchor" href="#Loss和Acc可视化" aria-hidden="true"></a></h3><figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="comment"># Retrieve a list of accuracy results on training and test data</span></span><br><span class="line"><span class="comment"># sets for each training epoch</span></span><br><span class="line">acc = history.history[<span class="string">'acc'</span>]</span><br><span class="line">val_acc = history.history[<span class="string">'val_acc'</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># Retrieve a list of list results on training and test data</span></span><br><span class="line"><span class="comment"># sets for each training epoch</span></span><br><span class="line">loss = history.history[<span class="string">'loss'</span>]</span><br><span class="line">val_loss = history.history[<span class="string">'val_loss'</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># Get number of epochs</span></span><br><span class="line">epochs = range(len(acc))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Plot training and validation accuracy per epoch</span></span><br><span class="line">plt.plot(epochs, acc)</span><br><span class="line">plt.plot(epochs, val_acc)</span><br><span class="line">plt.title(<span class="string">'Training and validation accuracy'</span>)</span><br><span class="line"></span><br><span class="line">plt.figure()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Plot training and validation loss per epoch</span></span><br><span class="line">plt.plot(epochs, loss)</span><br><span class="line">plt.plot(epochs, val_loss)</span><br><span class="line">plt.title(<span class="string">'Training and validation loss'</span>)</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/卷积神经网络复习/20190119020805093.png" alt><br>上图表示模型过拟合了，简单来说就是训练集和验证集上模型表现不一致。主要原因的数据集太小，一些示例太少，导致模型学习到的知识推广不到新的数据集上，即当模型开始用不相关的特征进行预测的时候就会发生过拟合。例如，如果你作为人类，只能看到三个伐木工人的图像，以及三个水手人的图像，其中唯一一个戴帽子的人是伐木工人，你可能会开始认为戴着帽子是一名伐木工人而不是水手的标志。然后你会做一个非常差的伐木工人 / 水手分类器。</p>
<h2 id="Reference" class="heading-control"><a href="#Reference" class="headerlink" title="Reference"></a>Reference<a class="heading-anchor" href="#Reference" aria-hidden="true"></a></h2><ul>
<li><a href="https://developers.google.cn/machine-learning/practica/image-classification/">https://developers.google.cn/machine-learning/practica/image-classification/</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzA3NDIyMjM1NA==&mid=2649029512&idx=1&sn=a46fc10de7daba25694bda75a916aa91&chksm=871345f5b064cce3c16ab3b7c671f9e93c838836e20d0aa91bc83f7879915d0c8318bcd9d187&token=1879088111&lang=zh_CN#rd">从 LeNet 到 VGG，看卷积 + 池化串联的网络结构</a></li>
</ul>
</body></html>]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>CNN</tag>
      </tags>
  </entry>
  <entry>
    <title>向上捅破天，向下扎到根</title>
    <url>/post/fdb68096.html</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><blockquote>
<p>10 月 27 日，华为 “心声社区” 刊发创始人任正非 9 月 14-18 日访问北京大学、清华大学、中国科学院等学校与部分科学家、学生代表座谈时的发言，题为《向上捅破天，向下扎到根》。</p>
</blockquote>
<p>习主席在与科学家座谈会讲了，基础教育、基础研究、基础理论、基础工业，也讲了科学家的好奇心驱动。国家不仅要重视科学理论、工程技术的研究，也要重视一些不以应用为目的的纯研究。不然我们怎么能向上捅破天呢？我们这么大的经济总量，允许一部分人是 “梵高” 应该是可以的。科学史上，有一种生存了八千万年的蛭虫，多少科学家研究了数十年，有些科学家因找不到雄的蛭虫而发大火，实际上他已经走到诺贝尔奖的边上了，最后由比利时科学家发现它是单性繁殖。两性繁殖，两条基因链的结合会产生突变，会有优秀的一代产生，当然，不健康的就流产了，自然淘汰。那么单亲繁殖的基因链若有病变、有问题，遗传下去不就灭绝了吗？她发现蛭虫的基因链会断裂，又会重新整合，这不就是优选吗？所以它们经历八千万年，经历多少灾难，还存活下来了。</p>
<a id="more"></a>
<p>我国的经济总量这么大，这么大的一棵树，根不强是不行的，不扎到根，树是不稳的，万一刮台风呢？我们拧开水龙头就出水的短、平、快的经济发展模式是不可持续的。我国的基础工业还是不强的，小小一滴胶，就制约一个国家的故事，我们已经看到了，这是分子工程，是高科技中的高科技。而这几千种胶、研磨剂、特种气体……，都是高科技中的高科技，我国现在还基本达不到，很多种技术一年的需求量只有几千万美元、几百万美元甚至更少，试看泡沫经济下有几个公司肯干这种事。缺一种就会卡了一个国家的脖子。</p>
<p>过河需要船和桥，我们有了很好的科学目标，过河的船夫就是人才，人才来自教育，因此，国家的发展根本在教育。我们振兴中华，不是靠口号，而是要靠 “船” 和 “桥”。</p>
<p>我国每年有七、八百万大学生毕业，加上中专生大约有一千万，聪明人很多，如果允许差别化的教育，就是姹紫嫣红。一二一，齐步走，同质化就缺少活力，就不易产生天才。世界有一个乔布斯就改变了移动互联网。差异化就容易产生尖子，政策要支持少数人因材施教。同时，也要重视农村教育，现在有些种田能手、养猪状元，如果他们过去有机会受到系统教育，也许就能成为精英、天才。早期中共的领袖大多来自农村，毛主席、粟裕……。我们今天的农村孩子中，怎么知道不会有明天的爱因斯坦呢？深圳很重视中小学教育，全国达到深圳的水平可能有一些困难。但如果国家每年给边远地区一些经费，让穷孩子每天能吃上二两肉，也许比修些大房子强，房子总会旧的，孩子总会成为博士的，而且他们会更忠于祖国。那么二、三十年后，我们的创新能力就大幅度增强，与美国的差距会适当缩小。没有创新是支撑不了我们这么大的经济总量持续发展的。</p>
<p>在科学、技术、工程领域，不同人才选择不同的方向，充分发挥每个人的才智。多学科交叉突破会更有可能，横向融合创新才能形成颠覆性的效果；科学、技术、工程垂直打通才会形成能力，真正落实创新驱动发展的理念。因此合作交流越来越重要，当然，大学还是应偏科学理论，偏重发现；企业偏重技术、工程，偏重发明，结合起来，力量才会更强大。</p>
<p>美国是世界上最强大的科技国家，特别是在吸引全球优秀人才上，有特别独到的优势。我们今天的科研状况很像二战前的美国，二战前 50 年时间，尽管美国产业已经领先全球，但在科研上充满功利主义，不重视基础研究、基础教育，大量依赖欧洲的灯塔照耀，利用欧洲的基础研究成果，发展短、平、快的产业。二战即将结束时，罗斯福总统的科技顾问范内瓦・布什在 “科学：无尽的前沿” 中提出要重视不以应用为目的的基础研究，面向长远，逐步摆脱了对欧洲基础科学研究的依赖，从此，美国基础科学研究远远领跑全球，形成若干重大突破。美国经过几十年的实践，上世纪九十年代，美国普林斯顿大学的唐纳德・斯托克斯 1997 年在 “基础科学与技术创新：巴斯德象限” 中，强调美国不仅需要纯技术研究，即波尔象限，也要纯应用开发的爱迪生象限，更强调应用驱动的基础科学研究。理论上遥遥领先，又与应用结合，这样既拓展了科学认知，又能创造价值。例如，北大张平文副校长说，据说波音 777 飞机的风洞吹风是使用全新的空气动力学软件模拟仿真的，使过去需要 80 次风洞试验减少到现在的 7 次左右，那么说明美国已把空气动力学的漩涡都变成了经典力学方程。而我们不吹风还不敢造飞机。俄罗斯将核发动机小型化，形成了战略威慑；美国把核弹小型化、战术化、无污染化。和平需要实力相当才可获取，祥林嫂式的和平是不存在的。美国的科技发展史就是一面镜子，我们以此来反思我国的科技发展战略的系统性、科学性。学人之长，长自己之力。</p>
<p>现在美国主张中美科技脱钩，美国是因为开放才走到今天的强大，封闭会重返落后的。清华张钹教授讲，美国越讲脱钩，我们越要高举科学无国界，坚持开放和国际化。科学是对客观规律的认识，真理只有一个，不存在东方科学、西方科学。论文都会公开发表，可以查询的，我们要站在前人的肩膀上，摸到上帝的脚。我们要坚持向一切先进学习，封闭是不会成功的。华为今天遇到的困难，不是依托全球化平台，在战略方向上压上重兵产生突破，而有什么错误。而是我们设计的先进芯片，国内的基础工业还造不出来，我们不可能又做产品，又去制造芯片。就如我们缺粮，不能自己种稻子一样。技术创新它是可以依据理论，独立设计、发明出来的。就如汽车，都是四个轮子，车都不一样。理论是可以在网上看到的，是大江、大洋、大山阻隔不了的。</p>
<p>科学发现、技术创新中最主要的是宽容。领导经常会问，最新进展怎么样了，你们研究成果有什么价值，能创造多少 GDP。科学家要么说不出话，要么只好说违心的话。当科学家过多关心应用、关心价值，他的锚就锚在地上了，怎么飞得高？科学的道路是漫长的孤寂的道路，多少代人孜孜不倦的努力，才发现一点点真理。急功近利只有戏剧作家，才会写出科学家既会弹钢琴又会魔术般地出成果。我们要耐得住科学家的寂寞与无奈。就如我司 5G Massive MIMO，起初没有人认同，搞了八年终于成功上市，成为核心竞争力。又如，2G 与 3G 之间的算法打通，没有公司莫斯科研究所的小伙子安德烈默默无闻的几年，没有宽容，就没有华为的无线成功。我们如何追溯对这些过程中默默无闻贡献的人，并给予鼓励，包括中途已离职的有功员工，是我们干部部门应该改进的地方。过去几年由于评价不清楚、不准确，给人家打 C 了，可不可以追溯把他们重新评定为 A、B+，他们本来就是 A 的。我们只有尊重历史，才会英雄辈出。只有承认科学的历史观，才会有科学的发展观。我们今天受到百年未闻的打压及围剿，20 万员工的忘我奋斗，正在挽救公司的存亡，如果我们还有可能胜利的一天，我们不要忘了千万奋斗的英雄，各级干部部门要作好记录工作，追溯英雄，是为了产生更多的英雄。英雄是平凡人，不要忘记他们。忘记就意味着背叛。</p>
<p>我们处在一个最好的时代，我们的年青人又如此活跃，我们的国家一定充满希望。同学们快快起来，担负起天下的兴亡。你们今天桃李芬芳，明天是社会的栋梁。你们是早上八、九点钟的太阳，希望寄托在你们身上。</p>
]]></content>
      <tags>
        <tag>社会</tag>
      </tags>
  </entry>
  <entry>
    <title>在 Pypi 上发表自己的 Python 库</title>
    <url>/post/59741.html</url>
    <content><![CDATA[<html><head><link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script></head><body><p><img src="https://i.loli.net/2018/11/28/5bfdfc9b41bb7.png" alt></p>
<h2 id="推荐两篇很好的文章" class="heading-control"><a href="#推荐两篇很好的文章" class="headerlink" title="推荐两篇很好的文章"></a>推荐两篇很好的文章<a class="heading-anchor" href="#推荐两篇很好的文章" aria-hidden="true"></a></h2><ul>
<li><a href="https://www.xncoding.com/2015/10/26/python/setuptools.html">python 核心 - 打包与发布</a></li>
<li><a href="https://www.xncoding.com/2017/01/22/fullstack/readthedoc.html">使用 ReadtheDocs 托管文档</a></li>
</ul>
<h2 id="准备" class="heading-control"><a href="#准备" class="headerlink" title="准备"></a>准备<a class="heading-anchor" href="#准备" aria-hidden="true"></a></h2><h3 id="注册账号" class="heading-control"><a href="#注册账号" class="headerlink" title="注册账号"></a>注册账号<a class="heading-anchor" href="#注册账号" aria-hidden="true"></a></h3><p>很显然地要在 Pypi 上注册一个账号，记住账号和密码。<br><a id="more"></a></p>
<h3 id="安装必要的库" class="heading-control"><a href="#安装必要的库" class="headerlink" title="安装必要的库"></a>安装必要的库<a class="heading-anchor" href="#安装必要的库" aria-hidden="true"></a></h3><h4 id="setuptools" class="heading-control"><a href="#setuptools" class="headerlink" title="setuptools"></a>setuptools<a class="heading-anchor" href="#setuptools" aria-hidden="true"></a></h4><p>原则上安装了 pip 的环境都有 setuptools, 但并不影响你去尝试升级一下它。<br><code>pip install --upgrade setuptools</code></p>
<h4 id="twine" class="heading-control"><a href="#twine" class="headerlink" title="twine"></a>twine<a class="heading-anchor" href="#twine" aria-hidden="true"></a></h4><p>这是一个简化将库发布到 Pypi 上流程的工具，具体的使用之后会讲到。<br><code>pip install --upgrade setuptools</code></p>
<h4 id="克隆仓库" class="heading-control"><a href="#克隆仓库" class="headerlink" title="克隆仓库"></a>克隆仓库<a class="heading-anchor" href="#克隆仓库" aria-hidden="true"></a></h4><p>大名鼎鼎的 requests 库的作者大神 kennethreitz 为大家准备了一个仓库作为一个 setup.py 的很好的模板，当然你也可以自己手写 setup.py。<br><code>git clone  https://github.com/kennethreitz/setup.py</code></p>
<h2 id="编码" class="heading-control"><a href="#编码" class="headerlink" title="编码"></a>编码<a class="heading-anchor" href="#编码" aria-hidden="true"></a></h2><h3 id="编辑setup-py" class="heading-control"><a href="#编辑setup-py" class="headerlink" title="编辑setup.py"></a>编辑 setup.py<a class="heading-anchor" href="#编辑setup-py" aria-hidden="true"></a></h3><p>直接编辑之前的仓库里的 setup.py， 只需要修改一些必要的配置就可以了。</p>
<h3 id="编写核心代码" class="heading-control"><a href="#编写核心代码" class="headerlink" title="编写核心代码"></a>编写核心代码<a class="heading-anchor" href="#编写核心代码" aria-hidden="true"></a></h3><p>接下来我们就可以编写自己的代码了，要注意源代码文件夹（仓库里的 my <em>package 文件夹）的名字与 setup.py 里配置的包名（Name）要一致。<br>另外在重新上传之前我们要修改<em>_version</em></em>.py 里的版本号，以免覆盖了以前的上传。<br>最终的代码结构:<br></p><figure class="highlight shell"><table><tbody><tr><td class="code"><pre><span class="line">│  LICENSE</span><br><span class="line">│  MANIFEST.in</span><br><span class="line">│  README.rst</span><br><span class="line">│  setup.py</span><br><span class="line">│</span><br><span class="line">└─condition_chain</span><br><span class="line">        core.py</span><br><span class="line">        __init__.py</span><br><span class="line">        __version__.py</span><br></pre></td></tr></tbody></table></figure><p></p>
<h3 id="打包上传" class="heading-control"><a href="#打包上传" class="headerlink" title="打包上传"></a>打包上传<a class="heading-anchor" href="#打包上传" aria-hidden="true"></a></h3><p>在 setup.py 的同级目录下运行以下命令。<br><code>python setup.py sdist bdist_wheel</code><br>然后运行 <code>twine upload dist/*</code><br>注意要输入 Pypi 账号和密码。</p>
<h2 id="大功告成" class="heading-control"><a href="#大功告成" class="headerlink" title="大功告成"></a>大功告成<a class="heading-anchor" href="#大功告成" aria-hidden="true"></a></h2><p>之后我们就可以在 Pypi 里搜索到自己的 Python 库了，当然也可以直接通过 pip 安装。</p>
</body></html>]]></content>
      <categories>
        <category>工具</category>
      </categories>
      <tags>
        <tag>pypi</tag>
      </tags>
  </entry>
  <entry>
    <title>大数据专题</title>
    <url>/post/13373.html</url>
    <content><![CDATA[<html><head><link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script></head><body><h2 id="哈希函数" class="heading-control"><a href="#哈希函数" class="headerlink" title="哈希函数"></a>哈希函数<a class="heading-anchor" href="#哈希函数" aria-hidden="true"></a></h2><p>哈希函数又叫散列函数，输入范围很大，输出范围固定。<br>哈希函数的性质：</p>
<ul>
<li>无限的输入域</li>
<li>输出值相同时，返回值一样</li>
<li>输入值不同时，返回值可能一样，也可能不一样</li>
<li>不同的输入值得到的 hash, 整体均匀分布在输出域上</li>
</ul>
<p>1~3 是哈希函数的基础，第四点是评价 hash 函数优劣的关键。</p>
<a id="more"></a>
<h2 id="Map-Reduce" class="heading-control"><a href="#Map-Reduce" class="headerlink" title="Map-Reduce"></a>Map-Reduce<a class="heading-anchor" href="#Map-Reduce" aria-hidden="true"></a></h2><ol>
<li>map 阶段：把大任务分解为子任务</li>
<li> reduce 阶段：子任务并发处理然后合并结果</li>
</ol>
<p>注意点：</p>
<ul>
<li>数据备份和容灾（需要多少备份）</li>
<li>任务分配策略和任务进度跟踪</li>
<li>多用户权限的控制</li>
</ul>
<p>Map-Reduce 统计文章单词出现的个数<br><img src="https://i.loli.net/2019/08/10/8HSDQFfAn7uNliw.png" alt></p>
<h2 id="一致性hash" class="heading-control"><a href="#一致性hash" class="headerlink" title="一致性hash"></a>一致性 hash<a class="heading-anchor" href="#一致性hash" aria-hidden="true"></a></h2><p><strong>数据的归属问题</strong>：数据经过 hash 计算到环上，如果在中间顺时针到离它最近的机器上<br><img src="https://i.loli.net/2019/08/10/vleEFustc2J5mGH.png" alt><br><img src="https://i.loli.net/2019/08/10/UfbxsPk8T6HW4X3.png" alt><br>例如上图：data1 归属于 machine2，data3 归属于 machine3，data3、data4 归属于 machine1<br><strong>机器的添加和删除</strong>: 一个机器故障，数据顺时针迁移到下一台机器上。添加新的机器的时候添加机器和它逆时针的最近机器之间的数据迁移到添加机器上。</p>
<h2 id="常见海量处理题目的关键" class="heading-control"><a href="#常见海量处理题目的关键" class="headerlink" title="常见海量处理题目的关键"></a>常见海量处理题目的关键<a class="heading-anchor" href="#常见海量处理题目的关键" aria-hidden="true"></a></h2><ul>
<li>分而治之：通过 hash 函数把大任务分流到机器，或者分流成小文件</li>
<li>常用 hashMap 或者 bitMap 上面</li>
</ul>
<p>难点在对通讯、时间、空间复杂度的估计</p>
<h2 id="IPV4地址排序" class="heading-control"><a href="#IPV4地址排序" class="headerlink" title="IPV4地址排序"></a>IPV4 地址排序<a class="heading-anchor" href="#IPV4地址排序" aria-hidden="true"></a></h2><p><strong>请对 10 亿个 IPV4 地址排序，每个 ip 出现一次</strong><br>方法：BitMap:<br><img src="https://i.loli.net/2019/08/10/6HsKvB31w7GTd4y.png" alt></p>
<h2 id="年龄排序" class="heading-control"><a href="#年龄排序" class="headerlink" title="年龄排序"></a>年龄排序<a class="heading-anchor" href="#年龄排序" aria-hidden="true"></a></h2><p><strong>10 亿人的年龄排序</strong><br>方法：计数排序<br><img src="https://i.loli.net/2019/08/10/FfkoZyeItvrN5qw.png" alt></p>
<h2 id="出现内存中最多的数" class="heading-control"><a href="#出现内存中最多的数" class="headerlink" title="出现内存中最多的数"></a>出现内存中最多的数<a class="heading-anchor" href="#出现内存中最多的数" aria-hidden="true"></a></h2><p><strong>有一个包含 20 亿个全是 32 位整数的大文件，在其中找到出现次数最多的数。但是内存限制只有 2G.</strong><br>哈希表方案（不可行）：<br><img src="https://i.loli.net/2019/08/10/iPmbwZaGlUWLRx9.png" alt><br>哈希分流 (可行)：<br><img src="https://i.loli.net/2019/08/10/HhvMagYmzwRsbEi.png" alt></p>
<p><strong>计算：8 字节 x2 亿 = 1.6G</strong></p>
<h2 id="没出现过的数" class="heading-control"><a href="#没出现过的数" class="headerlink" title="没出现过的数"></a>没出现过的数<a class="heading-anchor" href="#没出现过的数" aria-hidden="true"></a></h2><p><strong>32 位无符号整数的范围是 0~4294967295。现在有一个正好包含 40 亿个无符号整数的文件，所以在整个范围中必然有没出现过的数。可以使用最多 10M 的内存，<br>只用找到一个没出现过的数即可，该如何找？</strong></p>
<p>hashMap 方法（不可行）：<br><img src="https://i.loli.net/2019/08/10/sQ2HklfwpB4Y7GA.png" alt><br>bitMap 方法（不可行）：<br><img src="https://i.loli.net/2019/08/10/WTrAG7pMvBwQHNd.png" alt><br>hash 分流<br><img src="https://i.loli.net/2019/08/10/nECHiFSG3gb4l1o.png" alt><br><img src="https://s2.ax1x.com/2019/08/10/eLwa4g.png" alt="eLwa4g.png"></p>
<h2 id="热词Topk" class="heading-control"><a href="#热词Topk" class="headerlink" title="热词Topk"></a>热词 Topk<a class="heading-anchor" href="#热词Topk" aria-hidden="true"></a></h2><p><strong>百亿数据量的搜索词汇，设计求每天最热 100 词的方法</strong><br>hash 分流<br><img src="https://s2.ax1x.com/2019/08/10/eLwNE8.png" alt="eLwNE8.png"></p>
</body></html>]]></content>
      <tags>
        <tag>大数据</tag>
      </tags>
  </entry>
  <entry>
    <title>如何入门深度学习</title>
    <url>/post/48955.html</url>
    <content><![CDATA[<html><head><link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script></head><body><h2 id="Step0：搭建深度学习环境" class="heading-control"><a href="#Step0：搭建深度学习环境" class="headerlink" title="Step0：搭建深度学习环境"></a>Step0：搭建深度学习环境<a class="heading-anchor" href="#Step0：搭建深度学习环境" aria-hidden="true"></a></h2><ul>
<li>Doker 搭建深度学习环境：<a href="https://www.cnblogs.com/bingmang/p/9813686.html">https://www.cnblogs.com/bingmang/p/9813686.html</a></li>
<li>Pycharm 远程连接服务器：<a href="https://www.cnblogs.com/zhuminghui/p/10947930.html">https://www.cnblogs.com/zhuminghui/p/10947930.html</a></li>
<li> 服务器使用 screen 后台运行程序：<a href="https://sunyanhust.github.io/post/fu-wu-qi-shi-yong-screen-hou-tai-yun-xing-cheng-xu/">https://sunyanhust.github.io/post/fu-wu-qi-shi-yong-screen-hou-tai-yun-xing-cheng-xu/</a></li>
</ul>
<a id="more"></a>
<h2 id="Step1-通过阅读《Python深度学习》掌握深度学习基础知识" class="heading-control"><a href="#Step1-通过阅读《Python深度学习》掌握深度学习基础知识" class="headerlink" title="Step1: 通过阅读《Python深度学习》掌握深度学习基础知识"></a>Step1: 通过阅读《Python 深度学习》掌握深度学习基础知识<a class="heading-anchor" href="#Step1-通过阅读《Python深度学习》掌握深度学习基础知识" aria-hidden="true"></a></h2><p>《Python 深度学习》这本书是 Keras 之父 Francois Chollet 所著，该书假定读者无任何机器学习知识，以 Keras 为工具，使用丰富的范例示范深度学习的最佳实践，该书通俗易懂，全书没有一个数学公式，注重培养读者的深度学习直觉。</p>
<ul>
<li><strong>电子版下载</strong>：<a href="https://pan.baidu.com/s/1-4q6VjLTb3ZxcefyNCbjSA">https://pan.baidu.com/s/1-4q6VjLTb3ZxcefyNCbjSA</a> 提取码：wtzo，</li>
<li><strong>代码</strong>：<a href="https://github.com/fchollet/deep-learning-with-python-notebooks">https://github.com/fchollet/deep-learning-with-python-notebooks</a></li>
</ul>
<h2 id="Step2：通过教程《30天吃掉那只-TensorFlow2》深入学习TensorFlow" class="heading-control"><a href="#Step2：通过教程《30天吃掉那只-TensorFlow2》深入学习TensorFlow" class="headerlink" title="Step2：通过教程《30天吃掉那只 TensorFlow2》深入学习TensorFlow"></a>Step2：通过教程《30 天吃掉那只 TensorFlow2》深入学习 TensorFlow<a class="heading-anchor" href="#Step2：通过教程《30天吃掉那只-TensorFlow2》深入学习TensorFlow" aria-hidden="true"></a></h2><ul>
<li>📚 gitbook 电子书地址： <a href="https://lyhue1991.github.io/eat_tensorflow2_in_30_days">https://lyhue1991.github.io/eat_tensorflow2_in_30_days</a></li>
<li>🚀 github 项目地址：<a href="https://github.com/lyhue1991/eat_tensorflow2_in_30_days">https://github.com/lyhue1991/eat_tensorflow2_in_30_days</a></li>
<li>🐳 kesci 专栏地址：<a href="https://www.kesci.com/home/column/5d8ef3c3037db3002d3aa3a0">https://www.kesci.com/home/column/5d8ef3c3037db3002d3aa3a0</a></li>
</ul>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:right"> 日期</th>
<th style="text-align:left">学习内容</th>
<th style="text-align:right">内容难度</th>
<th style="text-align:right">预计学习时间</th>
<th style="text-align:right">更新状态</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:right"> </td>
<td style="text-align:left"><a href="./一、TensorFlow的建模流程.md"><strong>一、TensorFlow 的建模流程</strong></a></td>
<td style="text-align:right">⭐️</td>
<td style="text-align:right">0hour</td>
<td style="text-align:right">✅</td>
</tr>
<tr>
<td style="text-align:right">day1</td>
<td style="text-align:left"><a href="./1-1,结构化数据建模流程范例.md">1-1, 结构化数据建模流程范例</a></td>
<td style="text-align:right">⭐️⭐️⭐️</td>
<td style="text-align:right">1hour</td>
<td style="text-align:right">✅</td>
</tr>
<tr>
<td style="text-align:right">day2</td>
<td style="text-align:left"><a href="./1-2,图片数据建模流程范例.md">1-2, 图片数据建模流程范例</a></td>
<td style="text-align:right">⭐️⭐️⭐️⭐️</td>
<td style="text-align:right">2hour</td>
<td style="text-align:right">✅</td>
</tr>
<tr>
<td style="text-align:right">day3</td>
<td style="text-align:left"><a href="./1-3,文本数据建模流程范例.md">1-3, 文本数据建模流程范例</a></td>
<td style="text-align:right">⭐️⭐️⭐️⭐️⭐️</td>
<td style="text-align:right">2hour</td>
<td style="text-align:right">✅</td>
</tr>
<tr>
<td style="text-align:right">day4</td>
<td style="text-align:left"><a href="./1-4,时间序列数据建模流程范例.md">1-4, 时间序列数据建模流程范例</a></td>
<td style="text-align:right">⭐️⭐️⭐️⭐️⭐️</td>
<td style="text-align:right">2hour</td>
<td style="text-align:right">✅</td>
</tr>
<tr>
<td style="text-align:right"> </td>
<td style="text-align:left"><a href="./二、TensorFlow的核心概念.md"><strong>二、TensorFlow 的核心概念</strong></a></td>
<td style="text-align:right">⭐️</td>
<td style="text-align:right">0hour</td>
<td style="text-align:right">✅</td>
</tr>
<tr>
<td style="text-align:right">day5</td>
<td style="text-align:left"><a href="./2-1,张量数据结构.md">2-1, 张量数据结构</a></td>
<td style="text-align:right">⭐️⭐️⭐️⭐️</td>
<td style="text-align:right">1hour</td>
<td style="text-align:right">✅</td>
</tr>
<tr>
<td style="text-align:right">day6</td>
<td style="text-align:left"><a href="./2-2,三种计算图.md">2-2, 三种计算图</a></td>
<td style="text-align:right">⭐️⭐️⭐️⭐️⭐️</td>
<td style="text-align:right">2hour</td>
<td style="text-align:right">✅</td>
</tr>
<tr>
<td style="text-align:right">day7</td>
<td style="text-align:left"><a href="./2-3,自动微分机制.md">2-3, 自动微分机制</a></td>
<td style="text-align:right">⭐️⭐️⭐️</td>
<td style="text-align:right">1hour</td>
<td style="text-align:right">✅</td>
</tr>
<tr>
<td style="text-align:right"> </td>
<td style="text-align:left"><a href="./三、TensorFlow的层次结构.md"><strong>三、TensorFlow 的层次结构</strong></a></td>
<td style="text-align:right">⭐️</td>
<td style="text-align:right">0hour</td>
<td style="text-align:right">✅</td>
</tr>
<tr>
<td style="text-align:right">day8</td>
<td style="text-align:left"><a href="./3-1,低阶API示范.md">3-1, 低阶 API 示范</a></td>
<td style="text-align:right">⭐️⭐️⭐️⭐️</td>
<td style="text-align:right">1hour</td>
<td style="text-align:right">✅</td>
</tr>
<tr>
<td style="text-align:right">day9</td>
<td style="text-align:left"><a href="./3-2,中阶API示范.md">3-2, 中阶 API 示范</a></td>
<td style="text-align:right">⭐️⭐️⭐️</td>
<td style="text-align:right">1hour</td>
<td style="text-align:right">✅</td>
</tr>
<tr>
<td style="text-align:right">day10</td>
<td style="text-align:left"><a href="./3-3,高阶API示范.md">3-3, 高阶 API 示范</a></td>
<td style="text-align:right">⭐️⭐️⭐️</td>
<td style="text-align:right">1hour</td>
<td style="text-align:right">✅</td>
</tr>
<tr>
<td style="text-align:right"> </td>
<td style="text-align:left"><a href="./四、TensorFlow的低阶API.md"><strong>四、TensorFlow 的低阶 API</strong></a></td>
<td style="text-align:right">⭐️</td>
<td style="text-align:right">0hour</td>
<td style="text-align:right">✅</td>
</tr>
<tr>
<td style="text-align:right">day11</td>
<td style="text-align:left"><a href="./4-1,张量的结构操作.md">4-1, 张量的结构操作</a></td>
<td style="text-align:right">⭐️⭐️⭐️⭐️⭐️</td>
<td style="text-align:right">2hour</td>
<td style="text-align:right">✅</td>
</tr>
<tr>
<td style="text-align:right">day12</td>
<td style="text-align:left"><a href="./4-2,张量的数学运算.md">4-2, 张量的数学运算</a></td>
<td style="text-align:right">⭐️⭐️⭐️⭐️</td>
<td style="text-align:right">1hour</td>
<td style="text-align:right">✅</td>
</tr>
<tr>
<td style="text-align:right">day13</td>
<td style="text-align:left"><a href="./4-3,AutoGraph的使用规范.md">4-3,AutoGraph 的使用规范</a></td>
<td style="text-align:right">⭐️⭐️⭐️</td>
<td style="text-align:right">0.5hour</td>
<td style="text-align:right">✅</td>
</tr>
<tr>
<td style="text-align:right">day14</td>
<td style="text-align:left"><a href="./4-4,AutoGraph的机制原理.md">4-4,AutoGraph 的机制原理</a></td>
<td style="text-align:right">⭐️⭐️⭐️⭐️⭐️</td>
<td style="text-align:right">2hour</td>
<td style="text-align:right">✅</td>
</tr>
<tr>
<td style="text-align:right">day15</td>
<td style="text-align:left"><a href="./4-5,AutoGraph和tf.Module.md">4-5,AutoGraph 和 tf.Module</a></td>
<td style="text-align:right">⭐️⭐️⭐️⭐️</td>
<td style="text-align:right">1hour</td>
<td style="text-align:right">✅</td>
</tr>
<tr>
<td style="text-align:right"> </td>
<td style="text-align:left"><a href="./五、TensorFlow的中阶API.md"><strong>五、TensorFlow 的中阶 API</strong></a></td>
<td style="text-align:right">⭐️</td>
<td style="text-align:right">0hour</td>
<td style="text-align:right">✅</td>
</tr>
<tr>
<td style="text-align:right">day16</td>
<td style="text-align:left"><a href="./5-1,数据管道Dataset.md">5-1, 数据管道 Dataset</a></td>
<td style="text-align:right">⭐️⭐️⭐️⭐️⭐️</td>
<td style="text-align:right">2hour</td>
<td style="text-align:right">✅</td>
</tr>
<tr>
<td style="text-align:right">day17</td>
<td style="text-align:left"><a href="./5-2,特征列feature_column.md">5-2, 特征列 feature_column</a></td>
<td style="text-align:right">⭐️⭐️⭐️⭐️</td>
<td style="text-align:right">1hour</td>
<td style="text-align:right">✅</td>
</tr>
<tr>
<td style="text-align:right">day18</td>
<td style="text-align:left"><a href="./5-3,激活函数activation.md">5-3, 激活函数 activation</a></td>
<td style="text-align:right">⭐️⭐️⭐️</td>
<td style="text-align:right">0.5hour</td>
<td style="text-align:right">✅</td>
</tr>
<tr>
<td style="text-align:right">day19</td>
<td style="text-align:left"><a href="./5-4,模型层layers.md">5-4, 模型层 layers</a></td>
<td style="text-align:right">⭐️⭐️⭐️</td>
<td style="text-align:right">1hour</td>
<td style="text-align:right">✅</td>
</tr>
<tr>
<td style="text-align:right">day20</td>
<td style="text-align:left"><a href="./5-5,损失函数losses.md">5-5, 损失函数 losses</a></td>
<td style="text-align:right">⭐️⭐️⭐️</td>
<td style="text-align:right">1hour</td>
<td style="text-align:right">✅</td>
</tr>
<tr>
<td style="text-align:right">day21</td>
<td style="text-align:left"><a href="./5-6,评估指标metrics.md">5-6, 评估指标 metrics</a></td>
<td style="text-align:right">⭐️⭐️⭐️</td>
<td style="text-align:right">1hour</td>
<td style="text-align:right">✅</td>
</tr>
<tr>
<td style="text-align:right">day22</td>
<td style="text-align:left"><a href="./5-7,优化器optimizers.md">5-7, 优化器 optimizers</a></td>
<td style="text-align:right">⭐️⭐️⭐️</td>
<td style="text-align:right">0.5hour</td>
<td style="text-align:right">✅</td>
</tr>
<tr>
<td style="text-align:right">day23</td>
<td style="text-align:left"><a href="./5-8,回调函数callbacks.md">5-8, 回调函数 callbacks</a></td>
<td style="text-align:right">⭐️⭐️⭐️⭐️</td>
<td style="text-align:right">1hour</td>
<td style="text-align:right">✅</td>
</tr>
<tr>
<td style="text-align:right"> </td>
<td style="text-align:left"><a href="./六、TensorFlow的高阶API.md"><strong>六、TensorFlow 的高阶 API</strong></a></td>
<td style="text-align:right">⭐️</td>
<td style="text-align:right">0hour</td>
<td style="text-align:right">✅</td>
</tr>
<tr>
<td style="text-align:right">day24</td>
<td style="text-align:left"><a href="./6-1,构建模型的3种方法.md">6-1, 构建模型的 3 种方法</a></td>
<td style="text-align:right">⭐️⭐️⭐️</td>
<td style="text-align:right">1hour</td>
<td style="text-align:right">✅</td>
</tr>
<tr>
<td style="text-align:right">day25</td>
<td style="text-align:left"><a href="./6-2,训练模型的3种方法.md">6-2, 训练模型的 3 种方法</a></td>
<td style="text-align:right">⭐️⭐️⭐️⭐️</td>
<td style="text-align:right">1hour</td>
<td style="text-align:right">✅</td>
</tr>
<tr>
<td style="text-align:right">day26</td>
<td style="text-align:left"><a href="./6-3,使用单GPU训练模型.md">6-3, 使用单 GPU 训练模型</a></td>
<td style="text-align:right">⭐️⭐️</td>
<td style="text-align:right">0.5hour</td>
<td style="text-align:right">✅</td>
</tr>
<tr>
<td style="text-align:right">day27</td>
<td style="text-align:left"><a href="./6-4,使用多GPU训练模型.md">6-4, 使用多 GPU 训练模型</a></td>
<td style="text-align:right">⭐️⭐️</td>
<td style="text-align:right">0.5hour</td>
<td style="text-align:right">✅</td>
</tr>
<tr>
<td style="text-align:right">day28</td>
<td style="text-align:left"><a href="./6-5,使用TPU训练模型.md">6-5, 使用 TPU 训练模型</a></td>
<td style="text-align:right">⭐️⭐️</td>
<td style="text-align:right">0.5hour</td>
<td style="text-align:right">✅</td>
</tr>
<tr>
<td style="text-align:right">day29</td>
<td style="text-align:left"><a href="./6-6,使用tensorflow-serving部署模型.md">6-6, 使用 tensorflow-serving 部署模型</a></td>
<td style="text-align:right">⭐️⭐️⭐️⭐️</td>
<td style="text-align:right">1hour</td>
<td style="text-align:right">✅</td>
</tr>
<tr>
<td style="text-align:right">day30</td>
<td style="text-align:left"><a href="./6-7,使用spark-scala调用tensorflow模型.md">6-7, 使用 spark-scala 调用 tensorflow 模型</a></td>
<td style="text-align:right">⭐️⭐️⭐️⭐️⭐️</td>
<td style="text-align:right">2hour</td>
<td style="text-align:right">✅</td>
</tr>
<tr>
<td style="text-align:right"> </td>
<td style="text-align:left"><a href="./后记：一个吃货和一道菜的故事.md">后记：一个吃货和一道菜的故事</a></td>
<td style="text-align:right">⭐️</td>
<td style="text-align:right">0hour</td>
<td style="text-align:right">✅</td>
</tr>
</tbody>
</table>
</div>
<h2 id="Step4-通过《CNN-Architectures》项目复现常见CNN模型，并阅读有关论文" class="heading-control"><a href="#Step4-通过《CNN-Architectures》项目复现常见CNN模型，并阅读有关论文" class="headerlink" title="Step4: 通过《CNN-Architectures》项目复现常见CNN模型，并阅读有关论文"></a>Step4: 通过《CNN-Architectures》项目复现常见 CNN 模型，并阅读有关论文<a class="heading-anchor" href="#Step4-通过《CNN-Architectures》项目复现常见CNN模型，并阅读有关论文" aria-hidden="true"></a></h2><p><strong>CNN-Architectures：</strong>  <a href="https://github.com/Machine-Learning-Tokyo/CNN-Architectures/tree/master/Implementations">https://github.com/Machine-Learning-Tokyo/CNN-Architectures/tree/master/Implementations</a></p>
<p>使用 <code>tf.keras</code>API 复现了一些常见 CNN 模型，包括：AlexNet、VGG、GoogLeNet、MobileNet、ResNet、Xception、SqueezeNet、DenseNet、ShuffleNet</p>
<h2 id="Step5-通过《Deep-Models-for-NLP-beginners》项目学习NLP基础知识" class="heading-control"><a href="#Step5-通过《Deep-Models-for-NLP-beginners》项目学习NLP基础知识" class="headerlink" title="Step5: 通过《Deep Models for NLP beginners》项目学习NLP基础知识"></a>Step5: 通过《Deep Models for NLP beginners》项目学习 NLP 基础知识<a class="heading-anchor" href="#Step5-通过《Deep-Models-for-NLP-beginners》项目学习NLP基础知识" aria-hidden="true"></a></h2><p>Deep Models for NLP beginners：<a href="https://github.com/BrambleXu/nlp-beginner-guide-keras">https://github.com/BrambleXu/nlp-beginner-guide-keras</a></p>
<p>包括词向量、情感分类以及实体识别</p>
</body></html>]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title>如何配置深度学习系统</title>
    <url>/post/65507.html</url>
    <content><![CDATA[<html><head><link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script></head><body><h2 id="Anacodna相关操作" class="heading-control"><a href="#Anacodna相关操作" class="headerlink" title="Anacodna相关操作"></a>Anacodna 相关操作<a class="heading-anchor" href="#Anacodna相关操作" aria-hidden="true"></a></h2><h3 id="下载安装以及切换镜像" class="heading-control"><a href="#下载安装以及切换镜像" class="headerlink" title="下载安装以及切换镜像"></a>下载安装以及切换镜像<a class="heading-anchor" href="#下载安装以及切换镜像" aria-hidden="true"></a></h3><figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="comment">#下载和安装anaconda</span></span><br><span class="line">wget https://mirrors.tuna.tsinghua.edu.cn/anaconda/archive/Anaconda3<span class="number">-5.2</span><span class="number">.0</span>-Linux-x86_64.sh</span><br><span class="line">bash Anaconda3<span class="number">-5.2</span><span class="number">.0</span>-Linux-x86_64.sh</span><br><span class="line"></span><br><span class="line"><span class="comment">#切换到清华源,加快下载速度</span></span><br><span class="line">wget https://tuna.moe/oh-my-tuna/oh-my-tuna.py</span><br><span class="line">python oh-my-tuna.py</span><br><span class="line">sudo python oh-my-tuna.py --<span class="keyword">global</span></span><br><span class="line"><span class="comment">#确认源是http而不是https</span></span><br><span class="line">vim ~/.condarc <span class="comment">#修改https为http</span></span><br></pre></td></tr></tbody></table></figure>
<p>conda 环境创建、退出和移除<br></p><figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line">conda create --name py36 python=<span class="number">3.6</span> <span class="comment">#创建环境</span></span><br><span class="line">conda activate py36 <span class="comment">#激活环境</span></span><br><span class="line">conda deactivate py36 <span class="comment">#退出环境</span></span><br><span class="line">conda remove --name py36 --all <span class="comment">#删除环境</span></span><br><span class="line">conda info -e <span class="comment">#查看系统中的所有环境</span></span><br></pre></td></tr></tbody></table></figure><br>conda查找包的所有版本<br><figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line">conda search tensorflow</span><br></pre></td></tr></tbody></table></figure><br>conda瘦身<br><figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line">conda clean -p      //删除没有用的包</span><br><span class="line">conda clean -t      //清理tar</span><br><span class="line">conda clean -a      //清理所有缓存包</span><br></pre></td></tr></tbody></table></figure><p></p>
<h2 id="查看系统内存和进程" class="heading-control"><a href="#查看系统内存和进程" class="headerlink" title="查看系统内存和进程"></a>查看系统内存和进程<a class="heading-anchor" href="#查看系统内存和进程" aria-hidden="true"></a></h2><figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="comment">#安装系统查看器</span></span><br><span class="line">pip install glances</span><br></pre></td></tr></tbody></table></figure>
<p>运行 <code>glances</code> 查看系统状态<br><img src="https://s2.ax1x.com/2019/10/26/K02cEn.png" alt="K02cEn.png"><br><a id="more"></a></p>
<h2 id="深度学习环境创建" class="heading-control"><a href="#深度学习环境创建" class="headerlink" title="深度学习环境创建"></a>深度学习环境创建<a class="heading-anchor" href="#深度学习环境创建" aria-hidden="true"></a></h2><p>注意不需要手动配置 cuda 和 cudnn, 直接 conda 安装</p>
<h3 id="TF环境" class="heading-control"><a href="#TF环境" class="headerlink" title="TF环境"></a>TF 环境<a class="heading-anchor" href="#TF环境" aria-hidden="true"></a></h3><p>1.x 推荐 1.14.0 版本<br></p><figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line">conda install tensorflow-gpu==<span class="number">1.14</span><span class="number">.0</span></span><br><span class="line"><span class="comment">#conda install tensorflow-gpu //默认是2.0版本</span></span><br><span class="line">conda install keras</span><br></pre></td></tr></tbody></table></figure><p></p>
<h3 id="Torch环境" class="heading-control"><a href="#Torch环境" class="headerlink" title="Torch环境"></a>Torch 环境<a class="heading-anchor" href="#Torch环境" aria-hidden="true"></a></h3><figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line">conda install pytorch torchvision cudatoolkit=<span class="number">10.0</span></span><br></pre></td></tr></tbody></table></figure>
<h3 id="在线安装失败" class="heading-control"><a href="#在线安装失败" class="headerlink" title="在线安装失败"></a>在线安装失败<a class="heading-anchor" href="#在线安装失败" aria-hidden="true"></a></h3><p>有可能因为网络原因下载失败，因此可以先下载然后本地安装，tf 和 torch 也类似</p>
<p>cuda 和 cudnn 安装<br></p><figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line">wget https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main/linux<span class="number">-64</span>/cudnn<span class="number">-7.3</span><span class="number">.1</span>-cuda10<span class="number">.0</span>_0.tar.bz2</span><br><span class="line">conda install cudnn<span class="number">-7.3</span><span class="number">.1</span>-cuda10<span class="number">.0</span>_0.tar.bz2 <span class="comment">#本地安装</span></span><br><span class="line">wget https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main/linux<span class="number">-64</span>/cudatoolkit<span class="number">-10.0</span><span class="number">.130</span><span class="number">-0.</span>tar.bz2</span><br><span class="line">conda install cudatoolkit<span class="number">-10.0</span><span class="number">.130</span><span class="number">-0.</span>tar.bz2 <span class="comment">#本地安装</span></span><br></pre></td></tr></tbody></table></figure><br>pytorch gpu版本<br><figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line">wget https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/pytorch/linux<span class="number">-64</span>/pytorch<span class="number">-1.3</span><span class="number">.0</span>-py3<span class="number">.6</span>_cuda10<span class="number">.0</span><span class="number">.130</span>_cudnn7<span class="number">.6</span><span class="number">.3</span>_0.tar.bz2</span><br><span class="line">conda install pytorch<span class="number">-1.3</span><span class="number">.0</span>-py3<span class="number">.6</span>_cuda10<span class="number">.0</span><span class="number">.130</span>_cudnn7<span class="number">.6</span><span class="number">.3</span>_0.tar.bz2</span><br></pre></td></tr></tbody></table></figure><p></p>
<h2 id="从头配置centos服务器环境" class="heading-control"><a href="#从头配置centos服务器环境" class="headerlink" title="从头配置centos服务器环境"></a>从头配置 centos 服务器环境<a class="heading-anchor" href="#从头配置centos服务器环境" aria-hidden="true"></a></h2><p>参考这篇 <a href="https://tengzi-will.github.io/2018/12/12/%E9%85%8D%E7%BD%AE-CentOS7-GPU-%E7%8E%AF%E5%A2%83/">博客</a></p>
</body></html>]]></content>
      <tags>
        <tag>系统</tag>
      </tags>
  </entry>
  <entry>
    <title>关于 AI 创业</title>
    <url>/post/54127.html</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>今天看到一个网站，<a href="http://www.yige.ai/">一个 AI</a>，看了一下是世纪佳缘做的。说实话，做的相当没有水平，完全是照抄 RASA 的，我甚至觉得我也可以做一个更好的出来，甚至由此萌发了想创业的想法。<br><a id="more"></a><br>也只是简单的想了一下，一来没什么本钱，二来觉得自己技术还不过硬。正好今天上午在知乎上看到<a href="https://www.zhihu.com/question/335394948/answer/752256254">互联网的十年</a>，感慨颇多。总体的感觉是 2009 到 2019 年互联网确实诞生了很多新兴行业和互联网公司，但是目前情况下的弱人工智能我暂时看不到什么很大的发展，觉得其中泡沫很多。<br>突然闪过的一个想法，按下不表吧。</p>
]]></content>
      <tags>
        <tag>创业</tag>
      </tags>
  </entry>
  <entry>
    <title>寻找最大的 K 个数</title>
    <url>/post/18004.html</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><ul>
<li>方法一：常规解法，先排序 (时间复杂度为 O (N*logN))</li>
<li> 方法二：利用快速排序原理 (时间复杂度 O (N*logK)</li>
<li> 方法三：利用最小堆的原理 (时间复杂度为 O (N*logK))</li>
<li> 方法四：计数排序，用空间换取时间的方法，不适合浮点数</li>
</ul>
]]></content>
      <tags>
        <tag>Topk</tag>
      </tags>
  </entry>
  <entry>
    <title>工作</title>
    <url>/post/60913.html</url>
    <content><![CDATA[<html><head><link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script></head><body><h2 id="招聘" class="heading-control"><a href="#招聘" class="headerlink" title="招聘"></a>招聘<a class="heading-anchor" href="#招聘" aria-hidden="true"></a></h2><p><a href="http://www.qhvss.com/about/2.html">陕西庆华汽车安全系统有限公司</a>是中国兵器工业集团所属特种能源集团直管单位，是集科研、生产、销售为一体的高新技术企业，是国内最大的汽车安全系统用火工品制造商，具有年产点火具 3000 万发，微型气体发生器 770 万发，产气药 500 吨的能力。</p>
<a id="more"></a>
<p>公司 2006 年 11 月成立，位于西安市灞桥区田洪正街 1 号。公司于 2009 年通过 ISO/16949 质量体系认证，达到美国 USCAR 标准；2014 年通过 ISO/14001 环境管理体系认证和 OHSMS 职业健康安全管理体系认证；2015 年通过 AK-LV16 认证；2016 年通过 IATF/16949 质量体系认证。</p>
<p>公司依托原西安北方庆华机电集团有限公司 50 多年的火工品研发、生产及试验优势，在汽车安全气囊用点火具和微型气体发生器等技术方面填补了国内空白，公司取得国家专利 17 项，其中发明专利 2 项，实用新型专利 15 项。目前，公司拥有点火具、微型气体发生器、产气药三大系列 100 多个品种的产品。产品配套与国际主流车型，凭借安全、可靠的性能和价格优势远销欧洲、美国、日本等国际市场，深受国内外用户欢迎。</p>
<p>为进一步加大公司国际化经营战略布局，公司成功引入华域汽车系统股份有限公司战略投资，在泾渭工业园兵器工业科技产业基地火工生产园建设经开分厂。2018 年投产后，公司生产能力在现有基础上增加一倍。</p>
<p>我公司现有职工 700 余人，其中管理技术人员 150 余人，公司有特能级科技带头人 1 人，公司级科技带头人 1 人，公司级关键技能带头人 1 人，公司级科技骨干 4 人，公司级技能骨干 7 人，中级及中级以上职称 40 余人。公司坚持科技发展，人才先行的人才战略，为员工建立了职业生涯规划，将员工的发展与企业的发展结合在一起，以实现员工与企业的双赢。</p>
<p>面对国内外市场的旺盛需求和对产品安全性能的严格要求，公司坚持技术一流、引领发展的科技理念，并秉承德才兼备、精业多能的人才理念。为给公司配备优秀的管理技术人员，特向社会各界广纳贤才，我们期望与您共同携手，将公司建设成为现代化管理、国际化经营的全球最具价值的点火具 MGG 独立供应商。</p>
<p>一、  招聘专业</p>
<p>化学工程与工艺：2 名</p>
<p>二、招聘条件</p>
<p>1、学历：本科及以上学历；</p>
<p>2、须通过英语四级；</p>
<p>3、2019 年应届毕业生；</p>
<p>4、身心健康。</p>
<p>三、福利待遇</p>
<p>1、工作时间：8 小时工作制，一周双休。按规定可享受年休假、婚假、产假、探亲假等带薪假期。</p>
<p>2、工资：见习期 1 年，见习期工资平均不低于 4000 元 / 月，见习期结束后，工资按照公司岗位绩效工资制度发放，年终根据公司经营情况发放年终奖励，转正定级后工资 6-10 万 / 年。新入司学生第 1 年享受安家费本科生 3000 元，研究生 5000 元。</p>
<p>3、社保待遇：签订劳动合同当月起开始享受五险一金（养老、工伤、失业、医疗、生育保险和住房公积金）待遇，公积金按照西安市单位最高标准 12%、个人最低标准 5% 缴纳。</p>
<p>4、公司提供单身公寓，单身公寓配有空调、电扇、暖气等设施。</p>
<p>5、每年发放一套工服，每季度发放劳保用品（洗衣粉肥皂），享受降温费、取暖费等福利待遇。</p>
<p>6、报名者经公司审查和面试合格后，新入司员工科享受免费体检及带薪培训。</p>
<p>四、报名应聘者提供以下相关资料：</p>
<p>1、本人简历。</p>
<p>2、本人有效身份证原件及复印件。</p>
<p>3、提供学校就业推荐证明，大学期间成绩单复印件。</p>
<p>五、报名时间：2018 年 11 月 1 日 - 2018 年 11 月 15 日</p>
<p>六、报名地点：西安市灞桥区田洪正街 1 号陕西庆华汽车安全系统有限公司人力资源部</p>
<p>联系人：宋  成             </p>
<p>电  话：029-62825341</p>
<p>投简历邮箱：songcheng@qhvss.com</p>
<p>网  址：www.qhvss.com</p>
<h2 id="位置" class="heading-control"><a href="#位置" class="headerlink" title="位置"></a>位置<a class="heading-anchor" href="#位置" aria-hidden="true"></a></h2><p><img src="https://i.loli.net/2018/12/06/5c090839d4569.png" alt></p>
<h2 id="其他" class="heading-control"><a href="#其他" class="headerlink" title="其他"></a>其他<a class="heading-anchor" href="#其他" aria-hidden="true"></a></h2><ul>
<li>江西国泰民爆集团股份有限公司招聘</li>
</ul>
</body></html>]]></content>
      <categories>
        <category>工作</category>
      </categories>
      <tags>
        <tag>工作</tag>
      </tags>
  </entry>
  <entry>
    <title>推荐系统召回算法</title>
    <url>/post/64078.html</url>
    <content><![CDATA[<html><head><link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script></head><body><h2 id="推荐系统整体流程" class="heading-control"><a href="#推荐系统整体流程" class="headerlink" title="推荐系统整体流程"></a>推荐系统整体流程<a class="heading-anchor" href="#推荐系统整体流程" aria-hidden="true"></a></h2><p><img src="https://i.loli.net/2020/08/31/FqeHsBKXUCgu8fJ.jpg" alt="img"></p>
<ul>
<li>多路召回：首先召回阶段是会配置召回的请求个数，通常会根据每路召回的后验表现设置动态配比，或者是根据业务的需求进行设置。所有的召回并发请求并设置 timeout，防止系统雪崩。</li>
<li>所有的召回结果 merge。</li>
<li>过滤：系统整体的黑名单，以及 by user 的黑名单过滤都可以在此处实现。</li>
<li>去重：此处通常都是简单的指纹去重，不做特别精细的多样性去重（比如相似新闻通常在排序后做）。(过滤和去重都是为了减少后续系统的压力，防止浪费算力进行后续步骤。)</li>
<li> 粗排后截断。当然粗排也可以放在每个召回队列中做，也是根据业务而定。</li>
<li>进行精排。</li>
<li>排序后的 rerank 处理，包括多样性去重，产品的特殊 boost 逻辑等。</li>
</ul>
<h2 id="什么是召回" class="heading-control"><a href="#什么是召回" class="headerlink" title="什么是召回"></a>什么是召回<a class="heading-anchor" href="#什么是召回" aria-hidden="true"></a></h2><p>召回系统，本质上是个<strong>信息漏斗</strong>，负责快速从海量信息中筛选出有价值的信息，缩小排序算法的搜素范围；也负责将多路召回的数据，进行<strong>信息融合</strong>，最后得到一个精简的候选集。</p>
<h3 id="召回的特性" class="heading-control"><a href="#召回的特性" class="headerlink" title="召回的特性"></a>召回的特性<a class="heading-anchor" href="#召回的特性" aria-hidden="true"></a></h3><p>处理的数据量非常大，速度要求快，所有使用的模型和特征都不能太复杂。</p>
<h3 id="召回的重要性" class="heading-control"><a href="#召回的重要性" class="headerlink" title="召回的重要性"></a>召回的重要性<a class="heading-anchor" href="#召回的重要性" aria-hidden="true"></a></h3><ul>
<li>奠基性：后续流程，基于召回数据展开</li>
<li>桥接性：建立用户和内容的桥梁</li>
<li>决定性：召回质量决定推荐质量</li>
</ul>
<a id="more"></a>
<h3 id="多路召回" class="heading-control"><a href="#多路召回" class="headerlink" title="多路召回"></a>多路召回<a class="heading-anchor" href="#多路召回" aria-hidden="true"></a></h3><p>如下图所示，每种算法按照各自的召回配比份额，进行召回对应数目的 item, 再进行去重 merge; 或者排序无性能压力的情况下，分别召回各自子召回域，再去重 merge; 亦或投票等等规则，得到我们推荐系统想要的召回池。<br><img src="https://i.loli.net/2020/08/31/UP2Vq6GacxZeb4I.jpg" alt="img"></p>
<h3 id="多路召回的演进" class="heading-control"><a href="#多路召回的演进" class="headerlink" title="多路召回的演进"></a>多路召回的演进<a class="heading-anchor" href="#多路召回的演进" aria-hidden="true"></a></h3><ul>
<li><strong>基于内容的召回</strong>：使用 item 之间的相似性来推荐与用户喜欢的 item 相似的 item</li>
<li><strong> 协同过滤</strong>：同时使用 query 和 item 之间的相似性来进行推荐。</li>
<li><strong>基于 FM 模型召回</strong>：FM 是基于矩阵分解的推荐算法，其核心是二阶特征组合。</li>
<li><strong>基于深度神经网络的方法</strong>：利用深度神经网络生成相应的候选集。</li>
</ul>
<p><img src="https://i.loli.net/2020/08/31/nTw7BabQkIAdeHt.png" alt="image-20200831213318505"></p>
<h2 id="评价指标" class="heading-control"><a href="#评价指标" class="headerlink" title="评价指标"></a>评价指标<a class="heading-anchor" href="#评价指标" aria-hidden="true"></a></h2><h3 id="真假正负" class="heading-control"><a href="#真假正负" class="headerlink" title="真假正负"></a>真假正负<a class="heading-anchor" href="#真假正负" aria-hidden="true"></a></h3><p>举一个狼来了的例子：</p>
<p><img src="https://i.loli.net/2020/08/31/RH35pfDWwKbjJ1B.png" alt="image-20200831204815515"></p>
<ul>
<li><strong>真正例</strong>是指模型将正类别样本正确地预测为正类别。</li>
<li><strong>真负例</strong>是指模型将负类别样本正确地预测为负类别。</li>
<li><strong>假正例</strong>是指模型将负类别样本错误地预测为正类别</li>
<li><strong>假负例</strong>是指模型将正类别样本错误地预测为负类别。</li>
</ul>
<h3 id="准确率" class="heading-control"><a href="#准确率" class="headerlink" title="准确率"></a>准确率<a class="heading-anchor" href="#准确率" aria-hidden="true"></a></h3><p><strong>准确率</strong>是指我们的模型预测正确的结果所占的比例，定义如下</p>
<p><img src="https://i.loli.net/2020/08/31/5dR43OLJDghcupP.png" alt="image-20200831205400100" style="zoom:50%;"></p>
<p>对于二分类，也可以根据正类别和负类别按如下方式计算准确率：</p>
<p><img src="https://i.loli.net/2020/08/31/LY6Gt5BDA2Nu3R7.png" alt="image-20200831205509668" style="zoom:50%;"></p>
<p>其中，TP = 真正例，TN = 真负例，FP = 假正例，FN = 假负例。</p>
<p>但是这个评估指标对于样本不均衡问题并不起作用。假设有下面的模型可以将 100 个肿瘤分为<a href="https://wikipedia.org/wiki/Malignancy">恶性</a>（正类别）或<a href="https://wikipedia.org/wiki/Benign_tumor">良性</a>（负类别）：</p>
<p><img src="https://i.loli.net/2020/08/31/lpdQzDVOH65B4AN.png" alt="image-20200831205716662"></p>
<p>按照正确率的计算公式：</p>
<p><img src="https://i.loli.net/2020/08/31/U39BpOzFdxIgQti.png" alt="image-20200831205755291" style="zoom:50%;"></p>
<p>看起来这个肿瘤分类器在识别恶性肿瘤方面表现得非常出色，对吧？但是实际上，只要我们仔细分析一下正类别和负类别，就可以更好地了解我们模型的效果。</p>
<p>在 100 个肿瘤样本中，91 个为良性（90 个 TN 和 1 个 FP），9 个为恶性（1 个 TP 和 8 个 FN）。在 91 个良性肿瘤中，该模型将 90 个正确识别为良性。这很好。不过，在 9 个恶性肿瘤中，该模型仅将 1 个正确识别为恶性。这是多么可怕的结果！9 个恶性肿瘤中有 8 个未被诊断出来！这说明我们的模型并没有区分恶性肿瘤和良性肿瘤的能力。</p>
<p>对于<strong>分类不平衡的数据集</strong>（比如正类别标签和负类别标签的数量之间存在明显差异）时，单单准确率一项并不能反映全面情况。在下一部分中，我们将介绍两个能够更好地评估分类不平衡问题的指标：精确率和召回率。</p>
<h3 id="精确率和召回率" class="heading-control"><a href="#精确率和召回率" class="headerlink" title="精确率和召回率"></a>精确率和召回率<a class="heading-anchor" href="#精确率和召回率" aria-hidden="true"></a></h3><p><img src="https://i.loli.net/2020/08/31/ehAUcQVECNHKnMt.png" alt="image-20200831210059135"></p>
<p><img src="https://i.loli.net/2020/08/31/I1jBUO73txCnq4i.png" alt="image-20200831210246036"></p>
<p>要全面评估模型的有效性，必须<strong>同时</strong>检查精确率和召回率。精确率和召回率往往是此消彼长的情况，也就是说，提高精确率通常会降低召回率值，反之亦然。</p>
<h2 id="召回的评测方法" class="heading-control"><a href="#召回的评测方法" class="headerlink" title="召回的评测方法"></a>召回的评测方法<a class="heading-anchor" href="#召回的评测方法" aria-hidden="true"></a></h2><p>在现有的个性化召回体系下，如果要新增一种个性化召回算法，需要知道这种个性化召回算法会对系统造成怎样的影响，是正向收益还是负向收益。所以经过离线和在线两个步骤的评测：</p>
<ol>
<li>离线评测：是作为能否进入线上的标准，主要是通过历史数据，场景重现，看用户反馈的各项指标是否有所提升，指标包括模型指标（P 值，r 值，F1 值等），业务指标 (CTR,CVR)。</li>
<li>在线评测：主要是通过逐级增大流量的 AB 实验的方法，进行测试，观察各种业务的在线指标，比如 CTR，CVR,GMV 等。</li>
</ol>
<p><img src="https://i.loli.net/2020/08/31/oalw95xWIj6ND3O.jpg" alt="img"></p>
</body></html>]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>召回</tag>
      </tags>
  </entry>
  <entry>
    <title>数值计算</title>
    <url>/post/58802.html</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>数值分析是研究科学计算中各种数学问题求解的数值计算方法。</p>
]]></content>
  </entry>
  <entry>
    <title>文本分词和去停止词的一次优化</title>
    <url>/post/314.html</url>
    <content><![CDATA[<html><head><link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script></head><body><p>之前在处理 QA 语料库的时候，在分词和去停止词的时候消耗时间很长，所以专门搜了一些资料针对这个问题进行了一次优化，总结如下。</p>
<h2 id="文本分词" class="heading-control"><a href="#文本分词" class="headerlink" title="文本分词"></a>文本分词<a class="heading-anchor" href="#文本分词" aria-hidden="true"></a></h2><h3 id="使用jieba自带的并行分词" class="heading-control"><a href="#使用jieba自带的并行分词" class="headerlink" title="使用jieba自带的并行分词"></a>使用 jieba 自带的并行分词<a class="heading-anchor" href="#使用jieba自带的并行分词" aria-hidden="true"></a></h3><p>在分词前添加 <code>jieba.enable_parallel(4)</code> 就行了。但是我这里并没有这么做，主要是怕分词顺序出错了。</p>
<h3 id="使用jieba-fast" class="heading-control"><a href="#使用jieba-fast" class="headerlink" title="使用jieba_fast"></a>使用 jieba_fast<a class="heading-anchor" href="#使用jieba-fast" aria-hidden="true"></a></h3><p>这是一个 cpython 的库，使用方法和 jieba 一致，<a href="https://github.com/deepcs233/jieba_fast">Github 官网</a>。官网的描述如下：</p>
<blockquote>
<p>使用 cpython 重写了 jieba 分词库中计算 DAG 和 HMM 中的 vitrebi 函数，速度得到大幅提升。</p>
</blockquote>
<p><img src="https://i.loli.net/2018/12/19/5c1a4826519eb.png" alt></p>
<h2 id="去停止词" class="heading-control"><a href="#去停止词" class="headerlink" title="去停止词"></a>去停止词<a class="heading-anchor" href="#去停止词" aria-hidden="true"></a></h2><h3 id="构建字典加速" class="heading-control"><a href="#构建字典加速" class="headerlink" title="构建字典加速"></a>构建字典加速<a class="heading-anchor" href="#构建字典加速" aria-hidden="true"></a></h3><p>我最开始使用的是把停止词读成列表，然后去列表里面查找，速度很慢。原先的代码如下：<br></p><figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_stopwords</span>(<span class="params">self,stopwords_path</span>):</span></span><br><span class="line">    stop_f = open(stopwords_path, <span class="string">"r"</span>, encoding=<span class="string">'utf-8'</span>)</span><br><span class="line">    stop_words = list()</span><br><span class="line">    <span class="keyword">for</span> line <span class="keyword">in</span> stop_f.readlines():</span><br><span class="line">        line = line.strip()</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> len(line):</span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line">        stop_words.append(line)</span><br><span class="line">    stop_f.close()</span><br><span class="line">    <span class="comment"># print('哈工大停止词表长度为：' + str(len(stop_words)))</span></span><br><span class="line">    <span class="keyword">return</span> stop_words</span><br></pre></td></tr></tbody></table></figure><br>改进之后，构建了停止词字典，速度提高了一倍左右。代码如下：<br><figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_stopwords</span>(<span class="params">self,stopwords_path</span>):</span></span><br><span class="line">    stop_f = open(stopwords_path, <span class="string">"r"</span>, encoding=<span class="string">'utf-8'</span>)</span><br><span class="line">    stop_words = {}</span><br><span class="line">    <span class="keyword">for</span> line <span class="keyword">in</span> stop_f.readlines():</span><br><span class="line">        line = line.strip()</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> len(line):</span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line">        stop_words[line] = line</span><br><span class="line">    stop_f.close()</span><br><span class="line">    <span class="comment"># print('哈工大停止词表长度为：' + str(len(stop_words)))</span></span><br><span class="line">    <span class="keyword">return</span> stop_words</span><br></pre></td></tr></tbody></table></figure><p></p>
<h2 id="总结" class="heading-control"><a href="#总结" class="headerlink" title="总结"></a>总结<a class="heading-anchor" href="#总结" aria-hidden="true"></a></h2><p>经过以上改进，代码加速了 4 倍左右，提升还是很明显的。</p>
</body></html>]]></content>
      <categories>
        <category>NLP</category>
      </categories>
      <tags>
        <tag>分词，优化，NLP</tag>
      </tags>
  </entry>
  <entry>
    <title>资料备忘</title>
    <url>/post/3119.html</url>
    <content><![CDATA[<html><head><link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script></head><body><h2 id="模型调参" class="heading-control"><a href="#模型调参" class="headerlink" title="模型调参"></a>模型调参<a class="heading-anchor" href="#模型调参" aria-hidden="true"></a></h2><ul>
<li><a href="https://juejin.im/post/5aeaac09f265da0b767d4e4b#heading-6">K 重交叉验证和网格搜索验证</a><br>keras 的分类模型调参</li>
<li><a href="https://juejin.im/post/5ad6fe92518825556670384c">深度学习工程模板</a><br>keras 的代码框架</li>
</ul>
<h2 id="算法" class="heading-control"><a href="#算法" class="headerlink" title="算法"></a>算法<a class="heading-anchor" href="#算法" aria-hidden="true"></a></h2><ul>
<li><a href="https://juejin.im/post/5bc5b4136fb9a05d171d6e7b#heading-6">程序员必须掌握的数据结构 1</a></li>
<li><a href="https://juejin.im/post/5bdffa0151882516bd2c4d6f">程序员必须掌握的数据结构 2</a></li>
</ul>
<h2 id="语言标注" class="heading-control"><a href="#语言标注" class="headerlink" title="语言标注"></a>语言标注<a class="heading-anchor" href="#语言标注" aria-hidden="true"></a></h2><p><a href="https://zhuanlan.zhihu.com/p/70067113">一文理解条件随机场 CRF</a></p>
<h2 id="对话系统" class="heading-control"><a href="#对话系统" class="headerlink" title="对话系统"></a>对话系统<a class="heading-anchor" href="#对话系统" aria-hidden="true"></a></h2><ul>
<li><a href="https://github.com/countstarlight/homo">Home</a><br>特点是加入了语音交互部分</li>
</ul>
<h2 id="阅读理解" class="heading-control"><a href="#阅读理解" class="headerlink" title="阅读理解"></a>阅读理解<a class="heading-anchor" href="#阅读理解" aria-hidden="true"></a></h2><ul>
<li><a href="https://github.com/dzorlu/natural_questions">natural_questions</a><br>谷歌的阅读理解数据集</li>
<li><a href="https://github.com/renatoviolin/bert-nq-python3">针对 natural_questions 的 BERT 实现</a></li>
</ul>
<h2 id="损失函数" class="heading-control"><a href="#损失函数" class="headerlink" title="损失函数"></a>损失函数<a class="heading-anchor" href="#损失函数" aria-hidden="true"></a></h2><ul>
<li><a href="https://juejin.im/post/5addcb9551882567236e6041">Triplet Loss</a></li>
<li><a href="http://lawlite.me/2018/10/16/Triplet-Loss%E5%8E%9F%E7%90%86%E5%8F%8A%E5%85%B6%E5%AE%9E%E7%8E%B0/">Triplet-Loss 原理及其实现</a></li>
</ul>
</body></html>]]></content>
      <tags>
        <tag>收藏</tag>
      </tags>
  </entry>
  <entry>
    <title>新看的一些文章</title>
    <url>/post/15245.html</url>
    <content><![CDATA[<html><head><link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script></head><body><h2 id="📚融合BN加速推理" class="heading-control"><a href="#📚融合BN加速推理" class="headerlink" title="📚融合BN加速推理"></a>📚融合 BN 加速推理<a class="heading-anchor" href="#📚融合BN加速推理" aria-hidden="true"></a></h2><p>批归一化（Batch Normalization）因其可以加速神经网络训练、使网络训练更稳定，而且还有一定的正则化效果，所以得到了非常广泛的应用。但是，在推理阶段，BN 层一般是可以完全融合到前面的卷积层的，而且丝毫不影响性能。<br><strong>参考文章</strong>：<a href="https://zhuanlan.zhihu.com/p/120265831">深度学习推理时融合 BN, 轻松获得约 5% 的提速</a><br><strong>代码</strong>：keras 的暂时没有找到，有空可以写写<br><a id="more"></a></p>
<h2 id="📚BERT推理加速实践" class="heading-control"><a href="#📚BERT推理加速实践" class="headerlink" title="📚BERT推理加速实践"></a>📚BERT 推理加速实践<a class="heading-anchor" href="#📚BERT推理加速实践" aria-hidden="true"></a></h2><p>主要基于 Faster Transformer，<strong>参考文章</strong>：</p>
<ol>
<li><a href="https://zhuanlan.zhihu.com/p/89694963">BERT 模型推理加速总结</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/91024786">BERT 推理加速实践</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/73715272">NVIDIA BERT 推理解决方案 Faster Transformer 开源啦</a></li>
</ol>
<h2 id="📚pytorch-C-前端推理模型" class="heading-control"><a href="#📚pytorch-C-前端推理模型" class="headerlink" title="📚pytorch C++前端推理模型"></a>📚pytorch C++ 前端推理模型<a class="heading-anchor" href="#📚pytorch-C-前端推理模型" aria-hidden="true"></a></h2><p>使用 libtorch C++ 前端来推理复杂模型，可能会用到。</p>
<p><strong>参考文章</strong>：<a href="https://zhuanlan.zhihu.com/p/69421019">嫌 python 慢？来这里用 pytorch C++ 前端推理模型</a></p>
<h2 id="📚ReZero-使用加权残差连接加速深度模型收敛" class="heading-control"><a href="#📚ReZero-使用加权残差连接加速深度模型收敛" class="headerlink" title="📚ReZero: 使用加权残差连接加速深度模型收敛"></a>📚ReZero: 使用加权残差连接加速深度模型收敛<a class="heading-anchor" href="#📚ReZero-使用加权残差连接加速深度模型收敛" aria-hidden="true"></a></h2><p><strong>论文标题</strong>：ReZero is All You Need: Fast Convergence at Large Depth</p>
<p><strong>论文作者</strong>：Thomas Bachlechner, Bodhisattwa Prasad Majumder, Huanru Henry Mao, Garrison W. Cottrell, Julian McAuley</p>
<p><strong>论文链接</strong>：<a href="https://arxiv.org/abs/2003.04887">https://arxiv.org/abs/2003.04887</a></p>
<p><strong>代码链接</strong>：<a href="https://github.com/majumderb/rezero">https://github.com/majumderb/rezero</a></p>
<p>简单来说对残差进行了加权并初始化权重为 0 来加快网络收敛速度。思路比较清晰，可证明也 work，具体参考文章 <a href="https://zhuanlan.zhihu.com/p/113384612">ReZero: 使用加权残差连接加速深度模型收敛</a></p>
</body></html>]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>笔记</tag>
      </tags>
  </entry>
  <entry>
    <title>日常 bug</title>
    <url>/post/52747.html</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><ol>
<li><code>TensorFlow报错FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated</code>, 解决方案：<code>pip install numpy==1.16.0</code></li>
<li>国内镜像 ustc 稳定性大于 tuna, 配置<code>.bashrc</code> 如下:<figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">channels:</span><br><span class="line">  - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main/</span><br><span class="line">  - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/</span><br><span class="line">  - https://mirrors.ustc.edu.cn/anaconda/cloud/menpo/</span><br><span class="line">  - https://mirrors.ustc.edu.cn/anaconda/cloud/bioconda/</span><br><span class="line">  - https://mirrors.ustc.edu.cn/anaconda/cloud/msys2/</span><br><span class="line">  - https://mirrors.ustc.edu.cn/anaconda/cloud/conda-forge/</span><br><span class="line">  - https://mirrors.ustc.edu.cn/anaconda/pkgs/free/</span><br><span class="line">  - https://mirrors.ustc.edu.cn/anaconda/pkgs/main/</span><br><span class="line">  - defaults</span><br><span class="line">show_channel_urls: <span class="literal">true</span></span><br></pre></td></tr></tbody></table></figure></li>
<li>删除虚拟环境：<code>conda remove -n your_env_name --all</code></li>
<li>nohup 查看运行的后台进程 <code>jobs -l</code></li>
<li>Anaconda 导出环境 / 从外部安装环境，导出已有环境：<code>conda env export &gt; environment.yaml</code>, 当我们想再次创建该环境，或根据别人提供的.yaml 文件复现环境时，可以：<code>conda env create -f environment.yaml</code></li>
<li>.tar.bz2 文件解压命令，从网络上下载到的源码包，最常见的是.tar.gz 包，还有一部分是.tar.bz2 包<br>.tar.gz 格式解压为 <code>tar   -zxvf   xx.tar.gz</code><br>.tar.bz2 格式解压为 <code>tar   -jxvf    xx.tar.bz2</code></li>
<li>Python 忽略警告信息:<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> warnings</span><br><span class="line">warnings.filterwarnings(<span class="string">"ignore"</span>)</span><br></pre></td></tr></tbody></table></figure></li>
<li><p>python 命令生成 requestment.txt 文件，<code>pip freeze &gt; requirements.txt</code>, 安装：<code>pip install -r requirements.txt</code></p>
</li>
<li><p>run <code>nvidia-smi</code> ，遇见 <code>Failed to initialize NVML: Driver/library version mismatch</code> 的错误。参考下面的解决方案：</p>
<figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">I had reinstalled nvidia driver: run these commands <span class="keyword">in</span> root mode:</span><br><span class="line">1. systemctl isolate multi-user.target</span><br><span class="line">2. modprobe -r nvidia-drm</span><br><span class="line">3. Reinstall Nvidia driver: chmod +x NVIDIA-Linux-x86_64–410.57.run</span><br><span class="line">4. systemctl start graphical.target</span><br><span class="line">and finally check nvidia-smi</span><br></pre></td></tr></tbody></table></figure>
</li>
</ol>
]]></content>
      <tags>
        <tag>bug</tag>
      </tags>
  </entry>
  <entry>
    <title>智力题</title>
    <url>/post/8a7396e.html</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><ol>
<li><strong>家里有两个孩子，一个是女孩，另一个也是女孩的概率是多少？</strong><br>已经有两个孩子说明孩子已经出生了，可能情况为（男，男）（男，女）（女，男）（女，女），又已知其中一个是女的，故排除（男，男）的可能，剩下三种情况一个是符合的，故 1/3。（不是问你已经生了一个女孩，下次再生是男是女的概率）。<a id="more"></a></li>
<li><strong>3L 和 5L 水桶各一个，怎样取 4L 的水？</strong><br>(通用解法： 用小的桶不断往大桶填水)<br>先装满 3L 的桶，将水倒入 5L 的桶中，再倒满 3L 的桶，慢慢往 5L 的桶里倒，直到 5L 的桶满为止，此时 3L 的桶中余下的是 1L 的水。把 5L 桶中的水倒光，然后将刚才 3L 的桶中剩下的那 1L 倒进 5L 桶中，再将 3L 的桶倒满后倒入 5L 桶中，此时 5L 桶中应该有 4L 水。</li>
<li><strong>100 人坐飞机，第一个乘客在座位中随便选一个坐下，中间的人尽量坐自己的座位，如果自己的座位被占了，就随机选一个座位。问第 100 人正确坐到自己坐位的概率是？</strong><br>第一种情况是第一个人坐对了，那么第 100 个人也肯定坐对了；第二种情况是第一个人坐错了，他坐在 2-99 号座位上的一个，那么这个座位的人会起身去找座位，这个时候如果更换目标，不是这个座位的人去找座位而是第一个人去找座位，其实是一样的。这样最后剩下两个座位，第一个坐了一个，第 100 个人要坐另一个，所以是 1/2; 最后一种是第一个人坐错了，那么第 100 个人也肯定坐错了。所以答案是 1/2。</li>
<li><strong>在一个重男轻女的国家里，每个家庭都想生男孩，如果他们生的孩子是女孩，就再生一个，直到生下的是男孩为止。这样的国家，男女比例会是多少？</strong><br>男女比例失调不在于生多少个孩子，是不是生到男孩才罢休，而在于会不会因为产前 B 超查到是女孩就堕胎，或者生出女婴就杀死。</li>
<li><strong>有红黄蓝三种颜色的兔子，数量分别为 x，y，z。规则是，如果两只不同颜色的兔子相遇，它们就会一起变成第三种颜色，比如一只红兔子和一只蓝兔子相遇，就会变成两只黄兔子。问 x，y，z 需要满足什么条件，才有可能让所有兔子都变成同一种颜色。</strong><br>三个数模 3 存在相等的两个，就可以变为同一种。</li>
<li><strong>证明只要整数的各个位数之和是 3 的倍数，那么这个整数就一定是 3 的倍数</strong><br>一个整数如 abcd，可以写成 1000×a+100×b+10×c+d＝999a+99b+9c+a+b+c+d</li>
</ol>
]]></content>
      <tags>
        <tag>面试</tag>
      </tags>
  </entry>
  <entry>
    <title>智慧海洋建设比赛</title>
    <url>/post/20868.html</url>
    <content><![CDATA[<html><head><link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script></head><body><p>这个比赛算是我第一个做的数值类特征的比赛，主要以学习为主。学习的内容包括：</p>
<ul>
<li>数值特征数据的特征工程，从数据中构建算法需要的特征</li>
<li>模型使用以及调参（包括 Lightgb, Xgboost 等等）</li>
</ul>
<h2 id="比赛内容和数据分析" class="heading-control"><a href="#比赛内容和数据分析" class="headerlink" title="比赛内容和数据分析"></a>比赛内容和数据分析<a class="heading-anchor" href="#比赛内容和数据分析" aria-hidden="true"></a></h2><p>这部分主要搞清楚几个问题：</p>
<ul>
<li>比赛内容是什么，以及给了哪些数据</li>
<li>是分类问题还是回归问题</li>
</ul>
<p>首先看赛题：</p>
<blockquote>
<p>本赛题基于位置数据对海上目标进行智能识别和作业行为分析，要求选手通过分析渔船北斗设备位置数据，得出该船的生产作业行为，具体判断出是拖网作业、围网作业还是流刺网作业。初赛将提供 11000 条 (其中 7000 条训练数据、2000 条 testA、2000 条 testB) 渔船轨迹北斗数据。数据包含脱敏后的渔船 ID、经纬度坐标、上报时间、速度、航向信息，由于真实场景下海上环境复杂，经常出现信号丢失，设备故障等原因导致的上报坐标错误、上报数据丢失、甚至有些设备疯狂上报等。</p>
</blockquote>
<p>数据示例：<br><img src="/智慧海洋建设比赛/20200122022107557.png" alt></p>
<ul>
<li>渔船 ID：渔船的唯一识别，结果文件以此 ID 为标示</li>
<li> x: 渔船在平面坐标系的 x 轴坐标</li>
<li> y: 渔船在平面坐标系的 y 轴坐标</li>
<li>速度：渔船当前时刻航速，单位节</li>
<li>方向：渔船当前时刻航首向，单位度</li>
<li> time：数据上报时刻，单位月日 时：分</li>
<li> type：渔船 label，作业类型</li>
</ul>
<p>可以看出这是一个分类问题，所给数据是数值型特征。再来看一下结果的评价指标：</p>
<p><img src="/智慧海洋建设比赛/20200122022332055.png" alt></p>
<h2 id="数据预处理" class="heading-control"><a href="#数据预处理" class="headerlink" title="数据预处理"></a>数据预处理<a class="heading-anchor" href="#数据预处理" aria-hidden="true"></a></h2><p>因为数据给的是一些 csv 文件，所以首先需要对所有的文件进行合并，生成一个训练文件和一个测试文件。这里是我参考的 <a href="https://github.com/GrinAndBear/tianchi_hy">baseline</a>。<br>baseline 采用的文件合并代码如下：<br></p><figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line">train_dir = <span class="string">"./data/hy_round1_train_20200102"</span></span><br><span class="line">test_dir = <span class="string">"./data/hy_round1_testA_20200102"</span></span><br><span class="line"></span><br><span class="line">test = pd.DataFrame(columns=[<span class="string">'渔船ID'</span>, <span class="string">'x'</span>, <span class="string">'y'</span>, <span class="string">'速度'</span>, <span class="string">'方向'</span>, <span class="string">'time'</span>])</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> root, dirs, files <span class="keyword">in</span> os.walk(test_dir):</span><br><span class="line">    <span class="keyword">for</span> file <span class="keyword">in</span> files:</span><br><span class="line">        filename = os.path.join(root, file)</span><br><span class="line">        temp = pd.read_csv(filename)</span><br><span class="line">        test = pd.concat([test, temp])</span><br><span class="line">print(test.info())</span><br><span class="line"></span><br><span class="line">train = pd.DataFrame(columns=[<span class="string">'渔船ID'</span>, <span class="string">'x'</span>, <span class="string">'y'</span>, <span class="string">'速度'</span>, <span class="string">'方向'</span>, <span class="string">'time'</span>])</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> root, dirs, files <span class="keyword">in</span> os.walk(train_dir):</span><br><span class="line">    <span class="keyword">for</span> file <span class="keyword">in</span> files:</span><br><span class="line">        filename = os.path.join(root, file)</span><br><span class="line">        temp = pd.read_csv(filename)</span><br><span class="line">        train = pd.concat([train, temp])</span><br><span class="line">print(train.info())</span><br><span class="line"></span><br><span class="line">test.to_csv(<span class="string">"./data/test_origin.csv"</span>, index=<span class="literal">None</span>)</span><br><span class="line">train.to_csv(<span class="string">"./data/train_origin.csv"</span>, index=<span class="literal">None</span>)</span><br></pre></td></tr></tbody></table></figure><br>这个代码没什么问题，但是实际跑起来却很慢，代码的瓶颈在于读取的数据是串行的，因此我们可以改造一个并行的加速版本。<p></p>
</body></html>]]></content>
      <tags>
        <tag>比赛</tag>
      </tags>
  </entry>
  <entry>
    <title>有趣的网站</title>
    <url>/post/35391.html</url>
    <content><![CDATA[<html><head><link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script></head><body><h2 id="📻音乐" class="heading-control"><a href="#📻音乐" class="headerlink" title="📻音乐"></a>📻音乐<a class="heading-anchor" href="#📻音乐" aria-hidden="true"></a></h2><ul>
<li><a href="http://music.qkhhyiu.cn/">音乐搜索器</a>: 多站合一音乐搜索解决方案</li>
<li><a href="http://guozhivip.com/yinyue/">果汁音乐</a></li>
</ul>
<h2 id="🔮搜索" class="heading-control"><a href="#🔮搜索" class="headerlink" title="🔮搜索"></a>🔮搜索<a class="heading-anchor" href="#🔮搜索" aria-hidden="true"></a></h2><ul>
<li><a href="https://scholar.chongbuluo.com/">虫部落</a></li>
<li><a href="http://guozhivip.com/so/">果汁搜索</a></li>
<li><a href="https://jikipedia.com/">小鸡词典</a>：网络流行语 </li>
<li><a href="https://zh.wikihow.com/%E9%A6%96%E9%A1%B5">wikihow</a>：生活维基百科</li>
</ul>
<a id="more"></a>
<h2 id="📜排行榜" class="heading-control"><a href="#📜排行榜" class="headerlink" title="📜排行榜"></a>📜排行榜<a class="heading-anchor" href="#📜排行榜" aria-hidden="true"></a></h2><ul>
<li><a href="http://guozhivip.com/rank/">果汁排行榜</a></li>
<li><a href="https://tophub.today/">今日热榜</a></li>
</ul>
<h2 id="📚-其他" class="heading-control"><a href="#📚-其他" class="headerlink" title="📚 其他"></a>📚 其他<a class="heading-anchor" href="#📚-其他" aria-hidden="true"></a></h2><ul>
<li><a href="http://guozhivip.com/eat/">今天吃啥呀</a></li>
<li><a href="http://www.underseacat.com/fan">云风扇</a>：心静自然凉 </li>
<li><a href="https://fonts.safe.360.cn/">360 查字体</a> ：你的字体能商用吗</li>
<li><a href="https://www.gaoding.com/koutu">搞定抠图</a></li>
<li><a href="http://www.nows.fun/">毒鸡汤</a></li>
</ul>
</body></html>]]></content>
      <categories>
        <category>网站</category>
      </categories>
      <tags>
        <tag>网站</tag>
      </tags>
  </entry>
  <entry>
    <title>服务器守护进程</title>
    <url>/post/46515.html</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><ul>
<li>首先把进程放到后台 <figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">nohup python main.py &amp;</span><br></pre></td></tr></tbody></table></figure></li>
<li>然后保持退出终端继续运行 <figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">ctrl-z</span><br><span class="line"><span class="built_in">bg</span></span><br></pre></td></tr></tbody></table></figure></li>
<li>输出在 <code>nohup.out</code> 里面</li>
<li>输入 fg，可以把任务调到前台并取消</li>
<li>输入 <code>jobs</code> 显示后台进程</li>
</ul>
]]></content>
      <categories>
        <category>项目</category>
      </categories>
      <tags>
        <tag>服务器</tag>
      </tags>
  </entry>
  <entry>
    <title>服务器环境配置命令</title>
    <url>/post/55264.html</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><ol>
<li><p>conda 检查和 clone 环境</p>
<figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">codna info -e</span><br><span class="line">conda create -n tf20 --<span class="built_in">clone</span> tf13 <span class="comment">#创建tf20环境</span></span><br></pre></td></tr></tbody></table></figure>
</li>
<li><p>pip 使用阿里云的源<br>Linux、Mac 下<br>修改～/.pip/pip.conf（不存在就创建一个），加入如下配置：</p>
<figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">[global]</span><br><span class="line">index-url = http://mirrors.aliyun.com/pypi/simple/</span><br><span class="line">[install]</span><br><span class="line">trusted-host=mirrors.aliyun.com</span><br></pre></td></tr></tbody></table></figure>
<p> windows 下，在当前用户目录下创建一个 pip 目录，即 C:\Users\ 用户名 \pip。在 pip 目录内新增一个 pip.ini 文件。加入如下配置：</p>
<figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">[global]</span><br><span class="line">index-url = http://mirrors.aliyun.com/pypi/simple/</span><br><span class="line">[install]</span><br><span class="line">trusted-host=mirrors.aliyun.com</span><br></pre></td></tr></tbody></table></figure>
</li>
<li><p>安装 tf20 和 pytorch</p>
<figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">pip install tensorflow-gpu</span><br><span class="line">pip install torch torchvision</span><br></pre></td></tr></tbody></table></figure></li>
</ol>
]]></content>
      <tags>
        <tag>服务器</tag>
      </tags>
  </entry>
  <entry>
    <title>朴素贝叶斯</title>
    <url>/post/58683.html</url>
    <content><![CDATA[<html><head><link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script></head><body><p>首先要明确的一点是朴素贝叶斯属于生成式模型，指导思想是贝叶斯公式。</p>
<h2 id="文本分类" class="heading-control"><a href="#文本分类" class="headerlink" title="文本分类"></a>文本分类<a class="heading-anchor" href="#文本分类" aria-hidden="true"></a></h2><p>假设现在有一些评论数据，需要识别出这篇文本属于正向评论还是负面评论，也就是对文本进行分类。用数学语言描述就是：<br>假设已经有分好类的 N 篇文档：(d1,c1)、(d2,c2)、(d3,c3)……(dn,cn)，di 表示第 i 篇文档，ci 表示第 i 个类别。目标是：寻找一个分类器，这个分类器能够：当丢给它一篇新文档 d，它就输出 d（最有可能）属于哪个类别 c。</p>
<a id="more"></a>
<h2 id="词袋模型" class="heading-control"><a href="#词袋模型" class="headerlink" title="词袋模型"></a>词袋模型<a class="heading-anchor" href="#词袋模型" aria-hidden="true"></a></h2><p>文本分类需要寻找文本的特征。而词袋模型就是表示文本特征的一种方式。词袋模型只考虑一篇文档中单词出现的频率 (次数)，用每个单词出现的频率作为文档的特征。<br><img src="https://s2.ax1x.com/2019/07/22/eCyJtP.png" alt="eCyJtP.png"></p>
<h2 id="朴素贝叶斯分类器" class="heading-control"><a href="#朴素贝叶斯分类器" class="headerlink" title="朴素贝叶斯分类器"></a>朴素贝叶斯分类器<a class="heading-anchor" href="#朴素贝叶斯分类器" aria-hidden="true"></a></h2><p>朴素贝叶斯分类器是一个概率分类器。假设现有的类别 C={c1，c2，……cm}。给定一篇文档 d，文档 d 最有可能属于哪个类呢？这个问题用数学公式表示如下：</p>
<script type="math/tex; mode=display">
\hat{c}=\underset{c \in C}{\operatorname{argmax}} P(c | d)</script><p>c^ 就是：在所有的类别 C={c1，c2，……cm} 中，使得：条件概率 P (c|d) 取最大值的类别。使用贝叶斯公式，将上式转换成如下形式：</p>
<script type="math/tex; mode=display">
\hat{c}=\underset{c \in C}{\operatorname{argmax}} P(c | d)=\underset{c \in C}{\operatorname{argmax}} \frac{P(d | c) P(c)}{P(d)}</script><p>对类别 C 中的每个类型，计算 (p (d|c)* p (c))/p (d) 的值，然后选取最大值对应的那个类型 ci ，该 ci 就是最优解 c^，因此，可以忽略掉分母 p (d)，可以变成如下形式：</p>
<script type="math/tex; mode=display">
\hat{c}=\underset{c \in C}{\operatorname{argmax}} P(c | d)=\underset{c \in C}{\operatorname{argmax}} P(d | c) P(c)</script><p>这个公式由两部分组成，前面那部分 P (d|c) 称为似然函数，后面那部分 P (c) 称为先验概率。<br>前面提到使用词袋模型来表示 文档 d，文档 d 的每个特征表示为：d={f1,f2,f3……fn}，那么这里的特征 fi 其实就是单词 wi 出现的频率（次数），因此可以转化成如下形式：</p>
<script type="math/tex; mode=display">
\hat{c}=\underset{c \in C}{\operatorname{argmax}} \overbrace{P\left(f_{1}, f_{2}, \ldots, f_{n} | c\right)}^{\text { likelihood }} \overbrace{P(c)}^{\text { prior }}</script><p>对文档 d 做个假设：假设各个特征之间是相互独立的。那么 p (f1,f2……fn|c)=p (f1|c)<em> p(f2|c) </em> …… * p (fn|c)，转化成如下形式：</p>
<script type="math/tex; mode=display">
c_{N B}=\underset{c \in C}{\operatorname{argmax}} P(c) \prod_{f \in F} P(f | c)</script><p>由于每个概率值很小（比如 0.0001）若干个很小的概率值直接相乘，得到的结果会越来越小。为了避免计算过程出现下溢 (underflower)，引入对数函数 Log，在 log space 中进行计算。然后使用词袋模型的每个单词 wi 出现频率作为特征，得到如下公式：</p>
<script type="math/tex; mode=display">
c_{N B}=\underset{c \in C}{\operatorname{largmax}} \log P(c)+\sum_{i \in \text {positions}} \log P\left(w_{i} | c\right)</script><h2 id="训练朴素贝叶斯分类器" class="heading-control"><a href="#训练朴素贝叶斯分类器" class="headerlink" title="训练朴素贝叶斯分类器"></a>训练朴素贝叶斯分类器<a class="heading-anchor" href="#训练朴素贝叶斯分类器" aria-hidden="true"></a></h2><p>训练朴素贝叶斯的过程其实就是计算先验概率和似然函数的过程。<br>①先验概率 P (c) 的计算<br>P (c) 的意思是：在所有的文档中，类别为 c 的文档出现的概率有多大？假设训练数据中一共有 Ndoc 篇文档，只要数一下类别 c 的文档有多少个就能计算 p (c) 了，类别 c 的文档共有 Nc 篇，先验概率的计算公式如下：</p>
<script type="math/tex; mode=display">
\hat{P}(c)=\frac{N_{c}}{N_{d o c}}</script><p>先验概率其实就是准备干一件事情时，目前已经掌握了哪些信息了。<br>②似然函数 P (wi|c) 的计算<br>由于是用词袋模型表示一篇文档 d，对于文档 d 中的每个单词 wi，找到训练数据集中所有类别为 c 的文档，数一数 单词 wi 在这些文档（类别为 c）中出现的次数：count (wi,c)，<br>然后，再数一数训练数据集中类别为 c 的文档一共有多少个单词，计算二者之间的比值，就是似然函数的值。似然函数计算公式如下：</p>
<script type="math/tex; mode=display">
\hat{P}\left(w_{i} | c\right)=\frac{\operatorname{count}\left(w_{i}, c\right)}{\sum_{w \in V} \operatorname{count}(w, c)}</script><p>其中 V，就是词库。（有些单词在词库中，但是不属于类别 C，那么 count (w,c)=0）</p>
<h2 id="unknow-words的情形" class="heading-control"><a href="#unknow-words的情形" class="headerlink" title="unknow words的情形"></a>unknow words 的情形<a class="heading-anchor" href="#unknow-words的情形" aria-hidden="true"></a></h2><p>假设只考虑文本二分类：将文档分成 positve 类别，或者 negative 类别，C={positive, negative}。<br>在训练数据集中，类别为 positive 的所有文档 都没有 包含 单词 wi = fantastic（fantastic 可能出现在类别为 negative 的文档中）那么 count (wi=fantastic，ci=positive)=0 。那么：</p>
<p>而注意到前面公式五中的累乘，整篇文档的似然函数值为 0，也就是说：如果文档 d 中有个单词 fantastic 在类别为 c 的训练数据集文档中从未出现过，那文档 d 被分类到类别 c 的概率为 0，尽管文档 d 中还有一些其他单词（特征），而这些单词所代表的特征认为文档 d 应该被分类到类别 c 中。<br>解决方案就是 add-one smoothing。似然函数公式变成如下形式：</p>
<script type="math/tex; mode=display">
\hat{P}\left(w_{i} | c\right)=\frac{\operatorname{count}\left(w_{i}, c\right)+1}{\sum_{w \in V}(\operatorname{count}(w, c)+1)}=\frac{\operatorname{count}\left(w_{i}, c\right)+1}{\left(\sum_{w \in V} \operatorname{count}(w, c)\right)+|V|}</script><h2 id="朴素贝叶斯分类示例" class="heading-control"><a href="#朴素贝叶斯分类示例" class="headerlink" title="朴素贝叶斯分类示例"></a>朴素贝叶斯分类示例<a class="heading-anchor" href="#朴素贝叶斯分类示例" aria-hidden="true"></a></h2><p>假设训练数据集有五篇文档，其中 Negative 类别的文档有三篇，用符号 ‘-‘ 标识；Positive 类别的文档有二篇，用符号 ‘+’ 标识，它们的内容如下：<br></p><figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">-  just plain boring</span><br><span class="line">-  entirely predictable and lacks energy</span><br><span class="line">-  no surprises and very few laughs</span><br><span class="line">+  very powerful</span><br><span class="line">+  the most fun film of the summer</span><br></pre></td></tr></tbody></table></figure><br>测试数据集T 有一篇文档dt，内容如下：<br><figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">predictable with no fun</span><br></pre></td></tr></tbody></table></figure><br>朴素贝叶斯分类器会把“predictable with no fun”归为哪个类呢？根据训练朴素贝叶斯分类器的过程，需要计算先验概率和似然函数。<p></p>
<p>由于训练数据集中一共有 5 篇文档，其中类别 ‘+’ 的文档有 2 篇，类别为 ‘-‘ 的文档有 3 篇，因此先验概率：P (c)=P (‘-‘)=Nc/Ndoc=3/5=0.6   </p>
<p>类别为’+’ 的文档有 2 篇，故 P (c)=P (‘+’)=Nc/Ndoc=2/5=0.4</p>
<p>对测试数据集文档 dt 中的每个单词，似然函数采用 “add-one smoothing” 处理，计算相应的似然概率：</p>
<p>首先单词 predictable 在训练数据集中 类别为’-‘的文档中只出现了 1 次，类别为’-‘的文档一共有 14 个单词，训练数据集中两种类型的文档加起来一共有 23 个单词，但是有三个单词 (and、</p>
<p>very、the) 重复出现了两次，故词库 V 的大小为 20。因此单词 predictable 对应的似然概率如下：</p>
<p>p(predictable|’-‘)=(1+1)/(14+20)=2/34</p>
<p>同理：p (predictable|’+’)=(0+1)/(9+20)=1/29   （predictable 没有在类别为’+’的训练数据集中出现过）</p>
<p>类似地：p (no|’-‘)=(1+1)/(14+20)        p (no|’+’)=(0+1)/(9+20)</p>
<p>p(fun|’-‘)=(0+1)/(14+20)                    p(fun|’+’)=(1+1)/(9+20)</p>
<p>因此，测试集中的文档 d 归类为 ‘-‘ 的概率为：0.6 <em> （2</em>2<em>1）/343 = 6.1</em>10-5</p>
<p>测试集中的文档 d 归类为 ‘+’ 的概率为：0.4<em>（1</em>1<em>2）/293 =3.2</em>10-5</p>
<p> 比较上面两个概率的大小，就可以知道将 “predictable with no fun” 归为 ‘-‘ 类别。</p>
<h2 id="代码实现" class="heading-control"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现<a class="heading-anchor" href="#代码实现" aria-hidden="true"></a></h2><figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">loaddata</span>():</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    :return: 文本数据集 和 对应的 label</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    text=[[<span class="string">'just'</span>,<span class="string">'plain'</span>,<span class="string">'boring'</span>],</span><br><span class="line"></span><br><span class="line">    [<span class="string">'entirely'</span>,<span class="string">'predictable'</span>,<span class="string">'and'</span>,<span class="string">'lacks'</span>,<span class="string">'energy'</span>],</span><br><span class="line"></span><br><span class="line">    [<span class="string">'no'</span>,<span class="string">'surprises'</span>,<span class="string">'and'</span>,<span class="string">'very'</span>,<span class="string">'few'</span>,<span class="string">'laughs'</span>],</span><br><span class="line"></span><br><span class="line">    [<span class="string">'very'</span>,<span class="string">'powerful'</span>],</span><br><span class="line"></span><br><span class="line">    [<span class="string">'the'</span> ,<span class="string">'most'</span>, <span class="string">'fun'</span> ,<span class="string">'film'</span> ,<span class="string">'of'</span> ,<span class="string">'the'</span>, <span class="string">'summer'</span>]]</span><br><span class="line"></span><br><span class="line">    label=[<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">1</span>,<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> text,label</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">createVocabList</span>(<span class="params">text</span>):</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    :param text: 文本数据集</span></span><br><span class="line"><span class="string">    :return: 词语表</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    vocabSet=set([])</span><br><span class="line">    <span class="keyword">for</span> document <span class="keyword">in</span> text:</span><br><span class="line">        vocabSet=vocabSet|set(document)</span><br><span class="line">    <span class="keyword">return</span> list(vocabSet)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">bag_words_vec</span>(<span class="params">vocab, text</span>):</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    :param vocab: 词表</span></span><br><span class="line"><span class="string">    :param text: 文本数据集</span></span><br><span class="line"><span class="string">    :return: 通过词袋模型转换后的向量</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    data = []</span><br><span class="line">    <span class="keyword">for</span> t <span class="keyword">in</span> text:</span><br><span class="line">        vec = [<span class="number">0</span>]*len(vocab)</span><br><span class="line">        <span class="keyword">for</span> word <span class="keyword">in</span> t:</span><br><span class="line">            <span class="keyword">if</span> word <span class="keyword">in</span> vocab:</span><br><span class="line">                vec[vocab.index(word)]+=<span class="number">1</span></span><br><span class="line">        data.append(vec)</span><br><span class="line">    <span class="keyword">return</span> data</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">NB</span>():</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self,vocab</span>):</span></span><br><span class="line">        self.data = <span class="literal">None</span></span><br><span class="line">        self.label = <span class="literal">None</span></span><br><span class="line">        self.vocab = vocab</span><br><span class="line">        self.vocab_len = len(self.vocab)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">fit</span>(<span class="params">self,data,label</span>):</span></span><br><span class="line">        self.data = data</span><br><span class="line">        self.label = label</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 计算每个类别的先验概率</span></span><br><span class="line">        self.pc0 = label.count(<span class="number">0</span>)/len(label) </span><br><span class="line">        self.pc1 = label.count(<span class="number">1</span>)/len(label)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 分出不同类别的数据</span></span><br><span class="line">        self.data0 = [data[i] <span class="keyword">for</span> i,c <span class="keyword">in</span> enumerate(label) <span class="keyword">if</span> c==<span class="number">0</span>] </span><br><span class="line">        self.data1 = [data[i] <span class="keyword">for</span> i,c <span class="keyword">in</span> enumerate(label) <span class="keyword">if</span> c==<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 计算每个类别中单词的数量，注意如果是len(),就不考虑重复元素，sum()考虑重复元素</span></span><br><span class="line">        self.word_num_0 = sum([i <span class="keyword">for</span> t <span class="keyword">in</span> self.data0 <span class="keyword">for</span> i <span class="keyword">in</span> t <span class="keyword">if</span> i!=<span class="number">0</span>]) </span><br><span class="line">        self.word_num_1 = sum([i <span class="keyword">for</span> t <span class="keyword">in</span> self.data1 <span class="keyword">for</span> i <span class="keyword">in</span> t <span class="keyword">if</span> i!=<span class="number">0</span>])</span><br><span class="line">        </span><br><span class="line">        <span class="comment">#打印不同类别的单词个数和词表长度</span></span><br><span class="line">        print(<span class="string">"类别0的单词个数：{},类别1的单词个数：{},总词表长度：{}"</span>.format(self.word_num_0,self.word_num_1,self.vocab_len))</span><br><span class="line"></span><br><span class="line">        self.word_freq_0 = np.sum(self.data0, axis = <span class="number">0</span>) <span class="comment">#计算每个类别中单词的频率</span></span><br><span class="line">        self.word_freq_1 = np.sum(self.data1, axis = <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">pridict</span>(<span class="params">self, text</span>):</span></span><br><span class="line">        <span class="comment"># 预测过程</span></span><br><span class="line">        </span><br><span class="line">        pred = []</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 对于预测集的每一个文本</span></span><br><span class="line">        <span class="keyword">for</span> t <span class="keyword">in</span> text:</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 计算属于class 0的概率</span></span><br><span class="line">            p0 = []</span><br><span class="line">            <span class="keyword">for</span> w <span class="keyword">in</span> t:</span><br><span class="line">                <span class="comment"># 不在词表中的不计算</span></span><br><span class="line">                <span class="keyword">if</span> w <span class="keyword">in</span> vocab:</span><br><span class="line">                    p0.append((self.word_freq_0[self.vocab.index(w)] + <span class="number">1</span>)/(self.word_num_0+ self.vocab_len))</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 计算属于class 0的概率</span></span><br><span class="line">            p1 = []</span><br><span class="line">            <span class="keyword">for</span> w <span class="keyword">in</span> t:</span><br><span class="line">                <span class="comment"># 不在词表中的不计算</span></span><br><span class="line">                <span class="keyword">if</span> w <span class="keyword">in</span> vocab:</span><br><span class="line">                    p1.append((self.word_freq_1[self.vocab.index(w)] + <span class="number">1</span>)/(self.word_num_1+self.vocab_len))</span><br><span class="line">            </span><br><span class="line">            print(p0)</span><br><span class="line">            print(p1)</span><br><span class="line"></span><br><span class="line">            print(self.pc0*np.prod(p0))</span><br><span class="line">            print(self.pc1*np.prod(p1))</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> self.pc0*np.prod(p0)> self.pc1*np.prod(p1):</span><br><span class="line">                pred.append(<span class="number">0</span>)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                pred.append(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> pred</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line"></span><br><span class="line">    text,label = loaddata()</span><br><span class="line">    vocab = createVocabList(text)</span><br><span class="line">    data = bag_words_vec(vocab, text)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    pred_text = [[<span class="string">"predictable"</span>,<span class="string">"with"</span>,<span class="string">"no"</span>,<span class="string">"fun"</span>]]</span><br><span class="line"></span><br><span class="line">    model = NB(vocab)</span><br><span class="line">    model.fit(data,label)</span><br><span class="line">    result = model.pridict(pred_text)</span><br><span class="line">    print(result)</span><br></pre></td></tr></tbody></table></figure>
<p>输出结果：<br></p><figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line">类别<span class="number">0</span>的单词个数：<span class="number">14</span>,类别<span class="number">1</span>的单词个数：<span class="number">9</span>,总词表长度：<span class="number">20</span></span><br><span class="line">[<span class="number">0.058823529411764705</span>, <span class="number">0.058823529411764705</span>, <span class="number">0.029411764705882353</span>]</span><br><span class="line">[<span class="number">0.034482758620689655</span>, <span class="number">0.034482758620689655</span>, <span class="number">0.06896551724137931</span>]</span><br><span class="line"><span class="number">6.106248727864848e-05</span></span><br><span class="line"><span class="number">3.280167288531715e-05</span></span><br><span class="line">[<span class="number">0</span>]</span><br></pre></td></tr></tbody></table></figure><p></p>
</body></html>]]></content>
      <tags>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title>机器学习 - 白板推导系列</title>
    <url>/post/19678.html</url>
    <content><![CDATA[<html><head><link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script></head><body><h2 id="课程介绍" class="heading-control"><a href="#课程介绍" class="headerlink" title="课程介绍"></a>课程介绍<a class="heading-anchor" href="#课程介绍" aria-hidden="true"></a></h2><p><img src="https://i.loli.net/2019/09/24/ga1PjFQG3WLnk8O.png" alt><br>B 站视频：<a href="https://www.bilibili.com/video/av31950221">https://www.bilibili.com/video/av31950221</a><br>观看次序: <a href="https://github.com/shuhuai007/Machine-Learning-Session">https://github.com/shuhuai007/Machine-Learning-Session</a></p>
<a id="more"></a>
<h2 id="Lecture-1：开篇" class="heading-control"><a href="#Lecture-1：开篇" class="headerlink" title="Lecture 1：开篇"></a>Lecture 1：开篇<a class="heading-anchor" href="#Lecture-1：开篇" aria-hidden="true"></a></h2><p>主要介绍频率派和贝叶斯派的区别以及一些推荐书籍和视频</p>
<h3 id="频率派和贝叶斯派" class="heading-control"><a href="#频率派和贝叶斯派" class="headerlink" title="频率派和贝叶斯派"></a>频率派和贝叶斯派<a class="heading-anchor" href="#频率派和贝叶斯派" aria-hidden="true"></a></h3><ul>
<li>频率派，Maximum Likelihood Estimation (MLE，最大似然估计)，把需要推断的参数 θ 看做是固定的未知常数，即概率虽然是未知的，但最起码是确定的一个值，同时，样本 X 是随机的，所以频率派重点研究样本空间，大部分的概率计算都是针对样本 X 的分布；</li>
<li>贝叶斯派，Bayesian - Maximum A Posteriori (MAP，最大后验估计)，的观点则截然相反，他们认为参数是随机变量，而样本 X 是固定的，由于样本是固定的，所以他们重点研究的是参数的分布。</li>
</ul>
<p>随着数据量的增加，参数分布会越来越向数据靠拢，先验的影响力会越来越小如果先验是 uniform distribution，则贝叶斯方法等价于频率方法。因为直观上来讲，先验是 uniform distribution 本质上表示对事物没有任何预判。</p>
<h3 id="推荐书籍" class="heading-control"><a href="#推荐书籍" class="headerlink" title="推荐书籍"></a>推荐书籍<a class="heading-anchor" href="#推荐书籍" aria-hidden="true"></a></h3><p>频率派 ———— 统计机器学习<br>贝叶斯派 ———— 概率图模型</p>
<p><strong>BOOK</strong>：</p>
<ul>
<li>李航 机器学习方法：感 K 朴决逻，支提 E 隐条</li>
<li>周志华：西瓜书</li>
<li> PRML </li>
<li>MLAPP</li>
<li>ESL</li>
<li>Deep Learning</li>
</ul>
<p><strong>视频</strong>：</p>
<ul>
<li>台大林轩田：机器学习基石和机器学习技法</li>
<li>张志华：机器学习导论，统计机器学习</li>
<li> Ng:CS229 </li>
<li>徐亦达 </li>
<li>李宏毅</li>
</ul>
<h2 id="Lecture-2：数学基础" class="heading-control"><a href="#Lecture-2：数学基础" class="headerlink" title="Lecture 2：数学基础"></a>Lecture 2：数学基础<a class="heading-anchor" href="#Lecture-2：数学基础" aria-hidden="true"></a></h2><h2 id="Lecture-3：线性分类" class="heading-control"><a href="#Lecture-3：线性分类" class="headerlink" title="Lecture 3：线性分类"></a>Lecture 3：线性分类<a class="heading-anchor" href="#Lecture-3：线性分类" aria-hidden="true"></a></h2><h2 id="Lecture-3：降维" class="heading-control"><a href="#Lecture-3：降维" class="headerlink" title="Lecture 3：降维"></a>Lecture 3：降维<a class="heading-anchor" href="#Lecture-3：降维" aria-hidden="true"></a></h2><h2 id="Lecture-4：支持向量机-SVM" class="heading-control"><a href="#Lecture-4：支持向量机-SVM" class="headerlink" title="Lecture 4：支持向量机(SVM)"></a>Lecture 4：支持向量机 (SVM)<a class="heading-anchor" href="#Lecture-4：支持向量机-SVM" aria-hidden="true"></a></h2><h2 id="Lecture-5：核方法-Kernel-Method" class="heading-control"><a href="#Lecture-5：核方法-Kernel-Method" class="headerlink" title="Lecture 5：核方法(Kernel Method)"></a>Lecture 5：核方法 (Kernel Method)<a class="heading-anchor" href="#Lecture-5：核方法-Kernel-Method" aria-hidden="true"></a></h2><h2 id="Lecture-6：指数族分布" class="heading-control"><a href="#Lecture-6：指数族分布" class="headerlink" title="Lecture 6：指数族分布"></a>Lecture 6：指数族分布<a class="heading-anchor" href="#Lecture-6：指数族分布" aria-hidden="true"></a></h2><h2 id="Lecture-7：概率图模型" class="heading-control"><a href="#Lecture-7：概率图模型" class="headerlink" title="Lecture 7：概率图模型"></a>Lecture 7：概率图模型<a class="heading-anchor" href="#Lecture-7：概率图模型" aria-hidden="true"></a></h2><h2 id="Lecture-8：EM算法" class="heading-control"><a href="#Lecture-8：EM算法" class="headerlink" title="Lecture 8：EM算法"></a>Lecture 8：EM 算法<a class="heading-anchor" href="#Lecture-8：EM算法" aria-hidden="true"></a></h2><h2 id="Lecture-9：高斯混合模型-GMM" class="heading-control"><a href="#Lecture-9：高斯混合模型-GMM" class="headerlink" title="Lecture 9：高斯混合模型(GMM)"></a>Lecture 9：高斯混合模型 (GMM)<a class="heading-anchor" href="#Lecture-9：高斯混合模型-GMM" aria-hidden="true"></a></h2><h2 id="Lecture-10：变分推断" class="heading-control"><a href="#Lecture-10：变分推断" class="headerlink" title="Lecture 10：变分推断"></a>Lecture 10：变分推断<a class="heading-anchor" href="#Lecture-10：变分推断" aria-hidden="true"></a></h2><h2 id="Lecture-11：MCMC" class="heading-control"><a href="#Lecture-11：MCMC" class="headerlink" title="Lecture 11：MCMC"></a>Lecture 11：MCMC<a class="heading-anchor" href="#Lecture-11：MCMC" aria-hidden="true"></a></h2><h2 id="Lecture-12：隐马尔可夫模型" class="heading-control"><a href="#Lecture-12：隐马尔可夫模型" class="headerlink" title="Lecture 12：隐马尔可夫模型"></a>Lecture 12：隐马尔可夫模型<a class="heading-anchor" href="#Lecture-12：隐马尔可夫模型" aria-hidden="true"></a></h2><h2 id="Lecture-13：线性动态系统-卡曼滤波" class="heading-control"><a href="#Lecture-13：线性动态系统-卡曼滤波" class="headerlink" title="Lecture 13：线性动态系统-卡曼滤波"></a>Lecture 13：线性动态系统 - 卡曼滤波<a class="heading-anchor" href="#Lecture-13：线性动态系统-卡曼滤波" aria-hidden="true"></a></h2><h2 id="Lecture-14：非线性动态系统-粒子滤波" class="heading-control"><a href="#Lecture-14：非线性动态系统-粒子滤波" class="headerlink" title="Lecture 14：非线性动态系统-粒子滤波"></a>Lecture 14：非线性动态系统 - 粒子滤波<a class="heading-anchor" href="#Lecture-14：非线性动态系统-粒子滤波" aria-hidden="true"></a></h2><h2 id="Lecture-15：条件随机场" class="heading-control"><a href="#Lecture-15：条件随机场" class="headerlink" title="Lecture 15：条件随机场"></a>Lecture 15：条件随机场<a class="heading-anchor" href="#Lecture-15：条件随机场" aria-hidden="true"></a></h2><h2 id="Lecture-16：高斯网络" class="heading-control"><a href="#Lecture-16：高斯网络" class="headerlink" title="Lecture 16：高斯网络"></a>Lecture 16：高斯网络<a class="heading-anchor" href="#Lecture-16：高斯网络" aria-hidden="true"></a></h2><h2 id="Lecture-17：贝叶斯线性回归" class="heading-control"><a href="#Lecture-17：贝叶斯线性回归" class="headerlink" title="Lecture 17：贝叶斯线性回归"></a>Lecture 17：贝叶斯线性回归<a class="heading-anchor" href="#Lecture-17：贝叶斯线性回归" aria-hidden="true"></a></h2><h2 id="Lecture-18：高斯过程回归" class="heading-control"><a href="#Lecture-18：高斯过程回归" class="headerlink" title="Lecture 18：高斯过程回归"></a>Lecture 18：高斯过程回归<a class="heading-anchor" href="#Lecture-18：高斯过程回归" aria-hidden="true"></a></h2><h2 id="Lecture-19：受限玻尔兹曼机" class="heading-control"><a href="#Lecture-19：受限玻尔兹曼机" class="headerlink" title="Lecture 19：受限玻尔兹曼机"></a>Lecture 19：受限玻尔兹曼机<a class="heading-anchor" href="#Lecture-19：受限玻尔兹曼机" aria-hidden="true"></a></h2></body></html>]]></content>
      <tags>
        <tag>白板推导</tag>
      </tags>
  </entry>
  <entry>
    <title>校招笔试题目</title>
    <url>/post/44950.html</url>
    <content><![CDATA[<html><head><link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script></head><body><h2 id="互娱模拟笔试" class="heading-control"><a href="#互娱模拟笔试" class="headerlink" title="互娱模拟笔试"></a>互娱模拟笔试<a class="heading-anchor" href="#互娱模拟笔试" aria-hidden="true"></a></h2><h4 id="个税征缴" class="heading-control"><a href="#个税征缴" class="headerlink" title="个税征缴"></a>个税征缴<a class="heading-anchor" href="#个税征缴" aria-hidden="true"></a></h4><p><img src="https://i.loli.net/2019/08/04/Rxiw6QHvKYTr8tB.png" alt><br><img src="https://i.loli.net/2019/08/04/7b45cCrzgojEaXD.png" alt><br><img src="https://i.loli.net/2019/08/04/iMvLtYcwTNOhR17.png" alt></p>
<h4 id="字符串缩写" class="heading-control"><a href="#字符串缩写" class="headerlink" title="字符串缩写"></a>字符串缩写<a class="heading-anchor" href="#字符串缩写" aria-hidden="true"></a></h4><p><img src="https://i.loli.net/2019/08/04/orbd5SFXlKuyfqc.png" alt><br><img src="https://i.loli.net/2019/08/04/vB9uUo3OGENXsLf.png" alt></p>
<h4 id="进制组合" class="heading-control"><a href="#进制组合" class="headerlink" title="进制组合"></a>进制组合<a class="heading-anchor" href="#进制组合" aria-hidden="true"></a></h4><p><img src="https://i.loli.net/2019/08/04/KTcl4Hmix5btUjX.png" alt><br><img src="https://i.loli.net/2019/08/04/XwqgncvWjMmVTEy.png" alt></p>
<h2 id="Leetcode" class="heading-control"><a href="#Leetcode" class="headerlink" title="Leetcode"></a>Leetcode<a class="heading-anchor" href="#Leetcode" aria-hidden="true"></a></h2><h4 id="Leetcode125-验证回文串" class="heading-control"><a href="#Leetcode125-验证回文串" class="headerlink" title="Leetcode125:验证回文串"></a>Leetcode125: 验证回文串<a class="heading-anchor" href="#Leetcode125-验证回文串" aria-hidden="true"></a></h4><ul>
<li>技巧 1：<code>str.isalnum()</code> 检测字符串是否由字母和数字组成。过滤非字母和数字的：<code>s = ''.join(filter(str.isalnum,s))</code></li>
<li>技巧二：大写和小写字母的差是 32，所有 <code>ord('A')^32==ord('a')</code>。<code>ord</code> 返回值是字符对应的十进制整数。</li>
</ul>
</body></html>]]></content>
      <tags>
        <tag>笔试</tag>
      </tags>
  </entry>
  <entry>
    <title>概率图模型理论与应用</title>
    <url>/post/14056.html</url>
    <content><![CDATA[<html><head><link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script></head><body><h2 id="概率图模型" class="heading-control"><a href="#概率图模型" class="headerlink" title="概率图模型"></a>概率图模型<a class="heading-anchor" href="#概率图模型" aria-hidden="true"></a></h2><p><img src="https://i.loli.net/2019/09/13/o1c8PFYmTK3JVXA.png" alt></p>
</body></html>]]></content>
      <tags>
        <tag>概率图模型</tag>
      </tags>
  </entry>
  <entry>
    <title>每周论文</title>
    <url>/post/7053.html</url>
    <content><![CDATA[<html><head><link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script></head><body><p><img src="https://i.loli.net/2018/11/29/5bffec15c0d38.jpeg" alt="pexels-photo-933964.jpeg"><br><a id="more"></a></p>
<h2 id="第一周" class="heading-control"><a href="#第一周" class="headerlink" title="第一周"></a>第一周<a class="heading-anchor" href="#第一周" aria-hidden="true"></a></h2><ol>
<li><p><a href="https://www.paperweekly.site/papers/2520">An Introductory Survey on Attention Mechanisms in NLP Problems</a><br><strong>标签</strong>：Attention 综述<br>本文来自佐治亚理工学院，这是一篇 Attention 机制在自然语言处理方面的综述文章，包括基本概念和 Attention 在不同 NLP 任务上的模型变种。</p>
</li>
<li><p><a href="https://www.paperweekly.site/papers/2524">LiveBot: Generating Live Video Comments Based on Visual and Textual Contexts</a><br><strong>标签</strong>：弹幕生成<br>本文是北京大学孙栩老师组和微软亚洲研究院发表在 AAAI 2019 上的工作。文章介绍了 “弹幕生成” 任务，根据一定时间范围内的视频帧和评论文本进行弹幕评论的生成，并且构建了基于 B 站的数据集。<br>通过对数据集的分析发现：弹幕评论长度较短；相邻时间间隔的评论具有较高的关联度。基于此，文章先是利用传统的 Seq2Seq 架构，设计了 Video Encoder 和 Text Encoder 进行图像和文字信息的融合，再交由 Comment Decoder 进行生成；进一步地，利用 Transformer 替代 RNN Encoder，提出了一个 Unified Transformer Model。<br>并且，为了更好的评估模型的性能，文章提出了一个基于生成概率对候选评论进行排序的指标，对比之前的 Seq2Seq 模型，文章提出的两个模型能够取得更好的效果。</p>
</li>
<li><a href="https://www.paperweekly.site/papers/2519">Contextual String Embeddings for Sequence Labeling</a><br><strong>标签</strong>：Word Embeddings<br><strong>源码</strong>:<a href="https://github.com/zalandoresearch/flair">https://github.com/zalandoresearch/flair</a><br>本文是 Zalando Research 发表于 COLING 2018 的工作，论文提出了一种全新产生 embedding 的 BiLSTM 模型结构，模型特点：<br>模型以 character 为原子单位，在网络中，每个 character 都有一个对应的 hidden state。这个特点对需要多一步分词的中文来说可能有避免因为分词错误导致下游 function 继续错误的弊端；<br>输出以 word 为单位的 embedding，这个 embedding 由前向 LSTM 中，该词最后一个字母的 hidden state 和反向 LSTM 中该词第一个字母的 hidden state 拼接组成，这样就能够兼顾上下文信息。<br>这种动态 embedding 的方法在序列标注上取得了良好效果，特别值得一提的是，在 NER 上的表现甚至超越了 BERT，但训练成本只是一个 GPU 一周，训练数据在十亿个词量，与 BERT 相比对硬件的要求极大降低，训练成本的大幅减少却仍有性能上的提升，动态 embedding 的思路值得借鉴和尝试。</li>
<li><a href="https://www.paperweekly.site/papers/2545">Discriminative Deep Dyna-Q: Robust Planning for Dialogue Policy Learning</a><br><strong>标签</strong>：Dialog Systems<br><strong>源码</strong>：<a href="https://github.com/MiuLab/DDQ">https://github.com/MiuLab/DDQ</a><br>本文是微软和台湾大学发表于 ACL 2018 的工作，论文提出了一种针对任务型对话系统的学习方式 ——Deep Dyna-Q，在仅使用少量真实用户交互数据的前提下，基于集成规划的方法进行对话策略学习。作者将 world model 引入对话 agent，模仿真实的用户响应并不断学习生成模拟的用户对话，利用真实和模拟的对话经验对 agent 进行优化。</li>
<li><a href="https://www.paperweekly.site/papers/2522">Learning Personalized End-to-End Goal-Oriented Dialog</a><br><strong>标签</strong>：Goal-Oriented Dialog<br>本文是微软亚洲研究院和北京大学孙栩组共同完成即将发表在 AAAI 2019 的工作。为对话系统引入个性化是今年对话领域最为火热的研究方向之一。此前有一些工作研究在开放式对话（chitchat）中引入个性化，使得对话生成中可以包含一定的对话者身份的信息，使对话质量更高。而本文关注在鲜有人研究且更加困难的任务型对话领域，探索如何能针对用户的不同身份采取不同的对话策略，提高任务完成率和用户满意度。<br>本文提出了 Personalized MemN2N 模型，引入 profile embedding，并在对话模型和 KB 之间建立联系，有效地提升了对话系统质量，达到任务型对话个性化数据集上新的 state-of-the-art。在针对任务型研究较少的环境下，这一工作具有非常高的参考价值。</li>
</ol>
</body></html>]]></content>
      <categories>
        <category>论文</category>
      </categories>
      <tags>
        <tag>论文</tag>
      </tags>
  </entry>
  <entry>
    <title>海量数据相似度 —— 局部敏感哈希 (LSH)</title>
    <url>/post/54839.html</url>
    <content><![CDATA[<html><head><link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script></head><body><h2 id="场景" class="heading-control"><a href="#场景" class="headerlink" title="场景"></a>场景<a class="heading-anchor" href="#场景" aria-hidden="true"></a></h2><p><strong>海量高维数据查找与某个数据最相似的一个或者多个数据。</strong>与其它基于 Tree 的数据结构，诸如 KD-Tree、SR-Tree 相比，它较好地克服了 Curse of Dimension，能够将 KNN 的时间复杂度缩减到 sub-linear。LSH 多被用于文本、多媒体（图像、音频）的相似性判断。</p>
<a id="more"></a>
<h2 id="simhash" class="heading-control"><a href="#simhash" class="headerlink" title="simhash"></a>simhash<a class="heading-anchor" href="#simhash" aria-hidden="true"></a></h2><p>谷歌的文档去重算法。主要步骤：</p>
<ul>
<li>对文本进行分词和加权，权重越大，单词重要性越高</li>
<li>对单词进行 hash：</li>
<li>加权：对 hash 进行加权</li>
<li>合并：单词 hash 相加，得到句子的 hash</li>
<li> 降维：每一位大于 0 记为 1，小于 0 记为 0</li>
</ul>
<p><a href="https://imgchr.com/i/eLQBes"><img src="https://s2.ax1x.com/2019/08/10/eLQBes.png" alt="eLQBes.png"></a><br>比较的时候只需要计算两个 hash 的海明距离：两个二进制串对应的位有几个不一样，那么海明距离就是几，值越小越相似（异或）。</p>
<h2 id="局部敏感" class="heading-control"><a href="#局部敏感" class="headerlink" title="局部敏感"></a>局部敏感<a class="heading-anchor" href="#局部敏感" aria-hidden="true"></a></h2><p><a href="https://imgchr.com/i/eLQUSS"><img src="https://s2.ax1x.com/2019/08/10/eLQUSS.png" alt="eLQUSS.png"></a><br><strong>存储</strong>：<br>1、将一个 64 位的 simhash code 拆分成 4 个 16 位的二进制码。（图上红色的 16 位）<br>2、分别拿着 4 个 16 位二进制码查找当前对应位置上是否有元素。（放大后的 16 位）<br>3、对应位置没有元素，直接追加到链表上；对应位置有则直接追加到链表尾端。（图上的 S1 — SN）</p>
<p><strong>查找</strong>：<br>1、将需要比较的 simhash code 拆分成 4 个 16 位的二进制码。<br>2、分别拿着 4 个 16 位二进制码每一个去查找 simhash 集合对应位置上是否有元素。<br>2、如果有元素，则把链表拿出来顺序查找比较，直到 simhash 小于一定大小的值，整个过程完成。</p>
<h2 id="与一般Hash的区别" class="heading-control"><a href="#与一般Hash的区别" class="headerlink" title="与一般Hash的区别"></a>与一般 Hash 的区别<a class="heading-anchor" href="#与一般Hash的区别" aria-hidden="true"></a></h2><p>局部敏感 hash 可以比较相似度，普通的 hash 不可以</p>
<h2 id="参考" class="heading-control"><a href="#参考" class="headerlink" title="参考"></a>参考<a class="heading-anchor" href="#参考" aria-hidden="true"></a></h2><ul>
<li><a href="http://www.lanceyan.com/tech/arch/simhash_hamming_distance_similarity.html">海量数据相似度计算之 simhash 和海明距离</a></li>
<li><a href="http://www.lanceyan.com/tech/arch/simhash_hamming_distance_similarity2-html.html">海量数据相似度计算之 simhash 短文本查找</a></li>
<li><a href="https://www.bbsmax.com/A/kjdw9a1qJN/">Locality Sensitive Hash 局部敏感哈希</a></li>
</ul>
</body></html>]]></content>
      <tags>
        <tag>局部敏感哈希</tag>
      </tags>
  </entry>
  <entry>
    <title>深度学习 NLP 的一些思考</title>
    <url>/post/48416.html</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p><img src="https://i.loli.net/2018/10/30/5bd7b7b675daa.png" alt="NLP.png"></p>
<ol>
<li><p>Ebedding 代表什么？<br>我们需要搞清楚的是是否 NLP 的一切都需要 Ebedding。比如陌生的符号、变量、数字、未登录词等。</p>
</li>
<li><p>Ebedding 的形式是否是” 向量”？<br>词可以 Ebedding 为向量，但是句子文章也这样表示就显得太单薄了，有没有更好的结构？</p>
<a id="more"></a></li>
<li><p>语言理解的生物启发模型是什么？<br>CNN 来自于视觉神经系统，但是 RNN 感觉并不像是生物模型。</p>
</li>
<li><p>NLP 的数据集都太小<br>NLP 的 ImageNet 什么时候出现？</p>
</li>
<li><p>cv 与 nlp 的区别？<br>1.cv 是对连续而具体的，nlp 是离散而抽象的<br>2.cv 是对二维信号的采样，nlp 是对一维信号的采样，对比而言，cv 携带的信息量比较大。</p>
</li>
<li><p>QA 系统的结果应该返回什么？<br>显然，结果不应该仅仅是文字、链接，结果应该更加丰富。</p>
</li>
</ol>
]]></content>
  </entry>
  <entry>
    <title>理解 Keras LSTM 中的参数 return_sequences 和 return_state</title>
    <url>/post/24110.html</url>
    <content><![CDATA[<html><head><link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script></head><body><p><img src="https://i.loli.net/2018/11/14/5bebd5524bc47.png" alt><br>今天才注意到 LSTM 的 output 和 hidden_state 是同一个东西！下面分情况讨论参数的设置问题。<br><a id="more"></a></p>
<h3 id="return-sequences-False-amp-amp-return-state-False" class="heading-control"><a href="#return-sequences-False-amp-amp-return-state-False" class="headerlink" title="return_sequences=False && return_state=False"></a>return_sequences=False && return_state=False<a class="heading-anchor" href="#return-sequences-False-amp-amp-return-state-False" aria-hidden="true"></a></h3><figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line">h = LSTM(X)</span><br></pre></td></tr></tbody></table></figure>
<p>Keras API 中，return_sequences 和 return_state 默认就是 false。此时只会返回最后一个 LSTM 的 hidden state 值。</p>
<h3 id="return-sequences-True-amp-amp-return-state-False" class="heading-control"><a href="#return-sequences-True-amp-amp-return-state-False" class="headerlink" title="return_sequences=True && return_state=False"></a>return_sequences=True && return_state=False<a class="heading-anchor" href="#return-sequences-True-amp-amp-return-state-False" aria-hidden="true"></a></h3><p>输出全部时间步 LSTM 的 hidden state 结果。</p>
<h3 id="return-sequences-False-amp-amp-return-state-True" class="heading-control"><a href="#return-sequences-False-amp-amp-return-state-True" class="headerlink" title="return_sequences=False && return_state=True"></a>return_sequences=False && return_state=True<a class="heading-anchor" href="#return-sequences-False-amp-amp-return-state-True" aria-hidden="true"></a></h3><figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line">lstm1, state_h, state_c = LSTM(<span class="number">1</span>, return_state=<span class="literal">True</span>)</span><br></pre></td></tr></tbody></table></figure>
<p>stm1 和 state_h 结果都是 hidden state。在这种参数设定下，它们俩的值相同。都是最后一个时间步的 hidden state。 state_c 是最后一个时间步 cell state 结果。</p>
<h3 id="return-sequences-True-amp-amp-return-state-True" class="heading-control"><a href="#return-sequences-True-amp-amp-return-state-True" class="headerlink" title="return_sequences=True && return_state=True"></a>return_sequences=True && return_state=True<a class="heading-anchor" href="#return-sequences-True-amp-amp-return-state-True" aria-hidden="true"></a></h3><figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line">lstm1, state_h, state_c = LSTM(<span class="number">1</span>, return_sequences=<span class="literal">True</span>, return_state=<span class="literal">True</span>)</span><br></pre></td></tr></tbody></table></figure>
<p>此时，我们既要输出全部时间步的 hidden state ，又要输出 cell state。lstm1 存放的就是全部时间步的 hidden state。state_h 存放的是最后一个时间步的 hidden state,state_c 存放的是最后一个时间步的 cell state<br>举一个输出例子，假设我们输入的时间步 time step=3：<br></p><figure class="highlight shell"><table><tbody><tr><td class="code"><pre><span class="line">[array([[[-0.02145359],</span><br><span class="line">        [-0.0540871 ],</span><br><span class="line">        [-0.09228823]]], dtype=float32),</span><br><span class="line"> array([[-0.09228823]], dtype=float32),</span><br><span class="line"> array([[-0.19803026]], dtype=float32)]</span><br></pre></td></tr></tbody></table></figure><br>可以看到state_h 的值和lstm1的最后一个时间步的值相同。<p></p>
<h3 id="Reference" class="heading-control"><a href="#Reference" class="headerlink" title="Reference"></a>Reference<a class="heading-anchor" href="#Reference" aria-hidden="true"></a></h3><ol>
<li><a href="https://blog.csdn.net/u011327333/article/details/78501054">https://blog.csdn.net/u011327333/article/details/78501054</a></li>
<li><a href="https://machinelearningmastery.com/return-sequences-and-return-states-for-lstms-in-keras/">Understand the Difference Between Return Sequences and Return States for LSTMs in Keras</a></li>
</ol>
</body></html>]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>Keras</tag>
      </tags>
  </entry>
  <entry>
    <title>生成模型和判别模型</title>
    <url>/post/6742.html</url>
    <content><![CDATA[<html><head><link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script></head><body><p><img src="https://s2.ax1x.com/2019/07/22/ePCNdg.png" alt="ePCNdg.png"></p>
<ul>
<li>生成模型可以产生数据，判别模型只能根据数据做判断。</li>
<li>生成模型的指导思想是贝叶斯，判别模型的指导思想是频率学派<a id="more"></a>
</li>
</ul>
<h2 id="生成模型" class="heading-control"><a href="#生成模型" class="headerlink" title="生成模型"></a>生成模型<a class="heading-anchor" href="#生成模型" aria-hidden="true"></a></h2><p><strong>生成模型</strong>（Generaive Model）一般以概率的方式描述了数据的产生方式，通过对模型采样就可以产生数据。<br>一个简单例子：给定平面上一系列点，我可以认为这些点是根据一个二维高斯分布产生的，这就是一个生成模型，它可以产生数据。我可以用最大似然方法，根据已有的样本估计出模型的参数，再对这个模型进行采样，就可以得到更多的样本，这些样本和之前的样本在空间分布上可能差不多。</p>
<p>对于分类来说：生成模型观察 x 与 c 的整体分布，通过对每一个 c 建模，最终选择能使结果最优的 c 作为最终分布 P (x,c)。训练完模型后，每新来一个数据，就根据所得到的 P (x,c) 与 x 的特征，来判断 c。</p>
<h2 id="判别模型" class="heading-control"><a href="#判别模型" class="headerlink" title="判别模型"></a>判别模型<a class="heading-anchor" href="#判别模型" aria-hidden="true"></a></h2><p><strong>判别模型</strong>（Discriminative Model）对数据之间的映射关系建模，而不考虑数据本身是如何生成的。判别模型可以根据给定的数据 预测对应的 （回归），或根据不同的映射结果来区分（discriminate）给定的数据 （分类）。但模型自身并不能产生数据 。</p>
<p>对于分类来说：判别模型直接根据 x 的特征，来对 c 建模，划定一个整体判别边界。训练完模型后，每新来一个数据，就根据这个边界来判断它应该属于哪一类。</p>
<h2 id="常见模型的分类" class="heading-control"><a href="#常见模型的分类" class="headerlink" title="常见模型的分类"></a>常见模型的分类<a class="heading-anchor" href="#常见模型的分类" aria-hidden="true"></a></h2><p><strong>生成模型</strong></p>
<ul>
<li>高斯混合模型（和其他类型的混合模型）</li>
<li>隐马尔可夫模型</li>
<li>贝叶斯网络（例如 Naive bayes，Autoregressive 模型）</li>
<li>LDA</li>
<li> 玻尔兹曼机器（例如受限玻尔兹曼机器，深信念网络）</li>
<li>变分自动编码器</li>
<li>生成对抗性网络</li>
</ul>
<p><strong>判别模型</strong></p>
<ul>
<li>k - 最近邻算法</li>
<li>逻辑回归</li>
<li>支持向量机</li>
<li>最大熵马尔可夫模型</li>
<li>条件随机场</li>
<li>神经网络</li>
</ul>
</body></html>]]></content>
      <tags>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title>目标检测综述</title>
    <url>/post/32742.html</url>
    <content><![CDATA[<html><head><link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script></head><body><h2 id="任务比较" class="heading-control"><a href="#任务比较" class="headerlink" title="任务比较"></a>任务比较<a class="heading-anchor" href="#任务比较" aria-hidden="true"></a></h2><p>图像分类，检测及分割是计算机视觉领域的三大任务。<br><img src="https://i.loli.net/2018/10/25/5bd153928d049.png" alt><br>这张图清楚说明了 image classification, object detection, semantic segmentation, instance segmentation 之间的关系。摘自 COCO dataset (<a href="https://arxiv.org/pdf/1405.0312.pdf">https://arxiv.org/pdf/1405.0312.pdf</a>)</p>
<ul>
<li>图像分类的任务是给图像分类，打标签，让机器明白图片是什么 (what)，通常一张图片对应一个类别</li>
<li>目标检测的任务是检测物体的位置，并用框标记出来，让机器明白物体在哪里 (where)，可以识别一张图片中的多个物体。</li>
<li>语义分割的任务是实现像素级别的分类，同一类用一种颜色表示</li>
<li>实例分割的任务是不但要进行分类，还要区别开不同的实例（这里的实例指的是具体的单个对象）</li>
</ul>
<a id="more"></a>
<h2 id="基于深度学习的目标检测算法" class="heading-control"><a href="#基于深度学习的目标检测算法" class="headerlink" title="基于深度学习的目标检测算法"></a>基于深度学习的目标检测算法<a class="heading-anchor" href="#基于深度学习的目标检测算法" aria-hidden="true"></a></h2><p>基于深度学习的目标检测模型主要可以分为两大类：</p>
<ul>
<li>One-Stage 检测算法</li>
</ul>
<p>一步到位，直接产生物体的类别概率和位置坐标值，代表算法如 YOLO 和 SSD。</p>
<ul>
<li>Two-Stage 检测算法</li>
</ul>
<p>这些算法将检测问题划分为两个阶段：第一阶段产生候选区域，第二阶段对候选区域进行分类和微调。代表算法是 R-CNN 系列算法，如 R-CNN，Fast R-CNN，Faster R-CNN 等</p>
<p>目标检测模型的主要性能指标是检测准确度和速度，对于准确度，目标检测要考虑物体的定位准确性，而不单单是分类准确度。一般情况下，Two-Stage 算法在准确度上有优势，而 One-Stage 算法在速度上有优势。</p>
<p>Google 在 2017 年开源了 TensorFlow Object Detection API，并对主流的 Faster R-CNN，R-FCN 及 SSD 三个算法在 MS COCO 数据集上的性能做了细致对比（见 Huang et al. 2017），如下图所示。<br><img src="https://i.loli.net/2018/10/25/5bd172e4bc3c0.png" alt></p>
<h2 id="从R-CNN到Mask-R-CNN" class="heading-control"><a href="#从R-CNN到Mask-R-CNN" class="headerlink" title="从R-CNN到Mask R-CNN"></a>从 R-CNN 到 Mask R-CNN<a class="heading-anchor" href="#从R-CNN到Mask-R-CNN" aria-hidden="true"></a></h2><h3 id="R-CNN-2013" class="heading-control"><a href="#R-CNN-2013" class="headerlink" title="R-CNN/2013"></a>R-CNN/2013<a class="heading-anchor" href="#R-CNN-2013" aria-hidden="true"></a></h3><p>区域卷积神经网络（Regions with CNN features，简称 R-CNN），<br>论文：<a href="https://arxiv.org/abs/1311.2524">Rich feature hierarchies for accurate object detection and semantic segmentation</a>。是利用卷积神经网络来做「目标检测」的开山之作，其意义深远不言而喻。R-CNN 的主要模型结构如下<br><img src="https://i.loli.net/2018/10/25/5bd1859fb4883.png" alt><br>实现 R-CNN 的主要步骤分为四步；</p>
<ol>
<li>首先对每张输入图像使用选择性搜索来选取多个高质量的提议区域。</li>
<li>选取一个预先训练好的卷积神经网络，去掉最后的输出层来作为特征抽取模块，得到一个特征向量。</li>
<li>每个类别训练一个 SVM 分类器，从特征向量中推断其属于该类别的概率大小。</li>
<li>为了提升定位准确性，R-CNN 最后又训练了一个边界框回归模型。</li>
</ol>
<p>相比于传统方法，R-CNN 的优点有:</p>
<ol>
<li>传统的区域选择使用滑窗，每滑一个窗口检测一次，相邻窗口信息重叠高，检测速度慢。R-CNN 使用一个启发式方法（Selective search），先生成候选区域再检测，降低信息冗余程度，从而提高检测速度。</li>
<li>使用了预先训练好的卷积神经网络来抽取特征，有效的提升了识别精度。</li>
</ol>
<h3 id="SPP-net-2014" class="heading-control"><a href="#SPP-net-2014" class="headerlink" title="SPP-net/2014"></a>SPP-net/2014<a class="heading-anchor" href="#SPP-net-2014" aria-hidden="true"></a></h3><p>论文 <a href="https://arxiv.org/pdf/1406.4729.pdf">Spatial Pyramid Pooling in Deep Convolutional Networks for Visual Recognition, He et al. 2014</a>。<br>R-CNN 提出后的一年，以何恺明、任少卿为首的团队提出了 SPP-net,SPP-net 中所提出的空间金字塔池化层（Spatial Pyramid Pooling Layer, SPP）可以和 R-CNN 结合在一起并提升其性能。<br>采用深度学习模型解决图像分类问题时，往往需要图像的大小固定（比如 224×224224×224），这并不是 CNN 层的硬性要求，主要原因在于 CNN 层提取的特征图最后要送入全连接层（如 softmax 层），对于变大小图片，CNN 层得到的特征图大小也是变化的，但是全连接层需要固定大小的输入，所以必须要将图片通过 resize, crop 或 wrap 等方式固定大小（训练和测试时都需要）。但是实际上真实的图片的大小是各种各样的，一旦固定大小可能会造成图像损失，从而影响识别精度。为了解决这个问题，SSP-net 在 CNN 层与全连接层之间插入了空间金字塔池化层来解决这个矛盾。<br><img src="https://i.loli.net/2018/10/25/5bd1889271272.png" alt></p>
<h3 id="Fast-RCNN" class="heading-control"><a href="#Fast-RCNN" class="headerlink" title="Fast-RCNN"></a>Fast-RCNN<a class="heading-anchor" href="#Fast-RCNN" aria-hidden="true"></a></h3><h2 id="Reference" class="heading-control"><a href="#Reference" class="headerlink" title="Reference"></a>Reference<a class="heading-anchor" href="#Reference" aria-hidden="true"></a></h2><ol>
<li><a href="http://zh.gluon.ai/chapter_computer-vision/rcnn.html">动手学深度学习</a></li>
<li><a href="https://blog.csdn.net/xiaohu2022/article/details/79600037">基于深度学习的目标检测</a></li>
</ol>
</body></html>]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>目标检测</tag>
      </tags>
  </entry>
  <entry>
    <title>算法</title>
    <url>/post/54150.html</url>
    <content><![CDATA[<html><head><link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script></head><body><p>秋招算法复习</p>
<h2 id="复习内容" class="heading-control"><a href="#复习内容" class="headerlink" title="复习内容"></a>复习内容<a class="heading-anchor" href="#复习内容" aria-hidden="true"></a></h2><h4 id="算法" class="heading-control"><a href="#算法" class="headerlink" title="算法"></a>算法<a class="heading-anchor" href="#算法" aria-hidden="true"></a></h4><p>1、排序算法：快速排序、归并排序、计数排序<br>2、搜索算法：回溯、递归、剪枝<br>3、图论：最短路径、最小生成树、网络流建模<br>4、动态规划：背包问题、最长子序列、计数问题<br>5、基础技巧：分治、倍增、二分法、贪心算法</p>
<h4 id="数据结构" class="heading-control"><a href="#数据结构" class="headerlink" title="数据结构"></a>数据结构<a class="heading-anchor" href="#数据结构" aria-hidden="true"></a></h4><p>1、数组和链表<br>2、栈与队列<br>3、树和图<br>4、哈希表<br>5、大 / 小跟堆，可并堆<br>6、字符串：字典树、后缀树<br><a id="more"></a></p>
<h2 id="排序算法" class="heading-control"><a href="#排序算法" class="headerlink" title="排序算法"></a>排序算法<a class="heading-anchor" href="#排序算法" aria-hidden="true"></a></h2><p><img src="https://i.loli.net/2019/07/19/5d315c07f3c2d68257.png" alt></p>
<h4 id="快速排序" class="heading-control"><a href="#快速排序" class="headerlink" title="快速排序"></a>快速排序<a class="heading-anchor" href="#快速排序" aria-hidden="true"></a></h4><p>递归写法<br></p><figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">quick_sort</span>(<span class="params">data</span>):</span></span><br><span class="line">    <span class="keyword">if</span> len(data) < <span class="number">2</span>:</span><br><span class="line">        <span class="keyword">return</span> data</span><br><span class="line">    </span><br><span class="line">    base = data[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">    left = [i <span class="keyword">for</span> i <span class="keyword">in</span> data[<span class="number">1</span>:] <span class="keyword">if</span> i <= base]</span><br><span class="line">    right = [i <span class="keyword">for</span> i <span class="keyword">in</span> data[<span class="number">1</span>:] <span class="keyword">if</span> i > base]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> quick_sort(left) + [base] + quick_sort(right)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    data = [<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">3</span>,<span class="number">5</span>,<span class="number">2</span>,<span class="number">8</span>,<span class="number">1</span>,<span class="number">4</span>]</span><br><span class="line">    print(quick_sort(data))</span><br></pre></td></tr></tbody></table></figure><br>双指针写法<p></p>
<h4 id="归并排序" class="heading-control"><a href="#归并排序" class="headerlink" title="归并排序"></a>归并排序<a class="heading-anchor" href="#归并排序" aria-hidden="true"></a></h4><h4 id="堆排序" class="heading-control"><a href="#堆排序" class="headerlink" title="堆排序"></a>堆排序<a class="heading-anchor" href="#堆排序" aria-hidden="true"></a></h4><h4 id="计数排序" class="heading-control"><a href="#计数排序" class="headerlink" title="计数排序"></a>计数排序<a class="heading-anchor" href="#计数排序" aria-hidden="true"></a></h4><h2 id="查找算法" class="heading-control"><a href="#查找算法" class="headerlink" title="查找算法"></a>查找算法<a class="heading-anchor" href="#查找算法" aria-hidden="true"></a></h2><h4 id="二分查找" class="heading-control"><a href="#二分查找" class="headerlink" title="二分查找"></a>二分查找<a class="heading-anchor" href="#二分查找" aria-hidden="true"></a></h4><p>非递归<br></p><figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">binary_search</span>(<span class="params">data,value</span>):</span></span><br><span class="line">    </span><br><span class="line">    left = <span class="number">0</span></span><br><span class="line">    right = len(data)<span class="number">-1</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">while</span> left<=right: </span><br><span class="line">        mid = (left+right)//<span class="number">2</span></span><br><span class="line">        <span class="keyword">if</span> value == data[mid]:</span><br><span class="line">            <span class="keyword">return</span> mid</span><br><span class="line">        <span class="keyword">if</span> value<data[mid]:</span><br><span class="line">            right = mid <span class="number">-1</span></span><br><span class="line">        <span class="keyword">if</span> value>data[mid]:</span><br><span class="line">            left = mid +<span class="number">1</span></span><br><span class="line">    <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    print(binary_search([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>],<span class="number">5</span>))</span><br></pre></td></tr></tbody></table></figure><br>递归<br><figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">binary_search</span>(<span class="params">data,left, right, value</span>):</span></span><br><span class="line">    <span class="keyword">if</span> left>right:</span><br><span class="line">        <span class="keyword">return</span> <span class="number">-1</span></span><br><span class="line">    mid = (left+right)//<span class="number">2</span></span><br><span class="line">    <span class="keyword">if</span> value == data[mid]:</span><br><span class="line">        <span class="keyword">return</span> mid</span><br><span class="line">    <span class="keyword">if</span> value<data[mid]:</span><br><span class="line">        right = mid <span class="number">-1</span></span><br><span class="line">    <span class="keyword">if</span> value>data[mid]:</span><br><span class="line">        left = mid +<span class="number">1</span></span><br><span class="line">    <span class="keyword">return</span> binary_search(data, left, right, value)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    print(binary_search([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>],<span class="number">0</span>,<span class="number">5</span>,<span class="number">5</span>))</span><br></pre></td></tr></tbody></table></figure><p></p>
<h2 id="剑指offer" class="heading-control"><a href="#剑指offer" class="headerlink" title="剑指offer"></a>剑指 offer<a class="heading-anchor" href="#剑指offer" aria-hidden="true"></a></h2><h4 id="二维数组中的查找" class="heading-control"><a href="#二维数组中的查找" class="headerlink" title="二维数组中的查找"></a>二维数组中的查找<a class="heading-anchor" href="#二维数组中的查找" aria-hidden="true"></a></h4><p></p><div class="tip">
在一个二维数组中（每个一维数组的长度相同），每一行都按照从左到右递增的顺序排序，每一列都按照从上到下递增的顺序排序。请完成一个函数，输入这样的一个二维数组和一个整数，判断数组中是否含有该整数。
</div><br><strong>思路 </strong>：沿着对角线，以左下角为例子。如果目标整数大于当前值，则说明目标整数在该列右侧。 如果目标整数小于当前值，则说明目标整数在该行上侧。 如果目标整数等于当前值，则找到。如果从左下角沿着对角线走到右上角，则说明找不到目标整数。<br><figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">Find</span>(<span class="params">target, array</span>):</span></span><br><span class="line">   rows = len(array)</span><br><span class="line">   cols = len(array[<span class="number">0</span>])</span><br><span class="line">       </span><br><span class="line">   i,j = <span class="number">0</span>,cols<span class="number">-1</span></span><br><span class="line">   <span class="keyword">while</span> i<rows <span class="keyword">and</span> j>=<span class="number">0</span>:</span><br><span class="line">       <span class="keyword">if</span> array[i][j] == target:</span><br><span class="line">           <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line">       <span class="keyword">if</span> array[i][j] > target:</span><br><span class="line">           j -= <span class="number">1</span></span><br><span class="line">       <span class="keyword">else</span>:</span><br><span class="line">           i += <span class="number">1</span></span><br><span class="line">       </span><br><span class="line">   <span class="keyword">return</span> <span class="literal">False</span></span><br></pre></td></tr></tbody></table></figure><p></p>
<blockquote>
<p>python 不支持 i++ 这种写法，改用 i+=1</p>
</blockquote>
<h4 id="替换空格" class="heading-control"><a href="#替换空格" class="headerlink" title="替换空格"></a>替换空格<a class="heading-anchor" href="#替换空格" aria-hidden="true"></a></h4><p></p><div class="tip">
请实现一个函数，将一个字符串中的每个空格替换成 “%20”。例如，当字符串为 We Are Happy. 则经过替换之后的字符串为 We%20Are%20Happy。
</div><br>思路：空格一个字符，替换后变成3个字符，因此字符串变长了，应该从后向前替换。<br><figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">replace_space</span>(<span class="params">self, s</span>):</span></span><br><span class="line">        result = <span class="string">''</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(len(s)<span class="number">-1</span>, <span class="number">-1</span>, <span class="number">-1</span>):</span><br><span class="line">            <span class="keyword">if</span> s[i] == <span class="string">' '</span>:</span><br><span class="line">                result = <span class="string">'%20'</span> + result</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                result = s[i] + result</span><br><span class="line">        <span class="keyword">return</span> result</span><br></pre></td></tr></tbody></table></figure><p></p>
<h4 id="从尾到头打印链表" class="heading-control"><a href="#从尾到头打印链表" class="headerlink" title="从尾到头打印链表"></a>从尾到头打印链表<a class="heading-anchor" href="#从尾到头打印链表" aria-hidden="true"></a></h4><p></p><div class="tip">
输入一个链表，按链表值从尾到头的顺序返回一个 ArrayList。
</div><br><strong>思路 </strong>: (栈):读入数组，逆序输出<br><figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="comment"># 返回从尾部到头部的列表值序列，例如[1,2,3]</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">printListFromTailToHead</span>(<span class="params">self, listNode</span>):</span></span><br><span class="line">        <span class="comment"># write code here</span></span><br><span class="line">        temp = list()</span><br><span class="line">        current_node = listNode</span><br><span class="line">        <span class="keyword">while</span> current_node != <span class="literal">None</span>:</span><br><span class="line">            temp.append(current_node.val)</span><br><span class="line">            current_node = current_node.next</span><br><span class="line">        <span class="keyword">return</span> temp[::<span class="number">-1</span>]</span><br></pre></td></tr></tbody></table></figure><p></p>
<h4 id="重建二叉树" class="heading-control"><a href="#重建二叉树" class="headerlink" title="重建二叉树"></a>重建二叉树<a class="heading-anchor" href="#重建二叉树" aria-hidden="true"></a></h4><p></p><div class="tip">
输入某二叉树的前序遍历和中序遍历的结果，请重建出该二叉树。假设输入的前序遍历和中序遍历的结果中都不含重复的数字。例如输入前序遍历序列 {1,2,4,7,3,5,6,8} 和中序遍历序列 {4,7,2,1,5,3,8,6}，则重建二叉树并返回。
</div><br><strong>思路 </strong>：前序遍历第一个是根节点，在中序遍历中根据根节点可划分左右子树<br><figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="comment"># -*- coding:utf-8 -*-</span></span><br><span class="line"><span class="comment"># class TreeNode:</span></span><br><span class="line"><span class="comment">#     def __init__(self, x):</span></span><br><span class="line"><span class="comment">#         self.val = x</span></span><br><span class="line"><span class="comment">#         self.left = None</span></span><br><span class="line"><span class="comment">#         self.right = None</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="comment"># 返回构造的TreeNode根节点</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">reConstructBinaryTree</span>(<span class="params">self, pre, tin</span>):</span></span><br><span class="line">        <span class="comment"># write code here</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> pre <span class="keyword">or</span> <span class="keyword">not</span> tin:</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line">        root = TreeNode(pre.pop(<span class="number">0</span>))</span><br><span class="line">        index = tin.index(root.val)</span><br><span class="line">        root.left = self.reConstructBinaryTree(pre, tin[:index])</span><br><span class="line">        root.right = self.reConstructBinaryTree(pre, tin[index + <span class="number">1</span>:])</span><br><span class="line">        <span class="keyword">return</span> root</span><br></pre></td></tr></tbody></table></figure><p></p>
<h4 id="用两个栈实现队列" class="heading-control"><a href="#用两个栈实现队列" class="headerlink" title="用两个栈实现队列"></a>用两个栈实现队列<a class="heading-anchor" href="#用两个栈实现队列" aria-hidden="true"></a></h4><p></p><div class="tip">
用两个栈来实现一个队列，完成队列的 Push 和 Pop 操作。 队列中的元素为 int 类型。
</div><br><figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="comment"># -*- coding:utf-8 -*-</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        self.stack1 = []</span><br><span class="line">        self.stack2 = []</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">push</span>(<span class="params">self, node</span>):</span></span><br><span class="line">        <span class="comment"># write code here</span></span><br><span class="line">        self.stack1.append(node)</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">pop</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="comment"># return xx</span></span><br><span class="line">        <span class="keyword">if</span> len(self.stack2) == <span class="number">0</span>:</span><br><span class="line">            <span class="keyword">while</span> self.stack1:</span><br><span class="line">                self.stack2.append(self.stack1.pop())</span><br><span class="line">        <span class="keyword">return</span> self.stack2.pop()</span><br></pre></td></tr></tbody></table></figure><p></p>
</body></html>]]></content>
      <tags>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title>算法和开发哪个更累</title>
    <url>/post/1215.html</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>来自知乎，觉得很有道理。<a href="https://www.zhihu.com/question/353534822/answer/878932462">原文</a></p>
<ul>
<li>在做开发的时候，主要是体力和精神紧绷，做不完的需求和紧迫的 deadline，没完没了的加班。体力上会更累一些，精神上虽然紧绷，但大部分的时候不慌。</li>
<li>在做算法的时候，主要就是精神压力了。大量的不确定性，导致没有办法保证这次做的事情会不会有产出，没有产出就没有办法生存，会主动的做尝试很多 idea。不确定性带来的心理压力，是做开发的时候没有的，心累。</li>
</ul>
<p>我的博客即将同步至腾讯云 + 社区，邀请大家一同入驻：<a href="https://cloud.tencent.com/developer/support-plan?invite_code=33juwuyf1pa8c">https://cloud.tencent.com/developer/support-plan?invite_code=33juwuyf1pa8c</a></p>
]]></content>
      <tags>
        <tag>工作</tag>
      </tags>
  </entry>
  <entry>
    <title>给印度年轻人的一封公开信</title>
    <url>/post/ffd64b18.html</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><blockquote>
<p>印度年轻人的失业率极高，约 30％。与此同时，这些年轻人在 Facebook 和 Instagram 上花费了大量时间，印度人在 Facebook 和 Instagram 花费的时间在所有国家 / 地区排名第一。印度互联网广告业的收入却极低，广告主根本找不到对这些人有价值的广告，他们没有购买力。</p>
<p>最近，印度最著名的作家之一的切坦・巴加特（Chetan Bhagat）在《印度时报》上发表了这封公开信，呼吁印度年轻人不要沉溺于手机。</p>
</blockquote>
<p>亲爱的年轻朋友们，</p>
<p>这封公开信尽管在大报纸上发表，但是我不知道你是否会看到它。你们中的许多人都忙于使用手机，观看视频，玩视频游戏，与朋友聊天，在社交媒体上发表评论，或者只是滚动浏览名人新闻。你们顾不上阅读文章。</p>
<p>但是，如果你碰巧遇到了这篇文章，请完整读完它。这很重要，这关系到你的生活。你正在手机上浪费生命。</p>
<a id="more"></a>
<p>你们是印度历史上第一代可以使用智能手机和廉价数据流量的人。你们每天在手机上花费大量时间，对于年轻人来说，每天平均达到 5 到 7 个小时。</p>
<p>五小时是你每天清醒时间的三分之一。就像香烟或其他毒品一样，这种手机成瘾正在吞噬你生命的一部分，损害你的职业前景，并弄乱你的大脑。如果这样下去，整个一代印度年轻人将成为被 4G 毁掉的一代人，这一代人全都沉迷于 4G，他们的生活毫无目标，对国家一无所知。</p>
<p>首先，手机成瘾绝对浪费时间，这些时间本可以用于生活中更具生产力的事物。想象一下，每天从手机上节省三个小时，花在任何其他事情上，比如健身，学习技能，找工作，开办企业。如果你始终如一地这样做，它将带你到何处。</p>
<p>第二，手机成瘾会使大脑变钝。当你观看垃圾时，大脑会放松并且运转较少，你很快将变得缺乏逻辑思考、推理或争论的能力。你将不再看到不同的观点，不再能处理不同的问题、评估利弊或做出正确的决定。</p>
<p>由于大脑麻木，你会变得被情绪主导，出现两极分化的情绪，对名人或政客强烈狂热或强烈仇恨。一代人都变得情绪化，失去理性。</p>
<p>最后，连续三个小时以上玩手机，消磨你的动力和精力。生活中的成功来自于设定目标，保持动力并为实现目标而努力。但是，看着手机屏幕会让你失去动力，每天划着屏幕消磨时间。</p>
<p>年轻人将决定印度的未来。想象一下，让印度独立的那一代年轻人，他们关心国家问题，为解放印度而战。今天，年轻人真的在乎影响国家命运的事情吗？还是更在乎轰动的新闻，忙于对娱乐性事件或疯狂性事情做出情绪性反应？</p>
<p>当务之急是使印度的经济再次增长。中国比我们富裕五倍。请在互联网上搜一下中国城市的照片。为了让印度也这样发展，我们必须做很多事情。我们应该集中精力发展经济，还是继续对那些宗教广告表达愤怒？你应该专注于自己的职业，还是应该将时间浪费在永无止境的印度教－穆斯林的历史问题上？你想过上幸福的生活，还是希望搞清楚宝莱坞明星的各种混乱新闻？</p>
<p>你，今天的年轻人，将决定这些问题的答案。没有其他人会为你做这件事，你必须对自己和这个国家的命运负责。印度的贫穷和强烈的民族情绪并不值得自豪，你们的目标应该是让印度和你自己变得富有而谦虚。放下你的手机，将你的思想投入到那些富有成效和创造力的事情中，为自己的生活和国家做出改变。</p>
<p>你们应该使用 4G 成为印度领先的一代人，而不要最终成为被 4G 毁掉的一代人。</p>
<p>爱你们的，</p>
<p>切坦・巴加特</p>
]]></content>
      <tags>
        <tag>社会</tag>
      </tags>
  </entry>
  <entry>
    <title>聊天机器人总结</title>
    <url>/post/25360.html</url>
    <content><![CDATA[<html><head><link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script></head><body><h2 id="技术分类" class="heading-control"><a href="#技术分类" class="headerlink" title="技术分类"></a>技术分类<a class="heading-anchor" href="#技术分类" aria-hidden="true"></a></h2><p>首先我们把聊天机器人分为两种：主动式和被动式。</p>
<ul>
<li><strong>主动式</strong> 这是每个做聊天机器人的厂家都希望做到的，核心是 chatbot 在合适的时间，合适的地点给用户提供合适的信息。举个反面的例子，如果在半夜两点聊天机器人突然给你说：” 我给你讲个笑话吧”，这显然是不合适的，会引起反感的。所以主动式既是最好的，也是最难控制的，难度最大的。</li>
<li><strong>被动式</strong> 这个是现在最流行的，又可以分为闲聊型、问答系统和任务型。问答系统是单轮的，通常任务型对话是多轮的。<br><img src="https://i.loli.net/2018/11/03/5bdd8c61b3736.png" alt>上面这种回复是安全的，但是 chatbot 中最忌讳的。</li>
</ul>
<a id="more"></a>
<h2 id="任务型对话" class="heading-control"><a href="#任务型对话" class="headerlink" title="任务型对话"></a>任务型对话<a class="heading-anchor" href="#任务型对话" aria-hidden="true"></a></h2><p><img src="https://i.loli.net/2018/11/03/5bdd8e1dcb541.png" alt><br>里面提到一个名词叫槽位。其实可以简单的理解为填表格。DPO 发起询问，NLG 生成回复，为了使得回复自然，这里采用推荐时的回复。</p>
<h2 id="检索式机器人框架" class="heading-control"><a href="#检索式机器人框架" class="headerlink" title="检索式机器人框架"></a>检索式机器人框架<a class="heading-anchor" href="#检索式机器人框架" aria-hidden="true"></a></h2><p><img src="https://i.loli.net/2018/11/03/5bdd9095442c8.png" alt><br>上面这张图是一个典型的检索式 chatbot 框架，分为三个步骤，拿到问题，从问题数据库中进行匹配，如果有多条相关数据就进<br>行排序，选出得分最高的输出。<br>这个框架中最重要的是匹配操作。传统方法是基于规则的方法，包括下图的几种计算距离的方法。当然也可以用 ML 来提取特征后做匹配的。<br><img src="https://i.loli.net/2018/11/03/5bdd910210306.png" alt><br>基于深度学习的方法。<br><img src="https://i.loli.net/2018/11/03/5bdd92726cc44.png" alt><br><img src="https://i.loli.net/2018/11/03/5bdd94223ba3d.png" alt></p>
</body></html>]]></content>
      <categories>
        <category>课程笔记</category>
      </categories>
      <tags>
        <tag>NLP</tag>
        <tag>AI研习社</tag>
        <tag>chat</tag>
      </tags>
  </entry>
  <entry>
    <title>腾讯广告部门一面 - 自然语言处理方向</title>
    <url>/post/6306.html</url>
    <content><![CDATA[<html><head><link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script></head><body><p>今天上午 10 点突然接到面试的电话，面完之后感觉不怎么好，还是总结一下吧。</p>
<h2 id="Pool的作用" class="heading-control"><a href="#Pool的作用" class="headerlink" title="Pool的作用"></a>Pool 的作用<a class="heading-anchor" href="#Pool的作用" aria-hidden="true"></a></h2><p>池化层是一个采样的过程。<br><img src="https://s2.ax1x.com/2019/07/11/Z24iUU.png" alt="Z24iUU.png"><br><img src="https://s2.ax1x.com/2019/07/11/Z24QUO.png" alt="Z24QUO.png"></p>
<h2 id="Word2Vec的损失函数" class="heading-control"><a href="#Word2Vec的损失函数" class="headerlink" title="Word2Vec的损失函数"></a>Word2Vec 的损失函数<a class="heading-anchor" href="#Word2Vec的损失函数" aria-hidden="true"></a></h2><h2 id="ElMo的损失函数" class="heading-control"><a href="#ElMo的损失函数" class="headerlink" title="ElMo的损失函数"></a>ElMo 的损失函数<a class="heading-anchor" href="#ElMo的损失函数" aria-hidden="true"></a></h2><h3 id="预训练部分" class="heading-control"><a href="#预训练部分" class="headerlink" title="预训练部分"></a>预训练部分<a class="heading-anchor" href="#预训练部分" aria-hidden="true"></a></h3><p>在 EMLo 中，他们使用的是一个双向的 LSTM 语言模型，由一个前向和一个后向语言<br>模型构成，目标函数就是取这两个方向语言模型的最大似然。<br>前向部分</p>
<script type="math/tex; mode=display">
p\left(t_{1}, t_{2}, \ldots, t_{N}\right)=\prod_{k=1}^{N} p\left(t_{k} | t_{1}, t_{2}, \ldots, t_{k-1}\right)</script><p>反向部分</p>
<script type="math/tex; mode=display">
p\left(t_{1}, t_{2}, \ldots, t_{N}\right)=\prod_{k=1}^{N} p\left(t_{k} | t_{k+1}, t_{k+2}, \ldots, t_{N}\right)</script><p>合起来部分如下，也就是损失函数</p>
<script type="math/tex; mode=display">
\begin{array}{l}{\sum_{k=1}^{N}\left(\log p\left(t_{k} | t_{1}, \ldots, t_{k-1} ; \Theta_{x}, \vec{\Theta}_{LSTM}, 
\Theta_{s}\right)\right.} \\ {\quad+\log p\left(t_{k} | t_{k+1}, \ldots, t_{N} ; \Theta_{x}, \widetilde{\Theta}_{LSTM}, \Theta_{s}\right) )}\end{array}</script><h3 id="微调部分（用于下游任务）" class="heading-control"><a href="#微调部分（用于下游任务）" class="headerlink" title="微调部分（用于下游任务）"></a>微调部分（用于下游任务）<a class="heading-anchor" href="#微调部分（用于下游任务）" aria-hidden="true"></a></h3><p>在进行有监督的 NLP 任务时，可以将 ELMo 直接当做特征拼接到具体任务模型的<br>词向量输入，具体来说就是把这个双向语言模型的每一中间层进行一个求和得到动态的词向量表示。<br>提取词向量的过程如下：对于第 K 个 Token, 使用 L 层的双向 ELMo 可以得到的表示如下：</p>
<script type="math/tex; mode=display">
\begin{aligned} R_{k} &=\left\{\mathbf{x}_{k}^{L M}, \overrightarrow{\mathbf{h}}_{k, j}^{L M}, \widetilde{\mathbf{h}}_{k, j}^{L M} | j=1, \ldots, L\right\} \\ &=\left\{\mathbf{h}_{k, j}^{L M} | j=0, \ldots, L\right\} \end{aligned}</script><p>对于下游任务来说，得到表示就是各层双向 LSTM 的表示的加权和</p>
<script type="math/tex; mode=display">
\mathbf{E} \mathbf{L} \mathbf{M} \mathbf{o}_{k}^{\text {task}}=E\left(R_{k} ; \Theta^{\text {task}}\right)=\gamma^{\text {task}} \sum_{j=0}^{L} s_{j}^{\text {task}} \mathbf{h}_{k, j}^{L M}</script><h2 id="快速排序的复杂度计算" class="heading-control"><a href="#快速排序的复杂度计算" class="headerlink" title="快速排序的复杂度计算"></a>快速排序的复杂度计算<a class="heading-anchor" href="#快速排序的复杂度计算" aria-hidden="true"></a></h2></body></html>]]></content>
      <categories>
        <category>腾讯广告一面</category>
      </categories>
      <tags>
        <tag>面试</tag>
      </tags>
  </entry>
  <entry>
    <title>最近调代码两个的 bug</title>
    <url>/post/19186.html</url>
    <content><![CDATA[<html><head><link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script></head><body><h3 id="标签错误" class="heading-control"><a href="#标签错误" class="headerlink" title="标签错误"></a>标签错误<a class="heading-anchor" href="#标签错误" aria-hidden="true"></a></h3><p>错误 log:<br></p><figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">RuntimeError: cuda runtime error (59) :device-side assert triggered</span><br></pre></td></tr></tbody></table></figure><br>一般是标签出错，检查两点：<p></p>
<ul>
<li>标签中是否有 - 1</li>
<li> 标签个数和分类的个数是否匹配（检查模型最后的分类个数）</li>
</ul>
<h3 id="Shell脚本dos2unix" class="heading-control"><a href="#Shell脚本dos2unix" class="headerlink" title="Shell脚本dos2unix"></a>Shell 脚本 dos2unix<a class="heading-anchor" href="#Shell脚本dos2unix" aria-hidden="true"></a></h3><figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">Shell脚本出现$<span class="string">'\r'</span>: <span class="built_in">command</span> not found</span><br></pre></td></tr></tbody></table></figure>
<p>这是因为脚本文件可能在 window 弄过，有 window 下的空行，把他转换成 unix 格式的就行。<br></p><figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">yum install dos2unix</span><br><span class="line">dos2unix run.sh</span><br></pre></td></tr></tbody></table></figure><p></p>
</body></html>]]></content>
      <tags>
        <tag>bug</tag>
      </tags>
  </entry>
  <entry>
    <title>论文阅读 - 20190924</title>
    <url>/post/50252.html</url>
    <content><![CDATA[<html><head><link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script></head><body><h2 id="论文1" class="heading-control"><a href="#论文1" class="headerlink" title="论文1"></a>论文 1<a class="heading-anchor" href="#论文1" aria-hidden="true"></a></h2><p><strong>《SANVis: Visual Analytics for Understanding Self-Attention Networks》</strong></p>
<h3 id="简介" class="heading-control"><a href="#简介" class="headerlink" title="简介"></a>简介<a class="heading-anchor" href="#简介" aria-hidden="true"></a></h3><p>这一篇文章是关于 Self-Attention 可视化的，可视化的网络有 Transformer 和 BERT。里面有一幅 Transformer 的图很好，贴过来。</p>
<p><img src="https://i.loli.net/2019/09/24/RF15kyJbirDtnh3.png" alt></p>
<a id="more"></a>
<h2 id="论文2" class="heading-control"><a href="#论文2" class="headerlink" title="论文2"></a>论文 2<a class="heading-anchor" href="#论文2" aria-hidden="true"></a></h2><p><strong>《BERT Meets Chinese Word Segmentation》</strong></p>
<h3 id="简介-1" class="heading-control"><a href="#简介-1" class="headerlink" title="简介"></a>简介<a class="heading-anchor" href="#简介-1" aria-hidden="true"></a></h3><p>这篇论文介绍 BERT 用于中文分词任务的。里面提到一点有趣的地方在于，BERT 后面接 Softmax 和 CRF 层的最终效果差不多，但是 SoftMax 更快。<br><strong>模型结构</strong><br><img src="https://i.loli.net/2019/09/24/nUMNzwXO9gPY71b.png" alt><br><strong>实验结果</strong><br>注意这个是只使用 BERT 的第一层做特征提取的效果，这里 CRF 要比 SoftMax 好。<br><img src="https://i.loli.net/2019/09/24/J7HroBZNMEi5qyu.png" alt><br>这个是不同层做特征提取的效果，可以看到微调 12 层的时候 SoftMax 和 CRF 效果差不多。<br><img src="https://i.loli.net/2019/09/24/er5Mnz1kPaS7lC4.png" alt></p>
<h3 id="论文结果" class="heading-control"><a href="#论文结果" class="headerlink" title="论文结果"></a>论文结果<a class="heading-anchor" href="#论文结果" aria-hidden="true"></a></h3><ul>
<li>BERT 可以稍微提高 CWS 任务的性能。就 Softmax 分类器来说，MSR 数据集和 PKU 数据集 F1 分数分别有 + 0.3 和 + 0.4 提高。</li>
<li>充分训练的时候，CRF 和 Softmax 达到相同的性能。但是由于 Softmax 预测时间更短，因此更受欢迎。</li>
<li>随着模型尺寸的增加，BERT 的性能逐渐提高。</li>
</ul>
<h2 id="论文3" class="heading-control"><a href="#论文3" class="headerlink" title="论文3"></a>论文 3<a class="heading-anchor" href="#论文3" aria-hidden="true"></a></h2><p><strong>《Enriching BERT with Knowledge Graph Embeddings for Document Classification》</strong></p>
<h3 id="简介-2" class="heading-control"><a href="#简介-2" class="headerlink" title="简介"></a>简介<a class="heading-anchor" href="#简介-2" aria-hidden="true"></a></h3><p>这篇文章是<a href="https://competitions.codalab.org/competitions/20139#learn_the_details">一个比赛</a>的方法，这个比赛是进行文档分类，但是还有一些其他的数据（作者，ISBN 等等），因此要做特征的融合，作者提出的融合方法很简单，如下：<br><img src="https://i.loli.net/2019/09/24/ByvGczodnQZFjEq.png" alt></p>
<h2 id="论文4" class="heading-control"><a href="#论文4" class="headerlink" title="论文4"></a>论文 4<a class="heading-anchor" href="#论文4" aria-hidden="true"></a></h2><p><strong>《Subword ELMo》</strong></p>
<h3 id="简介-3" class="heading-control"><a href="#简介-3" class="headerlink" title="简介"></a>简介<a class="heading-anchor" href="#简介-3" aria-hidden="true"></a></h3><p>这篇文章主要使用 Subword 提升 ELMo 的性能，思路很简单。这里主要看一下网络结构。<br><img src="https://i.loli.net/2019/09/24/xrv4EGNKWqBlmkn.png" alt><br>稍微扩充一下 Highway Network, <a href="https://arxiv.org/pdf/1505.00387.pdf">论文</a> , 公式如下，其中<script type="math/tex">T=sigmoid(wx + b)</script>:<br><img src="https://i.loli.net/2019/09/24/yYWfLEptgezoCAd.png" alt><br><strong>流程图</strong><br><img src="https://i.loli.net/2019/09/24/VNnrUc96zJwMBG3.png" alt><br><strong>对比 ResNet</strong><br><img src="https://i.loli.net/2019/09/24/FUT4zA9lNufjob8.png" alt></p>
</body></html>]]></content>
      <tags>
        <tag>论文</tag>
      </tags>
  </entry>
  <entry>
    <title>论文阅读 - 20190928</title>
    <url>/post/49484.html</url>
    <content><![CDATA[<html><head><link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script></head><body><h2 id="论文1" class="heading-control"><a href="#论文1" class="headerlink" title="论文1"></a>论文 1<a class="heading-anchor" href="#论文1" aria-hidden="true"></a></h2><p><strong>《 3R: Reading - Ranking - Recognizing for Multi-Passage Reading Comprehension》</strong></p>
<h3 id="简介" class="heading-control"><a href="#简介" class="headerlink" title="简介"></a>简介<a class="heading-anchor" href="#简介" aria-hidden="true"></a></h3><p>ITAIC 2019 的一篇文章。本文主要用来解决的是 Multi-passage reading comprehension 问题。</p>
<h3 id="模型结构" class="heading-control"><a href="#模型结构" class="headerlink" title="模型结构"></a>模型结构<a class="heading-anchor" href="#模型结构" aria-hidden="true"></a></h3><p>文章提出了阅读 - 排序 - 识别三段式模型，分别为：</p>
<ul>
<li><strong>段落提取模块</strong>：提取所有与问题相关的段落</li>
<li><strong>阅读理解模块</strong>：阅读每个提取出来的相关段落，抽取出候选答案。其中阅读理解模块基于 BERT。</li>
<li><strong>答案排序模块</strong>：提出两种答案排序策略，分别是 question-to-answer verify 和 answer-to-answer verify</li>
</ul>
<p>这三个模块完成后，还增加了 no answer recognition section，来判断是否有问题的答案。</p>
<p><img src="https://i.loli.net/2019/09/29/Y94pMrHwCWDZyue.png" alt></p>
<a id="more"></a>
<h4 id="段落提取模块" class="heading-control"><a href="#段落提取模块" class="headerlink" title="段落提取模块"></a>段落提取模块<a class="heading-anchor" href="#段落提取模块" aria-hidden="true"></a></h4><h2 id="论文2" class="heading-control"><a href="#论文2" class="headerlink" title="论文2"></a>论文 2<a class="heading-anchor" href="#论文2" aria-hidden="true"></a></h2><p><strong>《Joint Training of Candidate Extraction and Answer Selection for Reading Comprehension》</strong></p>
<h3 id="简介-1" class="heading-control"><a href="#简介-1" class="headerlink" title="简介"></a>简介<a class="heading-anchor" href="#简介-1" aria-hidden="true"></a></h3><p> 百度的一篇文章，Accepted by ACL 2018。论文把 RC 分为两个阶段，第一阶段产生候选答案集合，第二阶段进行答案选择即答案评分。整体模型结构如下：</p>
<p><img src="https://s2.ax1x.com/2019/10/11/uH8TRU.png" alt="uH8TRU.png"></p>
<p>产生候选答案的模型</p>
<p><img src="https://s2.ax1x.com/2019/10/11/uHGHtP.png" alt="uHGHtP.png"></p>
<p>进行答案选择的模型</p>
<p><img src="https://s2.ax1x.com/2019/10/11/uHJ3cD.png" alt="uHJ3cD.png"></p>
<h2 id="论文3" class="heading-control"><a href="#论文3" class="headerlink" title="论文3"></a>论文 3<a class="heading-anchor" href="#论文3" aria-hidden="true"></a></h2><p><strong>《Retrieve-and-Read: Multi-task Learning of Information Retrieval and Reading Comprehension》</strong></p>
<h3 id="简介-2" class="heading-control"><a href="#简介-2" class="headerlink" title="简介"></a>简介<a class="heading-anchor" href="#简介-2" aria-hidden="true"></a></h3><p>百度的一篇文章， Accepted as a full paper at CIKM 2018。本文把基于文档的阅读理解系统称之为 machine reading at scale (MRS) Task（但是不知道是不是这篇文章首先提出的这个概念）。任务的具体描述如下：</p>
<blockquote>
<p>given a question, a system retrieves passages relevant to the question from a corpus and then extracts the answer span from the retrieved passages.</p>
</blockquote>
<p>其实是 IR 和 RC 结合的任务，这种类型任务的数据集有 DrQA 等，来自下面这篇陈丹奇的论文：</p>
<blockquote>
<p>Danqi Chen, Adam Fisch, Jason Weston, and Antoine Bordes. 2017. Reading Wikipedia to Answer Open-Domain Questions. In ACL. 1870–1879.</p>
</blockquote>
<p>但是这篇论文有个缺点就是第一步检索或者叫召回文档的时候精确率不高（500 万文档中召回 Top5），一般召回的文档是包含问题里面的词语的，但是由于召回的文档不全是和问题相关的。<br>这篇文章主要关注 IR 和 MC 的关系。论文指出 RC 找出答案范围的能力会提升 IR 区分段落和问题是否相关的能力。</p>
<ul>
<li>是否可以通过训练好的 RC 模型提升 IR 的能力？<br>不行，因为训练的 RC 模型使用和问题强相关的段落训练的，并不能预测与问题无关的段落上没有答案。（这个地方的理解有点问题，是在说模型的泛化能力有问题？我倾向于是说 SQUAD1.1 的任务上面都是有答案的，所有模型架构不支持无答案的回答）<br>本论文谈到了 3R 那篇论文提出了联合训练 IR 和 MC 任务。</li>
</ul>
<h3 id="具体实现" class="heading-control"><a href="#具体实现" class="headerlink" title="具体实现"></a>具体实现<a class="heading-anchor" href="#具体实现" aria-hidden="true"></a></h3><p>本文提出了一种监督的多任务学习方法，即共享模型隐藏层参数，然后最小化 RC 和 IR 的 Joint Loss。<strong>模型总体结构</strong>如下：<br><img src="https://i.loli.net/2019/09/29/rWBNx4qQamAM3IY.png" alt><br>从模型架构上看，如果是单任务的 RC，那么模型和 BiDAF 一样。<br>接着论文介绍了模型的各个层的设计，我们重点关注一下 <strong>Retrieval layer</strong>，其实就是 BIDAF 的输出接单层 LSTM，然后做 Attention Pooling, 最后 Sigmoid 输出，输出代表问题和文档的相关程度。<br>接着介绍了如何多任务学习的另一个重要内容就是<strong>多任务学习的损失函数</strong>设计:</p>
<script type="math/tex; mode=display">L(\theta) = L_{RC} + \lambda L_{IR}</script><p>然后介绍模型的实际工作原理。来了一个 Q，和文档拼接输入到这个模型中，由模型给出答案和 IR 评分，根据 IR 评分给出最后的答案排序。但是这里有个大问题就是当海量文档的时候不适用，论文提出了改进的方案，参考的这一篇论文：<strong>《High accuracy retrieval with multiple nested ranker》</strong>，稍后读一下。</p>
<h3 id="结果" class="heading-control"><a href="#结果" class="headerlink" title="结果"></a>结果<a class="heading-anchor" href="#结果" aria-hidden="true"></a></h3><p>主要在 SQuAD 上测试的。作者回复了几个问题。</p>
<ul>
<li>消融实验，分别比较了 IR 和 MC 的效果<br><img src="https://i.loli.net/2019/09/29/XT7dr3Qz8kwGlYO.png" alt></li>
</ul>
<h2 id="论文4" class="heading-control"><a href="#论文4" class="headerlink" title="论文4"></a>论文 4<a class="heading-anchor" href="#论文4" aria-hidden="true"></a></h2><p><strong>《Denoising Distantly Supervised Open-Domain Question Answering》</strong></p>
<h3 id="简介-3" class="heading-control"><a href="#简介-3" class="headerlink" title="简介"></a>简介<a class="heading-anchor" href="#简介-3" aria-hidden="true"></a></h3><p>清华大学 ACL2018 的论文。分为两个部分：Paragraph Selector 和 Paragraph Reader。</p>
<p>监督的开放域问答（DS-QA）的目的是在未标记文本的集合中找到答案。 现有的 DS-QA 模型通常从大型语料库中检索相关段落并运用阅读理解技术从最相关的段落中提取答案。 他们忽略了其他段落中包含的丰富信息。<br>此外，远程监管数据不可避免地会伴随着错误的标签问题，而这些嘈杂的数据将大大降低 DS-QA 的性能。 为了解决这些问题，我们提出了一种新颖的 DS-QA 模型，该模型采用段落选择器过滤掉那些嘈杂的段落，并使用段落阅读器从那些去噪的段落中提取正确答案。 实际数据集上的实验结果表明，与所有基线相比，我们的模型可以从嘈杂的数据中捕获有用的信息，并在 DS-QA 上取得重大改进。 论文代码：<a href="https://github.com/thunlp/OpenQA">https://github.com/thunlp/OpenQA</a></p>
<p><img src="/tmp/1570762041589.png" alt="1570762041589"></p>
<h2 id="论文5" class="heading-control"><a href="#论文5" class="headerlink" title="论文5"></a>论文 5<a class="heading-anchor" href="#论文5" aria-hidden="true"></a></h2><p><strong>《Evidence Aggregation for Answer Re-Ranking in Open-Domain Question Answering》</strong></p>
<h3 id="简介-4" class="heading-control"><a href="#简介-4" class="headerlink" title="简介"></a>简介<a class="heading-anchor" href="#简介-4" aria-hidden="true"></a></h3><p>Published as a conference paper at ICLR 2018。回答开放域问题的最新流行方法是首先搜索与问题相关的段落，然后应用阅读理解模型来提取答案。 现有方法通常从单个段落中独立提取答案。 但是，有些问题需要来自不同来源的综合证据才能正确回答。 在本文中，我们提出了两个模型，它们利用多个段落来产生答案。 两者都使用答案排序方法，该方法对由现有的最新质量检查模型生成的答案候选者进行重新排序。 我们提出两种方法，即基于强度的重新排名和基于覆盖率的重新排名，以利用来自不同段落的汇总证据来更好地确定答案。 我们的模型在三个公共开放域 QA 数据集：Quasar-T，SearchQA 和 TriviaQA 的开放域版本上取得了最新的成果，与前两个数据集相比，改进了大约 8 个百分点。</p>
<p><img src="/tmp/1570762546081.png" alt="1570762546081"></p>
<h2 id="论文6" class="heading-control"><a href="#论文6" class="headerlink" title="论文6"></a>论文 6<a class="heading-anchor" href="#论文6" aria-hidden="true"></a></h2><p><strong>《Quasar: Datasets for Question Answering by Search and Reading》</strong></p>
<h3 id="简介-5" class="heading-control"><a href="#简介-5" class="headerlink" title="简介"></a>简介<a class="heading-anchor" href="#简介-5" aria-hidden="true"></a></h3><p>这篇文章是一个数据集。我们提出了两个新的大规模数据集，旨在评估旨在理解自然语言查询并从大型文本语料库中提取其答案的系统。 Quasar-S 数据集由 37000 个完形填空组成，这些 queries 是根据流行网站 Stack Overflow 上的软件实体标签的定义构造的。网站上的帖子和评论用作回答完形填空问题的背景语料库。 Quasar-T 数据集包含 43000 个开放域琐事问题以及从各种 Internet 来源获得的答案。 ClueWeb09 用作提取这些答案的背景语料库。我们将这些数据集摆在对事实相关问题的两个相关子任务的挑战上：（1）搜索包含查询正确答案的相关文本，以及（2）读取检索到的文本以回答查询。我们还描述了一种检索系统，用于从给出查询的语料库中提取相关的句子和文档，并将其包含在发布版本中，以供研究人员仅关注（3）我们评估了这两个数据集上的几个基线，从简单的启发式方法到强大的神经模型，都表明，对于 Quasar-S 和 Quasar-T，这些基线分别落后于人类性能 16.4％和 32.1％。数据集地址 <a href="https://github.com/bdhingra/quasar。">https://github.com/bdhingra/quasar。</a></p>
<h2 id="论文7" class="heading-control"><a href="#论文7" class="headerlink" title="论文7"></a>论文 7<a class="heading-anchor" href="#论文7" aria-hidden="true"></a></h2><p><strong>《S-Net: From Answer Extraction to Answer Generation for Machine Reading Comprehension》</strong></p>
<h3 id="简介-6" class="heading-control"><a href="#简介-6" class="headerlink" title="简介"></a>简介<a class="heading-anchor" href="#简介-6" aria-hidden="true"></a></h3><p><img src="/tmp/1570763338546.png" alt="1570763338546"></p>
<h2 id="论文8" class="heading-control"><a href="#论文8" class="headerlink" title="论文8"></a>论文 8<a class="heading-anchor" href="#论文8" aria-hidden="true"></a></h2><p><strong>《Selecting Paragraphs to Answer Questions for Multi-passage Machine Reading Comprehension》</strong></p>
<h3 id="简介-7" class="heading-control"><a href="#简介-7" class="headerlink" title="简介"></a>简介<a class="heading-anchor" href="#简介-7" aria-hidden="true"></a></h3><p>focus on 单问题多段落的段落排序</p>
<p><img src="/tmp/1570763840060.png" alt="1570763840060"></p>
</body></html>]]></content>
      <tags>
        <tag>论文</tag>
      </tags>
  </entry>
  <entry>
    <title>词向量的新进展</title>
    <url>/post/56232.html</url>
    <content><![CDATA[<html><head><link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script></head><body><p><img src="https://i.loli.net/2018/11/29/5bffec15b6522.jpeg" alt="pexels-photo-1627276.jpeg"><br>最近谷歌研究人员通过新的 BERT 模型在 11 项 NLP 任务中夺得 STOA 结果，这在自然语言处理学界以及工业界都引起了不小的热议。作者通过在 33 亿文本的语料上训练语言模型，再分别在不同的下游任务上微调，这样的模型在不同的任务均得到了目前为止最好的结果，并且有一些结果相比此前的最佳成绩得到了幅度不小的提升。借此契机，我们回顾一下词表示方向的这两年的一些新进展，希望能发现一些规律和新的 idea。基本的介绍路线如下：</p>
<ul>
<li>从预训练说起，词向量其实就是 NLP 领域的迁移学习的起点</li>
<li> Word2Vec 有哪些缺点，为什么大家要去寻找新的方法</li>
<li> AlanNLP 提出的 ELMo</li>
<li>Transformer 的结构</li>
<li> FastAI 就推出的 ULMFiT</li>
<li>OpenAI 提出的 GPT</li>
<li> 谷歌出品的的 BERT</li>
</ul>
<a id="more"></a>
<h2 id="从预训练说起" class="heading-control"><a href="#从预训练说起" class="headerlink" title="从预训练说起"></a>从预训练说起<a class="heading-anchor" href="#从预训练说起" aria-hidden="true"></a></h2><p>早在 2015 年的时候，微软研究院的<strong>何恺明</strong>和他的同事们发表了<strong>残差网络</strong>的论文，第一次通过残差的方式将卷积神经网络推进到了 100 层以上，并在图像识别的任务上刷新了当时的最高纪录。自那以后起，随着网络不断地加深，效果也在不断提升。然而大量的数据训练出来的大型网络虽然效果更好，但随着网络的加深以及数据集的不断扩大，完全重新训练一个模型所需要的成本也在不断地增加。</p>
<p>因此在计算机视觉处理中，人们越来越多地采用在大规模数据集上预训练好的大型网络来提取特征，然后再进行微调来满足特定任务，这种预训练和微调的方法称之为<strong>迁移学习</strong>。</p>
<p>迁移学习有以下几点实践中的优点：</p>
<ul>
<li>实际训练的数据集小，很难训练复杂网络 (容易过拟合)</li>
<li> 可以加快模型的训练速度</li>
<li>给一个不错的参数初始化，有利于后续的优化</li>
</ul>
<p>那为什么迁移学习是可行的呢？这是因为预训练好的网络参数，尤其是底层的网络参数抽取出特征跟具体任务越无关，越具备任务的通用性，而高层特征跟任务关联较大，实际可以不用使用，或者采用 Fine-tuning 用新数据集合清洗掉高层无关的特征抽取器。</p>
<p>最近大神何恺明的新作 <a href="https://arxiv.org/abs/1811.08883">Rethinking ImageNet Pre-training</a> 里面说参数随机初始化的效果不比微调的效果差（算力充足，迭代足够多轮），但是也证明了微调确实可以加速训练。</p>
<p><img src="https://i.loli.net/2018/11/29/5bffc0bae470d.png" alt></p>
<center>何恺明文章里面的随机初始化和预训练的结果比较</center>

<p>相比之下，自然语言处理目前通常会使用预训练的词向量来进行后续任务。但词向量是通过浅层网络进行无监督训练，虽然在词的级别上有着不错的特性，但却缺少对连续文本的内在联系和语言结构的表达能力。因此大家也希望能像图像领域那样，通过大量数据来预训练一个大型的神经网络，然后用它来对文本提取特征去做后续的任务，以期望能得到更好的效果。</p>
<h2 id="Word2Vec" class="heading-control"><a href="#Word2Vec" class="headerlink" title="Word2Vec"></a>Word2Vec<a class="heading-anchor" href="#Word2Vec" aria-hidden="true"></a></h2><p><strong>论文</strong>：</p>
<ul>
<li><p><a href="https://arxiv.org/abs/1405.4053v1">Distributed Representations of Sentences and Documents</a></p>
<p>在前人基础上提出更精简的语言模型（language model）框架并用于生成词向量，这个框架就是 Word2vec</p>
</li>
<li><p><a href="https://arxiv.org/abs/1301.3781">Efficient estimation of word representations in vector space</a></p>
</li>
</ul>
<p>​      专门讲训练 Word2vec 中的两个 trick：hierarchical softmax 和 negative sampling</p>
<p>Word2Vec 有两种训练方法，一种叫 CBOW，核心思想是从一个句子里面把一个词抠掉，用这个词的上文和下文去预测被抠掉的这个词；第二种叫做 Skip-gram，和 CBOW 正好反过来，输入某个单词，要求网络预测它的上下文单词。</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">Continous Bag of Words Model</th>
<th style="text-align:center">Skip-Gram model</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center"><img src="https://i.loli.net/2018/11/29/5bffb65a503e5.png" alt></td>
<td style="text-align:center"><img src="https://i.loli.net/2018/11/29/5bffb6db45c19.png" alt></td>
</tr>
</tbody>
</table>
</div>
<center>Word2Vec 的两种训练方式</center>

<p>应用于下游任务例如问答、翻译、情感分析的时候，词向量不用随机的初始化，而是采用从预训练词表里查表初始化即可。下游 NLP 任务在使用 Word Embedding 的时候也类似图像有两种做法，一种是 Frozen，就是 Word Embedding 那层网络参数固定不动；另外一种是 Fine-Tuning，就是 Word Embedding 这层参数使用新的训练集合训练也需要跟着训练过程更新掉。</p>
<p>那么 Word2Vec 有什么问题呢？其实问题就在于词向量训练的时候有一个假设：将语义相似的词分配相似的词向量，以确保它们在向量空间的距离尽可能的近 (一义多词)。所以问题就在于通过这种方式训练之后的词向量是静态的，上下文无关的，<strong>不能解决一词多义</strong>。这实际上是一个比较大的问题，因为多义词在语言中还是非常见的，也是语言灵活性和高效性的一种体现。</p>
<p>下文的 ELMo 就是着重来解决这个问题的。</p>
<h2 id="ELMo" class="heading-control"><a href="#ELMo" class="headerlink" title="ELMo"></a>ELMo<a class="heading-anchor" href="#ELMo" aria-hidden="true"></a></h2><p>ELMO 是 “Embedding from Language Models” 的简称，</p>
<h2 id="Transformer" class="heading-control"><a href="#Transformer" class="headerlink" title="Transformer"></a>Transformer<a class="heading-anchor" href="#Transformer" aria-hidden="true"></a></h2><p>Transformer 是和 CNN、RNN 一样的特征提取器，只不过里面用的是纯 Attention 罢了。</p>
<p>Transformer 舍弃了 RNN 的循环式网络结构，完全基于注意力机制来对一段文本进行建模。注意力机制的核心思想是去计算一句话中的每个词对于这句话中所有词的相互关系，然后认为这些词与词之间的相互关系在一定程度上反应了这句话中不同词之间的关联性以及重要程度。因此再利用这些相互关系来调整每个词的重要性（权重）就可以获得每个词新的表达。这个新的表征不但蕴含了该词本身，还蕴含了其他词与这个词的关系，因此和单纯的词向量相比是一个更加全局的表达。</p>
<p>Transformer 通过对输入的文本不断进行这样的注意力机制层和普通的非线性层交叠来得到最终的文本表达。</p>
<h2 id="BERT" class="heading-control"><a href="#BERT" class="headerlink" title="BERT"></a>BERT<a class="heading-anchor" href="#BERT" aria-hidden="true"></a></h2><p>说白了，BERT 就是一个预训练好的表示模型。论文的主要特点以下几点：</p>
<ol>
<li>使用了 Transformer 作为算法的主要框架，Trabsformer 能更彻底的捕捉语句中的双向关系；</li>
<li>使用了 Mask Language Model (MLM) 和 Next Sentence Prediction (NSP) 的多任务训练目标；</li>
<li>使用更强大的机器训练更大规模的数据，使 BERT 的结果达到了全新的高度，并且 Google 开源了 BERT 模型，用户可以直接使用 BERT 作为 Word2Vec 的转换矩阵并高效的将其应用到自己的任务中。</li>
</ol>
<h3 id="使用" class="heading-control"><a href="#使用" class="headerlink" title="使用"></a>使用<a class="heading-anchor" href="#使用" aria-hidden="true"></a></h3><ul>
<li><a href="https://github.com/Socialbird-AILab/BERT-Classification-Tutorial">BERT 文本分类教程</a></li>
<li><a href="https://github.com/macanv/BERT-BiLSTM-CRF-NER">用谷歌 BERT 模型在 BLSTM-CRF 模型上进行预训练用于中文命名实体识别的 Tensorflow 代码</a></li>
<li><a href="https://github.com/huggingface/pytorch-pretrained-BERT">BERT 的 PyTorch 实现</a></li>
</ul>
<h2 id="Reference" class="heading-control"><a href="#Reference" class="headerlink" title="Reference"></a>Reference<a class="heading-anchor" href="#Reference" aria-hidden="true"></a></h2><ol>
<li><a href="http://nlp.seas.harvard.edu/2018/04/03/attention.html#prelims">The Annotated Transformer</a></li>
<li></li>
</ol>
</body></html>]]></content>
      <categories>
        <category>项目</category>
      </categories>
      <tags>
        <tag>词向量</tag>
      </tags>
  </entry>
  <entry>
    <title>轻量终端打印工具:wasabi</title>
    <url>/post/23212.html</url>
    <content><![CDATA[<html><head><link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script></head><body><p><img src="https://i.loli.net/2018/11/29/5bffea4e6ae22.png" alt><br>可以用于终端打印一些信息<br><a id="more"></a></p>
<h2 id="安装" class="heading-control"><a href="#安装" class="headerlink" title="安装"></a>安装<a class="heading-anchor" href="#安装" aria-hidden="true"></a></h2><figure class="highlight shell"><table><tbody><tr><td class="code"><pre><span class="line">pip install wasabi</span><br></pre></td></tr></tbody></table></figure>
<h2 id="代码以及对应的执行效果" class="heading-control"><a href="#代码以及对应的执行效果" class="headerlink" title="代码以及对应的执行效果"></a>代码以及对应的执行效果<a class="heading-anchor" href="#代码以及对应的执行效果" aria-hidden="true"></a></h2><figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> wasabi <span class="keyword">import</span> Printer</span><br><span class="line"></span><br><span class="line">msg = Printer()</span><br><span class="line">msg.text(<span class="string">"Hello world!"</span>)</span><br><span class="line"></span><br><span class="line">msg.good(<span class="string">"Success"</span>)</span><br><span class="line">msg.fail(<span class="string">"Error"</span>)</span><br><span class="line">msg.warn(<span class="string">"Warning"</span>)</span><br><span class="line">msg.info(<span class="string">"Info"</span>)</span><br><span class="line"></span><br><span class="line">msg.divider(<span class="string">"Heading"</span>,char=<span class="string">'-'</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">with</span> msg.loading(<span class="string">"Loading..."</span>):</span><br><span class="line">    <span class="comment"># Do something here that takes longer</span></span><br><span class="line">    time.sleep(<span class="number">3</span>)</span><br><span class="line">msg.good(<span class="string">"Successfully loaded something!"</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> wasabi <span class="keyword">import</span> color</span><br><span class="line"></span><br><span class="line">formatted = color(<span class="string">"This is a text"</span>, fg=<span class="string">"white"</span>, bg=<span class="string">"green"</span>, bold=<span class="literal">True</span>)</span><br><span class="line">print(formatted)</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> wasabi <span class="keyword">import</span> wrap</span><br><span class="line"></span><br><span class="line">wrapped = wrap(<span class="string">"Hello world, this is a text."</span>, indent=<span class="number">2</span>)</span><br><span class="line">print(wrapped)</span><br></pre></td></tr></tbody></table></figure>
<p><img src="https://i.loli.net/2018/11/29/5bffea4e6ae22.png" alt></p>
</body></html>]]></content>
      <categories>
        <category>工具</category>
      </categories>
      <tags>
        <tag>wasabi</tag>
      </tags>
  </entry>
  <entry>
    <title>过拟合现象及解决方案</title>
    <url>/post/20184.html</url>
    <content><![CDATA[<html><head><link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script></head><body><h2 id="过拟合" class="heading-control"><a href="#过拟合" class="headerlink" title="过拟合"></a>过拟合<a class="heading-anchor" href="#过拟合" aria-hidden="true"></a></h2><p>每迭代几次就对模型进行检查它在验证集上的工作情况，并保存每个比以前所有迭代时都要好的模型。此外，还设置最大迭代次数这个限制，超过此值时停止学习。<br><img src="https://i.loli.net/2019/07/23/5d367c0ac0f3d17413.png" alt></p>
<a id="more"></a>
<h2 id="交叉验证" class="heading-control"><a href="#交叉验证" class="headerlink" title="交叉验证"></a>交叉验证<a class="heading-anchor" href="#交叉验证" aria-hidden="true"></a></h2><p>交叉验证的原理为在给定的建模样本中，拿出大部分样本进行建模型，留小部分样本用于建立的模型进行预报，并求这小部分样本的预报误差，记录它们的平方加和。一般有三种常见形式：简单交叉验证 (Holdout 验证)；K 折交叉验证 (K-fold cross-validation)；留一验证 (leave-one-out cross validation)。其中 K 折交叉验证又是最常用的一种。</p>
<p><img src="https://i.loli.net/2019/07/23/5d367c009c80128818.png" alt></p>
<p>如果交叉验证的结果比单次训练的结果精度下降，就证明了单次分割测试集与训练集出来的结果确实存在过拟合的现象。但缺点也非常明显，速度慢，此外，交叉检验只能起到检验过拟合的作用，并不能抑制过拟合。</p>
<h2 id="增加数据" class="heading-control"><a href="#增加数据" class="headerlink" title="增加数据"></a>增加数据<a class="heading-anchor" href="#增加数据" aria-hidden="true"></a></h2><p>一种是增加训练样本，第二种是数据增强。</p>
<ul>
<li>在计算机视觉领域中，增广的方式是对图像旋转，缩放，剪切，添加噪声等。</li>
<li>在自然语言处理领域中，可以做同义词替换扩充数据集。</li>
<li>语音识别中可以对样本数据添加随机的噪声。</li>
</ul>
<h2 id="L1和L2正则化" class="heading-control"><a href="#L1和L2正则化" class="headerlink" title="L1和L2正则化"></a>L1 和 L2 正则化<a class="heading-anchor" href="#L1和L2正则化" aria-hidden="true"></a></h2><p>从贝叶斯角度理解最为合理。</p>
<p><img src="https://i.loli.net/2019/07/23/5d367bf5c24c777152.png" alt></p>
<h2 id="Dropout" class="heading-control"><a href="#Dropout" class="headerlink" title="Dropout"></a>Dropout<a class="heading-anchor" href="#Dropout" aria-hidden="true"></a></h2><p>神经网络的每个单元（属于输出层的那些单元）都被赋予在计算中被暂时忽略的概率 p。超参数 p 称为丢失率，通常将其默认值设置为 0.5。然后，在每次迭代中，根据指定的概率随机选择丢弃的神经元。测试的时候输出乘以概率 p，保证和训练的时候期望一样。<br><img src="https://i.loli.net/2019/07/23/5d367c048857384281.png" alt></p>
<h2 id="提前停止（early-stopping）" class="heading-control"><a href="#提前停止（early-stopping）" class="headerlink" title="提前停止（early stopping）"></a>提前停止（early stopping）<a class="heading-anchor" href="#提前停止（early-stopping）" aria-hidden="true"></a></h2><p>每迭代几次就对模型进行检查它在验证集上的工作情况，并保存每个比以前所有迭代时都要好的模型。此外，还设置最大迭代次数这个限制，超过此值时停止学习。缺点在于需要额外的空间，而且不好和其他的参数一起调。</p>
<h2 id="结合多种模型" class="heading-control"><a href="#结合多种模型" class="headerlink" title="结合多种模型"></a>结合多种模型<a class="heading-anchor" href="#结合多种模型" aria-hidden="true"></a></h2><p>训练多个模型，以每个模型的平均输出作为结果。</p>
<ol>
<li>Bagging：多个强模型的输出平均，是并行的</li>
<li> Boosting：多个弱模型的递进学习，增加前面学习器没有学习好的样本的权重，是串行的</li>
</ol>
<h2 id="剪枝" class="heading-control"><a href="#剪枝" class="headerlink" title="剪枝"></a>剪枝<a class="heading-anchor" href="#剪枝" aria-hidden="true"></a></h2><p>剪枝是决策树类算法防止过拟合的方法。如果决策树的结构过于复杂，可能会导致过拟合问题，此时需要对树进行剪枝，消掉某些节点让它变得更简单。剪枝的关键问题是确定减掉哪些树节点以及减掉它们之后如何进行节点合并。决策树的剪枝算法可以分为两类，分别称为预剪枝和后剪枝。</p>
<ul>
<li>预剪枝在树的训练过程中通过停止分裂对树的规模进行限制</li>
<li>后剪枝先构造出一棵完整的树，然后通过某种规则消除掉部分节点，用叶子节点替代。</li>
</ul>
<h2 id="多任务学习" class="heading-control"><a href="#多任务学习" class="headerlink" title="多任务学习"></a>多任务学习<a class="heading-anchor" href="#多任务学习" aria-hidden="true"></a></h2><p>深度学习中两种多任务学习模式：隐层参数的硬共享和软共享</p>
<ul>
<li>硬共享机制是指在所有任务中共享隐藏层，同时保留几个特定任务的输出层来实现。硬共享机制降低了过拟合的风险。多个任务同时学习，模型就越能捕捉到多个任务的同一表示，从而导致模型在原始任务上的过拟合风险越小。</li>
<li>软共享机制是指每个任务有自己的模型，自己的参数。模型参数之间的距离是正则化的，以便保障参数相似性。</li>
<li>特征选择，减少特征数或使用较少的特征组合</li>
<li>交叉检验，通过交叉检验得到较优的模型参数</li>
</ul>
<h2 id="BN" class="heading-control"><a href="#BN" class="headerlink" title="BN"></a>BN<a class="heading-anchor" href="#BN" aria-hidden="true"></a></h2><p>比较有争议。按照<a href="https://arxiv.org/pdf/1611.03530.pdf">这篇文章</a>说的，可能在一些情况下有抑制作用，使得 overfitting 再更多的 training epoch 后出现，但并不能阻止。</p>
<p>Batch Normalization（以下称 BN）的主要作用是加快网络的训练速度。</p>
<p>硬要说是防止过拟合，可以这样理解：BN 每次的 mini-batch 的数据都不一样，但是每次的 mini-batch 的数据都会对 moving mean 和 moving variance 产生作用，可以认为是引入了噪声，这就可以认为是进行了 data augmentation，而 data augmentation 被认为是防止过拟合的一种方法。因此，可以认为用 BN 可以防止过拟合。</p>
</body></html>]]></content>
  </entry>
  <entry>
    <title>逻辑回归</title>
    <url>/post/60504.html</url>
    <content><![CDATA[<html><head><link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script></head><body><h2 id="逻辑回归模型" class="heading-control"><a href="#逻辑回归模型" class="headerlink" title="逻辑回归模型"></a>逻辑回归模型<a class="heading-anchor" href="#逻辑回归模型" aria-hidden="true"></a></h2><p>模型的假设：数据服从伯努利分布。</p>
<script type="math/tex; mode=display">
y=\sigma(f(\boldsymbol{x}))=\sigma\left(\boldsymbol{w}^{T} \boldsymbol{x}\right)=\frac{1}{1+e^{-\boldsymbol{w}^{T} \boldsymbol{x}}}</script><a id="more"></a>
<h2 id="损失函数" class="heading-control"><a href="#损失函数" class="headerlink" title="损失函数"></a>损失函数<a class="heading-anchor" href="#损失函数" aria-hidden="true"></a></h2><script type="math/tex; mode=display">
P(y | \boldsymbol{x})=\left\{\begin{array}{c}{p, y=1} \\ {1-p, y=0}\end{array}\right.</script><p>等价于：</p>
<script type="math/tex; mode=display">
P\left(y_{i} | \boldsymbol{x}_{i}\right)=p^{y_{i}}(1-p)^{1-y_{i}}</script><p>如果我们采集到了一组数据一共 N 个，总概率为：</p>
<script type="math/tex; mode=display">
P =\prod_{n=1}^{N} p^{y_{n}}(1-p)^{1-y_{n}}</script><p>最大化这个概率即最小化负 Log 损失函数：</p>
<script type="math/tex; mode=display">
\begin{array}{l}{L=\sum_{n=1}^{N} \ln \left(p^{y_{n}}(1-p)^{1-y_{n}}\right)} \\ {=\sum_{n=1}^{N}\left(y_{n} \ln (p)+\left(1-y_{n}\right) \ln (1-p)\right)}\end{array}</script><h2 id="梯度计算" class="heading-control"><a href="#梯度计算" class="headerlink" title="梯度计算"></a>梯度计算<a class="heading-anchor" href="#梯度计算" aria-hidden="true"></a></h2><p>上面式子中的 p 的公式如下：</p>
<script type="math/tex; mode=display">
p=\frac{1}{1+e^{-\boldsymbol{w}^{T} \boldsymbol{x}}}</script><p>1-p 的公式：</p>
<script type="math/tex; mode=display">
1-p=\frac{e^{-\boldsymbol{w}^{T} \boldsymbol{x}}}{1+e^{-\boldsymbol{w}^{T} \boldsymbol{x}}}</script><p>p 的导数如下：</p>
<script type="math/tex; mode=display">
p^{\prime}=p(1-p) \boldsymbol{x}</script><p>1-p 的导数如下：</p>
<script type="math/tex; mode=display">
(1-p)^{\prime}=-p(1-p) \boldsymbol{x}</script><p>所以损失函数的梯度如下：</p>
<script type="math/tex; mode=display">
\begin{aligned} \nabla F(\boldsymbol{w}) &=\nabla\left(\sum_{n=1}^{N}\left(y_{n} \ln (p)+\left(1-y_{n}\right) \ln (1-p)\right)\right) \\ &=\sum\left(y_{n} \ln ^{\prime}(p)+\left(1-y_{n}\right) \ln ^{\prime}(1-p)\right) \\ &=\sum\left(\left(y_{n} \frac{1}{p} p^{\prime}\right)+\left(1-y_{n}\right) \frac{1}{1-p}(1-p)^{\prime}\right) \\ &=\sum_{N}\left(y_{n}(1-p) \boldsymbol{x}_{n}-\left(1-y_{n}\right) p \boldsymbol{x}_{n}\right) \\ &=\sum_{n=1}^{N}\left(y_{n}-p\right) \boldsymbol{x}_{n} \end{aligned}</script><h2 id="逻辑回归的决策边界" class="heading-control"><a href="#逻辑回归的决策边界" class="headerlink" title="逻辑回归的决策边界"></a>逻辑回归的决策边界<a class="heading-anchor" href="#逻辑回归的决策边界" aria-hidden="true"></a></h2><p>逻辑回归的决策边界如下：</p>
<script type="math/tex; mode=display">
\frac{1}{1+e^{-\boldsymbol{w}^{T} \boldsymbol{x}}}=0.5</script><p>简一下上面的曲线公式，得到：</p>
<script type="math/tex; mode=display">
e^{-\boldsymbol{w}^{T} \boldsymbol{x}}=1=e^{0}</script><p>如下图所示，所以决策边界是线性的。</p>
<script type="math/tex; mode=display">
-\boldsymbol{w}^{T} \boldsymbol{x}=0</script><p><img src="https://s2.ax1x.com/2019/07/23/ekKRw4.md.png" alt></p>
<h2 id="代码" class="heading-control"><a href="#代码" class="headerlink" title="代码"></a>代码<a class="heading-anchor" href="#代码" aria-hidden="true"></a></h2><p>逻辑回归 + L2 范数正则化代码<br></p><figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">LogisticRegression</span>():</span></span><br><span class="line">    <span class="string">""" A simple logistic regression model with L2 regularization (zero-mean</span></span><br><span class="line"><span class="string">    Gaussian priors on parameters). """</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, x_train=None, y_train=None, x_test=None, y_test=None,</span></span></span><br><span class="line"><span class="function"><span class="params">                 alpha=<span class="number">.1</span>, synthetic=False</span>):</span></span><br><span class="line">        <span class="comment"># Set L2 regularization strength</span></span><br><span class="line">        self.alpha = alpha</span><br><span class="line">        <span class="comment"># Set the data.</span></span><br><span class="line">        self.set_data(x_train, y_train, x_test, y_test)</span><br><span class="line">        <span class="comment"># Initialize parameters to zero, for lack of a better choice.</span></span><br><span class="line">        self.betas = np.zeros(self.x_train.shape[<span class="number">1</span>])</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">negative_lik</span>(<span class="params">self, betas</span>):</span></span><br><span class="line">        <span class="keyword">return</span> <span class="number">-1</span> * self.lik(betas)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">lik</span>(<span class="params">self, betas</span>):</span></span><br><span class="line">        <span class="string">""" Likelihood of the data under the current settings of parameters. """</span></span><br><span class="line">        <span class="comment"># Data likelihood</span></span><br><span class="line">        l = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(self.n):</span><br><span class="line">            l += log(sigmoid(self.y_train[i] * </span><br><span class="line">                             np.dot(betas, self.x_train[i,:])))</span><br><span class="line">        <span class="comment"># Prior likelihood</span></span><br><span class="line">        <span class="keyword">for</span> k <span class="keyword">in</span> range(<span class="number">1</span>, self.x_train.shape[<span class="number">1</span>]):</span><br><span class="line">            l -= (self.alpha / <span class="number">2.0</span>) * self.betas[k]**<span class="number">2</span></span><br><span class="line">        <span class="keyword">return</span> l</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">train</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="string">""" Define the gradient and hand it off to a scipy gradient-based</span></span><br><span class="line"><span class="string">        optimizer. """</span></span><br><span class="line">        <span class="comment"># Define the derivative of the likelihood with respect to beta_k.</span></span><br><span class="line">        <span class="comment"># Need to multiply by -1 because we will be minimizing.</span></span><br><span class="line">        dB_k = <span class="keyword">lambda</span> B, k : (k > <span class="number">0</span>) * self.alpha * B[k] - np.sum([</span><br><span class="line">            self.y_train[i] * self.x_train[i, k] * </span><br><span class="line">            sigmoid(-self.y_train[i] * np.dot(B, self.x_train[i,:])) </span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> range(self.n)])</span><br><span class="line"></span><br><span class="line">        <span class="comment"># The full gradient is just an array of componentwise derivatives</span></span><br><span class="line">        dB = <span class="keyword">lambda</span> B : np.array([dB_k(B, k) </span><br><span class="line">                                  <span class="keyword">for</span> k <span class="keyword">in</span> range(self.x_train.shape[<span class="number">1</span>])])</span><br><span class="line">        <span class="comment"># Optimize</span></span><br><span class="line">        self.betas = fmin_bfgs(self.negative_lik, self.betas, fprime=dB)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">set_data</span>(<span class="params">self, x_train, y_train, x_test, y_test</span>):</span></span><br><span class="line">        <span class="string">""" Take data that's already been generated. """</span></span><br><span class="line">        self.x_train = x_train</span><br><span class="line">        self.y_train = y_train</span><br><span class="line">        self.x_test = x_test</span><br><span class="line">        self.y_test = y_test</span><br><span class="line">        self.n = y_train.shape[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">training_reconstruction</span>(<span class="params">self</span>):</span></span><br><span class="line">        p_y1 = np.zeros(self.n)</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(self.n):</span><br><span class="line">            p_y1[i] = sigmoid(np.dot(self.betas, self.x_train[i,:]))</span><br><span class="line">        <span class="keyword">return</span> p_y1</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">test_predictions</span>(<span class="params">self</span>):</span></span><br><span class="line">        p_y1 = np.zeros(self.n)</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(self.n):</span><br><span class="line">            p_y1[i] = sigmoid(np.dot(self.betas, self.x_test[i,:]))</span><br><span class="line">        <span class="keyword">return</span> p_y1</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">plot_training_reconstruction</span>(<span class="params">self</span>):</span></span><br><span class="line">        plot(np.arange(self.n), <span class="number">.5</span> + <span class="number">.5</span> * self.y_train, <span class="string">'bo'</span>)</span><br><span class="line">        plot(np.arange(self.n), self.training_reconstruction(), <span class="string">'rx'</span>)</span><br><span class="line">        ylim([<span class="number">-.1</span>, <span class="number">1.1</span>])</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">plot_test_predictions</span>(<span class="params">self</span>):</span></span><br><span class="line">        plot(np.arange(self.n), <span class="number">.5</span> + <span class="number">.5</span> * self.y_test, <span class="string">'yo'</span>)</span><br><span class="line">        plot(np.arange(self.n), self.test_predictions(), <span class="string">'rx'</span>)</span><br><span class="line">        ylim([<span class="number">-.1</span>, <span class="number">1.1</span>])</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    <span class="keyword">from</span> pylab <span class="keyword">import</span> *</span><br><span class="line">    <span class="comment"># Create 20 dimensional data set with 25 points -- this will be</span></span><br><span class="line">    <span class="comment"># susceptible to overfitting.</span></span><br><span class="line">    data = SyntheticClassifierData(<span class="number">25</span>, <span class="number">20</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Run for a variety of regularization strengths</span></span><br><span class="line">    alphas = [<span class="number">0</span>, <span class="number">.001</span>, <span class="number">.01</span>, <span class="number">.1</span>]</span><br><span class="line">    <span class="keyword">for</span> j, a <span class="keyword">in</span> enumerate(alphas):</span><br><span class="line">        <span class="comment"># Create a new learner, but use the same data for each run</span></span><br><span class="line">        lr = LogisticRegression(x_train=data.X_train, y_train=data.Y_train,</span><br><span class="line">                                x_test=data.X_test, y_test=data.Y_test, alpha=a)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">print</span> <span class="string">"Initial likelihood:"</span></span><br><span class="line">        <span class="keyword">print</span> lr.lik(lr.betas)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Train the model</span></span><br><span class="line">        lr.train()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Display execution info</span></span><br><span class="line">        <span class="keyword">print</span> <span class="string">"Final betas:"</span></span><br><span class="line">        <span class="keyword">print</span> lr.betas</span><br><span class="line">        <span class="keyword">print</span> <span class="string">"Final lik:"</span></span><br><span class="line">        <span class="keyword">print</span> lr.lik(lr.betas)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Plot the results</span></span><br><span class="line">        subplot(len(alphas), <span class="number">2</span>, <span class="number">2</span>*j + <span class="number">1</span>)</span><br><span class="line">        lr.plot_training_reconstruction()</span><br><span class="line">        ylabel(<span class="string">"Alpha=%s"</span> % a)</span><br><span class="line">        <span class="keyword">if</span> j == <span class="number">0</span>:</span><br><span class="line">            title(<span class="string">"Training set reconstructions"</span>)</span><br><span class="line"></span><br><span class="line">        subplot(len(alphas), <span class="number">2</span>, <span class="number">2</span>*j + <span class="number">2</span>)</span><br><span class="line">        lr.plot_test_predictions()</span><br><span class="line">        <span class="keyword">if</span> j == <span class="number">0</span>:</span><br><span class="line">            title(<span class="string">"Test set predictions"</span>)</span><br><span class="line">    show()</span><br></pre></td></tr></tbody></table></figure><p></p>
<h3 id="逻辑回归中为什么使用对数损失而不用平方损失" class="heading-control"><a href="#逻辑回归中为什么使用对数损失而不用平方损失" class="headerlink" title="逻辑回归中为什么使用对数损失而不用平方损失"></a>逻辑回归中为什么使用对数损失而不用平方损失<a class="heading-anchor" href="#逻辑回归中为什么使用对数损失而不用平方损失" aria-hidden="true"></a></h3><p>对于逻辑回归，这里所说的对数损失和极大似然是相同的。 不使用平方损失的原因是，在使用 Sigmoid 函数作为正样本的概率时，同时将平方损失作为损失函数，这时所构造出来的损失函数是非凸的，不容易求解，容易得到其局部最优解。 而如果使用极大似然，其目标函数就是对数似然函数，该损失函数是关于未知参数的高阶连续可导的凸函数，便于求其全局最优解。</p>
<h2 id="Softmax" class="heading-control"><a href="#Softmax" class="headerlink" title="Softmax"></a>Softmax<a class="heading-anchor" href="#Softmax" aria-hidden="true"></a></h2><script type="math/tex; mode=display">
h_{\theta}(x)=\left[\begin{array}{c}{P(y=1 | x ; \theta)} \\ {P(y=2 | x ; \theta)} \\ {\vdots} \\ {P(y=K | x ; \theta)}\end{array}\right]=\frac{1}{\sum_{j=1}^{K} \exp \left(\theta_{j}^{T} x\right)}\left[\begin{array}{c}{\exp \left(\theta_{1}^{T} x\right)} \\ {\exp \left(\theta_{2}^{T} x\right)} \\ {\vdots} \\ {\exp \left(\theta_{K}^{T} x\right)}\end{array}\right]</script><p>代价函数：</p>
<script type="math/tex; mode=display">
J(\theta)=-\left[\sum_{i=1}^{n} \sum_{k=1}^{K} \mathbf{1}\left\{y^{(i)}=k\right\} \ln \frac{\exp \left(\theta_{k}^{T} x_{i}\right)}{\sum_{j=1}^{K} \exp \left(\theta_{j}^{T} x_{i}\right)}\right]</script><p>其中，1${x}$ 是指示函数，x 为真时取 1 否则取 0。</p>
</body></html>]]></content>
      <tags>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title>配置 CentOS7 GPU 环境</title>
    <url>/post/47363.html</url>
    <content><![CDATA[<html><head><link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script></head><body><p><img src="https://i.loli.net/2018/11/07/5be2c0ba79f37.png" alt></p>
<h2 id="基本配置" class="heading-control"><a href="#基本配置" class="headerlink" title="基本配置"></a>基本配置<a class="heading-anchor" href="#基本配置" aria-hidden="true"></a></h2><ol>
<li>先装 wget<figure class="highlight shell"><table><tbody><tr><td class="code"><pre><span class="line">yum -y install wget</span><br></pre></td></tr></tbody></table></figure></li>
<li>新建自己的文件夹 <figure class="highlight shell"><table><tbody><tr><td class="code"><pre><span class="line">mkdir sunyan</span><br></pre></td></tr></tbody></table></figure>
<a id="more"></a>
<h2 id="安装Anoconda" class="heading-control"><a href="#安装Anoconda" class="headerlink" title="安装Anoconda"></a>安装 Anoconda<a class="heading-anchor" href="#安装Anoconda" aria-hidden="true"></a></h2></li>
<li><p> 下载 Anoconda。注意最新 Anoconda 的是 3.7 版本的，但是 tensorflow 还没有更新到 3.7，这里我们安装 2018 年 5 月发布的 python 3.6 版本。</p>
<figure class="highlight shell"><table><tbody><tr><td class="code"><pre><span class="line">wget https://mirrors.tuna.tsinghua.edu.cn/anaconda/archive/Anaconda3-5.2.0-Linux-x86_64.sh</span><br></pre></td></tr></tbody></table></figure>
</li>
<li><p>安装 bzip2</p>
<figure class="highlight shell"><table><tbody><tr><td class="code"><pre><span class="line">yum install -y bzip2</span><br></pre></td></tr></tbody></table></figure></li>
<li><p>安装 Anoconda，一路 yes 即可。</p>
<figure class="highlight shell"><table><tbody><tr><td class="code"><pre><span class="line">bash Anaconda3-5.2.0-Linux-x86_64.sh</span><br></pre></td></tr></tbody></table></figure>
</li>
<li><p>使能配置</p>
<figure class="highlight shell"><table><tbody><tr><td class="code"><pre><span class="line">source .bashrc</span><br></pre></td></tr></tbody></table></figure></li>
<li>输入 Python，查看是否配置正确<br><img src="https://i.loli.net/2018/11/07/5be2bf612e76c.png" alt></li>
</ol>
<h2 id="Conda安装TesnorFlow-GPU版本" class="heading-control"><a href="#Conda安装TesnorFlow-GPU版本" class="headerlink" title="Conda安装TesnorFlow GPU版本"></a>Conda 安装 TesnorFlow GPU 版本<a class="heading-anchor" href="#Conda安装TesnorFlow-GPU版本" aria-hidden="true"></a></h2><ol>
<li>配置国内 conda 源。由于 cudnn 和 cuda 很大，conda 又在国外，容易导致下载中断，这里我们配置国内中科大的镜像。<figure class="highlight shell"><table><tbody><tr><td class="code"><pre><span class="line">conda config --add channels https://mirrors.ustc.edu.cn/anaconda/pkgs/main/</span><br></pre></td></tr></tbody></table></figure></li>
<li>安装 <figure class="highlight shell"><table><tbody><tr><td class="code"><pre><span class="line">conda install tensorflow-gpu</span><br></pre></td></tr></tbody></table></figure>
我的 cuda 版本是 9.0，cudnn 版本是 7.1.2，tensorflow-gpu 版本是 1.9.0。<br><img src="https://i.loli.net/2018/11/07/5be2bf613b4fe.png" alt><br><img src="https://i.loli.net/2018/11/07/5be2bf6139235.png" alt></li>
</ol>
<h2 id="安装NVIDIA驱动" class="heading-control"><a href="#安装NVIDIA驱动" class="headerlink" title="安装NVIDIA驱动"></a>安装 NVIDIA 驱动<a class="heading-anchor" href="#安装NVIDIA驱动" aria-hidden="true"></a></h2><ol>
<li><p>安装 gcc</p>
<figure class="highlight shell"><table><tbody><tr><td class="code"><pre><span class="line">yum -y install gcc-c++</span><br></pre></td></tr></tbody></table></figure>
</li>
<li><p>安装 Open JDK</p>
<figure class="highlight shell"><table><tbody><tr><td class="code"><pre><span class="line">yum  install  java-1.8.0-openjdk   java-1.8.0-openjdk-devel</span><br></pre></td></tr></tbody></table></figure></li>
<li><p>检测显卡驱动及型号</p>
<figure class="highlight shell"><table><tbody><tr><td class="code"><pre><span class="line">sudo rpm --import https://www.elrepo.org/RPM-GPG-KEY-elrepo.org</span><br><span class="line">sudo rpm -Uvh http://www.elrepo.org/elrepo-release-7.0-2.el7.elrepo.noarch.rpm</span><br><span class="line">sudo yum install nvidia-detect</span><br></pre></td></tr></tbody></table></figure>
<p><img src="https://i.loli.net/2018/11/07/5be2bf613a072.png" alt><br>这里显示的是 Tesla P4，410.66 NVIDIA driver</p>
</li>
<li><p>去<a href="https://www.nvidia.cn/Download/index.aspx?lang=cn">官网</a>下载对应的驱动</p>
<figure class="highlight shell"><table><tbody><tr><td class="code"><pre><span class="line">wget http://cn.download.nvidia.com/tesla/384.145/NVIDIA-Linux-x86_64-384.145.run</span><br></pre></td></tr></tbody></table></figure>
</li>
<li><p>屏蔽默认带有的 nouveau, 使用 su 命令切换到 root 用户下，然后修改 /etc/modprobe.d/blacklist.conf 文件，如果系统没有该文件需要新建一个。</p>
<figure class="highlight shell"><table><tbody><tr><td class="code"><pre><span class="line">su root</span><br><span class="line">echo -e "blacklist nouveau\noptions nouveau modeset=0" > /etc/modprobe.d/blacklist.conf</span><br></pre></td></tr></tbody></table></figure>
<p>然后查看一下文件内容：</p>
<figure class="highlight shell"><table><tbody><tr><td class="code"><pre><span class="line">cat /etc/modprobe.d/blacklist.conf</span><br></pre></td></tr></tbody></table></figure>
<p><img src="https://i.loli.net/2018/11/07/5be2bf612d424.png" alt></p>
</li>
<li><p>重建 initramfs image</p>
<figure class="highlight shell"><table><tbody><tr><td class="code"><pre><span class="line">mv /boot/initramfs-$(uname -r).img /boot/initramfs-$(uname -r).img.bak</span><br><span class="line">dracut /boot/initramfs-$(uname -r).img $(uname -r)</span><br></pre></td></tr></tbody></table></figure>
</li>
<li><p>修改运行级别为文本模式</p>
</li>
</ol>
<figure class="highlight shell"><table><tbody><tr><td class="code"><pre><span class="line">systemctl set-default multi-user.target</span><br></pre></td></tr></tbody></table></figure>
<ol>
<li><p>重新启动，使用 root 用户登陆，这里需要等待一下，约 1 分钟。</p>
<figure class="highlight shell"><table><tbody><tr><td class="code"><pre><span class="line">sudo iptables stop</span><br><span class="line">reboot</span><br></pre></td></tr></tbody></table></figure>
</li>
<li><p>查看 nouveau 是否已经禁用，如果没有显示相关的内容，说明已禁用。</p>
<figure class="highlight shell"><table><tbody><tr><td class="code"><pre><span class="line">ls mod | grep nouveau</span><br></pre></td></tr></tbody></table></figure></li>
<li>安装 kenel-devel<figure class="highlight shell"><table><tbody><tr><td class="code"><pre><span class="line">wget ftp://ftp.riken.jp/Linux/cern/centos/7/updates/x86_64/Packages/kernel-devel-3.10.0-693.17.1.el7.x86_64.rpm</span><br><span class="line">yum install kernel-devel-3.10.0-693.17.1.el7.x86_64.rpm </span><br></pre></td></tr></tbody></table></figure></li>
<li>安装 NVIDIA 驱动，一路 Enter 即可 <figure class="highlight shell"><table><tbody><tr><td class="code"><pre><span class="line">chmod +x NVIDIA-Linux-x86_64-384.145.run</span><br><span class="line">sh NVIDIA-Linux-x86_64-384.145.run</span><br></pre></td></tr></tbody></table></figure>
<h2 id="测试" class="heading-control"><a href="#测试" class="headerlink" title="测试"></a>测试<a class="heading-anchor" href="#测试" aria-hidden="true"></a></h2></li>
<li><p> nvidia-smi 测试和 TensorFlow 测试，显示 GPU 信息即可。报警告没有关系，是 TF 本身的警告，也可以通过 <code>pip install h5py==2.8.0rc1</code> 来解决。</p>
<figure class="highlight shell"><table><tbody><tr><td class="code"><pre><span class="line">nvidia-smi</span><br><span class="line">python3</span><br><span class="line">import tensorflow as tf</span><br><span class="line">sess = tf.Session()</span><br></pre></td></tr></tbody></table></figure>
<p><img src="https://i.loli.net/2018/11/07/5be2bf617cf6d.png" alt><br><img src="https://i.loli.net/2018/11/07/5be2bf619a6bc.png" alt></p>
</li>
<li><p>更换 PyPi 为国内源</p>
<figure class="highlight shell"><table><tbody><tr><td class="code"><pre><span class="line">pip install pqi</span><br><span class="line">pqi use tuna</span><br><span class="line">pqi show</span><br></pre></td></tr></tbody></table></figure>
</li>
<li><p>更换 conda 源为国内源</p>
<figure class="highlight shell"><table><tbody><tr><td class="code"><pre><span class="line">conda config --add channels https://mirrors.ustc.edu.cn/anaconda/pkgs/main/</span><br><span class="line">conda config --add channels https://mirrors.ustc.edu.cn/anaconda/pkgs/free/</span><br><span class="line">conda config --add channels https://mirrors.ustc.edu.cn/anaconda/cloud/conda-forge/</span><br><span class="line">conda config --add channels https://mirrors.ustc.edu.cn/anaconda/cloud/msys2/</span><br><span class="line">conda config --add channels https://mirrors.ustc.edu.cn/anaconda/cloud/bioconda/</span><br><span class="line">conda config --add channels https://mirrors.ustc.edu.cn/anaconda/cloud/menpo/</span><br><span class="line">conda config --set show_channel_urls yes</span><br></pre></td></tr></tbody></table></figure>
</li>
</ol>
</body></html>]]></content>
      <categories>
        <category>项目</category>
      </categories>
      <tags>
        <tag>GPU</tag>
      </tags>
  </entry>
  <entry>
    <title>基于文档的限定领域对话式问答系统设计说明</title>
    <url>/post/5681.html</url>
    <content><![CDATA[<html><head><link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script></head><body><h2 id="引言" class="heading-control"><a href="#引言" class="headerlink" title="引言"></a>引言<a class="heading-anchor" href="#引言" aria-hidden="true"></a></h2><h3 id="编写目的" class="heading-control"><a href="#编写目的" class="headerlink" title="编写目的"></a>编写目的<a class="heading-anchor" href="#编写目的" aria-hidden="true"></a></h3><p>为了从整体上描述基于文档的限定领域对话式问答系统要实现的功能，使用户能够对本系统有一个全面正确的认识，同时给程序开发者一个关于系统的使用，系统的功能模块，以及系统的各种技术解决方案一个详细的说明。</p>
<h3 id="背景" class="heading-control"><a href="#背景" class="headerlink" title="背景"></a>背景<a class="heading-anchor" href="#背景" aria-hidden="true"></a></h3><p>问答系统 (Question Answering System, QA) 是信息检索系统的一种高级形式，它能用准确、简洁的自然语言回答用户用自然语言提出的问题。其研究兴起的主要原因是人们对快速、准确地获取信息的需求。问答系统是目前人工智能和自然语言处理领域中一个倍受关注并具有广泛发展前景的研究方向。<br>不同的应用需要不同形式的问答系统，其所采用的语料和技术也不尽相同。从涉及的应用领域进行分类，可将问答系统分为限定域问答系统和开放域问答系统。<br>限定域问答系统是指系统所能处理的问题只限定于某个领域或者某个内容范围，比如只限定于医学、化学或者某企业的业务领域等。由于系统要解决的问题限定于某个领域或者范围，因此如果把系统所需要的全部领域知识都按照统一的方式表示成内部的结构化格式，则回答问题时就能比较容易地产生答案。<br><img src="/针对文档的问答系统设计说明/20191017082302115.png" alt><br>开放域问答系统不同于限定域问答系统，这类系统可回答的问题不限定于某个特定领域。在回答开放领域的问题时，需要一定的常识知识或者世界知识并具有语义词典。<br>按支持问答系统产生答案的文档库、知识库，以及实现的技术分类，可分为自然语言的数据库问答系统、对话式问答系统、阅读理解系统、基于常用问题集的问答系统、基于知识库的问答系统，以及基于大规模文档集的问答系统。<br>目前国内的大多数问答系统都是针对开放领域的对话式问答系统，在限定领域特别是基于文档的对话式问答系统很少，且功能均不够完善。本文设计了一种使用最先进的深度学习自然语言技术的基于文档的限定领域对话式问答系统设计说明。基本步骤包括处理文档数据、构造训练数据集、模型训练和优化、模型部署等，使用时输入用户需要查询的问题，系统可以自动匹配与问题最相关的段落，并由模型给出问题的答案。此外模型有完整的日志系统以及在线训练和离线训练模块。</p>
<h2 id="概要设计" class="heading-control"><a href="#概要设计" class="headerlink" title="概要设计"></a>概要设计<a class="heading-anchor" href="#概要设计" aria-hidden="true"></a></h2><h3 id="系统总体设计" class="heading-control"><a href="#系统总体设计" class="headerlink" title="系统总体设计"></a>系统总体设计<a class="heading-anchor" href="#系统总体设计" aria-hidden="true"></a></h3><p>系统的整体编程语言使用 Python 进行开发，使用的深度学习框架为 TensorFlow。基于机器阅读理解模型的问答流程如下图所示：<br><img src="/针对文档的问答系统设计说明/20191017084213733.png" alt></p>
<h3 id="系统模块功能" class="heading-control"><a href="#系统模块功能" class="headerlink" title="系统模块功能"></a>系统模块功能<a class="heading-anchor" href="#系统模块功能" aria-hidden="true"></a></h3><h4 id="文档数据识别和处理模块" class="heading-control"><a href="#文档数据识别和处理模块" class="headerlink" title="文档数据识别和处理模块"></a>文档数据识别和处理模块<a class="heading-anchor" href="#文档数据识别和处理模块" aria-hidden="true"></a></h4><p>常见的办公文档多数为 txt 文档，word 文档，excel 表格或者 pdf 文档。针对不同的文档需要设计不同的数据读取方式并进行读取后数据的存储。</p>
<h4 id="模型训练数据的构建模块" class="heading-control"><a href="#模型训练数据的构建模块" class="headerlink" title="模型训练数据的构建模块"></a>模型训练数据的构建模块<a class="heading-anchor" href="#模型训练数据的构建模块" aria-hidden="true"></a></h4><p>SQuAD 示例：<br>内容：阿波罗计划于 1962 至 1972 年间进行，期间得到了同期的双子座计划（1962 年 - 1966 年）的支持。双子座计划为阿波罗计划成功必需的一些太空旅行技术做了铺垫。阿波罗计划使用土星系列火箭作为运载工具来发射飞船。这些火箭还被用于阿波罗应用计划，包括 1973 年到 1974 年间支持了三个载人飞行任务的空间站 Skylab，以及 1975 年和前苏联合作的联合地球轨道任务阿波罗联盟测试计划。<br>问题：哪一个空间站于 1973 到 1974 年间承载了三项载人飞行任务？<br>答案：Skylab 空间站</p>
<h4 id="基于深度学习的阅读理解模型" class="heading-control"><a href="#基于深度学习的阅读理解模型" class="headerlink" title="基于深度学习的阅读理解模型"></a>基于深度学习的阅读理解模型<a class="heading-anchor" href="#基于深度学习的阅读理解模型" aria-hidden="true"></a></h4><p>YESNO 问题类型的处理方式<br>在第一阶段使用的是分类的方法，我后来考虑同样的问题可能在不同原文中可能是不同的回答，所以我就把 YESNO 作为原文进行训练。具体做法就是在原文后边拼接 YESNO 字符串，然后将之前的答案索引修改为 YESNO 对应的索引。这样在训练过程中就可以学到答案跟原文之间的关系，而不像之前只关注问题直接得出答案，实验证明这种方法确实能提高成绩，大概提高了 3 个百分点。2. 不能回答的问题的处理方式在 BERT 的源码中，对于不能回答的问题有一套处理方式，就是根据预测结果得出的 nbest 和答案为空的概率进行对比，如果答案为空的概率最高就把空作为答案。我使用与处理 YESNO 问题的方式去试了一下，就是将 NULL 拼接到原文后，将对应的答案索引改为 NULL 的索引，实验效果证明能提升， 但是只能提升百分之零点几，anyway，有点提升就用起来吧。</p>
<h4 id="模型导出和部署模块" class="heading-control"><a href="#模型导出和部署模块" class="headerlink" title="模型导出和部署模块"></a>模型导出和部署模块<a class="heading-anchor" href="#模型导出和部署模块" aria-hidden="true"></a></h4><h4 id="针对问题段落匹配的信息检索模块" class="heading-control"><a href="#针对问题段落匹配的信息检索模块" class="headerlink" title="针对问题段落匹配的信息检索模块"></a>针对问题段落匹配的信息检索模块<a class="heading-anchor" href="#针对问题段落匹配的信息检索模块" aria-hidden="true"></a></h4></body></html>]]></content>
  </entry>
  <entry>
    <title>长文本分类</title>
    <url>/post/35349.html</url>
    <content><![CDATA[<html><head><link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script></head><body><p>在 NLP 领域中，文本分类舆情分析等任务相较于文本抽取，和摘要等任务更容易获得大量标注数据。因此在文本分类领域中深度学习相较于传统方法更容易获得比较好的效果。<br>文本分类领域比较重要的的深度学习模型主要有 FastText，TextCNN，HAN，DPCNN。</p>
<h2 id="FastText" class="heading-control"><a href="#FastText" class="headerlink" title="FastText"></a>FastText<a class="heading-anchor" href="#FastText" aria-hidden="true"></a></h2><p>FastText 是 Facebook 于 2016 年开源的一个词向量计算和文本分类工具，在学术上并没有太大创新。但是它的优点也非常明显，在文本分类任务中，fastText（浅层网络）往往能取得和深度网络相媲美的精度，却在训练时间上比深度网络快许多数量级。在标准的多核 CPU 上， 能够训练 10 亿词级别语料库的词向量在 10 分钟之内，能够分类有着 30 万多类别的 50 多万句子在 1 分钟之内。</p>
<h2 id="Reference" class="heading-control"><a href="#Reference" class="headerlink" title="Reference"></a>Reference<a class="heading-anchor" href="#Reference" aria-hidden="true"></a></h2><ul>
<li><a href="https://zhuanlan.zhihu.com/p/46331902">如何用深度学习做好长文本分类与法律文书智能化处理</a></li>
<li><a href="https://www.kaggle.com/michaelsnell/conv1d-dpcnn-in-keras">Conv1D DPCNN in Keras 代码</a></li>
</ul>
</body></html>]]></content>
      <categories>
        <category>项目</category>
      </categories>
      <tags>
        <tag>NLP</tag>
        <tag>分类</tag>
      </tags>
  </entry>
  <entry>
    <title>最大似然估计和最大后验估计</title>
    <url>/post/46328.html</url>
    <content><![CDATA[<html><head><link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script></head><body><p><img src="https://i.loli.net/2019/07/22/5d357cfaebdc553807.png" alt></p>
<p>图片来自<a href="https://www.xkcd.com/1132/">网站</a></p>
<ul>
<li>频率学派 - Frequentist - Maximum Likelihood Estimation (MLE，最大似然估计)</li>
<li> 贝叶斯学派 - Bayesian - Maximum A Posteriori (MAP，最大后验估计)</li>
</ul>
<a id="more"></a>
<h2 id="问题引入" class="heading-control"><a href="#问题引入" class="headerlink" title="问题引入"></a>问题引入<a class="heading-anchor" href="#问题引入" aria-hidden="true"></a></h2><p>已知一组数据集 $D={x_1,x_2,…,x_n}$ 是独立地从概率分布 $P (x)$ 上采样生成的，且 $P (x)$ 具有确定的形式（如高斯分布，二项分布等）但参数 $\theta$ 未知。</p>
<p><strong>问题：如何根据数据集 $D$ 估计参数 $\theta$ ?</strong></p>
<p>为了解决上述问题，统计学界存在两种不同的解决方案：</p>
<ul>
<li><strong>频率学派</strong>：<strong>参数 $\theta$ 是一个客观存在的固定值</strong>，其可以通过找到使数据集 $D$ 出现可能性最大的值，对参数 $\theta$ 进行估计，此便是极大似然估计的核心思想。</li>
<li><strong>贝叶斯学派</strong>：<strong>参数 $\theta$ 是一个随机变量，服从一个概率分布</strong>，其首先根据主观的经验假定 $\theta$ 的概率分布为 $P (\theta)$（先验分布，往往并不准确），然后根据观察到的新信息（数据集 $D$ ）对其进行修正，此时 $\theta$ 的概率分布为 $p (\theta|D)$（后验分布）。</li>
</ul>
<h2 id="最大似然估计" class="heading-control"><a href="#最大似然估计" class="headerlink" title="最大似然估计"></a>最大似然估计<a class="heading-anchor" href="#最大似然估计" aria-hidden="true"></a></h2><p>Maximum Likelihood Estimation, MLE 是频率学派常用的估计方法。<br>核心思想：找到使数据集 $D$ 出现可能性最大的值，对参数 $D$ 进行估计，即:</p>
<script type="math/tex; mode=display">
\begin{aligned} \hat{\theta}_{\mathrm{MLE}} &=\underset{\arg \max } P(X ; \theta) \\ &=\arg \max P\left(x_{1} ; \theta\right) P\left(x_{2} ; \theta\right) \cdots P\left(x_{n} ; \theta\right) \\ &=\arg \max \log \prod_{i=1}^{n} P\left(x_{i} ; \theta\right) \\ &=\arg \max \sum_{i=1}^{n} \log P\left(x_{i} ; \theta\right) \\ &=\arg \min -\sum_{i=1}^{n} \log P\left(x_{i} ; \theta\right) \end{aligned}</script><p>最后这一行所优化的函数被称为 Negative Log Likelihood。深度学习做分类任务时所用的 cross entropy loss，其本质也是 MLE。</p>
<h2 id="最大后验估计" class="heading-control"><a href="#最大后验估计" class="headerlink" title="最大后验估计"></a>最大后验估计<a class="heading-anchor" href="#最大后验估计" aria-hidden="true"></a></h2><p>Maximum A Posteriori, MAP 是贝叶斯学派常用的估计方法。<br>原则上，贝叶斯学派对 $\theta$ 的估计应该就是 $\theta$ 的后验分布 $p (\theta|D)$ ，但是大多数时候后验分布的计算较为棘手，因此此时出现一种折衷解法：找到使后验概率最大的值，对参数 $\theta$ 进行估计，即:</p>
<script type="math/tex; mode=display">
\begin{aligned} \hat{\theta}_{\mathrm{MAP}} &=\arg \max P(\theta | X) \\ &=\arg \min -\log P(\theta | X) \\ &=\arg \min -\log P(X | \theta)-\log P(\theta)+\log P(X) \\ &=\arg \min -\log P(X | \theta)-\log P(\theta) \end{aligned}</script><p>其中，第二行到第三行使用了贝叶斯定理，第三行到第四行 $P (X)$ 可以丢掉因为与 $\theta$ 无关。</p>
<p>注意到 $-\log P (X | \theta)$ 就是 Negative Log Likelihood，所以 MLE 和 MAP 在优化时的不同就是在于先验项<br>$-\log P (\theta)$。假定先验是一个高斯分布，</p>
<script type="math/tex; mode=display">
P(\theta)=\text { constant } \times e^{-\frac{\theta^{2}}{2 \sigma^{2}}}</script><p>那么:</p>
<script type="math/tex; mode=display">
-\log P(\theta)=\text { constant }+\frac{\theta^{2}}{2 \sigma^{2}}</script><p>此时在 MAP 中使用一个高斯分布的先验等价于在 MLE 中采用 L2 的 regularizaton。<br>如果在 MAP 中使用一个拉普拉斯分布的先验，即：</p>
<script type="math/tex; mode=display">
P\left(\theta\right)=\frac{1}{\sqrt{2 a}} e^{\frac{-\left|\theta\right|}{a}}</script><p>则有：</p>
<script type="math/tex; mode=display">
\log P(\theta)=\log \prod_{j} \frac{1}{\sqrt{2 a}} e^{\frac{-|\theta|}{a}}=-\frac{1}{a} \sum_{j}\left|\theta\right|+C^{\prime}</script><p>可以看到，在拉普拉斯分布下的效果等价于在代价函数中增加 L1 正则项。</p>
<h2 id="说明" class="heading-control"><a href="#说明" class="headerlink" title="说明"></a>说明<a class="heading-anchor" href="#说明" aria-hidden="true"></a></h2><ul>
<li>随着数据量的增加，参数分布会越来越向数据靠拢，先验的影响力会越来越小</li>
<li>如果先验是 uniform distribution，则贝叶斯方法等价于频率方法。因为直观上来讲，先验是 uniform distribution 本质上表示对事物没有任何预判</li>
</ul>
<h2 id="总结" class="heading-control"><a href="#总结" class="headerlink" title="总结"></a>总结<a class="heading-anchor" href="#总结" aria-hidden="true"></a></h2><p>至此，在深入理解了频率学派和贝叶斯学派之后，终于把 L1 和 L2 正则化技术，MLP 和 MAP，以及生成式判别式模型联系起来了。</p>
<ul>
<li>所谓 MAP 就是在 MLP 的基础上加了一项先验分布。（当然背后的思想不一样）</li>
<li>如果先验分布是均匀分布，两者一致</li>
<li>如果先验分布是高斯分布，那么等价于增加了 L2 正则</li>
<li>如果先验是拉普拉斯分布，那么等价与增加了 L1 正则</li>
<li>频率思想下指导的判别式模型，贝叶斯思想指导下的是生成模型。</li>
<li>频率派衍生出来的是统计机器学习模型，最终转换为一个优化问题。贝叶斯派衍生出来的是概率图模型，最终转换为一个积分问题。</li>
</ul>
</body></html>]]></content>
      <tags>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title>Dureader 数据集</title>
    <url>/post/51975.html</url>
    <content><![CDATA[<html><head><link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script></head><body><h2 id="Dureader数据集" class="heading-control"><a href="#Dureader数据集" class="headerlink" title="Dureader数据集"></a>Dureader 数据集<a class="heading-anchor" href="#Dureader数据集" aria-hidden="true"></a></h2><h3 id="数据示例" class="heading-control"><a href="#数据示例" class="headerlink" title="数据示例"></a>数据示例<a class="heading-anchor" href="#数据示例" aria-hidden="true"></a></h3><figure class="highlight json"><table><tbody><tr><td class="code"><pre><span class="line">{<span class="attr">"documents"</span>: [{</span><br><span class="line">		<span class="attr">"is_selected"</span>: <span class="literal">true</span>,</span><br><span class="line">		<span class="attr">"title"</span>: <span class="string">"iOS里,把一个页面链接分享给好友,好友在微信里打开这个链接,怎么跳"</span>,</span><br><span class="line">		<span class="attr">"most_related_para"</span>: <span class="number">0</span>,</span><br><span class="line">		<span class="attr">"segmented_title"</span>: [<span class="string">"iOS"</span>, <span class="string">"里"</span>, <span class="string">","</span>, <span class="string">"把"</span>, <span class="string">"一"</span>, <span class="string">"个"</span>, <span class="string">"页面"</span>, <span class="string">"链接"</span>, <span class="string">"分享"</span>, <span class="string">"给"</span>, <span class="string">"好友"</span>, <span class="string">","</span>, <span class="string">"好友"</span>, <span class="string">"在"</span>, <span class="string">"微信"</span>, <span class="string">"里"</span>, <span class="string">"打开"</span>, <span class="string">"这个"</span>, <span class="string">"链接"</span>, <span class="string">","</span>, <span class="string">"怎么"</span>, <span class="string">"跳"</span>],</span><br><span class="line">		<span class="attr">"segmented_paragraphs"</span>: [</span><br><span class="line">			[<span class="string">"iOS"</span>, <span class="string">"里"</span>, <span class="string">","</span>, <span class="string">"把"</span>, <span class="string">"一"</span>, <span class="string">"个"</span>, <span class="string">"页面"</span>, <span class="string">"链接"</span>, <span class="string">"分享"</span>, <span class="string">"给"</span>, <span class="string">"好友"</span>, <span class="string">","</span>, <span class="string">"好友"</span>, <span class="string">"在"</span>, <span class="string">"微信"</span>, <span class="string">"里"</span>, <span class="string">"打开"</span>, <span class="string">"这个"</span>, <span class="string">"链接"</span>, <span class="string">","</span>, <span class="string">"怎么"</span>, <span class="string">"跳"</span>, <span class="string">"<splitter>"</span>, <span class="string">"iOS"</span>, <span class="string">"里"</span>, <span class="string">","</span>, <span class="string">"把"</span>, <span class="string">"一"</span>, <span class="string">"个"</span>, <span class="string">"页面"</span>, <span class="string">"链接"</span>, <span class="string">"分享"</span>, <span class="string">"给"</span>, <span class="string">"微信"</span>, <span class="string">"好友"</span>, <span class="string">"("</span>, <span class="string">"会话"</span>, <span class="string">")"</span>, <span class="string">","</span>, <span class="string">"好友"</span>, <span class="string">"在"</span>, <span class="string">"微信"</span>, <span class="string">"里"</span>, <span class="string">"打开"</span>, <span class="string">"这个"</span>, <span class="string">"链接"</span>, <span class="string">","</span>, <span class="string">"也"</span>, <span class="string">"就是"</span>, <span class="string">"打开"</span>, <span class="string">"了"</span>, <span class="string">"一"</span>, <span class="string">"个"</span>, <span class="string">"网页"</span>, <span class="string">","</span>, <span class="string">"点击"</span>, <span class="string">"网页"</span>, <span class="string">"里"</span>, <span class="string">"的"</span>, <span class="string">"某"</span>, <span class="string">"个"</span>, <span class="string">"地方"</span>, <span class="string">"后"</span>, <span class="string">"("</span>, <span class="string">"比如"</span>, <span class="string">"网页"</span>, <span class="string">"中"</span>, <span class="string">"“"</span>, <span class="string">"打开"</span>, <span class="string">"xx"</span>, <span class="string">"应用程序"</span>, <span class="string">"”"</span>, <span class="string">"的"</span>, <span class="string">"按钮"</span>, <span class="string">")"</span>, <span class="string">","</span>, <span class="string">"代码"</span>, <span class="string">"里"</span>, <span class="string">"怎么"</span>, <span class="string">"设置"</span>, <span class="string">"可以"</span>, <span class="string">"跳"</span>, <span class="string">"回到"</span>, <span class="string">"第三方"</span>, <span class="string">"app"</span>, <span class="string">"?"</span>, <span class="string">"知乎"</span>, <span class="string">"的"</span>, <span class="string">"ios"</span>, <span class="string">"客户端"</span>, <span class="string">"就"</span>, <span class="string">"有"</span>, <span class="string">"这种"</span>, <span class="string">"功能"</span>, <span class="string">","</span>, <span class="string">"在"</span>, <span class="string">"微信"</span>, <span class="string">"里"</span>, <span class="string">"分享"</span>, <span class="string">"链接"</span>, <span class="string">"后"</span>, <span class="string">","</span>, <span class="string">"点"</span>, <span class="string">"开"</span>, <span class="string">"链接"</span>, <span class="string">","</span>, <span class="string">"再"</span>, <span class="string">"点"</span>, <span class="string">"网页"</span>, <span class="string">"中"</span>, <span class="string">"的"</span>, <span class="string">"某处"</span>, <span class="string">","</span>, <span class="string">"就"</span>, <span class="string">"可以"</span>, <span class="string">"打开"</span>, <span class="string">"知乎"</span>, <span class="string">"客户端"</span>, <span class="string">"显示全部"</span>, <span class="string">"<splitter>"</span>, <span class="string">"微信"</span>, <span class="string">"中"</span>, <span class="string">"不能"</span>, <span class="string">"用"</span>, <span class="string">"自定义"</span>, <span class="string">"url"</span>, <span class="string">"的"</span>, <span class="string">"方式"</span>, <span class="string">","</span>, <span class="string">"微信"</span>, <span class="string">"提供"</span>, <span class="string">"了"</span>, <span class="string">"打开"</span>, <span class="string">"第三方"</span>, <span class="string">"应用"</span>, <span class="string">"的"</span>, <span class="string">"接口"</span>, <span class="string">":"</span>, <span class="string">"launch"</span>, <span class="string">"3rd"</span>, <span class="string">"App"</span>, <span class="string">"<splitter>"</span>, <span class="string">"谢"</span>, <span class="string">"。"</span>, <span class="string">"一般"</span>, <span class="string">"用"</span>, <span class="string">"自带"</span>, <span class="string">"浏览器"</span>, <span class="string">"可以"</span>, <span class="string">"调用"</span>, <span class="string">"起"</span>, <span class="string">"app"</span>, <span class="string">"没问题"</span>, <span class="string">"。"</span>, <span class="string">"微信"</span>, <span class="string">"里面"</span>, <span class="string">"能"</span>, <span class="string">"调出"</span>, <span class="string">"app"</span>, <span class="string">"的"</span>, <span class="string">","</span>, <span class="string">"是"</span>, <span class="string">"和"</span>, <span class="string">"腾讯"</span>, <span class="string">"有"</span>, <span class="string">"合作"</span>, <span class="string">"的"</span>, <span class="string">"应用"</span>, <span class="string">","</span>, <span class="string">"其他"</span>, <span class="string">"会"</span>, <span class="string">"被"</span>, <span class="string">"过滤"</span>, <span class="string">"掉"</span>, <span class="string">"。"</span>, <span class="string">"<splitter>"</span>, <span class="string">"有"</span>, <span class="string">"一"</span>, <span class="string">"个"</span>, <span class="string">"公司"</span>, <span class="string">"的"</span>, <span class="string">"产品"</span>, <span class="string">","</span>, <span class="string">"叫"</span>, <span class="string">"魔"</span>, <span class="string">"窗"</span>, <span class="string">","</span>, <span class="string">"免费"</span>, <span class="string">"可以"</span>, <span class="string">"接入"</span>, <span class="string">"的"</span>, <span class="string">"<splitter>"</span>, <span class="string">"分享"</span>, <span class="string">"出去"</span>, <span class="string">"的"</span>, <span class="string">"是"</span>, <span class="string">"一"</span>, <span class="string">"个"</span>, <span class="string">"网页"</span>, <span class="string">","</span>, <span class="string">"前端"</span>, <span class="string">"人员"</span>, <span class="string">"与"</span>, <span class="string">"app"</span>, <span class="string">"客户端"</span>, <span class="string">"人员"</span>, <span class="string">"约定"</span>, <span class="string">"好"</span>, <span class="string">"一"</span>, <span class="string">"个"</span>, <span class="string">"头部"</span>, <span class="string">"协议"</span>, <span class="string">"。"</span>, <span class="string">"当"</span>, <span class="string">"用户"</span>, <span class="string">"在"</span>, <span class="string">"网页"</span>, <span class="string">"的"</span>, <span class="string">"点击"</span>, <span class="string">"某"</span>, <span class="string">"个"</span>, <span class="string">"按钮"</span>, <span class="string">","</span>, <span class="string">"调用"</span>, <span class="string">"注册"</span>, <span class="string">"的"</span>, <span class="string">"协议"</span>, <span class="string">"头"</span>, <span class="string">","</span>, <span class="string">"就"</span>, <span class="string">"可以"</span>, <span class="string">"呼"</span>, <span class="string">"起"</span>, <span class="string">"安装"</span>, <span class="string">"的"</span>, <span class="string">"app"</span>, <span class="string">"。"</span>, <span class="string">"比如"</span>, <span class="string">"知乎"</span>, <span class="string">"app"</span>, <span class="string">"可能"</span>, <span class="string">"注册"</span>, <span class="string">"了"</span>, <span class="string">"zhifu"</span>, <span class="string">":"</span>, <span class="string">"/"</span>, <span class="string">"/"</span>, <span class="string">"xxx"</span>, <span class="string">"zhifu"</span>, <span class="string">":"</span>, <span class="string">"/"</span>, <span class="string">"/"</span>, <span class="string">"就是"</span>, <span class="string">"约定"</span>, <span class="string">"好"</span>, <span class="string">"的"</span>, <span class="string">"xxx"</span>, <span class="string">"是"</span>, <span class="string">"指"</span>, <span class="string">"参数"</span>, <span class="string">"可以"</span>, <span class="string">"任意"</span>, <span class="string">"带"</span>, <span class="string">"这样"</span>, <span class="string">"访问"</span>, <span class="string">"后"</span>, <span class="string">"就"</span>, <span class="string">"可以"</span>, <span class="string">"呼"</span>, <span class="string">"起"</span>, <span class="string">"app"</span>, <span class="string">"了"</span>, <span class="string">"。"</span>, <span class="string">"<splitter>"</span>, <span class="string">"目前"</span>, <span class="string">"已经"</span>, <span class="string">"解决"</span>, <span class="string">"直接"</span>, <span class="string">"从"</span>, <span class="string">"微信"</span>, <span class="string">"打开"</span>, <span class="string">"的"</span>, <span class="string">"链接"</span>, <span class="string">"可以直接"</span>, <span class="string">"点击"</span>, <span class="string">"下载"</span>, <span class="string">"APP"</span>, <span class="string">"的"</span>, <span class="string">"跳转"</span>, <span class="string">","</span>, <span class="string">"无需"</span>, <span class="string">"再"</span>, <span class="string">"通过"</span>, <span class="string">"另外"</span>, <span class="string">"浏览"</span>, <span class="string">"中"</span>, <span class="string">"打开"</span>, <span class="string">"才能"</span>, <span class="string">"点击"</span>, <span class="string">"下载"</span>, <span class="string">","</span>, <span class="string">"在"</span>, <span class="string">"微信"</span>, <span class="string">"中"</span>, <span class="string">"即可"</span>, <span class="string">"直接"</span>, <span class="string">"点击"</span>, <span class="string">"下载"</span>, <span class="string">","</span>, <span class="string">"需要"</span>, <span class="string">"的"</span>, <span class="string">"联系"</span>, <span class="string">"QQ"</span>, <span class="string">"77408026"</span>, <span class="string">"<splitter>"</span>, <span class="string">"你可以"</span>, <span class="string">"去"</span>, <span class="string">"看看"</span>, <span class="string">"openinstall"</span>, <span class="string">","</span>, <span class="string">"它"</span>, <span class="string">"可以"</span>, <span class="string">"实现"</span>, <span class="string">"让"</span>, <span class="string">"用户"</span>, <span class="string">"分享"</span>, <span class="string">"链接"</span>, <span class="string">"让"</span>, <span class="string">"别"</span>, <span class="string">"的"</span>, <span class="string">"用户"</span>, <span class="string">"可以打开"</span>, <span class="string">"下载"</span>, <span class="string">"或者"</span>, <span class="string">"跳转"</span>, <span class="string">"APP"</span>, <span class="string">"。"</span>, <span class="string">"而且"</span>, <span class="string">"打开"</span>, <span class="string">"或者"</span>, <span class="string">"下载"</span>, <span class="string">"后"</span>, <span class="string">"还能"</span>, <span class="string">"获取"</span>, <span class="string">"到"</span>, <span class="string">"自己"</span>, <span class="string">"想"</span>, <span class="string">"传"</span>, <span class="string">"过去"</span>, <span class="string">"的"</span>, <span class="string">"参数"</span>, <span class="string">"。"</span>, <span class="string">"<splitter>"</span>, <span class="string">"方法"</span>, <span class="string">"一"</span>, <span class="string">":"</span>, <span class="string">"微信"</span>, <span class="string">"API"</span>, <span class="string">"-"</span>, <span class="string">"-"</span>, <span class="string">"WXApp"</span>, <span class="string">"Extend"</span>, <span class="string">"Object"</span>, <span class="string">"."</span>, <span class="string">"("</span>, <span class="string">"参考"</span>, <span class="string">"app"</span>, <span class="string">"-"</span>, <span class="string">"微博"</span>, <span class="string">")"</span>, <span class="string">"方法"</span>, <span class="string">"二"</span>, <span class="string">":"</span>, <span class="string">"iOS"</span>, <span class="string">"9"</span>, <span class="string">"Universal"</span>, <span class="string">"Link"</span>, <span class="string">"."</span>, <span class="string">"("</span>, <span class="string">"参考"</span>, <span class="string">"app"</span>, <span class="string">"-"</span>, <span class="string">"蘑菇街"</span>, <span class="string">")"</span>, <span class="string">"<splitter>"</span>, <span class="string">"目前"</span>, <span class="string">"要"</span>, <span class="string">"先"</span>, <span class="string">"用"</span>, <span class="string">"浏览器"</span>, <span class="string">"打开"</span>, <span class="string">","</span>, <span class="string">"然后"</span>, <span class="string">"才能"</span>, <span class="string">"跳"</span>, <span class="string">"。"</span>, <span class="string">"有"</span>, <span class="string">"解决办法"</span>, <span class="string">"么"</span>, <span class="string">"<splitter>"</span>, <span class="string">"下载"</span>, <span class="string">"知乎"</span>, <span class="string">"客户端"</span>, <span class="string">"与"</span>, <span class="string">"世界"</span>, <span class="string">"分享"</span>, <span class="string">"知识"</span>, <span class="string">"、"</span>, <span class="string">"经验"</span>, <span class="string">"和"</span>, <span class="string">"见解"</span>, <span class="string">"<splitter>"</span>, <span class="string">"相关"</span>, <span class="string">"Live"</span>, <span class="string">"推荐"</span>]</span><br><span class="line">		],</span><br><span class="line">		<span class="attr">"paragraphs"</span>: [<span class="string">"iOS里,把一个页面链接分享给好友,好友在微信里打开这个链接,怎么跳<splitter>iOS里,把一个页面链接分享给微信好友(会话),好友在微信里打开这个链接,也就是打开了一个网页,点击网页里的某个地方后(比如网页中“打开xx应用程序”的按钮),代码里怎么设置可以跳回到第三方app?知乎的ios客户端就有这种功能,在微信里分享链接后,点开链接,再点网页中的某处,就可以打开知乎客户端显示全部<splitter>微信中不能用自定义url的方式,微信提供了打开第三方应用的接口:launch3rdApp<splitter>谢。一般用自带浏览器可以调用起app没问题。微信里面能调出app的,是和腾讯有合作的应用,其他会被过滤掉。<splitter>有一个公司的产品,叫魔窗,免费可以接入的<splitter>分享出去的是一个网页,前端人员与app客户端人员约定好一个头部协议。当用户在网页的点击某个按钮,调用注册的协议头,就可以呼起安装的app。比如知乎app可能注册了zhifu://xxxzhifu://就是约定好的xxx是指参数可以任意带这样访问后就可以呼起app了。<splitter>目前已经解决直接从微信打开的链接可以直接点击下载APP的跳转,无需再通过另外浏览中打开才能点击下载,在微信中即可直接点击下载,需要的联系QQ77408026<splitter>你可以去看看openinstall,它可以实现让用户分享链接让别的用户可以打开下载或者跳转APP。而且打开或者下载后还能获取到自己想传过去的参数。<splitter>方法一:微信API--WXAppExtendObject.(参考app-微博)方法二:iOS9UniversalLink.(参考app-蘑菇街)<splitter>目前要先用浏览器打开,然后才能跳。有解决办法么<splitter>下载知乎客户端与世界分享知识、经验和见解<splitter>相关Live推荐"</span>],</span><br><span class="line">		<span class="attr">"segmented_paragraphs_scores"</span>: [<span class="number">1.0</span>],</span><br><span class="line">		<span class="attr">"paragraphs_length"</span>: [<span class="number">415</span>]</span><br><span class="line">	}, {</span><br><span class="line">		<span class="attr">"is_selected"</span>: <span class="literal">true</span>,</span><br><span class="line">		<span class="attr">"title"</span>: <span class="string">"怎么可以在微信里面打开APP下载链接地址_百度经验"</span>,</span><br><span class="line">		<span class="attr">"most_related_para"</span>: <span class="number">0</span>,</span><br><span class="line">		<span class="attr">"segmented_title"</span>: [<span class="string">"怎么"</span>, <span class="string">"可以"</span>, <span class="string">"在"</span>, <span class="string">"微信"</span>, <span class="string">"里面"</span>, <span class="string">"打开"</span>, <span class="string">"APP"</span>, <span class="string">"下载"</span>, <span class="string">"链接地址"</span>, <span class="string">"_"</span>, <span class="string">"百度"</span>, <span class="string">"经验"</span>],</span><br><span class="line">		<span class="attr">"segmented_paragraphs"</span>: [</span><br><span class="line">			[<span class="string">"怎么"</span>, <span class="string">"可以"</span>, <span class="string">"在"</span>, <span class="string">"微信"</span>, <span class="string">"里面"</span>, <span class="string">"打开"</span>, <span class="string">"APP"</span>, <span class="string">"下载"</span>, <span class="string">"链接地址"</span>, <span class="string">"_"</span>, <span class="string">"百度"</span>, <span class="string">"经验"</span>, <span class="string">"<splitter>"</span>, <span class="string">"百度"</span>, <span class="string">"经验"</span>, <span class="string">":"</span>, <span class="string">"jingyan"</span>, <span class="string">"."</span>, <span class="string">"baidu"</span>, <span class="string">"."</span>, <span class="string">"com"</span>, <span class="string">"<splitter>"</span>, <span class="string">"我们"</span>, <span class="string">"都"</span>, <span class="string">"知道"</span>, <span class="string">"手游"</span>, <span class="string">"、"</span>, <span class="string">"APP"</span>, <span class="string">"想"</span>, <span class="string">"在"</span>, <span class="string">"微信"</span>, <span class="string">"分享"</span>, <span class="string">"时"</span>, <span class="string">","</span>, <span class="string">"下载"</span>, <span class="string">"的"</span>, <span class="string">"链接"</span>, <span class="string">"会"</span>, <span class="string">"被"</span>, <span class="string">"微信"</span>, <span class="string">"屏蔽"</span>, <span class="string">","</span>, <span class="string">"不能"</span>, <span class="string">"直接"</span>, <span class="string">"点击"</span>, <span class="string">","</span>, <span class="string">"那"</span>, <span class="string">"怎样"</span>, <span class="string">"才能"</span>, <span class="string">"得到"</span>, <span class="string">"微信"</span>, <span class="string">"认可"</span>, <span class="string">"的"</span>, <span class="string">"下载"</span>, <span class="string">"页面"</span>, <span class="string">"呢"</span>, <span class="string">","</span>, <span class="string">"这里"</span>, <span class="string">"就"</span>, <span class="string">"需要"</span>, <span class="string">"用"</span>, <span class="string">"到"</span>, <span class="string">"腾讯"</span>, <span class="string">"的"</span>, <span class="string">"开放"</span>, <span class="string">"平台"</span>, <span class="string">","</span>, <span class="string">"而"</span>, <span class="string">"你"</span>, <span class="string">"的"</span>, <span class="string">"应用"</span>, <span class="string">"也"</span>, <span class="string">"需要提交"</span>, <span class="string">"到"</span>, <span class="string">"这个平台"</span>, <span class="string">"。"</span>, <span class="string">"在"</span>, <span class="string">"这里"</span>, <span class="string">"可以"</span>, <span class="string">"得到"</span>, <span class="string">"微信"</span>, <span class="string">"认可"</span>, <span class="string">"的"</span>, <span class="string">"链接地址"</span>, <span class="string">"。"</span>, <span class="string">"接下来"</span>, <span class="string">"介绍"</span>, <span class="string">"相关"</span>, <span class="string">"方法"</span>, <span class="string">"。"</span>, <span class="string">"<splitter>"</span>, <span class="string">"1"</span>, <span class="string">"首先"</span>, <span class="string">"打开"</span>, <span class="string">"腾讯"</span>, <span class="string">"开放"</span>, <span class="string">"平台"</span>, <span class="string">","</span>, <span class="string">"注册"</span>, <span class="string">"开放"</span>, <span class="string">"平台"</span>, <span class="string">"的"</span>, <span class="string">"一"</span>, <span class="string">"个"</span>, <span class="string">"账号"</span>, <span class="string">","</span>, <span class="string">"如"</span>, <span class="string">"下"</span>, <span class="string">"图"</span>, <span class="string">"所示"</span>, <span class="string">"。"</span>, <span class="string">"步骤"</span>, <span class="string">"阅读"</span>, <span class="string">"2"</span>, <span class="string">"登录"</span>, <span class="string">"后"</span>, <span class="string">"在"</span>, <span class="string">"”"</span>, <span class="string">"管理"</span>, <span class="string">"中心"</span>, <span class="string">"“"</span>, <span class="string">"中"</span>, <span class="string">"创建"</span>, <span class="string">"应用"</span>, <span class="string">","</span>, <span class="string">"如"</span>, <span class="string">"下"</span>, <span class="string">"图"</span>, <span class="string">"所示"</span>, <span class="string">"点击"</span>, <span class="string">"红线"</span>, <span class="string">"框"</span>, <span class="string">"选"</span>, <span class="string">"按钮"</span>, <span class="string">"。"</span>, <span class="string">"步骤"</span>, <span class="string">"阅读"</span>, <span class="string">"3"</span>, <span class="string">"选择"</span>, <span class="string">"创建"</span>, <span class="string">"应用"</span>, <span class="string">"的"</span>, <span class="string">"类型"</span>, <span class="string">"如"</span>, <span class="string">"下"</span>, <span class="string">"图"</span>, <span class="string">"所示"</span>, <span class="string">","</span>, <span class="string">"然后"</span>, <span class="string">"按钮"</span>, <span class="string">"提示"</span>, <span class="string">"填写"</span>, <span class="string">"应用"</span>, <span class="string">"的"</span>, <span class="string">"相关"</span>, <span class="string">"信息"</span>, <span class="string">","</span>, <span class="string">"提交"</span>, <span class="string">"进入"</span>, <span class="string">"审核"</span>, <span class="string">"。"</span>, <span class="string">"步骤"</span>, <span class="string">"阅读"</span>, <span class="string">"步骤"</span>, <span class="string">"阅读"</span>, <span class="string">"4"</span>, <span class="string">"应用"</span>, <span class="string">"审核"</span>, <span class="string">"通过"</span>, <span class="string">"后"</span>, <span class="string">"会"</span>, <span class="string">"在"</span>, <span class="string">"管理"</span>, <span class="string">"中心"</span>, <span class="string">"中"</span>, <span class="string">"显示"</span>, <span class="string">"”"</span>, <span class="string">"已"</span>, <span class="string">"上线"</span>, <span class="string">"“"</span>, <span class="string">","</span>, <span class="string">"然后"</span>, <span class="string">"点击"</span>, <span class="string">"应用"</span>, <span class="string">"的"</span>, <span class="string">"图标"</span>, <span class="string">"。"</span>, <span class="string">"步骤"</span>, <span class="string">"阅读"</span>, <span class="string">"5"</span>, <span class="string">"在"</span>, <span class="string">"应用"</span>, <span class="string">"详情"</span>, <span class="string">"中"</span>, <span class="string">"找到"</span>, <span class="string">"运营"</span>, <span class="string">"服务"</span>, <span class="string">"中"</span>, <span class="string">"的"</span>, <span class="string">"”"</span>, <span class="string">"微"</span>, <span class="string">"下载"</span>, <span class="string">"“"</span>, <span class="string">","</span>, <span class="string">"点击进入"</span>, <span class="string">"详情"</span>, <span class="string">"页面"</span>, <span class="string">"。"</span>, <span class="string">"步骤"</span>, <span class="string">"阅读"</span>, <span class="string">"6"</span>, <span class="string">"在"</span>, <span class="string">"详情"</span>, <span class="string">"页面"</span>, <span class="string">"中"</span>, <span class="string">"就"</span>, <span class="string">"可以"</span>, <span class="string">"看到"</span>, <span class="string">"系统"</span>, <span class="string">"生成"</span>, <span class="string">"的"</span>, <span class="string">"推广"</span>, <span class="string">"链接地址"</span>, <span class="string">"了"</span>, <span class="string">","</span>, <span class="string">"复制"</span>, <span class="string">"此"</span>, <span class="string">"地址"</span>, <span class="string">"就"</span>, <span class="string">"可以"</span>, <span class="string">"微信"</span>, <span class="string">"中"</span>, <span class="string">"转发"</span>, <span class="string">"了"</span>, <span class="string">"。"</span>, <span class="string">"步骤"</span>, <span class="string">"阅读"</span>, <span class="string">"END"</span>, <span class="string">"<splitter>"</span>, <span class="string">"经验"</span>, <span class="string">"内容"</span>, <span class="string">"仅供参考"</span>, <span class="string">","</span>, <span class="string">"如果"</span>, <span class="string">"您"</span>, <span class="string">"需"</span>, <span class="string">"解决"</span>, <span class="string">"具体"</span>, <span class="string">"问题"</span>, <span class="string">"("</span>, <span class="string">"尤其"</span>, <span class="string">"法律"</span>, <span class="string">"、"</span>, <span class="string">"医学"</span>, <span class="string">"等"</span>, <span class="string">"领域"</span>, <span class="string">")"</span>, <span class="string">","</span>, <span class="string">"建议"</span>, <span class="string">"您"</span>, <span class="string">"详细"</span>, <span class="string">"咨询"</span>, <span class="string">"相关"</span>, <span class="string">"领域"</span>, <span class="string">"专业人士"</span>, <span class="string">"。"</span>]</span><br><span class="line">		],</span><br><span class="line">		<span class="attr">"paragraphs"</span>: [<span class="string">"怎么可以在微信里面打开APP下载链接地址_百度经验<splitter>百度经验:jingyan.baidu.com<splitter>我们都知道手游、APP想在微信分享时,下载的链接会被微信屏蔽,不能直接点击,那怎样才能得到微信认可的下载页面呢,这里就需要用到腾讯的开放平台,而你的应用也需要提交到这个平台。在这里可以得到微信认可的链接地址。接下来介绍相关方法。<splitter>1首先打开腾讯开放平台,注册开放平台的一个账号,如下图所示。步骤阅读2登录后在”管理中心“中创建应用,如下图所示点击红线框选按钮。步骤阅读3选择创建应用的类型如下图所示,然后按钮提示填写应用的相关信息,提交进入审核。步骤阅读步骤阅读4应用审核通过后会在管理中心中显示”已上线“,然后点击应用的图标。步骤阅读5在应用详情中找到运营服务中的”微下载“,点击进入详情页面。步骤阅读6在详情页面中就可以看到系统生成的推广链接地址了,复制此地址就可以微信中转发了。步骤阅读END<splitter>经验内容仅供参考,如果您需解决具体问题(尤其法律、医学等领域),建议您详细咨询相关领域专业人士。"</span>],</span><br><span class="line">		<span class="attr">"segmented_paragraphs_scores"</span>: [<span class="number">1.0</span>],</span><br><span class="line">		<span class="attr">"paragraphs_length"</span>: [<span class="number">266</span>]</span><br><span class="line">	}, {</span><br><span class="line">		<span class="attr">"is_selected"</span>: <span class="literal">false</span>,</span><br><span class="line">		<span class="attr">"title"</span>: <span class="string">"android微信分享的链接怎么启动app-CSDN论坛"</span>,</span><br><span class="line">		<span class="attr">"most_related_para"</span>: <span class="number">0</span>,</span><br><span class="line">		<span class="attr">"segmented_title"</span>: [<span class="string">"android"</span>, <span class="string">"微信"</span>, <span class="string">"分享"</span>, <span class="string">"的"</span>, <span class="string">"链接"</span>, <span class="string">"怎么"</span>, <span class="string">"启动"</span>, <span class="string">"app"</span>, <span class="string">"-"</span>, <span class="string">"CSDN"</span>, <span class="string">"论坛"</span>],</span><br><span class="line">		<span class="attr">"segmented_paragraphs"</span>: [</span><br><span class="line">			[<span class="string">"android"</span>, <span class="string">"微信"</span>, <span class="string">"分享"</span>, <span class="string">"的"</span>, <span class="string">"链接"</span>, <span class="string">"怎么"</span>, <span class="string">"启动"</span>, <span class="string">"app"</span>, <span class="string">"-"</span>, <span class="string">"CSDN"</span>, <span class="string">"论坛"</span>, <span class="string">"<splitter>"</span>, <span class="string">"app"</span>, <span class="string">"中"</span>, <span class="string">"分享"</span>, <span class="string">"到"</span>, <span class="string">"微信"</span>, <span class="string">"已经"</span>, <span class="string">"成功"</span>, <span class="string">","</span>, <span class="string">"但是"</span>, <span class="string">"通过"</span>, <span class="string">"分享"</span>, <span class="string">"的"</span>, <span class="string">"连接"</span>, <span class="string">"无法"</span>, <span class="string">"启动"</span>, <span class="string">"app"</span>, <span class="string">"。"</span>, <span class="string">"<splitter>"</span>, <span class="string">"分享"</span>, <span class="string">"的"</span>, <span class="string">"链接"</span>, <span class="string">"就是"</span>, <span class="string">"普通"</span>, <span class="string">"的"</span>, <span class="string">"自定义"</span>, <span class="string">"url"</span>, <span class="string">":"</span>, <span class="string">"myapp"</span>, <span class="string">":"</span>, <span class="string">"/"</span>, <span class="string">"/"</span>, <span class="string">"www"</span>, <span class="string">"."</span>, <span class="string">"myapp"</span>, <span class="string">"."</span>, <span class="string">"com"</span>, <span class="string">"."</span>, <span class="string">"<splitter>"</span>, <span class="string">"博客"</span>, <span class="string">"专家"</span>, <span class="string">"带"</span>, <span class="string">"你"</span>, <span class="string">"学"</span>, <span class="string">"swift"</span>, <span class="string">"晒"</span>, <span class="string">"图谱"</span>, <span class="string">","</span>, <span class="string">"涨"</span>, <span class="string">"知识"</span>, <span class="string">","</span>, <span class="string">"得"</span>, <span class="string">"好"</span>, <span class="string">"礼"</span>, <span class="string">"Swift"</span>, <span class="string">"问题"</span>, <span class="string">"与"</span>, <span class="string">"解答"</span>, <span class="string">"视频直播"</span>, <span class="string">"技术"</span>, <span class="string">"免费"</span>, <span class="string">"课"</span>]</span><br><span class="line">		],</span><br><span class="line">		<span class="attr">"paragraphs"</span>: [<span class="string">"android微信分享的链接怎么启动app-CSDN论坛<splitter>app中分享到微信已经成功,但是通过分享的连接无法启动app。<splitter>分享的链接就是普通的自定义url:myapp://www.myapp.com.<splitter>博客专家带你学swift晒图谱,涨知识,得好礼Swift问题与解答视频直播技术免费课"</span>],</span><br><span class="line">		<span class="attr">"segmented_paragraphs_scores"</span>: [<span class="number">1.0</span>],</span><br><span class="line">		<span class="attr">"paragraphs_length"</span>: [<span class="number">73</span>]</span><br><span class="line">	}, {</span><br><span class="line">		<span class="attr">"is_selected"</span>: <span class="literal">false</span>,</span><br><span class="line">		<span class="attr">"title"</span>: <span class="string">"android 从微信分享的网页中启动APP - mattdong1024的专栏 - CSDN"</span>,</span><br><span class="line">		<span class="attr">"most_related_para"</span>: <span class="number">0</span>,</span><br><span class="line">		<span class="attr">"segmented_title"</span>: [<span class="string">"android"</span>, <span class="string">"从"</span>, <span class="string">"微信"</span>, <span class="string">"分享"</span>, <span class="string">"的"</span>, <span class="string">"网页"</span>, <span class="string">"中"</span>, <span class="string">"启动"</span>, <span class="string">"APP"</span>, <span class="string">"-"</span>, <span class="string">"matt"</span>, <span class="string">"dong"</span>, <span class="string">"1024"</span>, <span class="string">"的"</span>, <span class="string">"专栏"</span>, <span class="string">"-"</span>, <span class="string">"CSDN"</span>],</span><br><span class="line">		<span class="attr">"segmented_paragraphs"</span>: [</span><br><span class="line">			[<span class="string">"android"</span>, <span class="string">"从"</span>, <span class="string">"微信"</span>, <span class="string">"分享"</span>, <span class="string">"的"</span>, <span class="string">"网页"</span>, <span class="string">"中"</span>, <span class="string">"启动"</span>, <span class="string">"APP"</span>, <span class="string">"-"</span>, <span class="string">"matt"</span>, <span class="string">"dong"</span>, <span class="string">"1024"</span>, <span class="string">"的"</span>, <span class="string">"专栏"</span>, <span class="string">"-"</span>, <span class="string">"CSDN"</span>, <span class="string">"<splitter>"</span>, <span class="string">"项目"</span>, <span class="string">"中"</span>, <span class="string">"有"</span>, <span class="string">"个"</span>, <span class="string">"需求"</span>, <span class="string">","</span>, <span class="string">"让"</span>, <span class="string">"用户"</span>, <span class="string">"可以"</span>, <span class="string">"从"</span>, <span class="string">"分享"</span>, <span class="string">"到"</span>, <span class="string">"微信"</span>, <span class="string">"的"</span>, <span class="string">"网页"</span>, <span class="string">"中"</span>, <span class="string">"启动"</span>, <span class="string">"自己"</span>, <span class="string">"的"</span>, <span class="string">"APP"</span>, <span class="string">","</span>, <span class="string">"如果"</span>, <span class="string">"本"</span>, <span class="string">"机"</span>, <span class="string">"没有"</span>, <span class="string">"安装"</span>, <span class="string">"该"</span>, <span class="string">"应用程序"</span>, <span class="string">"则"</span>, <span class="string">"打开"</span>, <span class="string">"应用"</span>, <span class="string">"商店"</span>, <span class="string">"并"</span>, <span class="string">"打开"</span>, <span class="string">"该"</span>, <span class="string">"程序"</span>, <span class="string">"在"</span>, <span class="string">"商店"</span>, <span class="string">"中"</span>, <span class="string">"的"</span>, <span class="string">"搜索"</span>, <span class="string">"结果"</span>, <span class="string">"页面"</span>, <span class="string">"。"</span>, <span class="string">"在这里"</span>, <span class="string">"跟"</span>, <span class="string">"大家"</span>, <span class="string">"分享"</span>, <span class="string">"一"</span>, <span class="string">"下"</span>, <span class="string">":"</span>, <span class="string">"<splitter>"</span>, <span class="string">"实践"</span>, <span class="string">":"</span>, <span class="string">"从"</span>, <span class="string">"微信"</span>, <span class="string">"分享"</span>, <span class="string">"的"</span>, <span class="string">"网页"</span>, <span class="string">"中"</span>, <span class="string">"启动"</span>, <span class="string">"app"</span>, <span class="string">","</span>, <span class="string">"如果"</span>, <span class="string">"本"</span>, <span class="string">"机"</span>, <span class="string">"安装"</span>, <span class="string">"了"</span>, <span class="string">"该"</span>, <span class="string">"应用"</span>, <span class="string">"可以"</span>, <span class="string">"正常"</span>, <span class="string">"启动"</span>, <span class="string">","</span>, <span class="string">"如果没有"</span>, <span class="string">"安装"</span>, <span class="string">"该"</span>, <span class="string">"应用"</span>, <span class="string">","</span>, <span class="string">"会"</span>, <span class="string">"跳转"</span>, <span class="string">"到"</span>, <span class="string">"应用宝"</span>, <span class="string">"的"</span>, <span class="string">"网页"</span>, <span class="string">","</span>, <span class="string">"提示"</span>, <span class="string">"你"</span>, <span class="string">"下载"</span>, <span class="string">"应用"</span>, <span class="string">"<splitter>"</span>, <span class="string">"如果"</span>, <span class="string">"是"</span>, <span class="string">"从"</span>, <span class="string">"其他"</span>, <span class="string">"浏览器"</span>, <span class="string">"启动"</span>, <span class="string">"app"</span>, <span class="string">"的"</span>, <span class="string">"话"</span>, <span class="string">","</span>, <span class="string">"除了"</span>, <span class="string">"自带"</span>, <span class="string">"浏览器"</span>, <span class="string">"和"</span>, <span class="string">"谷歌"</span>, <span class="string">"浏览器"</span>, <span class="string">"外"</span>, <span class="string">","</span>, <span class="string">"其他"</span>, <span class="string">"第三方"</span>, <span class="string">"浏览器"</span>, <span class="string">"可能会"</span>, <span class="string">"有"</span>, <span class="string">"兼容性"</span>, <span class="string">"问题"</span>, <span class="string">","</span>, <span class="string">"也就是说"</span>, <span class="string">","</span>, <span class="string">"有"</span>, <span class="string">"可能"</span>, <span class="string">"无法"</span>, <span class="string">"从"</span>, <span class="string">"第三方"</span>, <span class="string">"浏览器"</span>, <span class="string">"启动"</span>, <span class="string">"app"</span>, <span class="string">"。"</span>]</span><br><span class="line">		],</span><br><span class="line">		<span class="attr">"paragraphs"</span>: [<span class="string">"android从微信分享的网页中启动APP-mattdong1024的专栏-CSDN<splitter>项目中有个需求,让用户可以从分享到微信的网页中启动自己的APP,如果本机没有安装该应用程序则打开应用商店并打开该程序在商店中的搜索结果页面。在这里跟大家分享一下:<splitter>实践:从微信分享的网页中启动app,如果本机安装了该应用可以正常启动,如果没有安装该应用,会跳转到应用宝的网页,提示你下载应用<splitter>如果是从其他浏览器启动app的话,除了自带浏览器和谷歌浏览器外,其他第三方浏览器可能会有兼容性问题,也就是说,有可能无法从第三方浏览器启动app。"</span>],</span><br><span class="line">		<span class="attr">"segmented_paragraphs_scores"</span>: [<span class="number">1.0</span>],</span><br><span class="line">		<span class="attr">"paragraphs_length"</span>: [<span class="number">146</span>]</span><br><span class="line">	}, {</span><br><span class="line">		<span class="attr">"is_selected"</span>: <span class="literal">true</span>,</span><br><span class="line">		<span class="attr">"title"</span>: <span class="string">"微信浏览器中点击链接怎么打开本地app_百度经验"</span>,</span><br><span class="line">		<span class="attr">"most_related_para"</span>: <span class="number">0</span>,</span><br><span class="line">		<span class="attr">"segmented_title"</span>: [<span class="string">"微信"</span>, <span class="string">"浏览器"</span>, <span class="string">"中"</span>, <span class="string">"点击"</span>, <span class="string">"链接"</span>, <span class="string">"怎么"</span>, <span class="string">"打开"</span>, <span class="string">"本地"</span>, <span class="string">"app"</span>, <span class="string">"_"</span>, <span class="string">"百度"</span>, <span class="string">"经验"</span>],</span><br><span class="line">		<span class="attr">"segmented_paragraphs"</span>: [</span><br><span class="line">			[<span class="string">"微信"</span>, <span class="string">"浏览器"</span>, <span class="string">"中"</span>, <span class="string">"点击"</span>, <span class="string">"链接"</span>, <span class="string">"怎么"</span>, <span class="string">"打开"</span>, <span class="string">"本地"</span>, <span class="string">"app"</span>, <span class="string">"_"</span>, <span class="string">"百度"</span>, <span class="string">"经验"</span>, <span class="string">"<splitter>"</span>, <span class="string">"百度"</span>, <span class="string">"经验"</span>, <span class="string">":"</span>, <span class="string">"jingyan"</span>, <span class="string">"."</span>, <span class="string">"baidu"</span>, <span class="string">"."</span>, <span class="string">"com"</span>, <span class="string">"<splitter>"</span>, <span class="string">"微信"</span>, <span class="string">"已经成为"</span>, <span class="string">"现代人"</span>, <span class="string">"生活"</span>, <span class="string">"中"</span>, <span class="string">"必不可少"</span>, <span class="string">"的"</span>, <span class="string">"一部分"</span>, <span class="string">","</span>, <span class="string">"下面"</span>, <span class="string">"我"</span>, <span class="string">"就"</span>, <span class="string">"教"</span>, <span class="string">"大家"</span>, <span class="string">"如何"</span>, <span class="string">"在"</span>, <span class="string">"微信"</span>, <span class="string">"浏览器"</span>, <span class="string">"中"</span>, <span class="string">"打开"</span>, <span class="string">"本地"</span>, <span class="string">"APP"</span>, <span class="string">"吧"</span>, <span class="string">"!"</span>, <span class="string">"<splitter>"</span>, <span class="string">"1"</span>, <span class="string">"将"</span>, <span class="string">"手机"</span>, <span class="string">"微信"</span>, <span class="string">"打开"</span>, <span class="string">"。"</span>, <span class="string">"步骤"</span>, <span class="string">"阅读"</span>, <span class="string">"2"</span>, <span class="string">"打开"</span>, <span class="string">"微信"</span>, <span class="string">"中"</span>, <span class="string">"的"</span>, <span class="string">"链接"</span>, <span class="string">"。"</span>, <span class="string">"步骤"</span>, <span class="string">"阅读"</span>, <span class="string">"3"</span>, <span class="string">"如图"</span>, <span class="string">"我们"</span>, <span class="string">"打开"</span>, <span class="string">"百度"</span>, <span class="string">"经验"</span>, <span class="string">"的"</span>, <span class="string">"链接"</span>, <span class="string">","</span>, <span class="string">"用"</span>, <span class="string">"微信"</span>, <span class="string">"浏览器"</span>, <span class="string">"进入"</span>, <span class="string">"网页"</span>, <span class="string">"以后"</span>, <span class="string">","</span>, <span class="string">"点击"</span>, <span class="string">"右"</span>, <span class="string">"上方"</span>, <span class="string">"如图"</span>, <span class="string">"符号"</span>, <span class="string">"。"</span>, <span class="string">"步骤"</span>, <span class="string">"阅读"</span>, <span class="string">"4"</span>, <span class="string">"进入"</span>, <span class="string">"选择"</span>, <span class="string">"页面"</span>, <span class="string">","</span>, <span class="string">"点击"</span>, <span class="string">"“"</span>, <span class="string">"在"</span>, <span class="string">"浏览器"</span>, <span class="string">"”"</span>, <span class="string">"打开"</span>, <span class="string">"。"</span>, <span class="string">"步骤"</span>, <span class="string">"阅读"</span>, <span class="string">"5"</span>, <span class="string">"如图"</span>, <span class="string">"会出现"</span>, <span class="string">"手机"</span>, <span class="string">"已"</span>, <span class="string">"安装"</span>, <span class="string">"的"</span>, <span class="string">"本地"</span>, <span class="string">"APP"</span>, <span class="string">"浏览器"</span>, <span class="string">","</span>, <span class="string">"我们"</span>, <span class="string">"选择"</span>, <span class="string">"一"</span>, <span class="string">"个"</span>, <span class="string">"自己"</span>, <span class="string">"想"</span>, <span class="string">"用"</span>, <span class="string">"的"</span>, <span class="string">"本地"</span>, <span class="string">"浏览器"</span>, <span class="string">"点击"</span>, <span class="string">"下方"</span>, <span class="string">"“"</span>, <span class="string">"仅"</span>, <span class="string">"一次"</span>, <span class="string">"”"</span>, <span class="string">"或"</span>, <span class="string">"“"</span>, <span class="string">"总是"</span>, <span class="string">"”"</span>, <span class="string">"都"</span>, <span class="string">"可以"</span>, <span class="string">"打开"</span>, <span class="string">"打开"</span>, <span class="string">"本地"</span>, <span class="string">"APP"</span>, <span class="string">"浏览器"</span>, <span class="string">"。"</span>, <span class="string">"步骤"</span>, <span class="string">"阅读"</span>, <span class="string">"6"</span>, <span class="string">"此时"</span>, <span class="string">","</span>, <span class="string">"我们"</span>, <span class="string">"就"</span>, <span class="string">"已经"</span>, <span class="string">"在"</span>, <span class="string">"微信"</span>, <span class="string">"浏览器"</span>, <span class="string">"中将"</span>, <span class="string">"本地"</span>, <span class="string">"APP"</span>, <span class="string">"浏览器"</span>, <span class="string">"打开"</span>, <span class="string">"了"</span>, <span class="string">"步骤"</span>, <span class="string">"阅读"</span>, <span class="string">"END"</span>, <span class="string">"<splitter>"</span>, <span class="string">"经验"</span>, <span class="string">"内容"</span>, <span class="string">"仅供参考"</span>, <span class="string">","</span>, <span class="string">"如果"</span>, <span class="string">"您"</span>, <span class="string">"需"</span>, <span class="string">"解决"</span>, <span class="string">"具体"</span>, <span class="string">"问题"</span>, <span class="string">"("</span>, <span class="string">"尤其"</span>, <span class="string">"法律"</span>, <span class="string">"、"</span>, <span class="string">"医学"</span>, <span class="string">"等"</span>, <span class="string">"领域"</span>, <span class="string">")"</span>, <span class="string">","</span>, <span class="string">"建议"</span>, <span class="string">"您"</span>, <span class="string">"详细"</span>, <span class="string">"咨询"</span>, <span class="string">"相关"</span>, <span class="string">"领域"</span>, <span class="string">"专业人士"</span>, <span class="string">"。"</span>]</span><br><span class="line">		],</span><br><span class="line">		<span class="attr">"paragraphs"</span>: [<span class="string">"微信浏览器中点击链接怎么打开本地app_百度经验<splitter>百度经验:jingyan.baidu.com<splitter>微信已经成为现代人生活中必不可少的一部分,下面我就教大家如何在微信浏览器中打开本地APP吧!<splitter>1将手机微信打开。步骤阅读2打开微信中的链接。步骤阅读3如图我们打开百度经验的链接,用微信浏览器进入网页以后,点击右上方如图符号。步骤阅读4进入选择页面,点击“在浏览器”打开。步骤阅读5如图会出现手机已安装的本地APP浏览器,我们选择一个自己想用的本地浏览器点击下方“仅一次”或“总是”都可以打开打开本地APP浏览器。步骤阅读6此时,我们就已经在微信浏览器中将本地APP浏览器打开了步骤阅读END<splitter>经验内容仅供参考,如果您需解决具体问题(尤其法律、医学等领域),建议您详细咨询相关领域专业人士。"</span>],</span><br><span class="line">		<span class="attr">"segmented_paragraphs_scores"</span>: [<span class="number">1.0</span>],</span><br><span class="line">		<span class="attr">"paragraphs_length"</span>: [<span class="number">189</span>]</span><br><span class="line">	}],</span><br><span class="line">	<span class="attr">"answer_spans"</span>: [</span><br><span class="line">		[<span class="number">47</span>, <span class="number">157</span>]</span><br><span class="line">	],</span><br><span class="line">	<span class="attr">"fake_answers"</span>: [<span class="string">"1将手机微信打开。步骤阅读2打开微信中的链接。步骤阅读3如图我们打开百度经验的链接,用微信浏览器进入网页以后,点击右上方如图符号。步骤阅读4进入选择页面,点击“在浏览器”打开。步骤阅读5如图会出现手机已安装的本地APP浏览器,我们选择一个自己想用的本地浏览器点击下方“仅一次”或“总是”都可以打开打开本地APP浏览器。步骤阅读6此时,我们就已经在微信浏览器中将本地APP浏览器打开了"</span>],</span><br><span class="line">	<span class="attr">"question"</span>: <span class="string">"微信分享链接打开app"</span>,</span><br><span class="line">	<span class="attr">"segmented_answers"</span>: [</span><br><span class="line">		[<span class="string">"iOS"</span>, <span class="string">"里"</span>, <span class="string">"，"</span>, <span class="string">"把"</span>, <span class="string">"一"</span>, <span class="string">"个"</span>, <span class="string">"页面"</span>, <span class="string">"链接"</span>, <span class="string">"分享"</span>, <span class="string">"给"</span>, <span class="string">"微信"</span>, <span class="string">"好友"</span>, <span class="string">"（"</span>, <span class="string">"会话"</span>, <span class="string">"）"</span>, <span class="string">"，"</span>, <span class="string">"好友"</span>, <span class="string">"在"</span>, <span class="string">"微信"</span>, <span class="string">"里"</span>, <span class="string">"打开"</span>, <span class="string">"这个"</span>, <span class="string">"链接"</span>, <span class="string">","</span>, <span class="string">"也"</span>, <span class="string">"就是"</span>, <span class="string">"打开"</span>, <span class="string">"了"</span>, <span class="string">"一"</span>, <span class="string">"个"</span>, <span class="string">"网页"</span>, <span class="string">"，"</span>, <span class="string">"点击"</span>, <span class="string">"网页"</span>, <span class="string">"里"</span>, <span class="string">"的"</span>, <span class="string">"某"</span>, <span class="string">"个"</span>, <span class="string">"地方"</span>, <span class="string">"后"</span>, <span class="string">"（"</span>, <span class="string">"比如"</span>, <span class="string">"网页"</span>, <span class="string">"中"</span>, <span class="string">"“"</span>, <span class="string">"打开"</span>, <span class="string">"xx"</span>, <span class="string">"应用程序"</span>, <span class="string">"”"</span>, <span class="string">"的"</span>, <span class="string">"按钮"</span>, <span class="string">"）"</span>, <span class="string">"，"</span>, <span class="string">"代码"</span>, <span class="string">"里"</span>, <span class="string">"怎么"</span>, <span class="string">"设置"</span>, <span class="string">"可以"</span>, <span class="string">"跳"</span>, <span class="string">"回到"</span>, <span class="string">"第三方"</span>, <span class="string">"app"</span>, <span class="string">"？"</span>, <span class="string">"知乎"</span>, <span class="string">"的"</span>, <span class="string">"ios"</span>, <span class="string">"客户端"</span>, <span class="string">"就"</span>, <span class="string">"有"</span>, <span class="string">"这种"</span>, <span class="string">"功能"</span>, <span class="string">"，"</span>, <span class="string">"在"</span>, <span class="string">"微信"</span>, <span class="string">"里"</span>, <span class="string">"分享"</span>, <span class="string">"链接"</span>, <span class="string">"后"</span>, <span class="string">"，"</span>, <span class="string">"点"</span>, <span class="string">"开"</span>, <span class="string">"链接"</span>, <span class="string">"，"</span>, <span class="string">"再"</span>, <span class="string">"点"</span>, <span class="string">"网页"</span>, <span class="string">"中"</span>, <span class="string">"的"</span>, <span class="string">"某处"</span>, <span class="string">"，"</span>, <span class="string">"就"</span>, <span class="string">"可以"</span>, <span class="string">"打开"</span>, <span class="string">"知乎"</span>, <span class="string">"客户端"</span>, <span class="string">"。"</span>],</span><br><span class="line">		[<span class="string">"1"</span>, <span class="string">"、"</span>, <span class="string">"首先"</span>, <span class="string">"打开"</span>, <span class="string">"腾讯"</span>, <span class="string">"开放"</span>, <span class="string">"平台"</span>, <span class="string">"，"</span>, <span class="string">"注册"</span>, <span class="string">"开放"</span>, <span class="string">"平台"</span>, <span class="string">"的"</span>, <span class="string">"一"</span>, <span class="string">"个"</span>, <span class="string">"账号"</span>, <span class="string">"。"</span>, <span class="string">"2"</span>, <span class="string">"、"</span>, <span class="string">"登录"</span>, <span class="string">"后"</span>, <span class="string">"在"</span>, <span class="string">"”"</span>, <span class="string">"管理"</span>, <span class="string">"中心"</span>, <span class="string">"“"</span>, <span class="string">"中"</span>, <span class="string">"创建"</span>, <span class="string">"应用"</span>, <span class="string">"。"</span>, <span class="string">"3"</span>, <span class="string">"、"</span>, <span class="string">"选择"</span>, <span class="string">"创建"</span>, <span class="string">"应用"</span>, <span class="string">"的"</span>, <span class="string">"类型"</span>, <span class="string">"如"</span>, <span class="string">"下"</span>, <span class="string">"图"</span>, <span class="string">"所示"</span>, <span class="string">"，"</span>, <span class="string">"然后"</span>, <span class="string">"按钮"</span>, <span class="string">"提示"</span>, <span class="string">"填写"</span>, <span class="string">"应用"</span>, <span class="string">"的"</span>, <span class="string">"相关"</span>, <span class="string">"信息"</span>, <span class="string">"，"</span>, <span class="string">"提交"</span>, <span class="string">"进入"</span>, <span class="string">"审核"</span>, <span class="string">"。"</span>, <span class="string">"4"</span>, <span class="string">"、"</span>, <span class="string">"应用"</span>, <span class="string">"审核"</span>, <span class="string">"通过"</span>, <span class="string">"后"</span>, <span class="string">"会"</span>, <span class="string">"在"</span>, <span class="string">"管理"</span>, <span class="string">"中心"</span>, <span class="string">"中"</span>, <span class="string">"显示"</span>, <span class="string">"”"</span>, <span class="string">"已"</span>, <span class="string">"上线"</span>, <span class="string">"“"</span>, <span class="string">"，"</span>, <span class="string">"然后"</span>, <span class="string">"点击"</span>, <span class="string">"应用"</span>, <span class="string">"的"</span>, <span class="string">"图标"</span>, <span class="string">"。"</span>, <span class="string">"5"</span>, <span class="string">"、"</span>, <span class="string">"在"</span>, <span class="string">"应用"</span>, <span class="string">"详情"</span>, <span class="string">"中"</span>, <span class="string">"找到"</span>, <span class="string">"运营"</span>, <span class="string">"服务"</span>, <span class="string">"中"</span>, <span class="string">"的"</span>, <span class="string">"”"</span>, <span class="string">"微"</span>, <span class="string">"下载"</span>, <span class="string">"“"</span>, <span class="string">"。"</span>, <span class="string">"6"</span>, <span class="string">"、"</span>, <span class="string">"在"</span>, <span class="string">"详情"</span>, <span class="string">"页面"</span>, <span class="string">"中"</span>, <span class="string">"就"</span>, <span class="string">"可以"</span>, <span class="string">"看到"</span>, <span class="string">"系统"</span>, <span class="string">"生成"</span>, <span class="string">"的"</span>, <span class="string">"推广"</span>, <span class="string">"链接地址"</span>, <span class="string">"了"</span>, <span class="string">"，"</span>, <span class="string">"复制"</span>, <span class="string">"此"</span>, <span class="string">"地址"</span>, <span class="string">"就"</span>, <span class="string">"可以"</span>, <span class="string">"微信"</span>, <span class="string">"中"</span>, <span class="string">"转发"</span>, <span class="string">"了"</span>, <span class="string">"。"</span>],</span><br><span class="line">		[<span class="string">"1"</span>, <span class="string">"将"</span>, <span class="string">"手机"</span>, <span class="string">"微信"</span>, <span class="string">"打开"</span>, <span class="string">"。"</span>, <span class="string">"2"</span>, <span class="string">"打开"</span>, <span class="string">"微信"</span>, <span class="string">"中"</span>, <span class="string">"的"</span>, <span class="string">"链接"</span>, <span class="string">"。"</span>, <span class="string">"3"</span>, <span class="string">"我们"</span>, <span class="string">"打开"</span>, <span class="string">"百度"</span>, <span class="string">"经验"</span>, <span class="string">"的"</span>, <span class="string">"链接"</span>, <span class="string">"，"</span>, <span class="string">"用"</span>, <span class="string">"微信"</span>, <span class="string">"浏览器"</span>, <span class="string">"进入"</span>, <span class="string">"网页"</span>, <span class="string">"以后"</span>, <span class="string">"，"</span>, <span class="string">"点击"</span>, <span class="string">"右"</span>, <span class="string">"上方"</span>, <span class="string">"如图"</span>, <span class="string">"符号"</span>, <span class="string">"。"</span>, <span class="string">"4"</span>, <span class="string">"进入"</span>, <span class="string">"选择"</span>, <span class="string">"页面"</span>, <span class="string">"，"</span>, <span class="string">"点击"</span>, <span class="string">"“"</span>, <span class="string">"在"</span>, <span class="string">"浏览器"</span>, <span class="string">"”"</span>, <span class="string">"打开"</span>, <span class="string">"。"</span>, <span class="string">"5"</span>, <span class="string">"出现"</span>, <span class="string">"手机"</span>, <span class="string">"已"</span>, <span class="string">"安装"</span>, <span class="string">"的"</span>, <span class="string">"本地"</span>, <span class="string">"APP"</span>, <span class="string">"浏览器"</span>, <span class="string">"，"</span>, <span class="string">"我们"</span>, <span class="string">"选择"</span>, <span class="string">"一"</span>, <span class="string">"个"</span>, <span class="string">"自己"</span>, <span class="string">"想"</span>, <span class="string">"用"</span>, <span class="string">"的"</span>, <span class="string">"本地"</span>, <span class="string">"浏览器"</span>, <span class="string">"点击"</span>, <span class="string">"下方"</span>, <span class="string">"“"</span>, <span class="string">"仅"</span>, <span class="string">"一次"</span>, <span class="string">"”"</span>, <span class="string">"或"</span>, <span class="string">"“"</span>, <span class="string">"总是"</span>, <span class="string">"”"</span>, <span class="string">"都"</span>, <span class="string">"可以"</span>, <span class="string">"打开"</span>, <span class="string">"打开"</span>, <span class="string">"本地"</span>, <span class="string">"APP"</span>, <span class="string">"浏览器"</span>, <span class="string">"。"</span>, <span class="string">"6"</span>, <span class="string">"此时"</span>, <span class="string">"，"</span>, <span class="string">"我们"</span>, <span class="string">"就"</span>, <span class="string">"已经"</span>, <span class="string">"在"</span>, <span class="string">"微信"</span>, <span class="string">"浏览器"</span>, <span class="string">"中将"</span>, <span class="string">"本地"</span>, <span class="string">"APP"</span>, <span class="string">"浏览器"</span>, <span class="string">"打开"</span>, <span class="string">"了"</span>, <span class="string">"。"</span>]</span><br><span class="line">	],</span><br><span class="line">	<span class="attr">"answers"</span>: [<span class="string">"iOS里，把一个页面链接分享给微信好友（会话），好友在微信里打开这个链接,也就是打开了一个网页，点击网页里的某个地方后（比如网页中“打开xx应用程序”的按钮），代码里怎么设置可以跳回到第三方app？知乎的ios客户端就有这种功能，在微信里分享链接后，点开链接，再点网页中的某处，就可以打开知乎客户端 。"</span>, <span class="string">"1、首先打开腾讯开放平台，注册开放平台的一个账号。2、登录后在”管理中心“中创建应用。3、选择创建应用的类型如下图所示，然后按钮提示填写应用的相关信息，提交进入审核。4、应用审核通过后会在管理中心中显示”已上线“，然后点击应用的图标。5、在应用详情中找到运营服务中的”微下载“。6、在详情页面中就可以看到系统生成的推广链接地址了，复制此地址就可以微信中转发了。"</span>, <span class="string">"1将手机微信打开。2打开微信中的链接。3我们打开百度经验的链接，用微信浏览器进入网页以后，点击右上方如图符号。4进入选择页面，点击“在浏览器”打开。5出现手机已安装的本地APP浏览器，我们选择一个自己想用的本地浏览器点击下方“仅一次”或“总是”都可以打开打开本地APP浏览器。6此时，我们就已经在微信浏览器中将本地APP浏览器打开了。"</span>],</span><br><span class="line">	<span class="attr">"answer_docs"</span>: [<span class="number">4</span>],</span><br><span class="line">	<span class="attr">"segmented_question"</span>: [<span class="string">"微信"</span>, <span class="string">"分享"</span>, <span class="string">"链接"</span>, <span class="string">"打开"</span>, <span class="string">"app"</span>],</span><br><span class="line">	<span class="attr">"question_type"</span>: <span class="string">"DESCRIPTION"</span>,</span><br><span class="line">	<span class="attr">"match_scores"</span>: [<span class="number">0.8815165876777251</span>],</span><br><span class="line">	<span class="attr">"fact_or_opinion"</span>: <span class="string">"FACT"</span>,</span><br><span class="line">    <span class="attr">"question_id"</span>: <span class="number">91159</span></span><br><span class="line">    }</span><br></pre></td></tr></tbody></table></figure>
<a id="more"></a>
<h3 id="官方介绍" class="heading-control"><a href="#官方介绍" class="headerlink" title="官方介绍"></a>官方介绍<a class="heading-anchor" href="#官方介绍" aria-hidden="true"></a></h3><p>一些官方的介绍：<a href="http://ai.baidu.com/broad/download?dataset=dureader">http://ai.baidu.com/broad/download?dataset=dureader</a></p>
<p>DuReader version 2.0 contains more than 300K question, 1.4M evidence documents and 660K human generated answers.</p>
<p>There are 3 question types in the dataset. Below is data statistics of each question type:<br><img src="https://s2.ax1x.com/2019/11/01/K7PCND.png" alt="K7PCND.png"></p>
<p>We here provide 2 packages to download, each of them contains train set, development set and test set.  DuReader_v2.0_raw.zip is the original DuReader Dataset, DuReader_v2.0_preprocess.zip is the preprocessed version of  DuReader_v2.0_raw.zip, the preprocessing includes word segmentation, best match paragraph targeting, answer span locating.<br>See readme included with this package for more details</p>
<p>To get started, please refer to:</p>
<ul>
<li>Paper :DuReader: a Chinese Machine Reading Comprehension Dataset Built upon Real-world Applications.</li>
<li>Open source baseline system:<a href="https://github.com/baidu/DuReader">https://github.com/baidu/DuReader</a>.</li>
</ul>
<h3 id="论文介绍" class="heading-control"><a href="#论文介绍" class="headerlink" title="论文介绍"></a>论文介绍<a class="heading-anchor" href="#论文介绍" aria-hidden="true"></a></h3><p>百度在 2017 年发布了大规模的中文 MRC 数据集：DuReader。相比以前的 MRC 数据集，DuReader 有以下特点：</p>
<ul>
<li>所有的问题、原文都来源于实际数据（百度搜索引擎数据和百度知道问答社区），答案是由人类回答的。</li>
<li>数据集中包含大量的之前很少研究的是非和观点类的样本。</li>
<li>每个问题都对应多个答案，数据集包含 200k 问题、1000k 原文和 420k 答案，是目前最大的中文 MRC 数据集。</li>
</ul>
<p>根据答案类型，DuReader 将问题分为：Entity（实体）、Description（描述）和 YesNo（是非）。</p>
<p>对于实体类问题，其答案一般是单一确定的回答，比如：iPhone 是哪天发布？</p>
<p>对于描述类问题，其答案一般较长，是多个句子的总结，典型的 how/why 类型的问题，比如：消防车为什么是红的？</p>
<p>对于是非类问题，其答案往往较简单，是或者否，比如：39.5 度算高烧吗？</p>
<p>同时，无论将问题分类以上哪种类型都可以进一步细分为是事实（Fact）类还是观点（Opinion）类。</p>
</body></html>]]></content>
      <tags>
        <tag>Dureader</tag>
      </tags>
  </entry>
  <entry>
    <title>Quora Insincere Questions Classification</title>
    <url>/post/32747.html</url>
    <content><![CDATA[<html><head><link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script></head><body><h2 id="比赛介绍" class="heading-control"><a href="#比赛介绍" class="headerlink" title="比赛介绍"></a>比赛介绍<a class="heading-anchor" href="#比赛介绍" aria-hidden="true"></a></h2><p>Quora 平台，简单的来说就是美国版的知乎。最近 Quora 拿出 25,000 美元作为奖金，举办了一场 Kaggle 比赛:<a href="https://www.kaggle.com/c/quora-insincere-questions-classification">Quora Insincere Questions Classification</a>。那么什么是虚假问题呢？就是那些并非真心发问而另有用意的问题。<br>该竞赛是个典型的文本二分类问题，即判断用户的提问是否 “有害”，竞赛中最关键的要求有三点：</p>
<ol>
<li>只能使用 Kaggle Kernel 中生成的 submission.csv 来提交；</li>
<li>不能使用外部数据，也就是说 embedding 也只能用 Kernel 里提供的四个 embedding 文件；</li>
<li>Kernel 的 GPU 运行时间不能超过 120 分钟。也就是说不能使用 Bert 这样的大型模型。<br>目前的排名也不是最终排名，最后官方会用另一部分数据集来测试模型，然后给出最终的排名。<br><img src="https://i.loli.net/2019/01/15/5c3deb223cc97.png" alt><br><center>官方的四个 embedding 文件</center><br>从公开的 Kernel 来看，目测有 99% 都是使用 RNN 来解题。这 99% 使用 RNN 模型的，目测有 80% 都是使用了 Keras。<h2 id="文本分类" class="heading-control"><a href="#文本分类" class="headerlink" title="文本分类"></a>文本分类<a class="heading-anchor" href="#文本分类" aria-hidden="true"></a></h2>最常见的文本分类应用场景就是垃圾邮件分类，情感分类等等。<br><img src="/Quora-Insincere-Questions-Classification/20190119025322179.png" alt><h3 id="检查数据" class="heading-control"><a href="#检查数据" class="headerlink" title="检查数据"></a>检查数据<a class="heading-anchor" href="#检查数据" aria-hidden="true"></a></h3>首先加载数据集，然后对数据集进行检查。可以随机打印一些样本然后查看是不是和标签相对应 (df.sample)<h3 id="探索数据集并收集指标" class="heading-control"><a href="#探索数据集并收集指标" class="headerlink" title="探索数据集并收集指标"></a>探索数据集并收集指标<a class="heading-anchor" href="#探索数据集并收集指标" aria-hidden="true"></a></h3>收集以下有助于表征文本分类问题的重要指标：</li>
<li>样本数：数据中的示例总数。</li>
<li>课程数量：数据中的主题或类别总数。</li>
<li>每个类的样本数：每个类的样本数（主题 / 类别）。在平衡数据集中，所有类都将具有相似数量的样本；在不平衡的数据集中，每个类中的样本数量会有很大差异。</li>
<li>每个样本的单词数：一个样本中的单词中位数。</li>
<li>单词的频率分布：显示数据集中每个单词的频率（出现次数）的分布。</li>
<li>样本长度分布：分布显示数据集中每个样本的单词数。</li>
</ol>
<p><a href="https://github.com/google/eng-edu/blob/master/ml/guides/text_classification/explore_data.py">explore_data.py</a> contains functions to calculate and analyse these metrics.</p>
<h3 id="选择模型" class="heading-control"><a href="#选择模型" class="headerlink" title="选择模型"></a>选择模型<a class="heading-anchor" href="#选择模型" aria-hidden="true"></a></h3><p>这里谷歌给出了一个文本分类模型选择的流程图。</p>
<blockquote>
<p>我们针对不同类型的问题（特别是情绪分析和主题分类问题）运行了大量（~450K）实验，使用 12 个数据集，交替用于不同数据预处理技术和不同模型体系结构之间的每个数据集。这有助于我们识别影响最佳选择的数据集参数。下面的模型选择算法和流程图是我们实验的总结。</p>
<h4 id="Algorithm-for-Data-Preparation-and-Model-Building" class="heading-control"><a href="#Algorithm-for-Data-Preparation-and-Model-Building" class="headerlink" title="Algorithm for Data Preparation and Model Building"></a>Algorithm for Data Preparation and Model Building<a class="heading-anchor" href="#Algorithm-for-Data-Preparation-and-Model-Building" aria-hidden="true"></a></h4><figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">1. Calculate the number of samples/number of words per sample ratio.</span><br><span class="line">2. If this ratio is less than 1500, tokenize the text as n-grams and use a</span><br><span class="line">simple multi-layer perceptron (MLP) model to classify them (left branch <span class="keyword">in</span> the</span><br><span class="line">flowchart below):</span><br><span class="line">  a. Split the samples into word n-grams; convert the n-grams into vectors.</span><br><span class="line">  b. Score the importance of the vectors and <span class="keyword">then</span> select the top 20K using the scores.</span><br><span class="line">  c. Build an MLP model.</span><br><span class="line">3. If the ratio is greater than 1500, tokenize the text as sequences and use a</span><br><span class="line">   sepCNN model to classify them (right branch <span class="keyword">in</span> the flowchart below):</span><br><span class="line">  a. Split the samples into words; select the top 20K words based on their frequency.</span><br><span class="line">  b. Convert the samples into word sequence vectors.</span><br><span class="line">  c. If the original number of samples/number of words per sample ratio is less</span><br><span class="line">     than 15K, using a fine-tuned pre-trained embedding with the sepCNN</span><br><span class="line">     model will likely provide the best results.</span><br><span class="line">4. Measure the model performance with different hyperparameter values to find</span><br><span class="line">   the best model configuration <span class="keyword">for</span> the dataset.</span><br><span class="line">````</span><br><span class="line">翻译一下：</span><br><span class="line">1. 计算每个样本比例的样本数/单词数的比率。</span><br><span class="line">2. 如果此比率小于1500，则将文本标记为n-gram并使用简单的多层感知器（MLP）模型对它们进行分类（左侧分支）下面的流程图）：一个。将样本分成单词n-gram; 将n-gram转换为向量。湾 评分向量的重要性，然后使用分数选择前20K。C。建立MLP模型。</span><br><span class="line">3. 如果比率大于1500，则将文本标记为序列并使用sepCNN模型对它们进行分类（右下图在下面的流程图中）：一个。将样本分成单词; 根据频率选择前20K字。湾 将样本转换为单词序列向量。C。如果原始样本数/每个样本的单词数比例较小超过15K，使用经过微调的预训练嵌入sepCNN模型可能会提供最好的结果。</span><br><span class="line">4. 使用不同的超参数值测量模型性能以进行查找数据集的最佳模型配置。</span><br><span class="line"></span><br><span class="line">![TextClassificationFlowchart.png](https://i.loli.net/2019/01/19/5c42cec7588ae.png)</span><br><span class="line"><center>文本分类模型选择流程图</center></span><br><span class="line">>在下面的流程图中，黄色框表示数据和模型准备过程。灰色框和绿色框表示我们为每个过程考虑的选择。绿色框表示我们对每个过程的建议选择。您可以使用此流程图作为构建第一个实验的起点，因为它可以以较低的计算成本为您提供良好的准确性。然后，您可以在后续迭代中继续改进初始模型。</span><br><span class="line"></span><br><span class="line">此流程图回答了两个关键问题：</span><br><span class="line">- 我们应该使用哪种学习算法或模型？</span><br><span class="line">- 我们应该如何准备数据以有效地学习文本和标签之间的关系？</span><br><span class="line">第二个问题的答案取决于第一个问题的答案; 我们预先处理数据的方式将取决于我们选择的模型。模型可以大致分为两类：使用单词排序信息的那些（序列模型），以及仅将文本视为“包”（组）单词（n-gram模型）的模型。序列模型的类型包括卷积神经网络（CNN），递归神经网络（RNN）及其变体。n-gram模型的类型包括逻辑回归，简单的多层感知器（MLP或完全连接的神经网络），梯度增强树和支持向量机。</span><br><span class="line">根据我们的实验，我们观察到“样本数”（S）与“每个样本的单词数”（W）的比率与哪个模型表现良好相关。</span><br><span class="line">当该比率的值很小（<1500）时，以n-gram为输入的小型多层感知器（我们称之为选项A）表现得更好或至少与序列模型一样好。MLP很容易定义和理解，并且它们比序列模型花费更少的计算时间。当此比率的值很大（> = 1500）时，使用序列模型（选项B）。在接下来的步骤中，您可以根据样本/单词样本比率跳过所选模型类型的相关小节（标记为A或B）。</span><br><span class="line"><!--more--></span><br><span class="line"><span class="comment">### 数据集的平衡性</span></span><br><span class="line">对于分类的数据集来说，每个类中的样本数量不会过度失衡，也就是说，每个类中应该有相当数量的样本。但是这个比赛就是一个严重不平衡的数据集。</span><br><span class="line"><span class="comment">### 常用深度学习模型</span></span><br><span class="line">![](/Quora-Insincere-Questions-Classification/20190119051521899.png)</span><br><span class="line"><span class="comment">## 常用代码总结</span></span><br><span class="line">这里是英文数据集数据处理和Keras搭建模型的一些常用代码。Using pre-trained word embeddings <span class="keyword">in</span> a Keras model](https://blog.keras.io/using-pre-trained-word-embeddings-in<span class="_">-a</span>-keras-model.html)。</span><br><span class="line"><span class="comment">### Token and Padding</span></span><br><span class="line">```python</span><br><span class="line">from keras.preprocessing.text import Tokenizer</span><br><span class="line">from keras.preprocessing.sequence import pad_sequences</span><br><span class="line"></span><br><span class="line">tokenizer = Tokenizer(nb_words=MAX_NB_WORDS)</span><br><span class="line">tokenizer.fit_on_texts(texts)</span><br><span class="line">sequences = tokenizer.texts_to_sequences(texts)</span><br><span class="line"></span><br><span class="line">word_index = tokenizer.word_index</span><br><span class="line"><span class="built_in">print</span>(<span class="string">'Found %s unique tokens.'</span> % len(word_index))</span><br><span class="line"></span><br><span class="line">data = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH)</span><br><span class="line"></span><br><span class="line">labels = to_categorical(np.asarray(labels))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">'Shape of data tensor:'</span>, data.shape)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">'Shape of label tensor:'</span>, labels.shape)</span><br><span class="line"></span><br><span class="line"><span class="comment"># split the data into a training set and a validation set</span></span><br><span class="line">indices = np.arange(data.shape[0])</span><br><span class="line">np.random.shuffle(indices)</span><br><span class="line">data = data[indices]</span><br><span class="line">labels = labels[indices]</span><br><span class="line">nb_validation_samples = int(VALIDATION_SPLIT * data.shape[0])</span><br><span class="line"></span><br><span class="line">x_train = data[:-nb_validation_samples]</span><br><span class="line">y_train = labels[:-nb_validation_samples]</span><br><span class="line">x_val = data[-nb_validation_samples:]</span><br><span class="line">y_val = labels[-nb_validation_samples:]</span><br></pre></td></tr></tbody></table></figure>
<h3 id="Preparing-the-Embedding-layer" class="heading-control"><a href="#Preparing-the-Embedding-layer" class="headerlink" title="Preparing the Embedding layer"></a>Preparing the Embedding layer<a class="heading-anchor" href="#Preparing-the-Embedding-layer" aria-hidden="true"></a></h3><ol>
<li>Reading the data dump of pre-trained embeddings<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line">embeddings_index = {}</span><br><span class="line">f = open(os.path.join(GLOVE_DIR, <span class="string">'glove.6B.100d.txt'</span>))</span><br><span class="line"><span class="keyword">for</span> line <span class="keyword">in</span> f:</span><br><span class="line">    values = line.split()</span><br><span class="line">    word = values[<span class="number">0</span>]</span><br><span class="line">    coefs = np.asarray(values[<span class="number">1</span>:], dtype=<span class="string">'float32'</span>)</span><br><span class="line">    embeddings_index[word] = coefs</span><br><span class="line">f.close()</span><br><span class="line"></span><br><span class="line">print(<span class="string">'Found %s word vectors.'</span> % len(embeddings_index))</span><br></pre></td></tr></tbody></table></figure></li>
<li>Compute our embedding matrix:<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line">embedding_matrix = np.zeros((len(word_index) + <span class="number">1</span>, EMBEDDING_DIM))</span><br><span class="line"><span class="keyword">for</span> word, i <span class="keyword">in</span> word_index.items():</span><br><span class="line">    embedding_vector = embeddings_index.get(word)</span><br><span class="line">    <span class="keyword">if</span> embedding_vector <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">        <span class="comment"># words not found in embedding index will be all-zeros.</span></span><br><span class="line">        embedding_matrix[i] = embedding_vector</span><br></pre></td></tr></tbody></table></figure></li>
<li>Build embedding layer<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Embedding</span><br><span class="line"></span><br><span class="line">embedding_layer = Embedding(len(word_index) + <span class="number">1</span>,</span><br><span class="line">                            EMBEDDING_DIM,</span><br><span class="line">                            weights=[embedding_matrix],</span><br><span class="line">                            input_length=MAX_SEQUENCE_LENGTH,</span><br><span class="line">                            trainable=<span class="literal">False</span>)</span><br></pre></td></tr></tbody></table></figure>
<h3 id="Keras-F1-Socre" class="heading-control"><a href="#Keras-F1-Socre" class="headerlink" title="Keras F1 Socre"></a>Keras F1 Socre<a class="heading-anchor" href="#Keras-F1-Socre" aria-hidden="true"></a></h3><figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">F1</span>(<span class="params">y_true, y_pred</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">recall</span>(<span class="params">y_true, y_pred</span>):</span></span><br><span class="line">        <span class="string">"""Recall metric.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Only computes a batch-wise average of recall.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Computes the recall, a metric for multi-label classification of</span></span><br><span class="line"><span class="string">        how many relevant items are selected.</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        true_positives = K.sum(K.round(K.clip(y_true * y_pred, <span class="number">0</span>, <span class="number">1</span>)))</span><br><span class="line">        possible_positives = K.sum(K.round(K.clip(y_true, <span class="number">0</span>, <span class="number">1</span>)))</span><br><span class="line">        recall = true_positives / (possible_positives + K.epsilon())</span><br><span class="line">        <span class="keyword">return</span> recall</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">precision</span>(<span class="params">y_true, y_pred</span>):</span></span><br><span class="line">        <span class="string">"""Precision metric.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Only computes a batch-wise average of precision.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Computes the precision, a metric for multi-label classification of</span></span><br><span class="line"><span class="string">        how many selected items are relevant.</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        true_positives = K.sum(K.round(K.clip(y_true * y_pred, <span class="number">0</span>, <span class="number">1</span>)))</span><br><span class="line">        predicted_positives = K.sum(K.round(K.clip(y_pred, <span class="number">0</span>, <span class="number">1</span>)))</span><br><span class="line">        precision = true_positives / (predicted_positives + K.epsilon())</span><br><span class="line">        <span class="keyword">return</span> precision</span><br><span class="line">    precision = precision(y_true, y_pred)</span><br><span class="line">    recall = recall(y_true, y_pred)</span><br><span class="line">    <span class="keyword">return</span> <span class="number">2</span>*((precision*recall)/(precision+recall+K.epsilon()))</span><br></pre></td></tr></tbody></table></figure>
使用的时候：<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line">model.compile(</span><br><span class="line">        loss=<span class="string">'binary_crossentropy'</span>,</span><br><span class="line">        optimizer=adam,metrics=[F1])</span><br><span class="line">    print(model.summary())</span><br></pre></td></tr></tbody></table></figure>
<h3 id="Keras-Attention-Layer" class="heading-control"><a href="#Keras-Attention-Layer" class="headerlink" title="Keras Attention Layer"></a>Keras Attention Layer<a class="heading-anchor" href="#Keras-Attention-Layer" aria-hidden="true"></a></h3><figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Attention</span>(<span class="params">Layer</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, step_dim,</span></span></span><br><span class="line"><span class="function"><span class="params">                 W_regularizer=None, b_regularizer=None,</span></span></span><br><span class="line"><span class="function"><span class="params">                 W_constraint=None, b_constraint=None,</span></span></span><br><span class="line"><span class="function"><span class="params">                 bias=True, **kwargs</span>):</span></span><br><span class="line">        self.supports_masking = <span class="literal">True</span></span><br><span class="line">        <span class="comment"># self.init = initializations.get('glorot_uniform')</span></span><br><span class="line">        self.init = initializers.get(<span class="string">'glorot_uniform'</span>)</span><br><span class="line"></span><br><span class="line">        self.W_regularizer = regularizers.get(W_regularizer)</span><br><span class="line">        self.b_regularizer = regularizers.get(b_regularizer)</span><br><span class="line"></span><br><span class="line">        self.W_constraint = constraints.get(W_constraint)</span><br><span class="line">        self.b_constraint = constraints.get(b_constraint)</span><br><span class="line"></span><br><span class="line">        self.bias = bias</span><br><span class="line">        self.step_dim = step_dim</span><br><span class="line">        self.features_dim = <span class="number">0</span></span><br><span class="line">        super(Attention, self).__init__(**kwargs)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">build</span>(<span class="params">self, input_shape</span>):</span></span><br><span class="line">        <span class="keyword">assert</span> len(input_shape) == <span class="number">3</span></span><br><span class="line"></span><br><span class="line">        self.W = self.add_weight((input_shape[<span class="number">-1</span>],),</span><br><span class="line">                                 initializer=self.init,</span><br><span class="line">                                 name=<span class="string">'{}_W'</span>.format(self.name),</span><br><span class="line">                                 regularizer=self.W_regularizer,</span><br><span class="line">                                 constraint=self.W_constraint)</span><br><span class="line">        self.features_dim = input_shape[<span class="number">-1</span>]</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> self.bias:</span><br><span class="line">            self.b = self.add_weight((input_shape[<span class="number">1</span>],),</span><br><span class="line">                                     initializer=<span class="string">'zero'</span>,</span><br><span class="line">                                     name=<span class="string">'{}_b'</span>.format(self.name),</span><br><span class="line">                                     regularizer=self.b_regularizer,</span><br><span class="line">                                     constraint=self.b_constraint)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            self.b = <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">        self.built = <span class="literal">True</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">compute_mask</span>(<span class="params">self, input, input_mask=None</span>):</span></span><br><span class="line">        <span class="comment"># do not pass the mask to the next layers</span></span><br><span class="line">        <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">call</span>(<span class="params">self, x, mask=None</span>):</span></span><br><span class="line">        input_shape = K.int_shape(x)</span><br><span class="line"></span><br><span class="line">        features_dim = self.features_dim</span><br><span class="line">        <span class="comment"># step_dim = self.step_dim</span></span><br><span class="line">        step_dim = input_shape[<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">        eij = K.reshape(K.dot(K.reshape(x, (<span class="number">-1</span>, features_dim)), K.reshape(self.W, (features_dim, <span class="number">1</span>))), (<span class="number">-1</span>, step_dim))</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> self.bias:</span><br><span class="line">            eij += self.b[:input_shape[<span class="number">1</span>]]</span><br><span class="line"></span><br><span class="line">        eij = K.tanh(eij)</span><br><span class="line"></span><br><span class="line">        a = K.exp(eij)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># apply mask after the exp. will be re-normalized next</span></span><br><span class="line">        <span class="keyword">if</span> mask <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            <span class="comment"># Cast the mask to floatX to avoid float64 upcasting in theano</span></span><br><span class="line">            a *= K.cast(mask, K.floatx())</span><br><span class="line"></span><br><span class="line">        <span class="comment"># in some cases especially in the early stages of training the sum may be almost zero</span></span><br><span class="line">        <span class="comment"># and this results in NaN's. A workaround is to add a very small positive number ε to the sum.</span></span><br><span class="line">        a /= K.cast(K.sum(a, axis=<span class="number">1</span>, keepdims=<span class="literal">True</span>) + K.epsilon(), K.floatx())</span><br><span class="line"></span><br><span class="line">        a = K.expand_dims(a)</span><br><span class="line">        weighted_input = x * a</span><br><span class="line">    	<span class="comment"># print weigthted_input.shape</span></span><br><span class="line">        <span class="keyword">return</span> K.sum(weighted_input, axis=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">compute_output_shape</span>(<span class="params">self, input_shape</span>):</span></span><br><span class="line">        <span class="comment"># return input_shape[0], input_shape[-1]</span></span><br><span class="line">    	<span class="keyword">return</span> input_shape[<span class="number">0</span>], self.features_dim</span><br><span class="line"><span class="comment"># end Attention</span></span><br></pre></td></tr></tbody></table></figure>
<h3 id="加载IMDB电影评论数据集" class="heading-control"><a href="#加载IMDB电影评论数据集" class="headerlink" title="加载IMDB电影评论数据集"></a>加载 IMDB 电影评论数据集<a class="heading-anchor" href="#加载IMDB电影评论数据集" aria-hidden="true"></a></h3><figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">load_imdb_sentiment_analysis_dataset</span>(<span class="params">data_path, seed=<span class="number">123</span></span>):</span></span><br><span class="line">    <span class="string">"""Loads the IMDb movie reviews sentiment analysis dataset.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    # Arguments</span></span><br><span class="line"><span class="string">        data_path: string, path to the data directory.</span></span><br><span class="line"><span class="string">        seed: int, seed for randomizer.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    # Returns</span></span><br><span class="line"><span class="string">        A tuple of training and validation data.</span></span><br><span class="line"><span class="string">        Number of training samples: 25000</span></span><br><span class="line"><span class="string">        Number of test samples: 25000</span></span><br><span class="line"><span class="string">        Number of categories: 2 (0 - negative, 1 - positive)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    # References</span></span><br><span class="line"><span class="string">        Mass et al., http://www.aclweb.org/anthology/P11-1015</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Download and uncompress archive from:</span></span><br><span class="line"><span class="string">        http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    imdb_data_path = os.path.join(data_path, <span class="string">'aclImdb'</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Load the training data</span></span><br><span class="line">    train_texts = []</span><br><span class="line">    train_labels = []</span><br><span class="line">    <span class="keyword">for</span> category <span class="keyword">in</span> [<span class="string">'pos'</span>, <span class="string">'neg'</span>]:</span><br><span class="line">        train_path = os.path.join(imdb_data_path, <span class="string">'train'</span>, category)</span><br><span class="line">        <span class="keyword">for</span> fname <span class="keyword">in</span> sorted(os.listdir(train_path)):</span><br><span class="line">            <span class="keyword">if</span> fname.endswith(<span class="string">'.txt'</span>):</span><br><span class="line">                <span class="keyword">with</span> open(os.path.join(train_path, fname)) <span class="keyword">as</span> f:</span><br><span class="line">                    train_texts.append(f.read())</span><br><span class="line">                train_labels.append(<span class="number">0</span> <span class="keyword">if</span> category == <span class="string">'neg'</span> <span class="keyword">else</span> <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Load the validation data.</span></span><br><span class="line">    test_texts = []</span><br><span class="line">    test_labels = []</span><br><span class="line">    <span class="keyword">for</span> category <span class="keyword">in</span> [<span class="string">'pos'</span>, <span class="string">'neg'</span>]:</span><br><span class="line">        test_path = os.path.join(imdb_data_path, <span class="string">'test'</span>, category)</span><br><span class="line">        <span class="keyword">for</span> fname <span class="keyword">in</span> sorted(os.listdir(test_path)):</span><br><span class="line">            <span class="keyword">if</span> fname.endswith(<span class="string">'.txt'</span>):</span><br><span class="line">                <span class="keyword">with</span> open(os.path.join(test_path, fname)) <span class="keyword">as</span> f:</span><br><span class="line">                    test_texts.append(f.read())</span><br><span class="line">                test_labels.append(<span class="number">0</span> <span class="keyword">if</span> category == <span class="string">'neg'</span> <span class="keyword">else</span> <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Shuffle the training data and labels.</span></span><br><span class="line">    random.seed(seed)</span><br><span class="line">    random.shuffle(train_texts)</span><br><span class="line">    random.seed(seed)</span><br><span class="line">    random.shuffle(train_labels)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> ((train_texts, np.array(train_labels)),</span><br><span class="line">            (test_texts, np.array(test_labels)))</span><br></pre></td></tr></tbody></table></figure>
<h3 id="Keras-EarlyStopping" class="heading-control"><a href="#Keras-EarlyStopping" class="headerlink" title="Keras EarlyStopping"></a>Keras EarlyStopping<a class="heading-anchor" href="#Keras-EarlyStopping" aria-hidden="true"></a></h3><figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> keras.callbacks <span class="keyword">import</span> EarlyStopping</span><br><span class="line">early_stopping = EarlyStopping(monitor=<span class="string">'val_loss'</span>, patience=<span class="number">3</span>)</span><br><span class="line"></span><br><span class="line">model.fit(x_train, y_train,</span><br><span class="line">          batch_size=batch_size,</span><br><span class="line">          epochs=train_epochs,</span><br><span class="line">          validation_data=(x_val, y_val),verbose = <span class="number">2</span>,</span><br><span class="line">          callbacks=[early_stopping])</span><br></pre></td></tr></tbody></table></figure></li>
</ol>
<ul>
<li>monitor: 需要监视的量，val_loss，val_acc</li>
<li>patience: 当 early stop 被激活 (如发现 loss 相比上一个 epoch 训练没有下降)，则经过 - —patience 个 epoch 后停止训练</li>
<li> verbose: 信息展示模式，默认为 1，显示详细信息，2 是一轮显示最终信息，0 是不显示。</li>
<li>mode: ‘auto’,’min’,’max’之一，在 min 模式训练，如果检测值停止下降则终止训练。在 max 模式下，当检测值不再上升的时候则停止训练。</li>
</ul>
</blockquote>
<h3 id="Keras-Adam默认参数" class="heading-control"><a href="#Keras-Adam默认参数" class="headerlink" title="Keras Adam默认参数"></a>Keras Adam 默认参数<a class="heading-anchor" href="#Keras-Adam默认参数" aria-hidden="true"></a></h3><p>Adam 优化器由 Kingma 和 Lei Ba 在 Adam: A method for stochasticoptimization。默认参数是文章中建议的。<br></p><figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line">keras.optimizers.Adam(lr=<span class="number">0.001</span>, beta_1=<span class="number">0.9</span>, beta_2=<span class="number">0.999</span>, epsilon=<span class="number">1e-8</span>, kappa=<span class="number">1</span><span class="number">-1e-8</span>)</span><br></pre></td></tr></tbody></table></figure><br>可以在模型early_stopping后换用低一点的学习率继续训练两个epoch。<p></p>
<h2 id="一些经验" class="heading-control"><a href="#一些经验" class="headerlink" title="一些经验"></a>一些经验<a class="heading-anchor" href="#一些经验" aria-hidden="true"></a></h2><ol>
<li>在</li>
</ol>
<h2 id="Reference" class="heading-control"><a href="#Reference" class="headerlink" title="Reference"></a>Reference<a class="heading-anchor" href="#Reference" aria-hidden="true"></a></h2><ul>
<li><a href="https://blog.keras.io/using-pre-trained-word-embeddings-in-a-keras-model.html">Using pre-trained word embeddings in a Keras model</a></li>
</ul>
</body></html>]]></content>
  </entry>
  <entry>
    <title>你画我猜</title>
    <url>/post/50938.html</url>
    <content><![CDATA[<html><head><link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script></head><body><h2 id="介绍" class="heading-control"><a href="#介绍" class="headerlink" title="介绍"></a>介绍<a class="heading-anchor" href="#介绍" aria-hidden="true"></a></h2><p>Quick Draw 数据集是一个包含 5000 万张图画的集合，分成了 345 个类别，这些图画都来自于 Quick, Draw! 游戏的玩家。<br><img src="https://i.loli.net/2018/11/02/5bdc31e0a45e4.png" alt><br><a id="more"></a></p>
<h2 id="资源" class="heading-control"><a href="#资源" class="headerlink" title="资源"></a>资源<a class="heading-anchor" href="#资源" aria-hidden="true"></a></h2><ul>
<li><p>数据集地址：<a href="https://console.cloud.google.com/storage/browser/quickdraw_dataset/full/?pli=1">https://console.cloud.google.com/storage/browser/quickdraw_dataset/full/?pli=1</a></p>
</li>
<li><p> 数据集官网：<a href="https://quickdraw.withgoogle.com/data">https://quickdraw.withgoogle.com/data</a></p>
</li>
<li><p>Quick, Draw! 在线体验：<a href="https://quickdraw.withgoogle.com">https://quickdraw.withgoogle.com</a></p>
</li>
<li><p>AutoDraw 在线体验：<a href="https://www.autodraw.com">https://www.autodraw.com</a></p>
</li>
<li><p> 相关论文：<a href="https://arxiv.org/abs/1704.03477">https://arxiv.org/abs/1704.03477</a></p>
</li>
</ul>
<h2 id="模型压缩" class="heading-control"><a href="#模型压缩" class="headerlink" title="模型压缩"></a>模型压缩<a class="heading-anchor" href="#模型压缩" aria-hidden="true"></a></h2><p>自从 AlexNet 一举夺得 ILSVRC 2012 ImageNet 图像分类竞赛的冠军后，卷积神经网络（CNN）的热潮便席卷了整个计算机视觉领域。CNN 模型火速替代了传统人工设计（hand-crafted）特征和分类器，不仅提供了一种端到端的处理方法，还大幅度地刷新了各个图像竞赛任务的精度，更甚者超越了人眼的精度（LFW 人脸识别任务）。CNN 模型在不断逼近计算机视觉任务的精度极限的同时，其深度和尺寸也在成倍增长。<br>所有模型压缩方法的核心思想是 —— 在保证精度的同时使用最少的参数。</p>
<p>下面是几种经典模型的尺寸和参数数量对比：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">Model</th>
<th style="text-align:center">Model Size(MB)</th>
<th style="text-align:center"> 参数 (百万)</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">AlexNet</td>
<td style="text-align:center">>200</td>
<td style="text-align:center">60</td>
</tr>
<tr>
<td style="text-align:center">VGG16</td>
<td style="text-align:center">>500</td>
<td style="text-align:center">138</td>
</tr>
<tr>
<td style="text-align:center">GoogleNet</td>
<td style="text-align:center">~50</td>
<td style="text-align:center">6.8</td>
</tr>
<tr>
<td style="text-align:center">Inception-v3</td>
<td style="text-align:center">90~100</td>
<td style="text-align:center">23.2</td>
</tr>
</tbody>
</table>
</div>
<p>随之而来的是一个很尴尬的场景：如此巨大的模型只能在有限的平台下使用，根本无法移植到移动端和嵌入式芯片当中。就算想通过网络传输，但较高的带宽占用也让很多用户望而生畏。另一方面，大尺寸的模型也对设备功耗和运行速度带来了巨大的挑战。因此这样的模型距离实用还有一段距离。</p>
<p>在这样的情形下，模型小型化与加速成了亟待解决的问题。其实早期就有学者提出了一系列 CNN 模型压缩方法，包括权值剪值（prunning）和矩阵 SVD 分解等，但压缩率和效率还远不能令人满意。</p>
<p>近年来，关于模型小型化的算法从压缩角度上可以大致分为两类：从模型权重数值角度压缩和从网络架构角度压缩。另一方面，从兼顾计算速度方面，又可以划分为：仅压缩尺寸和压缩尺寸的同时提升速度。</p>
<h3 id="GAP替换全连接" class="heading-control"><a href="#GAP替换全连接" class="headerlink" title="GAP替换全连接"></a>GAP 替换全连接<a class="heading-anchor" href="#GAP替换全连接" aria-hidden="true"></a></h3><p>Golbal Average Pooling 第一次出现在论文 Network in Network 中，后来又很多工作延续使用了 GAP，实验证明：Global Average Pooling 确实可以提高 CNN 效果。</p>
<h4 id="Fully-Connected-layer" class="heading-control"><a href="#Fully-Connected-layer" class="headerlink" title="Fully Connected layer"></a>Fully Connected layer<a class="heading-anchor" href="#Fully-Connected-layer" aria-hidden="true"></a></h4><p>很长一段时间以来，全连接网络一直是 CNN 分类网络的标配结构。一般在全连接后会有激活函数来做分类，假设这个激活函数是一个多分类 softmax，那么全连接网络的作用就是将最后一层卷积得到的 feature map stretch 成向量，对这个向量做乘法，最终降低其维度，然后输入到 softmax 层中得到对应的每个类别的得分。</p>
<p>全连接层如此的重要，以至于全连接层过多的参数重要到会造成过拟合，所以也会有一些方法专门用来解决过拟合，比如 dropout。</p>
<h4 id="Global-Average-Pooling" class="heading-control"><a href="#Global-Average-Pooling" class="headerlink" title="Global Average Pooling"></a>Global Average Pooling<a class="heading-anchor" href="#Global-Average-Pooling" aria-hidden="true"></a></h4><p>既然全连接网络可以使 feature map 的维度减少，进而输入到 softmax，但是又会造成过拟合，是不是可以用 pooling 来代替全连接。</p>
<p>答案是肯定的，Network in Network 工作使用 GAP 来取代了最后的全连接层，直接实现了降维，更重要的是极大地减少了网络的参数 (CNN 网络中占比最大的参数其实后面的全连接层)。Global average pooling 的结构如下图所示:<br><img src="https://i.loli.net/2018/11/02/5bdc264ade394.png" alt><br>GAP 的意义是对整个网络从结构上做正则化防止过拟合。既要参数少避免全连接带来的过拟合风险，又要能达到全连接一样的转换功能，怎么做呢？直接从 feature map 的通道上下手，如果我们最终有 1000 类，那么最后一层卷积输出的 feature map 就只有 1000 个 channel，然后对这个 feature map 应用全局池化，输出长度为 1000 的向量，这就相当于剔除了全连接层黑箱子操作的特征，直接赋予了每个 channel 实际的类别意义。<br><img src="https://i.loli.net/2018/11/04/5bded5243aa18.png" alt><br>实验证明，这种方法是非常有效的，这样做还有另外一个好处：不用在乎网络输入的图像尺寸。同时需要注意的是，使用 gap 也有可能造成收敛变慢。</p>
<h4 id="Reference" class="heading-control"><a href="#Reference" class="headerlink" title="Reference"></a>Reference<a class="heading-anchor" href="#Reference" aria-hidden="true"></a></h4><ul>
<li><a href="https://arxiv.org/abs/1312.4400">Network In Network</a></li>
<li><a href="http://blog.leanote.com/post/sunalbert/Global-average-pooling">Global Average Pooling</a></li>
</ul>
<h3 id="SqueezeNet" class="heading-control"><a href="#SqueezeNet" class="headerlink" title="SqueezeNet"></a>SqueezeNet<a class="heading-anchor" href="#SqueezeNet" aria-hidden="true"></a></h3><p>SqueezeNet 是 F. N. Iandola,S.Han 等人于 2016 年的论文《SqueezeNet: AlexNet-level accuracy with 50x fewer parameters and < 0.5MB model size》中提出的一个小型化的网络模型结构，该网络能在保证不损失精度的同时，将原始 AlexNet 压缩至原来的 510 倍左右（< 0.5MB）。</p>
<p>SqueezeNet 提出了 3 点网络结构设计策略：</p>
<ul>
<li><p>策略 1. 将 3x3 卷积核替换为 1x1 卷积核。<br>这一策略很好理解，因为 1 个 1x1 卷积核的参数是 3x3 卷积核参数的 1/9，这一改动理论上可以将模型尺寸压缩 9 倍。</p>
</li>
<li><p>策略 2. 减小输入到 3x3 卷积核的输入通道数。<br>我们知道，对于一个采用 3x3 卷积核的卷积层，该层所有卷积参数的数量（不考虑偏置）为：</p>
<script type="math/tex; mode=display">
\begin{equation}
P=N*C*3*3
\end{equation}</script><p>式中，N 是卷积核的数量，也即输出通道数，C 是输入通道数。<br>因此，为了保证减小网络参数，不仅仅需要减少 3x3 卷积核的数量，还需减少输入到 3x3 卷积核的输入通道数量，即式中 C 的数量。</p>
</li>
<li><p>策略 3. 尽可能的将降采样放在网络后面的层中。<br>在卷积神经网络中，每层输出的特征图（feature map）是否下采样是由卷积层的步长或者池化层决定的。而一个重要的观点是：分辨率越大的特征图（延迟降采样）可以带来更高的分类精度，而这一观点从直觉上也可以很好理解，因为分辨率越大的输入能够提供的信息就越多。</p>
</li>
</ul>
<p>下面举一个例子，假如输入为 28×28×192，输出 feature map 通道数为 128。那么，直接接 3×3 卷积，参数量为 3×3×192×128=221184。</p>
<p>如果先用 1×1 卷积进行降维到 96 个通道，然后再用 3×3 升维到 128，则参数量为：1×1×192×96+3×3×96×128=129024，参数量减少一半。虽然参数量减少不是很明显，但是如果 1×1 输出维度降低到 48 呢？则参数量又减少一半。</p>
<p><img src="https://i.loli.net/2018/11/02/5bdc3041c78b3.png" alt><br>实验结果：<br><img src="https://i.loli.net/2018/11/02/5bdc307dca994.png" alt><br>总结一句，可以先使用 1x1 的卷积降低通道数，然后再用 3x3 卷积升维，参数量可以大大减小。</p>
<h2 id="实际建模" class="heading-control"><a href="#实际建模" class="headerlink" title="实际建模"></a>实际建模<a class="heading-anchor" href="#实际建模" aria-hidden="true"></a></h2><p><a href="https://pacinoyan.github.io/">游戏网址</a>在这里。<br><img src="https://i.loli.net/2018/12/06/5c090e8c8ea6a.png" alt></p>
<h3 id="简单的CNN模型" class="heading-control"><a href="#简单的CNN模型" class="headerlink" title="简单的CNN模型"></a>简单的 CNN 模型<a class="heading-anchor" href="#简单的CNN模型" aria-hidden="true"></a></h3><p>模型架构如下：<br><img src="https://i.loli.net/2018/11/04/5bded577194ee.png" alt><br>训练结果：(参数：110,052 Test accuarcy: 92.92% 大小：401KB)</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">TensorBoard</th>
<th style="text-align:center"> 训练集</th>
<th style="text-align:center">验证集</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">误差</td>
<td style="text-align:center"><img src="https://i.loli.net/2018/11/04/5bded8dd0b6f5.png" alt></td>
<td style="text-align:center"><img src="https://i.loli.net/2018/11/04/5bded8dc0ea7c.png" alt></td>
</tr>
<tr>
<td style="text-align:center">正确率</td>
<td style="text-align:center"><img src="https://i.loli.net/2018/11/04/5bded8dc0f29e.png" alt></td>
<td style="text-align:center"><img src="https://i.loli.net/2018/11/04/5bded8dc0e437.png" alt></td>
</tr>
</tbody>
</table>
</div>
<h3 id="先1后3" class="heading-control"><a href="#先1后3" class="headerlink" title="先1后3"></a>先 1 后 3<a class="heading-anchor" href="#先1后3" aria-hidden="true"></a></h3><p>模型架构如下：<br><img src="https://i.loli.net/2018/11/04/5bdecf2d9a4e1.png" alt><br>训练结果:（参数：106,236  Test accuarcy: 92.64% 大小：387KB）</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">TensorBoard</th>
<th style="text-align:center"> 训练集</th>
<th style="text-align:center">验证集</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">误差</td>
<td style="text-align:center"><img src="https://i.loli.net/2018/11/04/5bded14c0663a.png" alt></td>
<td style="text-align:center"><img src="https://i.loli.net/2018/11/04/5bded1afd038a.png" alt></td>
</tr>
<tr>
<td style="text-align:center">正确率</td>
<td style="text-align:center"><img src="https://i.loli.net/2018/11/04/5bded17296c6e.png" alt></td>
<td style="text-align:center"><img src="https://i.loli.net/2018/11/04/5bded1afd118f.png" alt></td>
</tr>
</tbody>
</table>
</div>
<h3 id="GAP" class="heading-control"><a href="#GAP" class="headerlink" title="GAP"></a>GAP<a class="heading-anchor" href="#GAP" aria-hidden="true"></a></h3><p>模型架构如下：<br><img src="https://i.loli.net/2018/11/04/5bdee438c7530.png" alt><br>训练结果:（参数：29,796 Test accuarcy: 88.82%(20 轮：90.88%) 大小：110KB）</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">TensorBoard</th>
<th style="text-align:center"> 训练集</th>
<th style="text-align:center">验证集</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">误差</td>
<td style="text-align:center"><img src="https://i.loli.net/2018/11/04/5bdee51a2d5c8.png" alt></td>
<td style="text-align:center"><img src="https://i.loli.net/2018/11/04/5bdee519ca278.png" alt></td>
</tr>
<tr>
<td style="text-align:center">正确率</td>
<td style="text-align:center"><img src="https://i.loli.net/2018/11/04/5bdee5199ca9c.png" alt></td>
<td style="text-align:center"><img src="https://i.loli.net/2018/11/04/5bdee519eaccd.png" alt></td>
</tr>
</tbody>
</table>
</div>
<h3 id="总结对比" class="heading-control"><a href="#总结对比" class="headerlink" title="总结对比"></a>总结对比<a class="heading-anchor" href="#总结对比" aria-hidden="true"></a></h3><p>下面是各方法在相同参数情况下，10 轮训练后的表现：<br>在简单 CNN 上：<br><img src="https://i.loli.net/2018/12/06/5c090fcf8ffb6.png" alt><br>在 LeNet 上：<br><img src="https://i.loli.net/2018/12/06/5c090fcfc2a16.png" alt><br>可以看出 GAP 的压缩比最高，但是也是收敛速度最慢的；K1K3 压缩表现不佳，主要原因是两个基本模型的 Feature Map 的数量都不够多，如果卷积层数达到 100 层以上可能效果会非常明显。</p>
<h3 id="代码" class="heading-control"><a href="#代码" class="headerlink" title="代码"></a>代码<a class="heading-anchor" href="#代码" aria-hidden="true"></a></h3><figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> tqdm <span class="keyword">import</span> tqdm</span><br><span class="line"><span class="keyword">import</span> keras</span><br><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> layers</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> joblib <span class="keyword">import</span> dump,load</span><br><span class="line"><span class="keyword">from</span> keras.callbacks <span class="keyword">import</span> TensorBoard</span><br><span class="line"><span class="keyword">from</span> keras.applications <span class="keyword">import</span> MobileNetV2</span><br><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> layers</span><br><span class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> Model</span><br><span class="line"><span class="keyword">from</span> keras.optimizers <span class="keyword">import</span> SGD</span><br><span class="line"></span><br><span class="line">root = <span class="string">'/media/sunyan/文档/data'</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">load_data</span>(<span class="params">root, vfold_ratio=<span class="number">0.2</span>, max_items_per_class=<span class="number">4000</span></span>):</span></span><br><span class="line">    all_files = os.listdir(root)</span><br><span class="line">    files_paths = [os.path.join(root,i) <span class="keyword">for</span> i <span class="keyword">in</span> all_files]</span><br><span class="line">    <span class="comment"># initialize variables</span></span><br><span class="line">    x = np.empty([<span class="number">0</span>, <span class="number">784</span>])</span><br><span class="line">    y = np.empty([<span class="number">0</span>])</span><br><span class="line">    class_names = []</span><br><span class="line"></span><br><span class="line">    <span class="comment"># load each data file</span></span><br><span class="line">    <span class="keyword">for</span> idx, file <span class="keyword">in</span> enumerate(tqdm(files_paths)):</span><br><span class="line">        data = np.load(file)</span><br><span class="line">        data = data[<span class="number">0</span>: max_items_per_class, :]</span><br><span class="line">        labels = np.full(data.shape[<span class="number">0</span>], idx)</span><br><span class="line"></span><br><span class="line">        x = np.concatenate((x, data), axis=<span class="number">0</span>)</span><br><span class="line">        y = np.append(y, labels)</span><br><span class="line"></span><br><span class="line">        class_name, ext = os.path.splitext(os.path.basename(file))</span><br><span class="line">        class_names.append(class_name)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># randomize the dataset</span></span><br><span class="line">    permutation = np.random.permutation(y.shape[<span class="number">0</span>])</span><br><span class="line">    x = x[permutation, :]</span><br><span class="line">    y = y[permutation]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># separate into training and testing</span></span><br><span class="line">    vfold_size = int(x.shape[<span class="number">0</span>] / <span class="number">100</span> * (vfold_ratio * <span class="number">100</span>))</span><br><span class="line"></span><br><span class="line">    x_test = x[<span class="number">0</span>:vfold_size, :]</span><br><span class="line">    y_test = y[<span class="number">0</span>:vfold_size]</span><br><span class="line"></span><br><span class="line">    x_train = x[vfold_size:x.shape[<span class="number">0</span>], :]</span><br><span class="line">    y_train = y[vfold_size:y.shape[<span class="number">0</span>]]</span><br><span class="line">    <span class="keyword">return</span> x_train, y_train, x_test, y_test, class_names</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">build_model</span>():</span></span><br><span class="line">    <span class="comment"># Define model</span></span><br><span class="line">    model = keras.Sequential()</span><br><span class="line">    model.add(layers.Convolution2D(<span class="number">16</span>, (<span class="number">3</span>, <span class="number">3</span>),</span><br><span class="line">                                   padding=<span class="string">'same'</span>,</span><br><span class="line">                                   input_shape=x_train.shape[<span class="number">1</span>:], activation=<span class="string">'relu'</span>))</span><br><span class="line">    model.add(layers.MaxPooling2D(pool_size=(<span class="number">2</span>, <span class="number">2</span>)))</span><br><span class="line">    model.add(layers.Convolution2D(<span class="number">32</span>, (<span class="number">3</span>, <span class="number">3</span>), padding=<span class="string">'same'</span>, activation=<span class="string">'relu'</span>))</span><br><span class="line">    model.add(layers.MaxPooling2D(pool_size=(<span class="number">2</span>, <span class="number">2</span>)))</span><br><span class="line">    model.add(layers.Convolution2D(<span class="number">64</span>, (<span class="number">3</span>, <span class="number">3</span>), padding=<span class="string">'same'</span>, activation=<span class="string">'relu'</span>))</span><br><span class="line">    model.add(layers.MaxPooling2D(pool_size=(<span class="number">2</span>, <span class="number">2</span>)))</span><br><span class="line">    model.add(layers.Flatten())</span><br><span class="line">    model.add(layers.Dense(<span class="number">128</span>, activation=<span class="string">'relu'</span>))</span><br><span class="line">    model.add(layers.Dense(<span class="number">100</span>, activation=<span class="string">'softmax'</span>))</span><br><span class="line">    <span class="comment"># Train model</span></span><br><span class="line">    model.compile(loss=<span class="string">'categorical_crossentropy'</span>,</span><br><span class="line">                  optimizer=<span class="string">'adam'</span>,</span><br><span class="line">                  metrics=[<span class="string">'top_k_categorical_accuracy'</span>])</span><br><span class="line">    print(model.summary())</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> model</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">gap_model</span>():</span></span><br><span class="line">    <span class="comment"># Define model</span></span><br><span class="line">    model = keras.Sequential()</span><br><span class="line">    model.add(layers.Convolution2D(<span class="number">16</span>, (<span class="number">3</span>, <span class="number">3</span>),</span><br><span class="line">                                   padding=<span class="string">'same'</span>,</span><br><span class="line">                                   input_shape=x_train.shape[<span class="number">1</span>:], activation=<span class="string">'relu'</span>))</span><br><span class="line">    model.add(layers.MaxPooling2D(pool_size=(<span class="number">2</span>, <span class="number">2</span>)))</span><br><span class="line">    model.add(layers.Convolution2D(<span class="number">32</span>, (<span class="number">3</span>, <span class="number">3</span>), padding=<span class="string">'same'</span>, activation=<span class="string">'relu'</span>))</span><br><span class="line">    model.add(layers.MaxPooling2D(pool_size=(<span class="number">2</span>, <span class="number">2</span>)))</span><br><span class="line">    model.add(layers.Convolution2D(<span class="number">64</span>, (<span class="number">3</span>, <span class="number">3</span>), padding=<span class="string">'same'</span>, activation=<span class="string">'relu'</span>))</span><br><span class="line">    model.add(layers.MaxPooling2D(pool_size=(<span class="number">2</span>, <span class="number">2</span>)))</span><br><span class="line">    model.add(layers.GlobalAveragePooling2D())</span><br><span class="line">    model.add(layers.Dense(<span class="number">100</span>, activation=<span class="string">'softmax'</span>))</span><br><span class="line">    <span class="comment"># Train model</span></span><br><span class="line">    model.compile(loss=<span class="string">'categorical_crossentropy'</span>,</span><br><span class="line">                  optimizer=<span class="string">'adam'</span>,</span><br><span class="line">                  metrics=[<span class="string">'top_k_categorical_accuracy'</span>])</span><br><span class="line">    print(model.summary())</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> model</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">one2three_model</span>():</span></span><br><span class="line">    model = keras.Sequential()</span><br><span class="line">    model.add(layers.Convolution2D(<span class="number">16</span>, (<span class="number">3</span>, <span class="number">3</span>),padding=<span class="string">'same'</span>,</span><br><span class="line">                                   input_shape=x_train.shape[<span class="number">1</span>:], activation=<span class="string">'relu'</span>))</span><br><span class="line">    model.add(layers.MaxPooling2D(pool_size=(<span class="number">2</span>, <span class="number">2</span>)))</span><br><span class="line">    model.add(layers.Convolution2D(<span class="number">32</span>, (<span class="number">3</span>, <span class="number">3</span>), padding=<span class="string">'same'</span>, activation=<span class="string">'relu'</span>))</span><br><span class="line">    model.add(layers.MaxPooling2D(pool_size=(<span class="number">2</span>, <span class="number">2</span>)))</span><br><span class="line">    model.add(layers.Convolution2D(<span class="number">24</span>, (<span class="number">1</span>, <span class="number">1</span>), padding=<span class="string">'same'</span>, activation=<span class="string">'relu'</span>))</span><br><span class="line">    model.add(layers.Convolution2D(<span class="number">64</span>, (<span class="number">3</span>, <span class="number">3</span>), padding=<span class="string">'same'</span>, activation=<span class="string">'relu'</span>))</span><br><span class="line">    model.add(layers.MaxPooling2D(pool_size=(<span class="number">2</span>, <span class="number">2</span>)))</span><br><span class="line">    model.add(layers.Flatten())</span><br><span class="line">    model.add(layers.Dense(<span class="number">128</span>, activation=<span class="string">'relu'</span>))</span><br><span class="line">    model.add(layers.Dense(<span class="number">100</span>, activation=<span class="string">'softmax'</span>))</span><br><span class="line">    <span class="comment"># Train model</span></span><br><span class="line">    model.compile(loss=<span class="string">'categorical_crossentropy'</span>,</span><br><span class="line">                  optimizer=<span class="string">'adam'</span>,</span><br><span class="line">                  metrics=[<span class="string">'top_k_categorical_accuracy'</span>])</span><br><span class="line">    print(model.summary())</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> model</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">lenet</span>():</span></span><br><span class="line">    model = keras.Sequential()</span><br><span class="line">    <span class="comment"># Layer 1: Convolutional. Input = 28x28x1. Output = 28x28x6.</span></span><br><span class="line">    model.add(keras.layers.Convolution2D(filters=<span class="number">6</span>, kernel_size=(<span class="number">5</span>, <span class="number">5</span>), strides=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                                         padding=<span class="string">'same'</span>, input_shape=x_train.shape[<span class="number">1</span>:], activation=<span class="string">'relu'</span>))</span><br><span class="line">    <span class="comment"># Pooling. Input = 28x28x6. Output = 14x14x6.</span></span><br><span class="line">    model.add(keras.layers.MaxPooling2D(pool_size=(<span class="number">2</span>, <span class="number">2</span>), strides=<span class="number">2</span>, padding=<span class="string">'valid'</span>))</span><br><span class="line">    <span class="comment"># Layer 2: Convolutional. Output = 10x10x16.</span></span><br><span class="line">    model.add(keras.layers.Convolution2D(filters=<span class="number">16</span>, kernel_size=(<span class="number">5</span>, <span class="number">5</span>), strides=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                                         padding=<span class="string">'valid'</span>, activation=<span class="string">'relu'</span>))</span><br><span class="line">    <span class="comment"># Pooling. Input = 10x10x16. Output = 5x5x16.</span></span><br><span class="line">    model.add(keras.layers.MaxPooling2D(pool_size=(<span class="number">2</span>, <span class="number">2</span>), strides=<span class="number">2</span>, padding=<span class="string">'valid'</span>))</span><br><span class="line">    <span class="comment"># Flatten. Input = 5x5x16. Output = 400.</span></span><br><span class="line">    model.add(keras.layers.Flatten())</span><br><span class="line">    <span class="comment"># Layer 3: Fully Connected. Input = 400. Output = 300.</span></span><br><span class="line">    model.add(keras.layers.Dense(<span class="number">300</span>, activation=<span class="string">'relu'</span>))</span><br><span class="line">    <span class="comment"># Layer 4: Fully Connected. Input = 300. Output = 200.</span></span><br><span class="line">    model.add(keras.layers.Dense(<span class="number">200</span>, activation=<span class="string">'relu'</span>))</span><br><span class="line">    <span class="comment"># Layer 5: Fully Connected. Input = 200. Output = 100.</span></span><br><span class="line">    model.add(keras.layers.Dense(<span class="number">100</span>, activation=<span class="string">'softmax'</span>))</span><br><span class="line">    <span class="comment"># Train model</span></span><br><span class="line">    model.compile(loss=<span class="string">'categorical_crossentropy'</span>,</span><br><span class="line">                  optimizer=<span class="string">'adam'</span>,</span><br><span class="line">                  metrics=[<span class="string">'top_k_categorical_accuracy'</span>])</span><br><span class="line">    print(model.summary())</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> model</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">lenet_one2three</span>():</span></span><br><span class="line">    model = keras.Sequential()</span><br><span class="line">    <span class="comment"># Layer 1: Convolutional. Input = 28x28x1. Output = 28x28x6.</span></span><br><span class="line">    model.add(keras.layers.Convolution2D(filters=<span class="number">6</span>, kernel_size=(<span class="number">5</span>, <span class="number">5</span>), strides=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                                         padding=<span class="string">'same'</span>, input_shape=x_train.shape[<span class="number">1</span>:], activation=<span class="string">'relu'</span>))</span><br><span class="line">    <span class="comment"># Pooling. Input = 28x28x6. Output = 14x14x6.</span></span><br><span class="line">    model.add(keras.layers.MaxPooling2D(pool_size=(<span class="number">2</span>, <span class="number">2</span>), strides=<span class="number">2</span>, padding=<span class="string">'valid'</span>))</span><br><span class="line">    <span class="comment"># Layer 2: Convolutional. Output = 10x10x16.</span></span><br><span class="line">    model.add(layers.Convolution2D(<span class="number">3</span>, kernel_size=(<span class="number">1</span>, <span class="number">1</span>), strides=(<span class="number">1</span>, <span class="number">1</span>),padding=<span class="string">'same'</span>, activation=<span class="string">'relu'</span>))</span><br><span class="line">    model.add(keras.layers.Convolution2D(filters=<span class="number">16</span>, kernel_size=(<span class="number">5</span>, <span class="number">5</span>), strides=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                                         padding=<span class="string">'valid'</span>, activation=<span class="string">'relu'</span>))</span><br><span class="line">    <span class="comment"># Pooling. Input = 10x10x16. Output = 5x5x16.</span></span><br><span class="line">    model.add(keras.layers.MaxPooling2D(pool_size=(<span class="number">2</span>, <span class="number">2</span>), strides=<span class="number">2</span>, padding=<span class="string">'valid'</span>))</span><br><span class="line">    <span class="comment"># Flatten. Input = 5x5x16. Output = 400.</span></span><br><span class="line">    model.add(keras.layers.Flatten())</span><br><span class="line">    <span class="comment"># Layer 3: Fully Connected. Input = 400. Output = 300.</span></span><br><span class="line">    model.add(keras.layers.Dense(<span class="number">300</span>, activation=<span class="string">'relu'</span>))</span><br><span class="line">    <span class="comment"># Layer 4: Fully Connected. Input = 300. Output = 200.</span></span><br><span class="line">    model.add(keras.layers.Dense(<span class="number">200</span>, activation=<span class="string">'relu'</span>))</span><br><span class="line">    <span class="comment"># Layer 5: Fully Connected. Input = 200. Output = 100.</span></span><br><span class="line">    model.add(keras.layers.Dense(<span class="number">100</span>, activation=<span class="string">'softmax'</span>))</span><br><span class="line">    <span class="comment"># Train model</span></span><br><span class="line">    model.compile(loss=<span class="string">'categorical_crossentropy'</span>,</span><br><span class="line">                  optimizer=<span class="string">'adam'</span>,</span><br><span class="line">                  metrics=[<span class="string">'top_k_categorical_accuracy'</span>])</span><br><span class="line">    print(model.summary())</span><br><span class="line">    <span class="keyword">return</span> model</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">lenet_gap</span>():</span></span><br><span class="line">    model = keras.Sequential()</span><br><span class="line">    <span class="comment"># Layer 1: Convolutional. Input = 28x28x1. Output = 28x28x6.</span></span><br><span class="line">    model.add(keras.layers.Convolution2D(filters=<span class="number">6</span>, kernel_size=(<span class="number">5</span>, <span class="number">5</span>), strides=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                                         padding=<span class="string">'same'</span>, input_shape=x_train.shape[<span class="number">1</span>:], activation=<span class="string">'relu'</span>))</span><br><span class="line">    <span class="comment"># Pooling. Input = 28x28x6. Output = 14x14x6.</span></span><br><span class="line">    model.add(keras.layers.MaxPooling2D(pool_size=(<span class="number">2</span>, <span class="number">2</span>), strides=<span class="number">2</span>, padding=<span class="string">'valid'</span>))</span><br><span class="line">    <span class="comment"># Layer 2: Convolutional. Output = 10x10x16.</span></span><br><span class="line">    model.add(keras.layers.Convolution2D(filters=<span class="number">16</span>, kernel_size=(<span class="number">5</span>, <span class="number">5</span>), strides=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                                         padding=<span class="string">'valid'</span>, activation=<span class="string">'relu'</span>))</span><br><span class="line">    <span class="comment"># Pooling. Input = 10x10x16. Output = 5x5x16.</span></span><br><span class="line">    model.add(keras.layers.MaxPooling2D(pool_size=(<span class="number">2</span>, <span class="number">2</span>), strides=<span class="number">2</span>, padding=<span class="string">'valid'</span>))</span><br><span class="line">    model.add(layers.GlobalAveragePooling2D())</span><br><span class="line">    <span class="comment"># Layer 5: Fully Connected. Input = 200. Output = 100.</span></span><br><span class="line">    model.add(keras.layers.Dense(<span class="number">64</span>,activation=<span class="string">'relu'</span>))</span><br><span class="line">    model.add(keras.layers.Dense(<span class="number">100</span>, activation=<span class="string">'softmax'</span>))</span><br><span class="line">    <span class="comment"># Train model</span></span><br><span class="line">    model.compile(loss=<span class="string">'categorical_crossentropy'</span>,</span><br><span class="line">                  optimizer=<span class="string">'adam'</span>,</span><br><span class="line">                  metrics=[<span class="string">'top_k_categorical_accuracy'</span>])</span><br><span class="line">    print(model.summary())</span><br><span class="line">    <span class="keyword">return</span> model</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">pickle_load</span>():</span></span><br><span class="line">    <span class="keyword">with</span> open(<span class="string">'x_train.pkl'</span>, <span class="string">'rb'</span>) <span class="keyword">as</span> f:</span><br><span class="line">        x_train= load(f)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">with</span> open(<span class="string">'y_train.pkl'</span>, <span class="string">'rb'</span>) <span class="keyword">as</span> f:</span><br><span class="line">        y_train = load(f)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">with</span> open(<span class="string">'x_test.pkl'</span>, <span class="string">'rb'</span>) <span class="keyword">as</span> f:</span><br><span class="line">        x_test = load(f)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">with</span> open(<span class="string">'y_test.pkl'</span>, <span class="string">'rb'</span>) <span class="keyword">as</span> f:</span><br><span class="line">        y_test = load(f)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">with</span> open(<span class="string">'class_names.pkl'</span>, <span class="string">'rb'</span>) <span class="keyword">as</span> f:</span><br><span class="line">        class_names = load(f)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> x_train, y_train, x_test, y_test, class_names</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    <span class="comment"># x_train, y_train, x_test, y_test, class_names = load_data(root=root)</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># with open('x_train.pkl', 'wb') as f:</span></span><br><span class="line">    <span class="comment">#     dump(x_train, f)</span></span><br><span class="line">    <span class="comment">#</span></span><br><span class="line">    <span class="comment"># with open('y_train.pkl', 'wb') as f:</span></span><br><span class="line">    <span class="comment">#     dump(y_train, f)</span></span><br><span class="line">    <span class="comment">#</span></span><br><span class="line">    <span class="comment"># with open('x_test.pkl', 'wb') as f:</span></span><br><span class="line">    <span class="comment">#     dump(x_test, f)</span></span><br><span class="line">    <span class="comment">#</span></span><br><span class="line">    <span class="comment"># with open('y_test.pkl', 'wb') as f:</span></span><br><span class="line">    <span class="comment">#     dump(y_test, f)</span></span><br><span class="line">    <span class="comment">#</span></span><br><span class="line">    <span class="comment"># with open('class_names.pkl', 'wb') as f:</span></span><br><span class="line">    <span class="comment">#     dump(class_names, f)</span></span><br><span class="line"></span><br><span class="line">    x_train, y_train, x_test, y_test, class_names = pickle_load()</span><br><span class="line"></span><br><span class="line">    num_classes = len(class_names)</span><br><span class="line">    image_size = <span class="number">28</span></span><br><span class="line">    print(len(x_train))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># import matplotlib.pyplot as plt</span></span><br><span class="line">    <span class="comment"># from random import randint</span></span><br><span class="line">    <span class="comment">#</span></span><br><span class="line">    <span class="comment"># idx = randint(0, len(x_train))</span></span><br><span class="line">    <span class="comment"># plt.imshow(x_train[idx].reshape(28, 28))</span></span><br><span class="line">    <span class="comment"># print(class_names[int(y_train[idx].item())])</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Reshape and normalize</span></span><br><span class="line">    x_train = x_train.reshape(x_train.shape[<span class="number">0</span>], image_size, image_size, <span class="number">1</span>).astype(<span class="string">'float32'</span>)</span><br><span class="line">    x_test = x_test.reshape(x_test.shape[<span class="number">0</span>], image_size, image_size, <span class="number">1</span>).astype(<span class="string">'float32'</span>)</span><br><span class="line"></span><br><span class="line">    x_train /= <span class="number">255.0</span></span><br><span class="line">    x_test /= <span class="number">255.0</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Convert class vectors to class matrices</span></span><br><span class="line">    y_train = keras.utils.to_categorical(y_train, num_classes)</span><br><span class="line">    y_test = keras.utils.to_categorical(y_test, num_classes)</span><br><span class="line"></span><br><span class="line">    model = lenet_one2three()</span><br><span class="line"></span><br><span class="line">    model.fit(x=x_train, y=y_train, validation_split=<span class="number">0.2</span>, batch_size=<span class="number">256</span>, verbose=<span class="number">2</span>, epochs=<span class="number">10</span>,callbacks=[TensorBoard(log_dir=<span class="string">'log'</span>)])</span><br><span class="line"></span><br><span class="line">    score = model.evaluate(x_test, y_test, verbose=<span class="number">0</span>)</span><br><span class="line">    print(<span class="string">'Test accuarcy: {:0.2f}%'</span>.format(score[<span class="number">1</span>] * <span class="number">100</span>))</span><br><span class="line"></span><br><span class="line">    model.save(<span class="string">'keras.h5'</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">with</span> open(<span class="string">'class_names.txt'</span>, <span class="string">'w'</span>) <span class="keyword">as</span> file_handler:</span><br><span class="line">        <span class="keyword">for</span> item <span class="keyword">in</span> class_names:</span><br><span class="line">            file_handler.write(<span class="string">"{}\n"</span>.format(item))</span><br><span class="line"></span><br></pre></td></tr></tbody></table></figure>
</body></html>]]></content>
      <categories>
        <category>项目</category>
      </categories>
      <tags>
        <tag>CNN</tag>
      </tags>
  </entry>
  <entry>
    <title>多标签文本分类 kaggle kernel</title>
    <url>/post/60709.html</url>
    <content><![CDATA[<html><head><link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script></head><body><p><img src="https://i.loli.net/2020/09/02/M3KakXbvHirSAE5.jpg" alt="shipshape_full_4k.jpg"><br><a id="more"></a></p>
<h2 id="基于LSTM的多标签文本分类" class="heading-control"><a href="#基于LSTM的多标签文本分类" class="headerlink" title="基于LSTM的多标签文本分类"></a>基于 LSTM 的多标签文本分类<a class="heading-anchor" href="#基于LSTM的多标签文本分类" aria-hidden="true"></a></h2><p>kaggle kernel 链接： <a href="https://www.kaggle.com/rftexas/gru-lstm-rnn-101">https://www.kaggle.com/rftexas/gru-lstm-rnn-101</a></p>
<p><strong>主要亮点</strong>：</p>
<ol>
<li>使用了 tf.keras 进行构建，很多代码可以复用为 baseline</li>
<li> 读取和加载 Glove 词向量</li>
<li> AUC 作为评价标准</li>
<li>数据集处理为 tf_dataset 输入 keras 模型</li>
<li>在训练集训练后，在验证集继续训练两个 epochs（小技巧，可能很有用）</li>
</ol>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> gc</span><br><span class="line"><span class="keyword">import</span> pickle</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">import</span> string</span><br><span class="line"><span class="keyword">import</span> warnings</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> keras.preprocessing.sequence <span class="keyword">import</span> pad_sequences</span><br><span class="line"><span class="keyword">from</span> keras.preprocessing.text <span class="keyword">import</span> Tokenizer</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras <span class="keyword">import</span> backend <span class="keyword">as</span> K</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras.losses <span class="keyword">import</span> binary_crossentropy</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras <span class="keyword">import</span> initializers, regularizers, constraints</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras.callbacks <span class="keyword">import</span> ReduceLROnPlateau, LearningRateScheduler, EarlyStopping</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras.layers <span class="keyword">import</span> Layer, Dense, Input, Embedding, SpatialDropout1D, Bidirectional, LSTM, \</span><br><span class="line">    GlobalMaxPooling1D, GlobalAveragePooling1D</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras.layers <span class="keyword">import</span> concatenate</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras.models <span class="keyword">import</span> Model</span><br><span class="line"><span class="keyword">from</span> tqdm.notebook <span class="keyword">import</span> tqdm</span><br><span class="line"></span><br><span class="line">tqdm.pandas()</span><br><span class="line"></span><br><span class="line">warnings.simplefilter(<span class="string">'ignore'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># HYPERPARAMETERS</span></span><br><span class="line">MAX_LEN = <span class="number">220</span></span><br><span class="line">MAX_FEATURES = <span class="number">100000</span></span><br><span class="line">EMBED_SIZE = <span class="number">600</span></span><br><span class="line">BATCH_SIZE = <span class="number">128</span></span><br><span class="line">N_EPOCHS = <span class="number">5</span></span><br><span class="line">LEARNING_RATE = <span class="number">8e-4</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># We will concatenate Crawl and GloVe embeddings</span></span><br><span class="line">CRAWL_EMB_PATH = <span class="string">'../input/pickled-glove840b300d-for-10sec-loading/glove.840B.300d.pkl'</span></span><br><span class="line">GLOVE_EMB_PATH = <span class="string">'../input/pickled-crawl300d2m-for-kernel-competitions/crawl-300d-2M.pkl'</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">display_training_curves</span>(<span class="params">training, validation, title, subplot</span>):</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Quickly display training curves</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="keyword">if</span> subplot % <span class="number">10</span> == <span class="number">1</span>:</span><br><span class="line">        plt.subplots(figsize=(<span class="number">10</span>, <span class="number">10</span>), facecolor=<span class="string">'#F0F0F0'</span>)</span><br><span class="line">        plt.tight_layout()</span><br><span class="line"></span><br><span class="line">    ax = plt.subplot(subplot)</span><br><span class="line">    ax.set_facecolor(<span class="string">'#F8F8F8'</span>)</span><br><span class="line">    ax.plot(training)</span><br><span class="line">    ax.plot(validation)</span><br><span class="line">    ax.set_title(<span class="string">'model'</span> + title)</span><br><span class="line">    ax.set_ylabel(title)</span><br><span class="line">    ax.set_xlabel(<span class="string">'epoch'</span>)</span><br><span class="line">    ax.legend([<span class="string">'train'</span>, <span class="string">'valid'</span>])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_coeffs</span>(<span class="params">word, *arr</span>):</span></span><br><span class="line">    <span class="keyword">return</span> word, np.asarray(arr, dtype=<span class="string">'float32'</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">load_embeddings</span>(<span class="params">embed_dir</span>):</span></span><br><span class="line">    <span class="keyword">with</span> open(embed_dir, <span class="string">'rb'</span>) <span class="keyword">as</span>  infile:</span><br><span class="line">        embeddings = pickle.load(infile)</span><br><span class="line">        <span class="keyword">return</span> embeddings</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">build_embedding_matrix</span>(<span class="params">word_index, embeddings_index, max_features, lower=True, verbose=True</span>):</span></span><br><span class="line">    embedding_matrix = np.zeros((max_features, <span class="number">300</span>))</span><br><span class="line">    <span class="keyword">for</span> word, i <span class="keyword">in</span> tqdm(word_index.items(), len=(word_index.items())):</span><br><span class="line">        <span class="keyword">if</span> lower:</span><br><span class="line">            word = word.lower()</span><br><span class="line">        <span class="keyword">if</span> i >= max_features: <span class="keyword">continue</span></span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            embedding_vector = embeddings_index[word]</span><br><span class="line">        <span class="keyword">except</span>:</span><br><span class="line">            embedding_vector = embeddings_index[<span class="string">"unknown"</span>]</span><br><span class="line">        <span class="keyword">if</span> embedding_vector <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            <span class="comment"># words not found in embedding index will be all-zeros.</span></span><br><span class="line">            embedding_matrix[i] = embedding_vector</span><br><span class="line">    <span class="keyword">return</span> embedding_matrix</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">build_matrix</span>(<span class="params">word_index, embeddings_index</span>):</span></span><br><span class="line">    embedding_matrix = np.zeros((len(word_index) + <span class="number">1</span>, <span class="number">300</span>))</span><br><span class="line">    <span class="keyword">for</span> word, i <span class="keyword">in</span> word_index.items():</span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            embedding_matrix[i] = embeddings_index[word]</span><br><span class="line">        <span class="keyword">except</span>:</span><br><span class="line">            embedding_matrix[i] = embeddings_index[<span class="string">"unknown"</span>]</span><br><span class="line">    <span class="keyword">return</span> embedding_matrix</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Attention</span>(<span class="params">Layer</span>):</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Custom Keras attention layer</span></span><br><span class="line"><span class="string">    Reference: https://www.kaggle.com/qqgeogor/keras-lstm-attention-glove840b-lb-0-043</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, step_dim, W_regularizer=None, b_regularizer=None,</span></span></span><br><span class="line"><span class="function"><span class="params">                 W_constraint=None, b_constraint=None, bias=True, **kwargs</span>):</span></span><br><span class="line"></span><br><span class="line">        self.supports_masking = <span class="literal">True</span></span><br><span class="line"></span><br><span class="line">        self.bias = bias</span><br><span class="line">        self.step_dim = step_dim</span><br><span class="line">        self.features_dim = <span class="literal">None</span></span><br><span class="line">        super(Attention, self).__init__(**kwargs)</span><br><span class="line"></span><br><span class="line">        self.param_W = {</span><br><span class="line">            <span class="string">'initializer'</span>: initializers.get(<span class="string">'glorot_uniform'</span>),</span><br><span class="line">            <span class="string">'name'</span>: <span class="string">'{}_W'</span>.format(self.name),</span><br><span class="line">            <span class="string">'regularizer'</span>: regularizers.get(W_regularizer),</span><br><span class="line">            <span class="string">'constraint'</span>: constraints.get(W_constraint)</span><br><span class="line">        }</span><br><span class="line">        self.W = <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">        self.param_b = {</span><br><span class="line">            <span class="string">'initializer'</span>: <span class="string">'zero'</span>,</span><br><span class="line">            <span class="string">'name'</span>: <span class="string">'{}_b'</span>.format(self.name),</span><br><span class="line">            <span class="string">'regularizer'</span>: regularizers.get(b_regularizer),</span><br><span class="line">            <span class="string">'constraint'</span>: constraints.get(b_constraint)</span><br><span class="line">        }</span><br><span class="line">        self.b = <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">build</span>(<span class="params">self, input_shape</span>):</span></span><br><span class="line">        <span class="keyword">assert</span> len(input_shape) == <span class="number">3</span></span><br><span class="line"></span><br><span class="line">        self.features_dim = input_shape[<span class="number">-1</span>]</span><br><span class="line">        self.W = self.add_weight(shape=(input_shape[<span class="number">-1</span>],),</span><br><span class="line">                                 **self.param_W)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> self.bias:</span><br><span class="line">            self.b = self.add_weight(shape=(input_shape[<span class="number">1</span>],),</span><br><span class="line">                                     **self.param_b)</span><br><span class="line"></span><br><span class="line">        self.built = <span class="literal">True</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">compute_mask</span>(<span class="params">self, input, input_mask=None</span>):</span></span><br><span class="line">        <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">call</span>(<span class="params">self, x, mask=None</span>):</span></span><br><span class="line">        step_dim = self.step_dim</span><br><span class="line">        features_dim = self.features_dim</span><br><span class="line"></span><br><span class="line">        eij = K.reshape(</span><br><span class="line">            K.dot(K.reshape(x, (<span class="number">-1</span>, features_dim)), K.reshape(self.W, (features_dim, <span class="number">1</span>))),</span><br><span class="line">            (<span class="number">-1</span>, step_dim))</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> self.bias:</span><br><span class="line">            eij += self.b</span><br><span class="line">        eij = K.tanh(eij)</span><br><span class="line">        a = K.exp(eij)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> mask <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            a *= K.cast(mask, K.floatx())</span><br><span class="line"></span><br><span class="line">        a /= K.cast(K.sum(a, axis=<span class="number">1</span>, keepdims=<span class="literal">True</span>) + K.epsilon(), K.floatx())</span><br><span class="line">        a = K.expand_dims(a)</span><br><span class="line">        weighted_input = x * a</span><br><span class="line">        <span class="keyword">return</span> K.sum(weighted_input, axis=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">compute_output_shape</span>(<span class="params">self, input_shape</span>):</span></span><br><span class="line">        <span class="keyword">return</span> input_shape[<span class="number">0</span>], self.features_dim</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># We create a balanced</span></span><br><span class="line"></span><br><span class="line">print(<span class="string">'Loading train sets...'</span>)</span><br><span class="line">train1 = pd.read_csv(<span class="string">"/kaggle/input/jigsaw-multilingual-toxic-comment-classification/jigsaw-toxic-comment-train.csv"</span>)</span><br><span class="line">train2 = pd.read_csv(<span class="string">"/kaggle/input/jigsaw-multilingual-toxic-comment-classification/jigsaw-unintended-bias-train.csv"</span>)</span><br><span class="line"></span><br><span class="line">train = pd.concat([</span><br><span class="line">    train1[[<span class="string">'comment_text'</span>, <span class="string">'toxic'</span>]],</span><br><span class="line">    train2[[<span class="string">'comment_text'</span>, <span class="string">'toxic'</span>]].query(<span class="string">'toxic==1'</span>),</span><br><span class="line">    train2[[<span class="string">'comment_text'</span>, <span class="string">'toxic'</span>]].query(<span class="string">'toxic==0'</span>).sample(n=<span class="number">100000</span>, random_state=<span class="number">0</span>)</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line"><span class="keyword">del</span> train1, train2</span><br><span class="line"></span><br><span class="line">print(<span class="string">'Loading validation sets...'</span>)</span><br><span class="line">valid = pd.read_csv(<span class="string">'/kaggle/input/val-en-df/validation_en.csv'</span>)</span><br><span class="line"></span><br><span class="line">print(<span class="string">'Loading test sets...'</span>)</span><br><span class="line">test = pd.read_csv(<span class="string">'/kaggle/input/test-en-df/test_en.csv'</span>)</span><br><span class="line">sub = pd.read_csv(<span class="string">'/kaggle/input/jigsaw-multilingual-toxic-comment-classification/sample_submission.csv'</span>)</span><br><span class="line"></span><br><span class="line">misspell_dict = {<span class="string">"aren't"</span>: <span class="string">"are not"</span>, <span class="string">"can't"</span>: <span class="string">"cannot"</span>, <span class="string">"couldn't"</span>: <span class="string">"could not"</span>,</span><br><span class="line">                 <span class="string">"didn't"</span>: <span class="string">"did not"</span>, <span class="string">"doesn't"</span>: <span class="string">"does not"</span>, <span class="string">"don't"</span>: <span class="string">"do not"</span>,</span><br><span class="line">                 <span class="string">"hadn't"</span>: <span class="string">"had not"</span>, <span class="string">"hasn't"</span>: <span class="string">"has not"</span>, <span class="string">"haven't"</span>: <span class="string">"have not"</span>,</span><br><span class="line">                 <span class="string">"he'd"</span>: <span class="string">"he would"</span>, <span class="string">"he'll"</span>: <span class="string">"he will"</span>, <span class="string">"he's"</span>: <span class="string">"he is"</span>,</span><br><span class="line">                 <span class="string">"i'd"</span>: <span class="string">"I had"</span>, <span class="string">"i'll"</span>: <span class="string">"I will"</span>, <span class="string">"i'm"</span>: <span class="string">"I am"</span>, <span class="string">"isn't"</span>: <span class="string">"is not"</span>,</span><br><span class="line">                 <span class="string">"it's"</span>: <span class="string">"it is"</span>, <span class="string">"it'll"</span>: <span class="string">"it will"</span>, <span class="string">"i've"</span>: <span class="string">"I have"</span>, <span class="string">"let's"</span>: <span class="string">"let us"</span>,</span><br><span class="line">                 <span class="string">"mightn't"</span>: <span class="string">"might not"</span>, <span class="string">"mustn't"</span>: <span class="string">"must not"</span>, <span class="string">"shan't"</span>: <span class="string">"shall not"</span>,</span><br><span class="line">                 <span class="string">"she'd"</span>: <span class="string">"she would"</span>, <span class="string">"she'll"</span>: <span class="string">"she will"</span>, <span class="string">"she's"</span>: <span class="string">"she is"</span>,</span><br><span class="line">                 <span class="string">"shouldn't"</span>: <span class="string">"should not"</span>, <span class="string">"that's"</span>: <span class="string">"that is"</span>, <span class="string">"there's"</span>: <span class="string">"there is"</span>,</span><br><span class="line">                 <span class="string">"they'd"</span>: <span class="string">"they would"</span>, <span class="string">"they'll"</span>: <span class="string">"they will"</span>, <span class="string">"they're"</span>: <span class="string">"they are"</span>,</span><br><span class="line">                 <span class="string">"they've"</span>: <span class="string">"they have"</span>, <span class="string">"we'd"</span>: <span class="string">"we would"</span>, <span class="string">"we're"</span>: <span class="string">"we are"</span>,</span><br><span class="line">                 <span class="string">"weren't"</span>: <span class="string">"were not"</span>, <span class="string">"we've"</span>: <span class="string">"we have"</span>, <span class="string">"what'll"</span>: <span class="string">"what will"</span>,</span><br><span class="line">                 <span class="string">"what're"</span>: <span class="string">"what are"</span>, <span class="string">"what's"</span>: <span class="string">"what is"</span>, <span class="string">"what've"</span>: <span class="string">"what have"</span>,</span><br><span class="line">                 <span class="string">"where's"</span>: <span class="string">"where is"</span>, <span class="string">"who'd"</span>: <span class="string">"who would"</span>, <span class="string">"who'll"</span>: <span class="string">"who will"</span>,</span><br><span class="line">                 <span class="string">"who're"</span>: <span class="string">"who are"</span>, <span class="string">"who's"</span>: <span class="string">"who is"</span>, <span class="string">"who've"</span>: <span class="string">"who have"</span>,</span><br><span class="line">                 <span class="string">"won't"</span>: <span class="string">"will not"</span>, <span class="string">"wouldn't"</span>: <span class="string">"would not"</span>, <span class="string">"you'd"</span>: <span class="string">"you would"</span>,</span><br><span class="line">                 <span class="string">"you'll"</span>: <span class="string">"you will"</span>, <span class="string">"you're"</span>: <span class="string">"you are"</span>, <span class="string">"you've"</span>: <span class="string">"you have"</span>,</span><br><span class="line">                 <span class="string">"'re"</span>: <span class="string">" are"</span>, <span class="string">"wasn't"</span>: <span class="string">"was not"</span>, <span class="string">"we'll"</span>: <span class="string">" will"</span>, <span class="string">"tryin'"</span>: <span class="string">"trying"</span>}</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_get_misspell</span>(<span class="params">misspell_dict</span>):</span></span><br><span class="line">    misspell_re = re.compile(<span class="string">'(%s)'</span> % <span class="string">'|'</span>.join(misspell_dict.keys()))</span><br><span class="line">    <span class="keyword">return</span> misspell_dict, misspell_re</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">replace_typical_misspell</span>(<span class="params">text</span>):</span></span><br><span class="line">    misspellings, misspellings_re = _get_misspell(misspell_dict)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">replace</span>(<span class="params">match</span>):</span></span><br><span class="line">        <span class="keyword">return</span> misspellings[match.group(<span class="number">0</span>)]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> misspellings_re.sub(replace, text)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">puncts = [<span class="string">','</span>, <span class="string">'.'</span>, <span class="string">'"'</span>, <span class="string">':'</span>, <span class="string">')'</span>, <span class="string">'('</span>, <span class="string">'-'</span>, <span class="string">'!'</span>, <span class="string">'?'</span>, <span class="string">'|'</span>, <span class="string">';'</span>, <span class="string">"'"</span>, <span class="string">'$'</span>, <span class="string">'&'</span>, <span class="string">'/'</span>, <span class="string">'['</span>, <span class="string">']'</span>,</span><br><span class="line">          <span class="string">'>'</span>, <span class="string">'%'</span>, <span class="string">'='</span>, <span class="string">'#'</span>, <span class="string">'*'</span>, <span class="string">'+'</span>, <span class="string">'\\'</span>, <span class="string">'•'</span>, <span class="string">'~'</span>, <span class="string">'@'</span>, <span class="string">'£'</span>, <span class="string">'·'</span>, <span class="string">'_'</span>, <span class="string">'{'</span>, <span class="string">'}'</span>, <span class="string">'©'</span>, <span class="string">'^'</span>,</span><br><span class="line">          <span class="string">'®'</span>, <span class="string">'`'</span>, <span class="string">'<'</span>, <span class="string">'→'</span>, <span class="string">'°'</span>, <span class="string">'€'</span>, <span class="string">'™'</span>, <span class="string">'›'</span>, <span class="string">'♥'</span>, <span class="string">'←'</span>, <span class="string">'×'</span>, <span class="string">'§'</span>, <span class="string">'″'</span>, <span class="string">'′'</span>, <span class="string">'Â'</span>, <span class="string">'█'</span>,</span><br><span class="line">          <span class="string">'½'</span>, <span class="string">'à'</span>, <span class="string">'…'</span>, <span class="string">'“'</span>, <span class="string">'★'</span>, <span class="string">'”'</span>, <span class="string">'–'</span>, <span class="string">'●'</span>, <span class="string">'â'</span>, <span class="string">'►'</span>, <span class="string">'−'</span>, <span class="string">'¢'</span>, <span class="string">'²'</span>, <span class="string">'¬'</span>, <span class="string">'░'</span>, <span class="string">'¶'</span>,</span><br><span class="line">          <span class="string">'↑'</span>, <span class="string">'±'</span>, <span class="string">'¿'</span>, <span class="string">'▾'</span>, <span class="string">'═'</span>, <span class="string">'¦'</span>, <span class="string">'║'</span>, <span class="string">'―'</span>, <span class="string">'¥'</span>, <span class="string">'▓'</span>, <span class="string">'—'</span>, <span class="string">'‹'</span>, <span class="string">'─'</span>, <span class="string">'▒'</span>, <span class="string">'：'</span>, <span class="string">'¼'</span>,</span><br><span class="line">          <span class="string">'⊕'</span>, <span class="string">'▼'</span>, <span class="string">'▪'</span>, <span class="string">'†'</span>, <span class="string">'■'</span>, <span class="string">'’'</span>, <span class="string">'▀'</span>, <span class="string">'¨'</span>, <span class="string">'▄'</span>, <span class="string">'♫'</span>, <span class="string">'☆'</span>, <span class="string">'é'</span>, <span class="string">'¯'</span>, <span class="string">'♦'</span>, <span class="string">'¤'</span>, <span class="string">'▲'</span>,</span><br><span class="line">          <span class="string">'è'</span>, <span class="string">'¸'</span>, <span class="string">'¾'</span>, <span class="string">'Ã'</span>, <span class="string">'⋅'</span>, <span class="string">'‘'</span>, <span class="string">'∞'</span>, <span class="string">'∙'</span>, <span class="string">'）'</span>, <span class="string">'↓'</span>, <span class="string">'、'</span>, <span class="string">'│'</span>, <span class="string">'（'</span>, <span class="string">'»'</span>, <span class="string">'，'</span>, <span class="string">'♪'</span>,</span><br><span class="line">          <span class="string">'╩'</span>, <span class="string">'╚'</span>, <span class="string">'³'</span>, <span class="string">'・'</span>, <span class="string">'╦'</span>, <span class="string">'╣'</span>, <span class="string">'╔'</span>, <span class="string">'╗'</span>, <span class="string">'▬'</span>, <span class="string">'❤'</span>, <span class="string">'ï'</span>, <span class="string">'Ø'</span>, <span class="string">'¹'</span>, <span class="string">'≤'</span>, <span class="string">'‡'</span>, <span class="string">'√'</span>]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">clean_text</span>(<span class="params">x</span>):</span></span><br><span class="line">    x = str(x)</span><br><span class="line">    <span class="keyword">for</span> punct <span class="keyword">in</span> puncts + list(string.punctuation):</span><br><span class="line">        <span class="keyword">if</span> punct <span class="keyword">in</span> x:</span><br><span class="line">            x = x.replace(punct, <span class="string">f' <span class="subst">{punct}</span> '</span>)</span><br><span class="line">    <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">clean_numbers</span>(<span class="params">x</span>):</span></span><br><span class="line">    <span class="keyword">return</span> re.sub(<span class="string">r'\d+'</span>, <span class="string">' '</span>, x)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">preprocess</span>(<span class="params">train, valid, test, tfms</span>):</span></span><br><span class="line">    <span class="keyword">for</span> tfm <span class="keyword">in</span> tfms:</span><br><span class="line">        print(tfm.__name__)</span><br><span class="line">        train[<span class="string">'comment_text'</span>] = train[<span class="string">'comment_text'</span>].progress_apply(tfm)</span><br><span class="line">        valid[<span class="string">'comment_text_en'</span>] = valid[<span class="string">'comment_text_en'</span>].progress_apply(tfm)</span><br><span class="line">        test[<span class="string">'content'</span>] = test[<span class="string">'content'</span>].progress_apply(tfm)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> train, valid, test</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">tfms = [replace_typical_misspell, clean_text, clean_numbers]</span><br><span class="line">train, valid, test = preprocess(train, valid, test, tfms)</span><br><span class="line"></span><br><span class="line">tokenizer = Tokenizer(num_words=MAX_FEATURES, filters=<span class="string">''</span>, lower=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">print(<span class="string">'Fitting tokenizer...'</span>)</span><br><span class="line">tokenizer.fit_on_texts(list(train[<span class="string">'comment_text'</span>]) + list(valid[<span class="string">'comment_text_en'</span>]) + list(test[<span class="string">'content_en'</span>]))</span><br><span class="line">word_index = tokenizer.word_index</span><br><span class="line"></span><br><span class="line">print(<span class="string">'Building training set...'</span>)</span><br><span class="line">X_train = tokenizer.texts_to_sequences(list(train[<span class="string">'comment_text'</span>]))</span><br><span class="line">y_train = train[<span class="string">'toxic'</span>].values</span><br><span class="line"></span><br><span class="line">print(<span class="string">'Building validation set...'</span>)</span><br><span class="line">X_valid = tokenizer.texts_to_sequences(list(valid[<span class="string">'comment_text_en'</span>]))</span><br><span class="line">y_valid = valid[<span class="string">'toxic'</span>].values</span><br><span class="line"></span><br><span class="line">print(<span class="string">'Building test set ...'</span>)</span><br><span class="line">X_test = tokenizer.texts_to_sequences(list(test[<span class="string">'content_en'</span>]))</span><br><span class="line"></span><br><span class="line">print(<span class="string">'Padding sequences...'</span>)</span><br><span class="line">X_train = pad_sequences(X_train, maxlen=MAX_LEN)</span><br><span class="line">X_valid = pad_sequences(X_valid, maxlen=MAX_LEN)</span><br><span class="line">X_test = pad_sequences(X_test, maxlen=MAX_LEN)</span><br><span class="line"></span><br><span class="line">y_train = train.toxic.values</span><br><span class="line">y_valid = valid.toxic.values</span><br><span class="line"></span><br><span class="line"><span class="keyword">del</span> tokenizer</span><br><span class="line"></span><br><span class="line">print(<span class="string">'Loading Crawl embeddings...'</span>)</span><br><span class="line">crawl_embeddings = load_embeddings(CRAWL_EMB_PATH)</span><br><span class="line"></span><br><span class="line">print(<span class="string">'Loading GloVe embeddings...'</span>)</span><br><span class="line">glove_embeddings = load_embeddings(GLOVE_EMB_PATH)</span><br><span class="line"></span><br><span class="line">print(<span class="string">'Building matrices...'</span>)</span><br><span class="line">embedding_matrix_1 = build_matrix(word_index, crawl_embeddings)</span><br><span class="line">embedding_matrix_2 = build_matrix(word_index, glove_embeddings)</span><br><span class="line"></span><br><span class="line">print(<span class="string">'Concatenating embedding matrices...'</span>)</span><br><span class="line">embedding_matrix = np.concatenate([embedding_matrix_1, embedding_matrix_2], axis=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">del</span> embedding_matrix_1, embedding_matrix_2</span><br><span class="line"><span class="keyword">del</span> crawl_embeddings, glove_embeddings</span><br><span class="line"></span><br><span class="line">gc.collect()</span><br><span class="line"></span><br><span class="line">train_dataset = (</span><br><span class="line">    tf.data.Dataset</span><br><span class="line">        .from_tensor_slices((X_train, y_train))</span><br><span class="line">        .repeat()</span><br><span class="line">        .shuffle(<span class="number">2048</span>)</span><br><span class="line">        .batch(BATCH_SIZE)</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">valid_dataset = (</span><br><span class="line">    tf.data.Dataset</span><br><span class="line">        .from_tensor_slices((X_valid, y_valid))</span><br><span class="line">        .batch(BATCH_SIZE)</span><br><span class="line">        .cache()</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">test_dataset = (</span><br><span class="line">    tf.data.Dataset</span><br><span class="line">        .from_tensor_slices(X_test)</span><br><span class="line">        .batch(BATCH_SIZE)</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">build_model</span>(<span class="params">word_index, embedding_matrix, verbose=True</span>):</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    credits go to: https://www.kaggle.com/thousandvoices/simple-lstm/</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    sequence_input = Input(shape=(MAX_LEN,), dtype=tf.int32)</span><br><span class="line"></span><br><span class="line">    embedding_layer = Embedding(*embedding_matrix.shape,</span><br><span class="line">                                weights=[embedding_matrix],</span><br><span class="line">                                trainable=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">    x = embedding_layer(sequence_input)</span><br><span class="line">    x = SpatialDropout1D(<span class="number">0.3</span>)(x)</span><br><span class="line">    x = Bidirectional(LSTM(<span class="number">256</span>, return_sequences=<span class="literal">True</span>))(x)</span><br><span class="line">    x = Bidirectional(LSTM(<span class="number">128</span>, return_sequences=<span class="literal">True</span>))(x)</span><br><span class="line"></span><br><span class="line">    att = Attention(MAX_LEN)(x)</span><br><span class="line">    avg_pool1 = GlobalAveragePooling1D()(x)</span><br><span class="line">    max_pool1 = GlobalMaxPooling1D()(x)</span><br><span class="line">    hidden = concatenate([att, avg_pool1, max_pool1])</span><br><span class="line"></span><br><span class="line">    hidden = Dense(<span class="number">512</span>, activation=<span class="string">'relu'</span>)(hidden)</span><br><span class="line">    hidden = Dense(<span class="number">128</span>, activation=<span class="string">'relu'</span>)(hidden)</span><br><span class="line">    out = Dense(<span class="number">1</span>, activation=<span class="string">'sigmoid'</span>)(hidden)</span><br><span class="line">    model = Model(sequence_input, out)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> model</span><br><span class="line"></span><br><span class="line">model = build_model(word_index, embedding_matrix)</span><br><span class="line">model.compile(optimizer=<span class="string">'adam'</span>, loss=<span class="string">'binary_crossentropy'</span>, metrics=[tf.keras.metrics.AUC()])</span><br><span class="line">model.summary()</span><br><span class="line"></span><br><span class="line">file_weights = <span class="string">'best_model.h5'</span></span><br><span class="line"><span class="comment"># cb1 = ModelCheckpoint(file_weights, save_best_only=True)</span></span><br><span class="line"></span><br><span class="line">cb2 = EarlyStopping(monitor=<span class="string">'val_loss'</span>, mode=<span class="string">'min'</span>, verbose=<span class="number">1</span>, patience=<span class="number">3</span>)</span><br><span class="line">cb3 = ReduceLROnPlateau(monitor=<span class="string">'val_loss'</span>, factor=<span class="number">0.5</span>, patience=<span class="number">2</span>, verbose=<span class="number">1</span>, cooldown=<span class="number">0</span>, min_lr=<span class="number">0.0001</span>)</span><br><span class="line">cb4 = LearningRateScheduler(<span class="keyword">lambda</span> epoch: LEARNING_RATE * (<span class="number">0.6</span> ** epoch))</span><br><span class="line"></span><br><span class="line">n_steps = X_train.shape[<span class="number">0</span>] // BATCH_SIZE</span><br><span class="line"></span><br><span class="line">train_history = model.fit(</span><br><span class="line">    train_dataset,</span><br><span class="line">    steps_per_epoch=n_steps,</span><br><span class="line">    validation_data=valid_dataset,</span><br><span class="line">    callbacks=[cb4],</span><br><span class="line">    epochs=N_EPOCHS</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">display_training_curves(</span><br><span class="line">    train_history.history[<span class="string">'loss'</span>],</span><br><span class="line">    train_history.history[<span class="string">'val_loss'</span>],</span><br><span class="line">    <span class="string">'loss'</span>,</span><br><span class="line">    <span class="number">211</span>)</span><br><span class="line"></span><br><span class="line">display_training_curves(</span><br><span class="line">    train_history.history[<span class="string">'auc'</span>],</span><br><span class="line">    train_history.history[<span class="string">'val_auc'</span>],</span><br><span class="line">    <span class="string">'AUC'</span>,</span><br><span class="line">    <span class="number">212</span>)</span><br><span class="line"></span><br><span class="line">n_steps = X_valid.shape[<span class="number">0</span>] // BATCH_SIZE</span><br><span class="line"></span><br><span class="line">train_history = model.fit(</span><br><span class="line">    valid_dataset.repeat(),</span><br><span class="line">    steps_per_epoch=n_steps,</span><br><span class="line">    callbacks=[cb4],</span><br><span class="line">    epochs=N_EPOCHS</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">preds = model.predict(test_dataset, verbose=<span class="number">1</span>)</span><br><span class="line">sub[<span class="string">'toxic'</span>] = preds</span><br><span class="line"></span><br></pre></td></tr></tbody></table></figure>
<h2 id="基于BERT的多标签文本分类-使用TPU" class="heading-control"><a href="#基于BERT的多标签文本分类-使用TPU" class="headerlink" title="基于BERT的多标签文本分类(使用TPU)"></a>基于 BERT 的多标签文本分类 (使用 TPU)<a class="heading-anchor" href="#基于BERT的多标签文本分类-使用TPU" aria-hidden="true"></a></h2><p>kaggle kernel 链接： <a href="https://www.kaggle.com/sunyancn/jigsaw-tpu-bert-with-huggingface-and-keras">https://www.kaggle.com/sunyancn/jigsaw-tpu-bert-with-huggingface-and-keras</a></p>
<p><strong>主要亮点</strong>：</p>
<ol>
<li>使用了 transformers 的分词器进行快速分词</li>
<li>文本长度的可视化</li>
<li> TF Hub BERT 模型的加载</li>
<li> TPU 策略 </li>
</ol>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="comment"># %% [markdown]</span></span><br><span class="line"><span class="comment"># ## About this notebook</span></span><br><span class="line"><span class="comment"># </span></span><br><span class="line"><span class="comment"># *[Jigsaw Multilingual Toxic Comment Classification](https://www.kaggle.com/c/jigsaw-multilingual-toxic-comment-classification)* is the 3rd annual competition organized by the Jigsaw team. It follows *[Toxic Comment Classification Challenge](https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge)*, the original 2018 competition, and *[Jigsaw Unintended Bias in Toxicity Classification](https://www.kaggle.com/c/jigsaw-unintended-bias-in-toxicity-classification)*, which required the competitors to consider biased ML predictions in their new models. This year, the goal is to use english only training data to run toxicity predictions on many different languages, which can be done using multilingual models, and speed up using TPUs.</span></span><br><span class="line"><span class="comment"># </span></span><br><span class="line"><span class="comment"># Many awesome notebooks has already been made so far. Many of them used really cool technologies like [Pytorch XLA](https://www.kaggle.com/theoviel/bert-pytorch-huggingface-starter). This notebook instead aims at constructing a **fast, concise, reusable, and beginner-friendly model scaffold**. It will focus on the following points:</span></span><br><span class="line"><span class="comment"># * **Using Tensorflow and Keras**: Tensorflow is a powerful framework, and Keras makes the training process extremely easy to understand. This is especially good for beginners to learn how to use TPUs, and for experts to focus on the modelling aspect.</span></span><br><span class="line"><span class="comment"># * **Using Huggingface's `transformers` library**: [This library](https://huggingface.co/transformers/) is extremely popular, so using this let you easily integrate the end result into your ML pipelines, and can be easily reused for your other projects.</span></span><br><span class="line"><span class="comment"># * **Native TPU usage**: The TPU usage is abstracted using the native `strategy` that was created using Tensorflow's `tf.distribute.experimental.TPUStrategy`. This avoids getting too much into the lower-level aspect of TPU management.</span></span><br><span class="line"><span class="comment"># * **Use a subset of the data**: Instead of using the entire dataset, we will only use the 2018 subset of the data available, which makes this much faster, all while achieving a respectable accuracy.</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># %% [code]</span></span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> warnings</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras.layers <span class="keyword">import</span> Dense, Input</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras.optimizers <span class="keyword">import</span> Adam</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras.models <span class="keyword">import</span> Model</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras.callbacks <span class="keyword">import</span> ModelCheckpoint</span><br><span class="line"><span class="keyword">from</span> kaggle_datasets <span class="keyword">import</span> KaggleDatasets</span><br><span class="line"><span class="keyword">import</span> transformers</span><br><span class="line"><span class="keyword">import</span> traitlets</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"><span class="keyword">from</span> tqdm.notebook <span class="keyword">import</span> tqdm</span><br><span class="line"><span class="keyword">from</span> tokenizers <span class="keyword">import</span> BertWordPieceTokenizer</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> roc_auc_score</span><br><span class="line"></span><br><span class="line">warnings.simplefilter(<span class="string">"ignore"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># %% [markdown]</span></span><br><span class="line"><span class="comment"># ## Helper Functions</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># %% [code]</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">fast_encode</span>(<span class="params">texts, tokenizer, chunk_size=<span class="number">256</span>, maxlen=<span class="number">512</span></span>):</span></span><br><span class="line">    tokenizer.enable_truncation(max_length=maxlen)</span><br><span class="line">    tokenizer.enable_padding(max_length=maxlen)</span><br><span class="line">    all_ids = []</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> tqdm(range(<span class="number">0</span>, len(texts), chunk_size)):</span><br><span class="line">        text_chunk = texts[i:i+chunk_size].tolist()</span><br><span class="line">        encs = tokenizer.encode_batch(text_chunk)</span><br><span class="line">        all_ids.extend([enc.ids <span class="keyword">for</span> enc <span class="keyword">in</span> encs])</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> np.array(all_ids)</span><br><span class="line"></span><br><span class="line"><span class="comment"># %% [code]</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">build_model</span>(<span class="params">transformer, loss=<span class="string">'binary_crossentropy'</span>, max_len=<span class="number">512</span></span>):</span></span><br><span class="line">    input_word_ids = Input(shape=(max_len,), dtype=tf.int32, name=<span class="string">"input_word_ids"</span>)</span><br><span class="line">    sequence_output = transformer(input_word_ids)[<span class="number">0</span>]</span><br><span class="line">    cls_token = sequence_output[:, <span class="number">0</span>, :]</span><br><span class="line">    x = tf.keras.layers.Dropout(<span class="number">0.35</span>)(cls_token)</span><br><span class="line">    out = Dense(<span class="number">1</span>, activation=<span class="string">'sigmoid'</span>)(x)</span><br><span class="line">    </span><br><span class="line">    model = Model(inputs=input_word_ids, outputs=out)</span><br><span class="line">    model.compile(Adam(lr=<span class="number">3e-5</span>), loss=loss, metrics=[tf.keras.metrics.AUC()])</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> model</span><br><span class="line"></span><br><span class="line"><span class="comment"># %% [markdown]</span></span><br><span class="line"><span class="comment"># Cosine similarity calculates similarity by measuring the cosine of angle between two vectors. This is calculated as:</span></span><br><span class="line"><span class="comment"># ![](https://miro.medium.com/max/426/1*hub04IikybZIBkSEcEOtGA.png)</span></span><br><span class="line"><span class="comment"># </span></span><br><span class="line"><span class="comment"># Cosine Similarity calculation for two vectors A and B [source]</span></span><br><span class="line"><span class="comment"># With cosine similarity, we need to convert sentences into vectors. One way to do that is to use bag of words with either TF (term frequency) or TF-IDF (term frequency- inverse document frequency). The choice of TF or TF-IDF depends on application and is immaterial to how cosine similarity is actually performed — which just needs vectors. TF is good for text similarity in general, but TF-IDF is good for search query relevance.</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># %% [code]</span></span><br><span class="line"><span class="comment"># https://stackoverflow.com/questions/8897593/how-to-compute-the-similarity-between-two-text-documents</span></span><br><span class="line"><span class="keyword">import</span> nltk, string</span><br><span class="line"><span class="keyword">from</span> sklearn.feature_extraction.text <span class="keyword">import</span> TfidfVectorizer</span><br><span class="line"></span><br><span class="line">nltk.download(<span class="string">'punkt'</span>) <span class="comment"># if necessary...</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">stemmer = nltk.stem.porter.PorterStemmer()</span><br><span class="line">remove_punctuation_map = dict((ord(char), <span class="literal">None</span>) <span class="keyword">for</span> char <span class="keyword">in</span> string.punctuation)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">stem_tokens</span>(<span class="params">tokens</span>):</span></span><br><span class="line">    <span class="keyword">return</span> [stemmer.stem(item) <span class="keyword">for</span> item <span class="keyword">in</span> tokens]</span><br><span class="line"></span><br><span class="line"><span class="string">'''remove punctuation, lowercase, stem'''</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">normalize</span>(<span class="params">text</span>):</span></span><br><span class="line">    <span class="keyword">return</span> stem_tokens(nltk.word_tokenize(text.lower().translate(remove_punctuation_map)))</span><br><span class="line"></span><br><span class="line">vectorizer = TfidfVectorizer(tokenizer=normalize, stop_words=<span class="string">'english'</span>)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">cosine_sim</span>(<span class="params">text1, text2</span>):</span></span><br><span class="line">    tfidf = vectorizer.fit_transform([text1, text2])</span><br><span class="line">    <span class="keyword">return</span> ((tfidf * tfidf.T).A)[<span class="number">0</span>,<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># %% [markdown]</span></span><br><span class="line"><span class="comment"># ## TPU Configs</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># %% [code]</span></span><br><span class="line">AUTO = tf.data.experimental.AUTOTUNE</span><br><span class="line"></span><br><span class="line"><span class="comment"># Create strategy from tpu</span></span><br><span class="line">tpu = tf.distribute.cluster_resolver.TPUClusterResolver()</span><br><span class="line">tf.config.experimental_connect_to_cluster(tpu)</span><br><span class="line">tf.tpu.experimental.initialize_tpu_system(tpu)</span><br><span class="line">strategy = tf.distribute.experimental.TPUStrategy(tpu)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Data access</span></span><br><span class="line"><span class="comment">#GCS_DS_PATH = KaggleDatasets().get_gcs_path('kaggle/input/') </span></span><br><span class="line"></span><br><span class="line"><span class="comment"># %% [markdown]</span></span><br><span class="line"><span class="comment"># ## Create fast tokenizer</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># %% [code]</span></span><br><span class="line"><span class="comment"># First load the real tokenizer</span></span><br><span class="line">tokenizer = transformers.BertTokenizer.from_pretrained(<span class="string">'bert-base-uncased'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Save the loaded tokenizer locally</span></span><br><span class="line">save_path = <span class="string">'/kaggle/working/distilbert_base_uncased/'</span></span><br><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(save_path):</span><br><span class="line">    os.makedirs(save_path)</span><br><span class="line">tokenizer.save_pretrained(save_path)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Reload it with the huggingface tokenizers library</span></span><br><span class="line">fast_tokenizer = BertWordPieceTokenizer(<span class="string">'distilbert_base_uncased/vocab.txt'</span>, lowercase=<span class="literal">True</span>)</span><br><span class="line">fast_tokenizer</span><br><span class="line"></span><br><span class="line"><span class="comment"># %% [markdown]</span></span><br><span class="line"><span class="comment"># ## Load text data into memory</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># %% [code]</span></span><br><span class="line">train1 = pd.read_csv(<span class="string">"/kaggle/input/jigsaw-multilingual-toxic-comment-classification/jigsaw-toxic-comment-train.csv"</span>)</span><br><span class="line">train2 = pd.read_csv(<span class="string">"/kaggle/input/jigsaw-multilingual-toxic-comment-classification/jigsaw-unintended-bias-train.csv"</span>)</span><br><span class="line"></span><br><span class="line">valid = pd.read_csv(<span class="string">'/kaggle/input/val-en-df/validation_en.csv'</span>)</span><br><span class="line">test1 = pd.read_csv(<span class="string">'/kaggle/input/test-en-df/test_en.csv'</span>)</span><br><span class="line">test2 = pd.read_csv(<span class="string">'/kaggle/input/jigsaw-multilingual-toxic-test-translated/jigsaw_miltilingual_test_translated.csv'</span>)</span><br><span class="line">sub = pd.read_csv(<span class="string">'/kaggle/input/jigsaw-multilingual-toxic-comment-classification/sample_submission.csv'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># %% [code]</span></span><br><span class="line">test2.head()</span><br><span class="line"></span><br><span class="line"><span class="comment"># %% [markdown]</span></span><br><span class="line"><span class="comment"># ## Test dataset comparision</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># %% [code]</span></span><br><span class="line">plt.figure(figsize=(<span class="number">12</span>, <span class="number">8</span>))</span><br><span class="line"></span><br><span class="line">sns.distplot(train1.comment_text.str.len(), label=<span class="string">'train'</span>)</span><br><span class="line">sns.distplot(test1.content_en.str.len(), label=<span class="string">'test1'</span>)</span><br><span class="line">sns.distplot(test2.translated.str.len(), label=<span class="string">'test2'</span>)</span><br><span class="line">plt.legend();</span><br><span class="line"></span><br><span class="line"><span class="comment"># %% [code]</span></span><br><span class="line">plt.figure(figsize=(<span class="number">12</span>, <span class="number">8</span>))</span><br><span class="line"></span><br><span class="line">sns.distplot(train1.comment_text.str.len(), label=<span class="string">'train'</span>)</span><br><span class="line">sns.distplot(test1.content_en.str.len(), label=<span class="string">'test1'</span>)</span><br><span class="line">sns.distplot(test2.translated.str.len(), label=<span class="string">'test2'</span>)</span><br><span class="line">plt.xlim([<span class="number">0</span>, <span class="number">512</span>])</span><br><span class="line">plt.legend();</span><br><span class="line"></span><br><span class="line"><span class="comment"># %% [markdown]</span></span><br><span class="line"><span class="comment"># Lets calculate cosine similarity two translated test datasets.</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># %% [code]</span></span><br><span class="line">test_set_similarity = [cosine_sim(t1, t2) <span class="keyword">for</span> t1, t2 <span class="keyword">in</span> tqdm(zip(test1.content_en, test2.translated))]</span><br><span class="line"></span><br><span class="line">plt.figure(figsize=(<span class="number">12</span>, <span class="number">8</span>))</span><br><span class="line"></span><br><span class="line">sns.distplot(test_set_similarity);</span><br><span class="line"></span><br><span class="line"><span class="comment"># %% [markdown]</span></span><br><span class="line"><span class="comment"># ## Fast encode</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># %% [code]</span></span><br><span class="line">x_train = fast_encode(train1.comment_text.astype(str), fast_tokenizer, maxlen=<span class="number">512</span>)</span><br><span class="line">x_valid = fast_encode(valid.comment_text_en.astype(str), fast_tokenizer, maxlen=<span class="number">512</span>)</span><br><span class="line">x_test1 = fast_encode(test1.content_en.astype(str), fast_tokenizer, maxlen=<span class="number">512</span>)</span><br><span class="line">x_test2 = fast_encode(test2.translated.astype(str), fast_tokenizer, maxlen=<span class="number">512</span>)</span><br><span class="line"></span><br><span class="line">y_train = train1.toxic.values</span><br><span class="line">y_valid = valid.toxic.values</span><br><span class="line"></span><br><span class="line"><span class="comment"># %% [markdown]</span></span><br><span class="line"><span class="comment"># ## Build datasets objects</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># %% [code]</span></span><br><span class="line">train_dataset = (</span><br><span class="line">    tf.data.Dataset</span><br><span class="line">    .from_tensor_slices((x_train, y_train))</span><br><span class="line">    .repeat()</span><br><span class="line">    .shuffle(<span class="number">2048</span>)</span><br><span class="line">    .batch(<span class="number">64</span>)</span><br><span class="line">    .prefetch(AUTO)</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">valid_dataset = (</span><br><span class="line">    tf.data.Dataset</span><br><span class="line">    .from_tensor_slices((x_valid, y_valid))</span><br><span class="line">    .batch(<span class="number">64</span>)</span><br><span class="line">    .cache()</span><br><span class="line">    .prefetch(AUTO)</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">test_dataset = [(</span><br><span class="line">    tf.data.Dataset</span><br><span class="line">    .from_tensor_slices(x_test1)</span><br><span class="line">    .batch(<span class="number">64</span>)</span><br><span class="line">),</span><br><span class="line">    (</span><br><span class="line">    tf.data.Dataset</span><br><span class="line">    .from_tensor_slices(x_test2)</span><br><span class="line">    .batch(<span class="number">64</span>)</span><br><span class="line">)]</span><br><span class="line"></span><br><span class="line"><span class="comment"># %% [markdown]</span></span><br><span class="line"><span class="comment"># # Focal Loss</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># %% [code]</span></span><br><span class="line"><span class="keyword">from</span> tensorflow.keras <span class="keyword">import</span> backend <span class="keyword">as</span> K</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">focal_loss</span>(<span class="params">gamma=<span class="number">2.</span>, alpha=<span class="number">.2</span></span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">focal_loss_fixed</span>(<span class="params">y_true, y_pred</span>):</span></span><br><span class="line">        pt_1 = tf.where(tf.equal(y_true, <span class="number">1</span>), y_pred, tf.ones_like(y_pred))</span><br><span class="line">        pt_0 = tf.where(tf.equal(y_true, <span class="number">0</span>), y_pred, tf.zeros_like(y_pred))</span><br><span class="line">        <span class="keyword">return</span> -K.mean(alpha * K.pow(<span class="number">1.</span> - pt_1, gamma) * K.log(pt_1)) - K.mean((<span class="number">1</span> - alpha) * K.pow(pt_0, gamma) * K.log(<span class="number">1.</span> - pt_0))</span><br><span class="line">    <span class="keyword">return</span> focal_loss_fixed</span><br><span class="line"></span><br><span class="line"><span class="comment"># %% [markdown]</span></span><br><span class="line"><span class="comment"># ## Load model into the TPU</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># %% [code]</span></span><br><span class="line">%%time</span><br><span class="line"><span class="keyword">with</span> strategy.scope():</span><br><span class="line">    transformer_layer = transformers.TFBertModel.from_pretrained(<span class="string">'bert-base-uncased'</span>)</span><br><span class="line">    model = build_model(transformer_layer, loss=focal_loss(gamma=<span class="number">1.5</span>), max_len=<span class="number">512</span>)</span><br><span class="line">model.summary()</span><br><span class="line"></span><br><span class="line"><span class="comment"># %% [markdown]</span></span><br><span class="line"><span class="comment"># ## RocAuc Callback</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># %% [code]</span></span><br><span class="line"><span class="keyword">from</span> tensorflow.keras.callbacks <span class="keyword">import</span> Callback </span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">RocAucCallback</span>(<span class="params">Callback</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, test_data, score_thr</span>):</span></span><br><span class="line">        self.test_data = test_data</span><br><span class="line">        self.score_thr = score_thr</span><br><span class="line">        self.test_pred = []</span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">on_epoch_end</span>(<span class="params">self, epoch, logs=None</span>):</span></span><br><span class="line">        <span class="keyword">if</span> logs[<span class="string">'val_auc'</span>] > self.score_thr:</span><br><span class="line">            print(<span class="string">'\nRun TTA...'</span>)</span><br><span class="line">            <span class="keyword">for</span> td <span class="keyword">in</span> self.test_data:</span><br><span class="line">                self.test_pred.append(self.model.predict(td))</span><br><span class="line"></span><br><span class="line"><span class="comment"># %% [markdown]</span></span><br><span class="line"><span class="comment"># # LrScheduler</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># %% [code]</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">build_lrfn</span>(<span class="params">lr_start=<span class="number">0.000001</span>, lr_max=<span class="number">0.000002</span>, </span></span></span><br><span class="line"><span class="function"><span class="params">               lr_min=<span class="number">0.0000001</span>, lr_rampup_epochs=<span class="number">7</span>, </span></span></span><br><span class="line"><span class="function"><span class="params">               lr_sustain_epochs=<span class="number">0</span>, lr_exp_decay=<span class="number">.87</span></span>):</span></span><br><span class="line">    lr_max = lr_max * strategy.num_replicas_in_sync</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">lrfn</span>(<span class="params">epoch</span>):</span></span><br><span class="line">        <span class="keyword">if</span> epoch < lr_rampup_epochs:</span><br><span class="line">            lr = (lr_max - lr_start) / lr_rampup_epochs * epoch + lr_start</span><br><span class="line">        <span class="keyword">elif</span> epoch < lr_rampup_epochs + lr_sustain_epochs:</span><br><span class="line">            lr = lr_max</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            lr = (lr_max - lr_min) * lr_exp_decay**(epoch - lr_rampup_epochs - lr_sustain_epochs) + lr_min</span><br><span class="line">        <span class="keyword">return</span> lr</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> lrfn</span><br><span class="line"></span><br><span class="line"><span class="comment"># %% [code]</span></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">plt.figure(figsize=(<span class="number">10</span>, <span class="number">7</span>))</span><br><span class="line"></span><br><span class="line">_lrfn = build_lrfn()</span><br><span class="line">plt.plot([i <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">35</span>)], [_lrfn(i) <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">35</span>)]);</span><br><span class="line"></span><br><span class="line"><span class="comment"># %% [markdown]</span></span><br><span class="line"><span class="comment"># ## Train Model</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># %% [code]</span></span><br><span class="line">roc_auc = RocAucCallback(test_dataset, <span class="number">0.9195</span>)</span><br><span class="line">lrfn = build_lrfn()</span><br><span class="line">lr_schedule = tf.keras.callbacks.LearningRateScheduler(lrfn, verbose=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">train_history = model.fit(</span><br><span class="line">    train_dataset,</span><br><span class="line">    steps_per_epoch=<span class="number">150</span>,</span><br><span class="line">    validation_data=valid_dataset,</span><br><span class="line">    callbacks=[lr_schedule, roc_auc],</span><br><span class="line">    epochs=<span class="number">35</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># %% [markdown]</span></span><br><span class="line"><span class="comment"># ## Submission</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># %% [code]</span></span><br><span class="line">sub[<span class="string">'toxic'</span>] = np.mean(roc_auc.test_pred, axis=<span class="number">0</span>)</span><br><span class="line">sub.to_csv(<span class="string">'submission.csv'</span>, index=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># %% [markdown]</span></span><br><span class="line"><span class="comment"># # Reference</span></span><br><span class="line"><span class="comment"># * [Jigsaw TPU: DistilBERT with Huggingface and Keras](https://www.kaggle.com/xhlulu/jigsaw-tpu-distilbert-with-huggingface-and-keras)</span></span><br><span class="line"><span class="comment"># * [inference of bert tpu model ml w/ validation](https://www.kaggle.com/abhishek/inference-of-bert-tpu-model-ml-w-validation)</span></span><br><span class="line"><span class="comment"># * [Overview of Text Similarity Metrics in Python](https://towardsdatascience.com/overview-of-text-similarity-metrics-3397c4601f50)</span></span><br><span class="line"><span class="comment"># * [test-en-df](https://www.kaggle.com/bamps53/test-en-df)</span></span><br><span class="line"><span class="comment"># * [val_en_df](https://www.kaggle.com/bamps53/val-en-df)</span></span><br><span class="line"><span class="comment"># * [Jigsaw multilingual toxic - test translated](https://www.kaggle.com/kashnitsky/jigsaw-multilingual-toxic-test-translated)</span></span><br></pre></td></tr></tbody></table></figure>
</body></html>]]></content>
      <categories>
        <category>文本分类</category>
      </categories>
      <tags>
        <tag>多标签</tag>
      </tags>
  </entry>
  <entry>
    <title>新冠病毒全球大流行，我们缺乏的只是疫苗？</title>
    <url>/post/63671.html</url>
    <content><![CDATA[<html><head><link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script></head><body><p><img src="https://i.loli.net/2020/09/02/k9ozZSuIshlQ3Ud.jpg" alt="全面消毒 北京疫情突然升溫，防控進入「戰時狀態」。防疫人員連日來在北京豐台區的農貿市場、居民小區等，進行全面消毒。 新華社"><br><a id="more"></a></p>
<blockquote>
<p>本文转自微信公众号，<a href="https://mp.weixin.qq.com/s?__biz=MjM5MjYxOTQ2NA==&mid=2650202369&idx=1&sn=738db7d0fc8c69f2dbe5b8ad64ae09e5&chksm=bea1cfa689d646b0183608329abdbf11c53f64924ce476a219bc39cbb7373805c3dbaf36c936&mpshare=1&scene=23&srcid=0404YwhJm01ENyZGtvQaeyr6&sharer_sharetime=1586009335106&sharer_shareid=47825813c3bfc95e426cc37b214c1ac0#rd">原文</a>。个人觉得写得非常好，作为此次疫情的反思和总结。</p>
</blockquote>
<p>又一次的开学典礼付诸东流，这一次春天的典礼是因为新冠肺炎，上一次冬天的典礼是因为香港动荡。不少朋友问我怎么没有看到我在新冠肺炎下的演讲、观点和文章？近两个月里，好文何止上百上千？有多少从疫情中央发出的令人潸然泪下的亲身经历？有多少发自内心的自省和思考？有多少对国家未来的焦虑和期许？我们已经好久没有经历过这样的场面，在同一个时刻、为同一个人、为同一件事发出我们谦卑的声音，吹起我们的口哨声？而这都是为了同一个目标，希望类似的悲剧可以再少些；希望我们无需生活在不必要的恐惧之中；希望这个民族无论何时都是被人敬重的。</p>
<p>这当然是一场灾难。庚子鼠年以超出所有人的想象力，开始了这一场天灾，但这也是一场人祸。根据英国南安普敦大学的研究，如果武汉提前三个星期开始狙击这一病毒，仅中国受感染的数目就可以减少 95%。当然这只是一项研究，而现实与数字模型之间存在的距离有时可以是如此之大！如果武汉封城之后欧美各国不会如此傲慢，而是积极合作应对，今天的欧洲和美国或许就不会面对这样的人道危机！在全球面临这样的大灾难面前，相反，我们看到的是自私与自大、嘲讽与指责、恐惧与推卸，甚至阴谋论甚嚣尘上，代替了理性的思考和应有的反思。面对这样的世纪疫情大流行的恐惧，我们缺乏的远非控制疫情的疫苗！</p>
<p>我们缺乏常识；我们缺乏见识；我们缺乏透明度；我们缺乏同理心；我们缺乏担当；我们缺乏反思……</p>
<h2 id="我们缺乏常识" class="heading-control"><a href="#我们缺乏常识" class="headerlink" title="我们缺乏常识"></a>我们缺乏常识<a class="heading-anchor" href="#我们缺乏常识" aria-hidden="true"></a></h2><p>在这场疫情席卷全球时，新冠肺炎也成了阴谋论的温床。短短的一个多月时间里，有武汉病毒研究所病毒外漏的 “泄毒之说”，有美国驻武汉领事馆留下八个可疑生化毒物箱的 “种毒之说”，有美国参议员柯顿指控毒源来自大陆生化实验室的 “放毒之说”，有武汉军运会期间美国兵 “播毒之说”，莫衷一是。我从一开始就对阴谋论存疑，我总觉得人性虽恶，但人类的恶行还不至于如此匪夷所思。有些指控，稍微求证，就知道是胡言乱语。美国驻武汉总领事馆位于武汉新世界国贸大楼第 47 楼，后院在哪里？生化毒物箱又如何埋在地下 1.5 公尺处？谎言哗众取宠，但信者众！如果病毒来自中国的生物基因作战实验室，对病毒的认识和控制还会那么难吗？这样低水准的阴谋论竟然畅行全球！其实只要有基本常识，反智的阴谋论就不可能大行其道。</p>
<p>我们缺乏常识也因为我们常常以偏盖全，信息不对称。意大利专家雷穆齐（Giuseppe Remuzzi）表示早在去年 11 月份，意大利北部就有人染上高度疑似新冠肺炎的不明肺炎。中国的一些媒体第一时间就报道了意大利是源头的说法，让不少中国人信以为真。中国的记者还纷纷打电话去采访，他对自己早先的采访被断章取义非常不满，并指出这是教科书式的 “宣传手段”。但之后他纠正中国媒体的说法，并没有被广泛报道。他还在另一个场合表示，武汉可能早已出现新冠肺炎感染，期间有大量中国人从武汉来到意大利，令意大利出现了疑似案例，由于一切来自中国的信息都不透明，才令疫情失去控制的黄金时机。其实意大利北部温州的人很多，而一月的时候，除了武汉，温州疫情也很严重。在中国就有专家因看到浙江有人感染之后，强烈建议武汉必须封城。</p>
<p>疫情刚爆发时，有不少人总在那里质问，美国每年季节性流感死了成千上万人，无人恐慌，世界各国没有切断和美国的联系，但美国为何要切掉和中国的联系？这是否过度反应？是否歧视中国？是否违反世界卫生组织的指引？但季节性流感有疫苗，死亡率只有新冠肺炎的十分之一，这样的事实很多人并不了解。如今看到疫情蔓延全球，纽约成为另一个武汉，大家应该可以明白每年在美国发生的季节性流感和新冠肺炎之间的根本不同。</p>
<p>我们缺乏常识是因为我们受制于我们有限的知识和见识，无法认识事物的真相；我们缺乏常识也是因为我们面对恐惧而惊慌失措，无法理性地看待自媒体时代所获得的虚假资讯；我们缺乏常识也是因为我们的立场和偏见挡住了自己的视线，无法走出原有的认知。</p>
<h2 id="我们缺乏见识" class="heading-control"><a href="#我们缺乏见识" class="headerlink" title="我们缺乏见识"></a>我们缺乏见识<a class="heading-anchor" href="#我们缺乏见识" aria-hidden="true"></a></h2><p>同样在欧美各国，不少人还真的将新冠肺炎和季节性流感等同起来，根本不把新冠病毒当回事，酿成今日欧美各国沦陷的惨痛教训。在发生新冠肺炎这样的全球公共医疗危机时，不要说普通人，即便全球最顶尖的传染病专家对病毒都缺乏足够的认识，束手无策，无法预见其发展方向，至多只能依靠模型做出推算，但最终和现实也可能相距甚远。在疫情初期，不要说西方的专家，即便内地最顶尖的传染病专家都不认为这次疫情比 “非典” 严重。因香港的特殊地位，香港大学的专家学者敢于发声，袁国勇教授早在 1 月 3 日就警告香港政府，这次疫情极为严重，香港特区政府早在 1 月 7 日就宣布把 “严重新型传染性病原体呼吸系统病” 列为须呈报的疾病，卫生部门有权强制隔离怀疑患者。管轶教授是香港大学新发传染性疾病国家重点实验室主任，最早发出疫情将失控的警告。</p>
<p>香港因 2003 年受 “非典” 的沉重打击，大家记忆犹新，不少香港人对新冠肺炎都非常恐惧，也出现了抢购潮。但在香港的西方人对此的反应就大为不同，包括香港大学中的白人学者也觉得这是类似流感的病毒，只不过传染率和死亡率高而已。这种判断一度让我觉得香港是否过度恐慌了，特别是香港医务人员以罢工逼迫政府封关的举动过激，违背了医务人员救死扶伤的伦理底线。疫情初期在香港街上也基本看不到有多少西方人戴口罩，所以在西方的华人因为担心感染病毒戴口罩也被视为怪物，不被理解还算次要，还受到白眼和歧视，甚至遭人毒打。因为在西方的文化里，只有得病的人才戴口罩，而你得病了就不该出现在公众的地方。其实西方人这样的行为也是因认知受限，而诉诸暴力的不法之徒更是蔑视人权。</p>
<p>这次疫情在欧美的迅速蔓延终于让西方意识到新冠病毒不只属于亚洲人，他们原先冷眼旁观，以为白种人可以刀枪不入。甚至欧美的不少医学专家初期都低估了这个疫情的风险，从意大利大意失荆州，到英国的 “群体免疫”，再到美国的全线沦陷，在一定程度上都和他们对这个病毒的有限认知有关，说难听点就是无知。因此政府不敢与普通民众的认知相左，轻易做出封城的决定。医学界本身也存在完全对立的看法，直到伦敦帝国理工学院流行病专家尼尔・弗格森团队的研究报告做出了令人恐惧的预测之后，英美两国政府才改变被动的应对策略。这份研究报告警告，如果英美两国不积极应对，英国将会有超过 50 万的人死亡，而美国将有 220 万人死亡。即便如此，牛津大学的研究团队在此之后还是得出截然不同的结论，认为新冠病毒在英国已经传播了一个多月，大约一半人口已经获得了实质的群体免疫能力。</p>
<p>全球在应对这个新型病毒的侵袭时，因为知识不足，做出了不少错误的判断。在疫情初期，对病毒的严重性难以做出正确的判断，在获得人传人的证据之后才被迫做出武汉封城的决定。但同时也因为认知不足，人的见识有限，影响了我们应对病毒的策略。东亚地区有 “非典” 的惨重教训就极为重视，西方民众对新冠病毒的认知则不同，完全放任。</p>
<p>我们的见识常常受限于我们的生活经历和环境，但我们不可能亲临其境去认知每一件事物，因此获取全面的信息就变得至关重要。不幸的是我们因防火墙无法获得客观的信息，因处在同温层里拒绝不同的信息，更不要说我们因缺乏透明度难以接收真实的信息。</p>
<h2 id="我们缺乏透明度" class="heading-control"><a href="#我们缺乏透明度" class="headerlink" title="我们缺乏透明度"></a>我们缺乏透明度<a class="heading-anchor" href="#我们缺乏透明度" aria-hidden="true"></a></h2><p>回首往事，不少人都低估了疫情的危害！但是，在疫情还没有开始蔓延时，如果做到信息公开透明，如果吹哨人不被劝诫、警告、和惩罚，或许新冠肺炎全球大流行的历史会改写。许多在武汉不该发生的事一定不会发生，武汉的牺牲就不会这么大，中国百姓的牺牲也就不会这么大。</p>
<p>从中国最早处理新冠肺炎的不当做法，到世界卫生组织迟迟未对全球发出最高级别的警告，到欧美各国的迟缓应对行动，都和缺乏透明度有关联。这次疫情如此迅猛扩散的第一责任人当然是武汉当局、湖北当局，他们对公众隐瞒信息甚至掩盖真相，引发了民众的不信任，国际社会不少人甚至怀疑中国的死亡率造假。中国最为受伤的就是因封锁和隐瞒信息，导致疫情的控制受到延误，遭到国际社会诟病、排斥和指责。武汉封城之后，中国的经济和民生受到重创的举措和牺牲也因此大打折扣，对中国的负面影响其实刚刚浮现。</p>
<p>美国政客在中国疫情最严重的时刻，颇有隔岸观火的看客心态。特朗普为了选举，为了股市不下跌，不影响经济，就是不愿承认疫情迟早会冲击美国。他本以为关闭了来往中国的航线，切断了来自中国的人流就万事大吉了。他还不让邮轮上受感染的游客在美国下船，就是要制造美国本土病毒感染者很低的假象。但这样的做法和一切以稳定为首要的考虑有何区别呢？在疫情终于席卷美国之后，他也是不断大事化小，尽量降低疫情所带来的冲击和影响，甚至在感染人数还在不断攀升时竟然表示美国的经济活动在复活节就可以恢复正常！所幸美国有独立的媒体，在白宫可以直接和总统公开叫板，不让政府传播的不实消息当道。在白宫记者会上，美国媒体公开质疑特朗普的抗疫政策不当，当场质问总统为何不停地使用 “中国病毒” 这样的歧视性字眼。</p>
<p>早在 1 月 20 日，当我确认这将是一场公共卫生灾难时，我就第一时间在我的朋友圈里转发了管轶教授对疫情的 “悲观” 看法。但他的科学分析在内地被视为耸人听闻，有人甚至借他的 “逃跑说” 对他进行人身攻击，但正是这样客观的信息才有助于我们了解事实真相，了解这一公共卫生危机已经去到了多么危险的境地！其实在发生类似新冠肺炎这样的危机时，面对太多的不确定性，要阻止谣言，信息的透明就显得尤为重要。</p>
<p>除了刻意隐瞒信息，还有虚假资讯泛滥。全球数百名科学家 2 月上旬出席日内瓦 “世卫论坛”，讨论新型冠肺炎疫情，学者就感叹他们不得不面对两条战线作战，除了应付病毒大流行，还要应付虚假资讯大泛滥 ，而应对虚假资讯泛滥比抗疫本身还艰难。网上流传最广最快的往往就是耸人听闻的假消息和渲染成见的看法，这些不实的信息，有恶意造谣，有断章取义，导致非理性的反应和恐慌，甚至制造混乱和分化。世卫顾问隆基尼（Ira Longini）和香港大学医学院院长梁卓伟曾提及全球三分之二的人口有可能感染新冠病毒，但网上的信息都忽略了 “如果传播未加抑制” 的假设，特意将最坏的可能性无限放大，引起不必要的恐慌。</p>
<p>在任何一场公共危机发生的时候，政府是不可能靠屏蔽信息来阻止危机的蔓延。恰恰相反，这只会造成危机的进一步恶化。即便在上个世纪的苏联时代，对切尔诺贝利核泄露的隐瞒最终给人类带来了一场世纪大灾难，更何况我们已经身处社交媒体如此发达的时代！</p>
<p>面对全球疫情大流行，信息披露和信息对称有助于我们了解不同地域，在不同的文化和背景下的不同应对策略和措施。不管是对疫情的判断，还是应对疫情的方法，各国都有不同的理解和做法，相互之间不仅不该嘲笑，反而应该借鉴。我们因条件限制无法获得全面的信息，但至少可以换位思考，从他者的角度看问题，避免幸灾乐祸的看客心理。</p>
<h2 id="我们缺乏同理心" class="heading-control"><a href="#我们缺乏同理心" class="headerlink" title="我们缺乏同理心"></a>我们缺乏同理心<a class="heading-anchor" href="#我们缺乏同理心" aria-hidden="true"></a></h2><p>疫情爆发之后，各国不仅有不同的认知过程，而且在获得相同的认知之后所采取的应对也并不相同。武汉封城的消息传出之后，西方的反应也是两极，有称这样的举措是流行病专家的天堂，而这只有在威权国家才能实现，民主国家只能羡慕。但也有一些西方国家看到中国面临的困境，在疫情刚刚爆发时，也带有事不关己高高挂起、甚至幸灾乐祸看笑话的心态来看待中国的抗疫，还把病毒与中国的国民性和低劣文化相联系。</p>
<p>各国抗疫的做法离不开其体制、文化、历史等因素。在中国，一声令下，举国体制立马见效，整个国家有如一部机器，全力抗灾，所有其它事情都要靠边站，甚至做出牺牲，包括在 “准战争” 状态下个体的权利和自由，其它病人可否受到正常的医疗救助，都不是最重要的考虑。事实证明，这样的牺牲确实巨大，但这一抗疫历史上未曾经历过的举措，一座上千万人口的大城市被封城两个月的战略最终是奏效的。</p>
<p>中国的牺牲阻止了疫情蔓延，可歌可泣。即便如此，可圈可点之处也多如牛毛，野蛮作业的现象也并非个别。中国人不喜欢美国指手画脚，那别的国家难道就喜欢中国这么做？一些自媒体对别国状况一知半解，充满无知、偏见和轻蔑，非要说人家不会抄作业。看看东邻日本，和韩国的做法也不同，连大面积的检测也没做，情况也不算太坏！日本的人口密度还超过中国！但日本人平时的生活和卫生习惯，你又了解多少？其实就是华人社会的香港、澳门、台湾、新加坡等地的处理方式都不同，当中新加坡的所谓 “佛系” 防疫措施相当成功让不少人大跌眼镜。</p>
<p>新加坡从 “重灾区” 到 “模范生”，表面上看去似乎选择了 “佛系” 的抗疫策略，曾引来不少怀疑、甚至嘲笑。新加坡防疫成功是有原因的，其策略可以概括为：最快反应、最早防范、最有系统、最严惩罚、最少折腾、最缺恐慌。新加坡一度是仅次于中国病例第二高的国家，同时人口稠密，还是国际交通枢纽。但新加坡政府反应迅速且效率高，最早限制来自中国的人流，并实施了对不同人群的休假令和居家隔离令。“非典” 之后建立起来的疫情警报系统立即派上用场。新加坡国家传染病中心集先进的检测、治疗与实验研究为一体，马上研发并合作生产了快速病毒检试剂，有健全的检测体系，保证了疑似患者尽快得到治疗，避免了疫情的传播，加强了民众的信心。新加坡缺乏口罩生产能力，不鼓励大家戴口罩，但政府还是快速购买了五百万个口罩派发到每家每户，安抚民众。新加坡有充足的医疗资源，类似于中国的发热门诊就有 873 个，相当于北京发热门诊的 11 倍。我很早在朋友圈里就转发相关的信息看好新加坡的做法，甚至比香港还成功，没有发生香港排长队争口罩、抢厕纸的 “奇观”。但话说回来，香港的恐慌是基于香港曾在 2003 年 “非典” 时曾遭重创的惨痛历史，以及香港和内地每天有大量的人员来往这一事实。</p>
<p>韩国这次的抗疫模式在西方更是受到肯定，法国总统和瑞典首相等多国政要甚至致电韩国讨教。但韩国对疫情的控制到底有何魅力？为何西方愿意到韩国取经和复制韩国模式呢？韩国也曾面对与中国相同的困境，但两国在大范围发生疫情之后，采取了类似的抗疫战略，新增病例曲线迅速被压平。但西方在看韩国的经验时，特别看重韩国没有因疫情出现压制言论和信息受阻的现象，没有因禁令影响民众的行动和自由，国家的经济更没有受到太大的冲击。韩国的经验可以归结为：早干预、早准备、早检测、早跟踪、早隔离、早观察。韩国的企业早就判断病毒迟早会扩散到韩国，第一时间就研发出检测试剂盒，获得政府的紧急审批投放市场，检测过程只需十分钟，几小时内可以出结果，准确率超过 98%。韩国单日可检测近两万人，检测率全球之冠，已有 120 多个国家争相从韩国进口测试盒。韩国政府还迅速修订法律，网站和手机都可以追踪病发者，一旦有新病例，就可以获得信息和警报。</p>
<p>好的经验当然可以抄，可以借鉴，但不必过分地显耀自己的成功，这只会让人反感。己所不欲，勿施于人。现在中国不准外国人入境，这是因为中国不能再冒第二次疫情失控的风险，于情于理都不是自私自利。同样，疫情爆发初期，香港、新加坡、意大利、美国等地对中国人封关、撤侨也是同理，人家也同样不愿意看到疫情蔓延，为何那时就可以攻击别人是恶意制造恐慌，是对中国背后插上一刀呢？美国在欧洲疫情严重之后也禁止欧洲人前往美国，最后连英国这个小兄弟也进了入境限制名单。日本现在对包括中国、韩国、美国、欧洲在内的国民入境都采取十四日隔离的政策。疫情初期，中国民众对日本的态度发生了 180 度的大转弯，曾经被我们骂得一无是处的大和民族似乎对中国很友好、很善良，向中国捐赠各类物资，而对美国政府的表现极为不满。其实抛开美国民间和企业的资助不提，为何一定就要期待和中国正在打贸易战的特朗普政府对你友好呢？而对中国最早锁国的是朝鲜、俄罗斯、越南等国！</p>
<p>在疫情袭击的恐惧中，我们更不可以幸灾乐祸地嘲笑别人的行为，透过渲染别国的疫情失控来展现自己的英明和伟大，而忘记了自己并没有走出险境。美国和意大利的报纸上密密麻麻的讣告，看去令人悲伤和沉重，恰恰彰显了人性的一面。中国不少媒体将意大利和美国医院中的尸体的照片无限渲染，而失去亲人的武汉人前去领取骨灰盒，为了正常的悼念发出的哀思和照片却消失了。我们当中总有人不愿正视自己的创伤，不可忍受将苦难、悲剧和丑恶呈现在他们面前的人，将读者高达五千万的 “日记” 视为恶毒、无耻，却又如此钟情地展示 “纽约医院尸满为患”、“纽约穷人疫情之下被迫乘坐地铁上班”、“英国政府勒令医生封口” 这样的文字和照片。广东一个企业老板竟然建议厂家做假测温枪卖给美国，让感染者越来越多，辽宁有餐厅门外贴出横幅祝贺美日疫情扩散，就不单单是没有同理心了，而是无知的反人类言论。</p>
<p>如果我们可以同样毫无顾虑地拷问自己，犹如如此心安理得地对他人提出质疑，我们的心智就一定不会萎缩，我们兴许也就有了希望。如今，我们甚至无法正常地伸出舌头，道出自己的甜酸苦辣，又何必如此居高临下，带着幸灾乐祸的病态，刻意营造似是而非的场景，来彰显那虚幻的优越感？！但我总是固执地坚信，一个人、一个国家、一个民族只要勇于承担起苦难中的责任，最终一定是会得到别人的理解和赞许的。</p>
<h2 id="我们缺乏担当" class="heading-control"><a href="#我们缺乏担当" class="headerlink" title="我们缺乏担当"></a>我们缺乏担当<a class="heading-anchor" href="#我们缺乏担当" aria-hidden="true"></a></h2><p>在这次疫情中最常听到的一个字就是甩锅，这场 “甩锅大战” 从武汉封城的那一刻开始就不断上演，从当地的医疗机构，到各级政府官员，到中国疾病控制中心，大家都在问，疫情失控和蔓延的责任在谁？</p>
<p>中国在 “非典” 之后耗资 11 亿，搭建了全球最大的传染病疫情和突发公共卫生事件网络直报系统，过去 15 年间持续监测 39 种法定传染病。这个全球最快速的疫情上报系统，可以在短短两小时内将疫情上达北京，中国最高的疾病防疫专家在 2019 年曾经表示中国绝不会重演 “非典” 悲剧。但话音刚落，这个耗费巨资的系统并没有在这次病毒蔓延中发挥功效。或许我们永远都无法知道真相，但有一点很清楚，专业判断在明哲保身、没有承担的官僚系统中被冷冻了，生命的价值也同样在个人权力的棋盘上被抛之脑后。</p>
<p>这场疫情最大的讽刺是，全球最大的两个经济体在面对这场世界公共卫生大危机时，竟然上演了一出极为相似的闹剧。几乎每天陪同特朗普在白宫见记者的美国传染病首席专家福西不谄媚权贵，不介意道出与他旁边的总统立场不同的看法，其独立的专业精神不受政治的左右，但他的专业判断也同样被美国总统束之高阁。疫情在中国蔓延恶化之时，美国的科学家就发出警告，但美国疾病防疫中心、美国食品和药物管理局、美国卫生和公共服务部似乎都没有看到采取行动的紧迫性，更何况美国总统特朗普本人了。特朗普向来蔑视科学和专业的意见，联邦政府被一群科学怀疑论者把持。而特朗普就喜欢看极右的福克斯电视台，曾与中国同行舌战的女主播 Trish Regan 就鼓吹疫情是民主党的阴谋，而特朗普本人就是一个阴谋论者。他同样不信任主流媒体，不停地和主流媒体在白宫记者会上唇枪舌剑，甚至当众侮辱记者。特朗普也不重视来自情报机关的报告，警告疫情的严重性被中国低估和隐瞒，以及疫情将会蔓延全球。此外，特朗普对玩政治的兴趣多过抗疫，为了竞选就是不愿承认疫情迟早会冲击美国，他对疫情轻描淡写的原因也是因为民主党主政的纽约州、加州、华盛顿州受到重创，但共和党的红州并未受到太大的影响。纽约时报在 3 月 28 日刊登万字文，以 “美国错失的一个月” 为题，分析了美国因检测技术落后，法规不配套，白宫领导无方，政府官僚作风，导致美国失去了疫情防控的黄金 30 天。</p>
<p>美国的科技和医疗发达，美国的医疗开支占 GDP 的比例最高，达到了近 18%，但美国至今的表现为何令人大跌眼镜？无法早期进行检测是疫情蔓延的元凶，美国疾病防控中心也不是不作为，但为何会发生这样灾难性的失误呢？这和欧美社会对新冠肺炎的轻视有相当大的关联。中国在修正了前期隐瞒疫情的错误之后，武汉封城的快速行动，为整个国际社会控制疫情争取了难得的宝贵时间。随后东亚各国和地区也纷纷采取行动，大体上都取得一定的成效，制止了新冠病毒的蔓延。遗憾的是，由于对疫情的认知存在极大的偏差，欧美国家都没有及时采取适当的应对措施，欧洲和美国先后演变成疫情的重灾区。此次疫情的另一个中心意大利，也只不过停飞了前往中国的航班。而美国早在 1 月 3 日就获得了中国的通报， 但美国和其它欧洲国家一样一直心态超然，觉得自己远隔重洋，“非典” 只在东亚流行，便以为此次新冠肺炎也同样会局限在东亚地区。</p>
<p>而疫情在美国开始蔓延后，这场 “甩锅” 大战竟然也蔓延到国际社会，中美两国爆发了令人捧腹的唇枪舌战。中国外交部的新任发言人在推特上怀疑美军在武汉播毒，特朗普亲自上阵，恶意地称新冠肺炎为 “中国病毒”。病毒起源地的争论凸显了各方意图透过 “甩锅” 来推卸应有的责任，其实起源地何罪之有？而美国国务卿蓬佩奥在特朗普改口之后，还坚持要将武汉病毒写进七大工业国外长的公报里，而被其它国家拒绝。美国自己浪费了一个多月的时间，疫情失控，特朗普却只会将矛头转移，掩盖自己抗疫能力的失误！更为严重的是，“中国病毒” 经过他的大嘴巴，在推特里一天又一天地在说，传遍全球，造成了美国等地歧视亚裔人的犯罪上升。美国联邦调查局的一项全新研究，警告全美针对亚裔人的仇恨犯罪案件数目，因新型冠状病毒疫情的扩散而飙升，危及美国的亚裔社群。连新加坡总理李显龙在接受美国有线电视新闻网 CNN 采访的时候，不仅感慨美国失去了领导世界战疫的能力，而且惊叹这两个世界大国竟然可以如此低水平地进行 “口水战”。</p>
<p>从亚洲到欧洲到美洲，昔日繁忙的大都会因这场疫情，生活已经停顿。这场疫情不仅暴露了我们制度的缺陷、系统的脆弱、和人性的罪恶，全球已经跌入新一轮的金融市场大动荡和全球经济大衰退，但不幸的是，我们不仅没有进行反思，却依旧在那里自我陶醉和自我撕裂！</p>
<h2 id="我们缺乏反思" class="heading-control"><a href="#我们缺乏反思" class="headerlink" title="我们缺乏反思"></a>我们缺乏反思<a class="heading-anchor" href="#我们缺乏反思" aria-hidden="true"></a></h2><p>一场史无前例的病毒大流行正向全球各个角落冲撞，死亡笼罩着这个星球。但面对这场突如其来的天灾，其中多少人祸是可以避免的呢？</p>
<p>封口 vs 封城：围绕着这场人道危机的争论焦点从一开始就从这里展开。如果没有发生 “封口” 事件，新冠肺炎的蔓延是否会有另一个结局？我们无法知道答案，但我们知道至少不会如此惨烈。问题在于一个经济如此发达的国度，为何依旧无法实现一个开放社会所需要的基本条件；一个自信的社会为何难以拉响危机来临的警报声。而这并非个别和单一现象，这有如隐藏在我们社会中的毒瘤和顽疾，总是如此粗暴地压制善意的提醒和批评。</p>
<p>在危机抵达临界点之后义无反顾的 “封城” 行动，尽管惨烈，却也是迫不得已的孤注一掷，但我们并非事事都一定要以牺牲个体的代价来实现宏大的目标，文明是体现在对每一个生命的关怀上的。“封口” 可以令一个民族、一个国家在全球失去信用和信任，即便在 “封城” 的巨大牺牲之后，受感染和死亡的官方的数据还是被质疑。扪心自问，为何中国常常成为这类被怀疑的目标与对象？一个真正开放的社会，和一个透明度高的社会，一定可以勇敢地面对真相并向大众提供真相。所幸，在疫情重击下，中国也出现了难得一见的媒体松绑现象。</p>
<p>另一方面，西方也常常从固有的认知出发，用有色眼镜看待中国的 “封城” 行动。在这场抗疫中，与东亚各地在武汉 “封城” 之后迅速进入作战状态完全不同，欧美各国不仅负面看待中国的 “封城” 行动，而且没有从中国的 “封城” 行动中嗅出危机的严重程度。</p>
<p>傲慢 vs 自大：这让我们再次活生生地看到了傲慢与无知，欧美各国普遍将最初在武汉出现的新病毒归结为黄种人的病。日本副首相兼财务大臣麻生太郎 2 月份曾在 G20 财长的一次会议上主动表示援助意大利和西班牙，却自讨没趣，欧洲国家非常不屑。意大利副总理后来在 G7 财政会议上更直截了当地表示，这是黄种人才会得的病，和他们西方人没有关系。无怪乎，意大利一度成为中国之外感染者最多的国家。特朗普的傲慢与自大终于在疫情横扫美国之后，被迫承认美国将面对比第二次世界大战还要惨重的死亡。</p>
<p>然而与西方的傲慢相对应的则是在中国自媒体的世界里无时不在的自大，在那里你只有看到中国成了全球抗疫的英雄和救世主，所有的悲剧都活脱脱地变成了赞歌的素材，而忘记了病毒是从武汉开始向全国和全球蔓延的。这样的自大在中国抗疫初现曙光之后，更是变成了对他国肆无忌惮的嘲笑。而最新的对象就是感染新冠肺炎人数最多的美国，却忘记了美国拥有强大的科技力量和发达的医疗体系，仅 ICU（重症监护室）的床位数量就远远超过中国。而 “傲慢” 与 “自大” 这对孪生兄弟却拥有一个共同点：偏见。</p>
<p>吃野味 vs 戴口罩：在有关病毒源头的吃野味文化，以及防止病毒扩散的戴口罩文化的讨论中，我们也看到了类似的偏见。2003 年 “非典” 之后中国人的确没有从中吸取惨痛的教训，及时关闭野味市场，不少人因而将此次病毒的爆发与中国人喜爱吃野味的文化联系在一起。这样的看法有其道理，中国人是时候改变吃野味的生活习俗。有趣的是，中国网民反而找出了纽约上流社会吃野味的视频，一时之间在朋友圈中疯传，证明美国人不过是五十步笑百步。不过这几年比较严重的传染病，包括中东呼吸综合症和甲型 H1N1 流感病毒并非源自中国。</p>
<p>另一方面，亚洲人戴口罩以防止病毒扩散基本是共识。但西方人，即便是生活在亚洲的西方人也不喜欢戴口罩。在西方，视口罩为病人标志的观念还带来了对亚裔人的歧视。在欧美各国生活的亚裔人处在戴口罩被歧视，不带口罩怕染上病毒的天人交战中。但在这次疫情重击欧美之后，戴口罩抵抗病毒的认知终于慢慢开始在欧美被接受了。</p>
<p>自媒体 vs 主流媒体（赞美 vs 批评）：在疫情的报道上，中国的主力军是自媒体，不管是赞歌，还是批评，自媒体带有更多的主观性和情绪性。而在许多其它地方，报道疫情的主力是主流媒体，力求客观。特别是美国媒体，其角色是监督政府，且喜欢监督全世界的政府，多数又是自由主义倾向，所以特朗普也反感美国主流媒体。但只有在美国这个国家，CBS 记者胆敢在白宫怒怼总统为何要使用歧视性的 “中国病毒”；NBC 的记者质问特朗普吹捧效果未经证实的抗疫药物是否给美国人虚假的希望，并指美国数百万人活于恐惧中；纽约时报驻京记者张彦（Ian Johnson ）的 “观点” 文章，指出中国为美国赢得了时间却被美国白白浪费了；纽约时报的社论公开谴责特朗普政府官员的言词加剧了对亚裔的种族仇恨。</p>
<p>中国自媒体里那个发自纽约的抗疫日记，作者声称其素材全部取自美国媒体的公开报道，而非道听途说，语带双关。的确，当纽约成为美国的武汉时，我每天在美国电视新闻上看到的几乎全是 “负面” 消息。每一个活生生的人离开人世时的凄惨故事；病人因缺乏医疗设备无法获得及时医治的悲剧；医务人员面对死亡威胁战斗在第一线几乎崩溃的场面；停留在街边装满尸体的冰冻车和医院走廊里运尸袋的场景；质问白宫何时可以确保医疗设备运抵现场的愤怒；受到病毒感染威胁下美国海军官兵的呼吁；失去工作的普通人无法交付房贷的忧虑。在这里你看到的是恐惧，是担忧，是悲伤，在这里你听不到任何赞歌。</p>
<p>威权 vs 民主：这次全球抗疫的叙事已经成为中国模式和西方模式之争，甚至上升到威权还是民主体制在抗疫中哪个更有成效的争论，但不少人却忘记了无论何种体制都有其成功与失败的经验与教训。在欧洲成为重灾区之后，德国的死亡率却一直很低，这或许与日耳曼民族的自律有关。在亚洲处于恐慌的时候，日本并没有跟随中国封城、没有跟随韩国大面积检测，但也没有像欧美发达国家那样失控，这或许与大和民族的自律和生活习惯有关。如果将抗疫简单地看成是中国体制的胜利，那么韩国、日本、新加坡、香港、台湾等地又是何种体制？无疑，中国自上而下的动员力量，让全球看到了中国体制战胜疫情的超强能力，但自下而上的公民社会的应变和调整能力在纽约成为疫情重灾区之后，同样令人刮目相看。</p>
<p>纽约在中央公园、体育场迅速建起方舟医院，并加快对受感染疑似人员的检测。来自全美的六万多名医务人员主动报名成为自愿者，自发前往纽约支援人手不足的医院，“捷蓝” 航空免费载送这些医护人员 “上战场”，酒店免费提供住宿，企业慷慨捐赠急需的防护用品和医疗设备，但没有企业对这些行动发稿、做公关、高调宣传。即便美国总统面对新冠肺炎的反应丑态百出，但这个国家所幸不是一个人说的算，受疫情影响最大的纽约州、加州、华盛顿州都不理睬他的狂言妄语。而美国的体制也决定了联邦政府对州一级政府的事务不可干涉，即便特朗普想对纽约和临近的两个州 “封城”，但纽约州州长公开反对，使得特朗普不得不放弃这一想法。特朗普随心所欲，疫情还未控制，就要求复活节恢复经济运作，但疾病专家和媒体则公开和他唱对台戏。因此，应对病毒需要在一个自下而上的公民社会里，民众敢于承担公民应有的责任和义务。</p>
<p>在全球面对这场前所未有的大灾难时，我们需要理性地思考人类的失误和失败，而非指责和推卸。这场大灾难离落幕之日还有漫漫长路，但这场天灾与人祸也给人类提供了一次难得的反思机会。在这场疫情结束之后，或许全球终将明白这不是 “中国病毒”，是各国必须共同面对的 “世界病毒”，病毒恰恰因我们人类的傲慢、自大、和自私而四处肆虐。在这个全球化被污名化的时代，尽管国与国的界线依旧分明，但病毒绝不会只在一国的边境线内停留。我们比以往任何时候都更需要有全球的视野和全球的胸怀，我们必须学会如何合作去共同应对前所未有的挑战。</p>
<p>庚子年常常是灾难之年，但或许也是转折之年。在新冠病毒横扫全球之后，这不应该是我们重拾孤立的时刻，而是通向一个不一样的全球化新时代的新起点。</p>
</body></html>]]></content>
      <categories>
        <category>生活</category>
      </categories>
      <tags>
        <tag>新冠疫情</tag>
      </tags>
  </entry>
  <entry>
    <title>村山谈话</title>
    <url>/post/ce85a882.html</url>
    <content><![CDATA[<html><head><link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script></head><body><blockquote>
<p>1995 年 8 月 15 日，村山富市首相就历史问题发表正式谈话，对日本的殖民统治和侵略，村山富市表示深刻的反省和由衷的歉意。</p>
</blockquote>
<h2 id="原文" class="heading-control"><a href="#原文" class="headerlink" title="原文"></a>原文<a class="heading-anchor" href="#原文" aria-hidden="true"></a></h2><p>先の大戦が終わりを告げてから、50 年の歳月が流れました。今、あらためて、あの戦争によって犠牲となられた内外の多くの人々に思いを馳せるとき、万感胸に迫るものがあります。<br>　敗戦後、日本は、あの焼け野原から、幾多の困難を乗りこえて、今日の平和と繁栄を築いてまいりました。このことは私たちの誇りであり、そのために注がれた国民の皆様 1 人 1 人の英知とたゆみない努力に、私は心から敬意の念を表わすものであります。ここに至るまで、米国をはじめ、世界の国々から寄せられた支援と協力に対し、あらためて深甚な謝意を表明いたします。また、アジア太平洋近隣諸国、米国、さらには欧州諸国との間に今日のような友好関係を築き上げるに至ったことを、心から喜びたいと思います。<br>平和で豊かな日本となった今日、私たちはややもすればこの平和の尊さ、有難さを忘れがちになります。私たちは過去のあやまちを 2 度と繰り返すことのないよう、戦争の悲惨さを若い世代に語り伝えていかなければなりません。とくに近隣諸国の人々と手を携えて、アジア太平洋地域ひいては世界の平和を確かなものとしていくためには、なによりも、これらの諸国との間に深い理解と信頼にもとづいた関係を培っていくことが不可欠と考えます。政府は、この考えにもとづき、特に近現代における日本と近隣アジア諸国との関係にかかわる歴史研究を支援し、各国との交流の飛躍的な拡大をはかるために、この 2 つを柱とした平和友好交流事業を展開しております。また、現在取り組んでいる戦後処理問題についても、わが国とこれらの国々との信頼関係を一層強化するため、私は、ひき続き誠実に対応してまいります。<br>　いま、戦後 50 周年の節目に当たり、われわれが銘記すべきことは、来し方を訪ねて歴史の教訓に学び、未来を望んで、人類社会の平和と繁栄への道を誤らないことであります。<br>　わが国は、遠くない過去の一時期、国策を誤り、戦争への道を歩んで国民を存亡の危機に陥れ、植民地支配と侵略によって、多くの国々、とりわけアジア諸国の人々に対して多大の損害と苦痛を与えました。私は、未来に誤ち無からしめんとするが故に、疑うべくもないこの歴史の事実を謙虚に受け止め、ここにあらためて痛切な反省の意を表し、心からのお詫びの気持ちを表明いたします。また、この歴史がもたらした内外すべての犠牲者に深い哀悼の念を捧げます。<br>　敗戦の日から 50 周年を迎えた今日、わが国は、深い反省に立ち、独善的なナショナリズムを排し、責任ある国際社会の一員として国際協調を促進し、それを通じて、平和の理念と民主主義とを押し広めていかなければなりません。同時に、わが国は、唯一の被爆国としての体験を踏まえて、核兵器の究極の廃絶を目指し、核不拡散体制の強化など、国際的な軍縮を積極的に推進していくことが肝要であります。これこそ、過去に対するつぐないとなり、犠牲となられた方々の御霊を鎮めるゆえんとなると、私は信じております。<br>　「杖るは信に如くは莫し」と申します。この記念すべき時に当たり、信義を施政の根幹とすることを内外に表明し、私の誓いの言葉といたします。<br><a id="more"></a></p>
<h2 id="翻译" class="heading-control"><a href="#翻译" class="headerlink" title="翻译"></a>翻译<a class="heading-anchor" href="#翻译" aria-hidden="true"></a></h2><p>上次大战结束以后已过了五十年的岁月。现在再次缅怀在那场战争中遇难的国内外许多人时，感慨万端。</p>
<p>战败后，日本从被战火烧光的情况开始，克服了许多困难，建立了今天的和平和繁荣。这是我们的自豪。每一个国民在这过程中倾注了才智，作出了不懈的努力。对此我谨表示由衷的敬意。对于美国以及世界各国直至今日所给予的支援和合作，再次深表谢意。另外，我国同亚太近邻各国、美国以及欧洲各国之间建立起来了像今天这样的友好关系，对此我感到由衷的高兴。</p>
<p>今天，日本成为和平、富裕的国家，因此我们动辄忘掉这和平之尊贵与其来之不易。我们应该把战争的悲惨传给年轻一代，以免重演过去的错误。并且要同近邻各国人民携起手来，进一步巩固亚太地区乃至世界的和平，为此目的特别重要的是，同这些国家之间建立基于深刻理解与相互信赖的关系。这是不可缺少的。日本政府本着这种想法，为支援有关近现代史上日本同近邻亚洲各国关系的历史研究，并为飞跃扩大同该地区各国的交流，正在展开以这两方面为支柱的和平友好交流事业。同时，关于我国政府现在致力解决的战后处理问题，为进一步加强我国和这些国家之间的信赖关系，继续要诚恳的处理。</p>
<p>正当战后五十周年之际，我们应该铭记在心的是回顾过去，从中学习历史教训，展望未来，不要走错人类社会向和平繁荣的道路。</p>
<p>我国在不久的过去一段时期，国策有错误，走了战争的道路，使国民陷入存亡的危机，殖民统治和侵略给许多国家，特别是亚洲各国人民带来了巨大的损害和痛苦。为了避免未来有错误，我就谦虚地对待毫无疑问的这一历史事实，谨此再次表示深刻的反省和由衷的歉意。同时谨向在这段历史中受到灾难的所有国内外人士表示沉痛的哀悼。</p>
<p>战败后 50 周年的今天，我国应该立足于过去的深刻反省，排除自以为是的国家主义，作为负责任的国际社会成员促进国际协调，来推广和平的理念和民主主义。与此同时，非常重要的是，我国作为经历过原子弹轰炸的唯一国家，包括追求彻底销毁核武器以及加强核不扩散体制等在内，要积极推进国际裁军。我相信只有这样才能偿还过去的错误，也能安慰遇难者的灵魂。</p>
<p>古话说：“杖莫如信”。在这值得纪念的时刻，我谨向国内外表明下一句作为我的誓言：信义就是我施政的根本。</p>
</body></html>]]></content>
      <tags>
        <tag>历史</tag>
      </tags>
  </entry>
  <entry>
    <title>《曾经我也想过一了百了》</title>
    <url>/post/25cf4fc9.html</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">日文歌词</th>
<th style="text-align:center">中文译文</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">仆が死のうと思ったのは<br>ウミネコが桟桥で鸣いたから<br>波の随意に浮かんで消える<br>过去も啄ばんで飞んでいけ<br>仆が死のうと思ったのは<br>诞生日に杏の花が咲いたから<br>その木漏れ日でうたた寝したら<br>虫の死骸と土になれるかな<br>薄荷饴 渔港の灯台<br>锖びたアーチ桥 舍てた自転车<br>木造の駅のストーブの前で<br>どこにも旅立てない心<br>今日はまるで昨日みたいだ<br>明日を変えるなら今日を変えなきゃ<br>分かってる 分かってる けれど<br>仆が死のうと思ったのは<br>心が空っぽになったから<br>満たされないと泣いているのは<br>きっと満たされたいと愿うから<br>仆が死のうと思ったのは<br>靴纽が解けたから<br>结びなおすのは苦手なんだよ<br>人との繋がりもまた然り<br>仆が死のうと思ったのは<br>少年が仆を见つめていたから<br>ベッドの上で土下座してるよ<br>あの日の仆にごめんなさいと<br>パソコンの薄明かり<br>上阶の部屋の生活音<br>インターフォンのチャイムの音<br>耳を塞ぐ鸟かごの少年<br>见えない敌と戦ってる<br>六畳一间のドンキホーテ<br>ゴールはどうせ丑いものさ<br>仆が死のうと思ったのは<br>冷たい人と言われたから<br>爱されたいと泣いているのは<br>人の温もりを知ってしまったから<br>仆が死のうと思ったのは<br>あなたが绮丽に笑うから<br>死ぬことばかり考えてしまうのは<br>きっと生きる事に真面目すぎるから<br>仆が死のうと思ったのは<br>まだあなたに出会ってなかったから<br>あなたのような人が生まれた<br>世界を少し好きになったよ<br>あなたのような人が生きてる<br>世界に少し期待するよ</td>
<td style="text-align:center">曾经我也想过一了百了<br>就因为看著海鸥在码头上悲鸣<br>随波逐流浮沉的海鸟啊<br>也将我的过去啄食 展翅飞去吧<br>曾经我也想过一了百了<br>因为生日那天杏花绽放<br>在那筛落阳光的树荫下小睡<br>大概就会像未能转生的虫 就此适应於土里长眠了吧<br>薄荷糖 渔港的灯塔<br>生锈的拱桥 被丢弃的自行车<br>杵立在木造车站的暖炉前<br>心却哪儿都不能就此启程<br>今日和昨日相同<br>想要更好的明天 今天就须有所行动<br>我知道 我都知道 但是<br>曾经我也想过一了百了<br>因为心早就被掏空<br>心不能被填满的哭泣著<br>因为我仍渴望著什麼<br>曾经我也想过一了百了<br>因为那松开的鞋带<br>我无法好好将它系紧<br>如同不懂得系紧某人一般<br>曾经我也想过一了百了<br>因为少年凝视著我<br>跪著在床上谢罪吧<br>向过去的我说声抱歉<br>电脑透出淡淡的光<br>楼上房间传来的动静<br>门口对讲机的声音<br>困在鸟笼中的少年捂住耳朵<br>与无形的敌人战斗著<br>他是三坪房间里的唐吉诃德<br>最后的结局 却是抖丑陋不堪<br>曾经我也想过一了百了<br>因为有人说我是冷漠的人<br>想要被爱的哭泣著<br>是因为终於尝到人间温暖<br>曾经我也想过一了百了<br>你美丽的笑著<br>满脑子想著自我了结<br>终究因为活著这事太过於刻骨<br>曾经我也想过一了百了<br>我还没有遇见你<br>因为有像你一样的人存在<br>我稍稍喜欢上这个世界了<br>因为有像你一样的人存在<br>我开始稍稍期待著这个世界</td>
</tr>
</tbody>
</table>
</div>
]]></content>
      <tags>
        <tag>歌词</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux Nvidia 驱动更新</title>
    <url>/post/abdb670.html</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>安装 nvidia 驱动，出现了一个错误：<br></p><figure class="highlight shell"><table><tbody><tr><td class="code"><pre><span class="line">ERROR: An NVIDIA kernel module 'nvidia' appears to already be loaded in your kernel.  This may be because it is in use (for</span><br><span class="line">       example, by an X server, a CUDA program, or the NVIDIA Persistence Daemon), but this may also happen if your kernel was</span><br><span class="line">       configured without support for module unloading.  Please be sure to exit any programs that may be using the GPU(s) before</span><br><span class="line">       attempting to upgrade your driver.  If no GPU-based programs are running, you know that your kernel supports module</span><br><span class="line">       unloading, and you still receive this message, then an error may have occured that has corrupted an NVIDIA kernel module's</span><br><span class="line">       usage count, for which the simplest remedy is to reboot your computer.</span><br></pre></td></tr></tbody></table></figure><br>这是因为系统中已经有 nvidia 驱动在运行着了。所以在安装新的驱动之前，要先解决就旧的驱动。<br><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">echo 'blacklist nvidia' &gt; /etc/modprobe.d/blacklist.conf</span><br><span class="line">bash NVIDIA-Linux-x86_64-xxx.xx.run --uninstall  # uninstall 这一步根据具体情况不同</span><br><span class="line">reboot</span><br></pre></td></tr></tbody></table></figure><br>重启后再安装一次，显示 driver is installed successfully。运行 nvidia-smi 检查 nvidia 驱动版本：<br><img src="https://i.loli.net/2020/12/17/2ijgPYEfH7Lvy9k.png" alt="pic01"><p></p>
]]></content>
  </entry>
  <entry>
    <title>基于用户的协同过滤算法 (UserCF)</title>
    <url>/post/7437a8cf.html</url>
    <content><![CDATA[<html><head><link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script></head><body><p>在推荐系统众多方法中，基于用户的协同过滤推荐算法是最早诞生的，原理也较为简单。该算法 1992 年提出并用于邮件过滤系统，两年后 1994 年被 GroupLens 用于新闻过滤。一直到 2000 年，该算法都是推荐系统领域最著名的算法。</p>
<p><img src="https://i.loli.net/2020/12/24/jIiVylmQeLzDBSP.png" alt="img"></p>
<h2 id="基本思想" class="heading-control"><a href="#基本思想" class="headerlink" title="基本思想"></a>基本思想<a class="heading-anchor" href="#基本思想" aria-hidden="true"></a></h2><p><strong>核心思想：相似的用户可能喜欢相同物品。</strong>当一个用户 A 需要个性化推荐时，可以先找到和他兴趣相似的用户群体 B，然后把 B 喜欢的、并且 A 没有听说过的物品推荐给 A，这就是基于用户的协同过滤算法。</p>
<a id="more"></a>
<h2 id="实现步骤" class="heading-control"><a href="#实现步骤" class="headerlink" title="实现步骤"></a>实现步骤<a class="heading-anchor" href="#实现步骤" aria-hidden="true"></a></h2><ol>
<li>找到与目标用户兴趣相似的用户集合</li>
<li>找到这个集合中用户喜欢的、并且目标用户没有听说过的物品推荐给目标用户</li>
</ol>
<!--more-->
<h3 id="发现兴趣相似的用户" class="heading-control"><a href="#发现兴趣相似的用户" class="headerlink" title="发现兴趣相似的用户"></a>发现兴趣相似的用户<a class="heading-anchor" href="#发现兴趣相似的用户" aria-hidden="true"></a></h3><p>协同过滤算法主要利用行为的相似度计算兴趣的相似度。</p>
<h4 id="获得数据" class="heading-control"><a href="#获得数据" class="headerlink" title="获得数据"></a>获得数据<a class="heading-anchor" href="#获得数据" aria-hidden="true"></a></h4><p>假设目前共有 4 个用户： A、B、C、D；共有 5 个物品：a、b、c、d、e。用户与物品的关系（用户喜欢物品）如下图所示：</p>
<p><img src="https://i.loli.net/2020/12/18/GH8FDuI2MitAC3P.png" alt="img"></p>
<h4 id="构建倒排表" class="heading-control"><a href="#构建倒排表" class="headerlink" title="构建倒排表"></a>构建倒排表<a class="heading-anchor" href="#构建倒排表" aria-hidden="true"></a></h4><p>建立 “物品 — 用户” 的倒排表</p>
<p><img src="https://i.loli.net/2020/12/18/Pg94wx5MTOJbh12.png" alt="img"></p>
<h4 id="构建用户相似度矩阵" class="heading-control"><a href="#构建用户相似度矩阵" class="headerlink" title="构建用户相似度矩阵"></a>构建用户相似度矩阵<a class="heading-anchor" href="#构建用户相似度矩阵" aria-hidden="true"></a></h4><p>构建用户相似度矩阵 matrix，其中 matrix [A][B] 表示用户 A 和用户 B 共同喜欢的电影的数量。</p>
<p><img src="https://i.loli.net/2020/12/18/OHa8ZNIuL4rkBof.png" alt="img"></p>
<h4 id="计算用户相似度" class="heading-control"><a href="#计算用户相似度" class="headerlink" title="计算用户相似度"></a>计算用户相似度<a class="heading-anchor" href="#计算用户相似度" aria-hidden="true"></a></h4><p><img src="https://i.loli.net/2020/12/18/9YbIVvjtdZfwyTK.png" alt="img"></p>
<h4 id="基于热度惩罚的用户相似度改进" class="heading-control"><a href="#基于热度惩罚的用户相似度改进" class="headerlink" title="基于热度惩罚的用户相似度改进"></a>基于热度惩罚的用户相似度改进<a class="heading-anchor" href="#基于热度惩罚的用户相似度改进" aria-hidden="true"></a></h4><h3 id="生成推荐" class="heading-control"><a href="#生成推荐" class="headerlink" title="生成推荐"></a>生成推荐<a class="heading-anchor" href="#生成推荐" aria-hidden="true"></a></h3><h2 id="评测指标" class="heading-control"><a href="#评测指标" class="headerlink" title="评测指标"></a>评测指标<a class="heading-anchor" href="#评测指标" aria-hidden="true"></a></h2><p>对用户 $u$ 推荐 $N$ 个物品 (记为 $R (u)$ )，令用户 $u$ 在测试集上喜欢的物品集合为 $T (u)$ ，然后可以通过准确率、召回率、覆盖率评测推荐算法的精度:</p>
<h3 id="召回率" class="heading-control"><a href="#召回率" class="headerlink" title="召回率"></a>召回率<a class="heading-anchor" href="#召回率" aria-hidden="true"></a></h3><h3 id="准确率" class="heading-control"><a href="#准确率" class="headerlink" title="准确率"></a>准确率<a class="heading-anchor" href="#准确率" aria-hidden="true"></a></h3><h3 id="覆盖率" class="heading-control"><a href="#覆盖率" class="headerlink" title="覆盖率"></a>覆盖率<a class="heading-anchor" href="#覆盖率" aria-hidden="true"></a></h3><p>覆盖率反映了推荐算法发掘长尾的能力，覆盖率越高，说明推荐算法越能够将长尾中的物品推荐给用户。</p>
<p>分子部分表示实验中所有被推荐给用户的物品数目 (集合去重)，分母表示数据集中所有物品的数目。</p>
</body></html>]]></content>
      <tags>
        <tag>推荐系统</tag>
      </tags>
  </entry>
  <entry>
    <title>简历模板</title>
    <url>/post/98c39c33.html</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><blockquote>
<p>一个知道怎么做的人可能总能找到一份工作，但是知道为什么做的人将成为他的老板。 — 约翰・麦克斯韦（John Maxwell），畅销书《影响力》的作者</p>
</blockquote>
<p>简历模板 <a href="https://www.overleaf.com/read/tbjwnnsydqjz">链接</a><br><img src="https://i.loli.net/2020/12/31/pA3Q9GHxYjMCfbl.png" alt="image.png"></p>
]]></content>
      <tags>
        <tag>简历</tag>
      </tags>
  </entry>
  <entry>
    <title>论文阅读 - 20201230</title>
    <url>/post/611a4db8.html</url>
    <content><![CDATA[<html><head><link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script></head><body><h2 id="论文1" class="heading-control"><a href="#论文1" class="headerlink" title="论文1"></a>论文 1<a class="heading-anchor" href="#论文1" aria-hidden="true"></a></h2><p>《<strong>Self-attention Comparison Module for Boosting Performance on Retrieval-based Open-Domain Dialog Systems</strong> 》，主要学习一下 Transformer 的简单描述，其他的没什么好看的。</p>
<p><img src="https://i.loli.net/2020/12/30/Y7neDC5vjURE4GI.png" alt="image.png" style="zoom:50%;"></p>
<h2 id="论文2" class="heading-control"><a href="#论文2" class="headerlink" title="论文2"></a>论文 2<a class="heading-anchor" href="#论文2" aria-hidden="true"></a></h2><p>《<strong>Why Neural Machine Translation Prefers Empty Outputs</strong>》</p>
</body></html>]]></content>
      <tags>
        <tag>论文</tag>
      </tags>
  </entry>
  <entry>
    <title>光是什么？</title>
    <url>/post/22ce43c.html</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>J.J. Thomson won the Nobel in Physics in 1906 when he showed electrons were particles.<br>His son G. P. Thomson won the Nobel Prize in Physics in 1937 for showing that electrons are waves.<br><img src="https://i.loli.net/2020/12/31/lIwgaCiyWNGupOK.jpg" alt="图像"></p>
]]></content>
  </entry>
  <entry>
    <title>Latex 安装和使用</title>
    <url>/post/1440dbb0.html</url>
    <content><![CDATA[<html><head><link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script></head><body><h2 id="Latex环境设置" class="heading-control"><a href="#Latex环境设置" class="headerlink" title="Latex环境设置"></a>Latex 环境设置<a class="heading-anchor" href="#Latex环境设置" aria-hidden="true"></a></h2><ol>
<li>下载安装 TexLive<br> <a href="http://mirror.ctan.org/systems/texlive/tlnet/install-tl-windows.exe">texlive windows 下载器 下载</a><br> <a href="https://mirrors.tuna.tsinghua.edu.cn/CTAN/systems/texlive/Images/texlive.iso">texlive 镜像下载</a><br> 建议使用第二个，速度较快。<br> 另外 TexLive 体积较大，建议安装到 C 盘之外的其他盘。<br> 相关参考教程：<a href="https://zhuanlan.zhihu.com/p/108258567">https://zhuanlan.zhihu.com/p/108258567</a></li>
<li> 下载安装 TexStudio<br> <a href="https://github.com/texstudio-org/texstudio/releases/download/3.0.4/texstudio-3.0.4-win-qt5.exe">TexStudio 下载</a><br> 相关参考教程：<a href="https://zhuanlan.zhihu.com/p/108258567">https://zhuanlan.zhihu.com/p/108258567</a></li>
<li> 打开美赛模板<br> 进入文件夹，修改.tex 文件的打开方式为 texstudio, 然后双击打开 tex 文件。<br> <a href="https://imgchr.com/i/s3EhBn"><img src="https://s3.ax1x.com/2021/01/11/s3EhBn.png" alt="s3EhBn.png"></a><br> 点击工具栏的两个绿色三角组成的图标即可编译和预览。<br> <a href="https://imgchr.com/i/s3V3uj"><img src="https://s3.ax1x.com/2021/01/11/s3V3uj.png" alt="s3V3uj.png"></a></li>
</ol>
<h2 id="Latex基本语法" class="heading-control"><a href="#Latex基本语法" class="headerlink" title="Latex基本语法"></a>Latex 基本语法<a class="heading-anchor" href="#Latex基本语法" aria-hidden="true"></a></h2><h3 id="支持中文" class="heading-control"><a href="#支持中文" class="headerlink" title="支持中文"></a>支持中文<a class="heading-anchor" href="#支持中文" aria-hidden="true"></a></h3><figure class="highlight latex"><table><tbody><tr><td class="code"><pre><span class="line"><span class="tag">\<span class="name">documentclass</span><span class="string">{article}</span></span></span><br><span class="line"><span class="tag">\<span class="name">usepackage</span><span class="string">[UTF8]</span><span class="string">{ctex}</span></span></span><br></pre></td></tr></tbody></table></figure>
<h3 id="图表公式的引用" class="heading-control"><a href="#图表公式的引用" class="headerlink" title="图表公式的引用"></a>图表公式的引用<a class="heading-anchor" href="#图表公式的引用" aria-hidden="true"></a></h3><p>参考文章：<a href="https://blog.csdn.net/zhazhazl/article/details/52783172">https://blog.csdn.net/zhazhazl/article/details/52783172</a></p>
<h3 id="公式" class="heading-control"><a href="#公式" class="headerlink" title="公式"></a>公式<a class="heading-anchor" href="#公式" aria-hidden="true"></a></h3><p><a href="https://zhuanlan.zhihu.com/p/32321996">Word 的公式转换成 LaTeX 公式</a></p>
<figure class="highlight latex"><table><tbody><tr><td class="code"><pre><span class="line"><span class="tag">\<span class="name">begin</span><span class="string">{document}</span></span></span><br><span class="line"></span><br><span class="line">	时光的单车飞快驶去，岁月的倒影也将消失，白天与黑夜不停的交替，轮回的四季斑驳了谁的岁月，蹉跎了谁的年华。公式<span class="tag">\<span class="name">ref</span><span class="string">{key}</span></span></span><br><span class="line">	</span><br><span class="line">	<span class="tag">\<span class="name">begin</span><span class="string">{equation}</span></span><span class="tag">\<span class="name">label</span><span class="string">{key}</span></span></span><br><span class="line">		e^x-1=8</span><br><span class="line">	<span class="tag">\<span class="name">end</span><span class="string">{equation}</span></span></span><br><span class="line"></span><br><span class="line"><span class="tag">\<span class="name">end</span><span class="string">{document}</span></span></span><br></pre></td></tr></tbody></table></figure>
<h3 id="参考文献" class="heading-control"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献<a class="heading-anchor" href="#参考文献" aria-hidden="true"></a></h3><p>第一种是使用 <code>\bibitem</code>，<code>\cite{}</code> 引用参考文献。</p>
<figure class="highlight latex"><table><tbody><tr><td class="code"><pre><span class="line"><span class="comment">%导言区</span></span><br><span class="line"><span class="tag">\<span class="name">documentclass</span><span class="string">{article}</span></span></span><br><span class="line"><span class="tag">\<span class="name">usepackage</span><span class="string">[UTF8]</span><span class="string">{ctex}</span></span></span><br><span class="line"><span class="comment">%正文区</span></span><br><span class="line"><span class="tag">\<span class="name">begin</span><span class="string">{document}</span></span></span><br><span class="line"></span><br><span class="line">	时光的单车飞快驶去，岁月的倒影也将消失，白天与黑夜不停的交替，轮回的四季斑驳了谁的岁月，蹉跎了谁的年华。一个人静静地与岁月交错，于平淡之中细细体会生活的深意，去注视，去聆听，去感受那些带着希望的别离以及那些经受沧桑的相逢，不论时光如何飞转，那些落花一样的往事，依然鲜活地存在于我的脑海之中。<span class="tag">\<span class="name">cite</span><span class="string">{ref1}</span></span>当岁月和美丽的回忆已成为风中的叹息，我们伤感的眼里也许依然残存旧时的泪痕，模糊了视线，不敢轻易触碰。</span><br><span class="line">	</span><br><span class="line">	<span class="tag">\<span class="name">begin</span><span class="string">{thebibliography}</span><span class="string">{99}</span></span></span><br><span class="line">		<span class="tag">\<span class="name">bibitem</span><span class="string">{ref1}</span></span>郭莉莉,白国君,尹泽成,魏惠芳. “互联网+”背景下沈阳智慧交通系统发展对策建议[A]. 中共沈阳市委、沈阳市人民政府.第十七届沈阳科学学术年会论文集[C].中共沈阳市委、沈阳市人民政府:沈阳市科学技术协会,2020:4.</span><br><span class="line">		</span><br><span class="line">		<span class="tag">\<span class="name">bibitem</span><span class="string">{ref2}</span></span>陈香敏,魏伟,吴莹. “文化+人工智能”视阈下文化创意产业融合发展实践及路径研究[A]. 中共沈阳市委、沈阳市人民政府.第十七届沈阳科学学术年会论文集[C].中共沈阳市委、沈阳市人民政府:沈阳市科学技术协会,2020:4.</span><br><span class="line">		</span><br><span class="line">		<span class="tag">\<span class="name">bibitem</span><span class="string">{ref3}</span></span>田晓曦,刘振鹏,彭宝权. 地方高校开展教育人工智能深度融合的路径探究[A]. 中共沈阳市委、沈阳市人民政府.第十七届沈阳科学学术年会论文集[C].中共沈阳市委、沈阳市人民政府:沈阳市科学技术协会,2020:5.</span><br><span class="line">		</span><br><span class="line">		<span class="tag">\<span class="name">bibitem</span><span class="string">{ref4}</span></span>柏卓君,潘勇,李仲余.彩色多普勒超声在早期胚胎停育诊断中的应用[J].影像研究与医学应用,2020,4(18):129-131.</span><br><span class="line">		</span><br><span class="line">		<span class="tag">\<span class="name">bibitem</span><span class="string">{ref5}</span></span>杨芸.我院2018年人血白蛋白临床应用调查与分析[J].上海医药,2020,41(17):34-35+74.</span><br><span class="line">	<span class="tag">\<span class="name">end</span><span class="string">{thebibliography}</span></span></span><br><span class="line"></span><br><span class="line"><span class="tag">\<span class="name">end</span><span class="string">{document}</span></span></span><br></pre></td></tr></tbody></table></figure>
<p><img src="https://i.loli.net/2021/01/18/wFaSuso8zYk6t4y.png" alt></p>
<p>第二种是使用 bib 文件。bib 文件可以在百度学术，谷歌学术等引用处下载，可<a href="https://jingyan.baidu.com/article/925f8cb8bce1f0c0dce0564f.html">参考文章</a>。</p>
<p><img src="https://i.loli.net/2021/01/18/ITMy5N78tP6mfFD.png" alt></p>
<p>打开后的 bib 文件内容如下，点击另存为，修改文件名为 <code>vaswani2017attention.bib</code>，放到 tex 文件的同级目录下。</p>
<figure class="highlight tex"><table><tbody><tr><td class="code"><pre><span class="line">@article{vaswani2017attention,</span><br><span class="line">  title={Attention is all you need. arXiv 2017},</span><br><span class="line">  author={Vaswani, A and Shazeer, N and Parmar, N and Uszkoreit, J and Jones, L and Gomez, AN and Kaiser, L and Polosukhin, I},</span><br><span class="line">  journal={arXiv preprint arXiv:1706.03762},</span><br><span class="line">  year={2017}</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure>
<p>然后就可以在代码里面引用了，注意需要多编译几次。</p>
<figure class="highlight latex"><table><tbody><tr><td class="code"><pre><span class="line"><span class="comment">%导言区</span></span><br><span class="line"><span class="tag">\<span class="name">documentclass</span><span class="string">{article}</span></span></span><br><span class="line"><span class="tag">\<span class="name">usepackage</span><span class="string">[UTF8]</span><span class="string">{ctex}</span></span></span><br><span class="line"><span class="tag">\<span class="name">usepackage</span><span class="string">{cite}</span></span></span><br><span class="line"><span class="comment">%正文区</span></span><br><span class="line"></span><br><span class="line"><span class="tag">\<span class="name">begin</span><span class="string">{document}</span></span></span><br><span class="line"></span><br><span class="line">	时光的单车飞快驶去，岁月的倒影也将消失，白天与黑夜不停的交替，轮回的四季斑驳了谁的岁月，蹉跎了谁的年华。一个人静静地与岁月交错，于平淡之中细细体会生活的深意，去注视，去聆听，去感受那些带着希望的别离以及那些经受沧桑的相逢，不论时光如何飞转，那些落花一样的往事，依然鲜活地存在于我的脑海之中。<span class="tag">\<span class="name">cite</span><span class="string">{vaswani2017attention}</span></span> 当岁月和美丽的回忆已成为风中的叹息，我们伤感的眼里也许依然残存旧时的泪痕，模糊了视线，不敢轻易触碰。</span><br><span class="line">	</span><br><span class="line">	<span class="tag">\<span class="name">bibliographystyle</span><span class="string">{plain}</span></span></span><br><span class="line">	<span class="tag">\<span class="name">bibliography</span><span class="string">{vaswani2017attention}</span></span>	</span><br><span class="line"></span><br><span class="line"><span class="tag">\<span class="name">end</span><span class="string">{document}</span></span></span><br></pre></td></tr></tbody></table></figure>
<p><img src="https://i.loli.net/2021/01/18/4JgmqHTlrkypS9Y.png" alt></p>
</body></html>]]></content>
      <tags>
        <tag>Latex</tag>
      </tags>
  </entry>
  <entry>
    <title>基金投资笔记 (2021 年)</title>
    <url>/post/f0b54271.html</url>
    <content><![CDATA[<html><head><link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script></head><body><h2 id="投资日记" class="heading-control"><a href="#投资日记" class="headerlink" title="投资日记"></a>投资日记<a class="heading-anchor" href="#投资日记" aria-hidden="true"></a></h2><h3 id="2021-2-23-周二" class="heading-control"><a href="#2021-2-23-周二" class="headerlink" title="2021.2.23 周二"></a>2021.2.23 周二<a class="heading-anchor" href="#2021-2-23-周二" aria-hidden="true"></a></h3><p>军工涨四个点，金银略涨，白酒，医药，科技，新能源，光伏都还在下跌。本来想买了白银的，考虑到买入位置并不高，就长期投资吧。</p>
<ul>
<li>科技加仓 1000：诺安和宝盈人工智能</li>
<li>证券加仓 500</li>
<li></li>
</ul>
<h3 id="2021-2-22-周一" class="heading-control"><a href="#2021-2-22-周一" class="headerlink" title="2021.2.22 周一"></a>2021.2.22 周一<a class="heading-anchor" href="#2021-2-22-周一" aria-hidden="true"></a></h3><p>今日加仓，总计买入 4100 元，包括定投的 800，其他总计 3300。</p>
<ul>
<li><strong>白酒</strong>：今天白酒暴跌了 8 个点（-7.84%），我年前最后一天高点清仓了招商中证白酒，今天重新买入 300 块，感觉后续还会继续跌一点。</li>
<li><strong>蓝筹</strong>：易方达蓝筹（-5%），买入 500 块。</li>
<li><strong>收益挑战</strong>：买入消费包 500 块（天弘中证食品饮料（-2%）和天弘中证医疗 100（-5%））。</li>
<li><strong>定投</strong>：广发稳健增长 A 和易方达安心回馈每周一定投，进入智能定投 400。</li>
<li><strong>医药</strong>：中欧医疗跌了（-6%），买入 200，总持仓到了 400，买入少是因为收益挑战已经买过医疗了。</li>
<li><strong>军工</strong>：易方达军工（-3%），快跌回 2 月 5 号的最低点了，补仓 300 块。</li>
<li><strong>光伏新能源</strong>：中欧先进制造股票 C （-3.5%）买入 100。</li>
<li><strong>其他</strong>：富国天惠（-3%）买入 300，汇添富全球消费买入 500，前海开源中国稀缺资产（-5.4%）买入 400，创金合信（-3%）买入 200。</li>
</ul>
<h3 id="2021-2-21-周日" class="heading-control"><a href="#2021-2-21-周日" class="headerlink" title="2021.2.21 周日"></a>2021.2.21 周日<a class="heading-anchor" href="#2021-2-21-周日" aria-hidden="true"></a></h3><p>支付宝定投广发稳健增长 A 和易方达安心回馈混合，每周一定投，定投 500 ，开启智能定投。</p>
<p>后续陆续加仓汇添富全球消费，易方达蓝筹可长期持有，军工目前亏 6% 考虑加仓，黄金建仓不宜多买。</p>
<p>19 日光伏下跌 3%，需要等一下看还不会不会再跌。</p>
<h2 id="投资组合" class="heading-control"><a href="#投资组合" class="headerlink" title="投资组合"></a>投资组合<a class="heading-anchor" href="#投资组合" aria-hidden="true"></a></h2><div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">基金名称</th>
<th style="text-align:center">代码</th>
<th style="text-align:center">基金经理</th>
<th style="text-align:center">重仓股票</th>
<th style="text-align:center">持仓</th>
<th>后续</th>
<th>板块</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">汇添富全球消费行业混合 (QDII) C</td>
<td style="text-align:center">006309</td>
<td style="text-align:center"> 郑慧莲</td>
<td style="text-align:center">中免 腾讯 拼多多 B 站 小米  特斯拉 苹果 美团</td>
<td style="text-align:center"> 500</td>
<td> 加仓</td>
<td>美股消费</td>
</tr>
<tr>
<td style="text-align:center">易方达蓝筹精选混合</td>
<td style="text-align:center"> 005827</td>
<td style="text-align:center"> 张坤</td>
<td style="text-align:center">白酒 腾讯 美团</td>
<td style="text-align:center"> 787.26</td>
<td></td>
<td> 白酒 + 港股</td>
</tr>
<tr>
<td style="text-align:center">中欧医疗健康混合 C</td>
<td style="text-align:center">003096</td>
<td style="text-align:center"> 葛兰</td>
<td style="text-align:center">爱尔眼科 药明康德 迈瑞医疗</td>
<td style="text-align:center"> 239.54</td>
<td></td>
<td> 医疗生物</td>
</tr>
<tr>
<td style="text-align:center">易方达新收益混合 C</td>
<td style="text-align:center">001217</td>
<td style="text-align:center"> 张清华</td>
<td style="text-align:center">海康威视 福斯特 隆基</td>
<td style="text-align:center"></td>
<td></td>
<td></td>
</tr>
<tr>
<td style="text-align:center">汇添富中证新能源 C</td>
<td style="text-align:center">501058</td>
<td style="text-align:center"> 过蓓蓓</td>
<td style="text-align:center">宁德时代 比亚迪 钴和锂电池</td>
<td style="text-align:center"></td>
<td></td>
<td>新能源</td>
</tr>
<tr>
<td style="text-align:center">创金合信工业周期股票 C</td>
<td style="text-align:center">005969</td>
<td style="text-align:center"> 李游</td>
<td style="text-align:center">隆基、通威、阳光电源</td>
<td style="text-align:center"></td>
<td></td>
<td>光伏</td>
</tr>
<tr>
<td style="text-align:center">天弘中证电子</td>
<td style="text-align:center"> 001618</td>
<td style="text-align:center"> 杨超</td>
<td style="text-align:center">海康威视 京东方 TCL</td>
<td style="text-align:center">100</td>
<td></td>
<td> 电子</td>
</tr>
<tr>
<td style="text-align:center">天弘中证计算机</td>
<td style="text-align:center"> 001630</td>
<td style="text-align:center"> 张子法</td>
<td style="text-align:center">海康威视 广联达 讯飞 深信服</td>
<td style="text-align:center"> 100</td>
<td></td>
<td> 计算机</td>
</tr>
<tr>
<td style="text-align:center">天弘中证食品饮料</td>
<td style="text-align:center"> 001632</td>
<td style="text-align:center"> 沙川</td>
<td style="text-align:center">茅台 伊利 五粮液 海天双汇</td>
<td style="text-align:center"></td>
<td></td>
<td>消费</td>
</tr>
<tr>
<td style="text-align:center">天弘中证医疗 100</td>
<td style="text-align:center">001551</td>
<td style="text-align:center"> 沙川</td>
<td style="text-align:center">恒瑞  药明康德 迈瑞</td>
<td style="text-align:center"></td>
<td></td>
<td>医药</td>
</tr>
<tr>
<td style="text-align:center">兴全和润混合</td>
<td style="text-align:center"> 163406</td>
<td style="text-align:center"> 谢治宇</td>
<td style="text-align:center">平安 海尔 三一 美的</td>
<td style="text-align:center"></td>
<td></td>
<td>混合型</td>
</tr>
<tr>
<td style="text-align:center">富国天惠成长混合 (LOF) C</td>
<td style="text-align:center">003494</td>
<td style="text-align:center"> 朱少醒</td>
<td style="text-align:center">生物 伊利 茅台 顺丰 平安</td>
<td style="text-align:center"></td>
<td></td>
<td>混合型</td>
</tr>
<tr>
<td style="text-align:center">前海开源中国稀缺资产混合 C</td>
<td style="text-align:center">002079</td>
<td style="text-align:center"> 曲扬</td>
<td style="text-align:center">茅台 宁德时代 中免 医疗</td>
<td style="text-align:center"> 500</td>
<td></td>
<td> 混合型</td>
</tr>
<tr>
<td style="text-align:center">银河创新成长混合</td>
<td style="text-align:center"> 519674</td>
<td style="text-align:center"> 郑巍山</td>
<td style="text-align:center">京东方 韦尔 长电 中芯国际</td>
<td style="text-align:center"></td>
<td></td>
<td>半导体</td>
</tr>
<tr>
<td style="text-align:center">中欧先进制造股票 C</td>
<td style="text-align:center">004813</td>
<td style="text-align:center"> 卢纯青</td>
<td style="text-align:center">宁德时代 隆基 通威</td>
<td style="text-align:center"></td>
<td></td>
<td>光伏</td>
</tr>
<tr>
<td style="text-align:center">广发稳健增长 A</td>
<td style="text-align:center">270002</td>
<td style="text-align:center"> 傅友兴</td>
<td style="text-align:center">迈瑞 双汇 三一 三环</td>
<td style="text-align:center"> 500</td>
<td> 定投</td>
<td>混合型</td>
</tr>
<tr>
<td style="text-align:center">易方达国防军工混合</td>
<td style="text-align:center"> 001475</td>
<td style="text-align:center"> 何崇恺</td>
<td style="text-align:center">中航机电 紫光国微  七一二</td>
<td style="text-align:center"> 1302</td>
<td></td>
<td> 军工</td>
</tr>
<tr>
<td style="text-align:center">易方达黄金</td>
<td style="text-align:center"> 002963</td>
<td style="text-align:center"> 余海燕</td>
<td style="text-align:center">黄金</td>
<td style="text-align:center"> 300</td>
<td></td>
<td> 黄金</td>
</tr>
<tr>
<td style="text-align:center">国投瑞银白银期货 (LOF)</td>
<td style="text-align:center">161226</td>
<td style="text-align:center"> 赵建</td>
<td style="text-align:center">白银</td>
<td style="text-align:center"> 205</td>
<td></td>
<td> 白银</td>
</tr>
<tr>
<td style="text-align:center">易方达安心回馈</td>
<td style="text-align:center"> 001182</td>
<td style="text-align:center"> 张清华</td>
<td style="text-align:center">阳光电源 隆基</td>
<td style="text-align:center"> 500</td>
<td> 定投</td>
<td>混合型</td>
</tr>
</tbody>
</table>
</div>
<a id="more"></a>
<h2 id="优秀基金" class="heading-control"><a href="#优秀基金" class="headerlink" title="优秀基金"></a>优秀基金<a class="heading-anchor" href="#优秀基金" aria-hidden="true"></a></h2><h3 id="芯片半导体基金" class="heading-control"><a href="#芯片半导体基金" class="headerlink" title="芯片半导体基金"></a>芯片半导体基金<a class="heading-anchor" href="#芯片半导体基金" aria-hidden="true"></a></h3><ul>
<li>诺安成长混合 (320007)</li>
<li> 银河创新成长混合 (519674)</li>
</ul>
<h3 id="电子板块基金" class="heading-control"><a href="#电子板块基金" class="headerlink" title="电子板块基金"></a>电子板块基金<a class="heading-anchor" href="#电子板块基金" aria-hidden="true"></a></h3><ul>
<li>天弘中证电子 ETF 联接 A (001617) 跟踪标的：中证电子指数 | 跟踪误差：0.22%  纯电子板块，偏消费电子</li>
</ul>
<h3 id="通信5G" class="heading-control"><a href="#通信5G" class="headerlink" title="通信5G"></a>通信 5G<a class="heading-anchor" href="#通信5G" aria-hidden="true"></a></h3><ul>
<li>华夏中证 5G（008087）—5G 板块</li>
</ul>
<h3 id="光伏" class="heading-control"><a href="#光伏" class="headerlink" title="光伏"></a>光伏<a class="heading-anchor" href="#光伏" aria-hidden="true"></a></h3><ul>
<li>广发高端（004997）</li>
<li>创金合信（005969）</li>
</ul>
<h3 id="医药行业板块基金" class="heading-control"><a href="#医药行业板块基金" class="headerlink" title="医药行业板块基金"></a>医药行业板块基金<a class="heading-anchor" href="#医药行业板块基金" aria-hidden="true"></a></h3><ul>
<li>中欧医疗健康混合 A (003095)</li>
</ul>
<h3 id="消费行业板块基金" class="heading-control"><a href="#消费行业板块基金" class="headerlink" title="消费行业板块基金"></a>消费行业板块基金<a class="heading-anchor" href="#消费行业板块基金" aria-hidden="true"></a></h3><ul>
<li>招商中证白酒指数分级 (161725) 跟踪标的：中证白酒指数 | 跟踪误差：0.15%</li>
<li> 鹏华酒分级 (160632) 跟踪标的：中证酒指数 | 跟踪误差：0.15%</li>
<li> 天弘中证食品饮料指数 A (001631) 跟踪标的：中证食品饮料指数 | 跟踪误差：0.14% 白酒 + 食品饮料</li>
<li>国泰国证食品饮料行业指数分级 (160222) 跟踪标的：国证食品饮料行业指数 | 跟踪误差：0.15%  白酒 + 食品饮料</li>
<li>易方达中小盘（110011）—- 白酒 + 医疗</li>
<li>易方达蓝筹（005827）— 白酒 + 港股（腾讯美团等）</li>
<li>易方达消费行业混合 — 白酒 + 可选消费</li>
</ul>
<h3 id="消费医药混合基金" class="heading-control"><a href="#消费医药混合基金" class="headerlink" title="消费医药混合基金"></a>消费医药混合基金<a class="heading-anchor" href="#消费医药混合基金" aria-hidden="true"></a></h3><ul>
<li>易方达中小盘混合 (110011)</li>
<li> 景顺长城新兴成长混合 (260108)</li>
</ul>
<h2 id="各行各业龙头" class="heading-control"><a href="#各行各业龙头" class="headerlink" title="各行各业龙头"></a>各行各业龙头<a class="heading-anchor" href="#各行各业龙头" aria-hidden="true"></a></h2><ul>
<li>白酒，贵州茅台</li>
<li>医药，恒瑞医药、迈瑞医疗</li>
<li>奶制品，伊利股份</li>
<li>矿泉水，农夫山泉</li>
<li>酱油，海天味业</li>
<li>锂电池，宁德时代</li>
<li>光伏，隆基股份</li>
<li>新能源汽车，比亚迪</li>
<li>军工，航发动力、中航沈飞</li>
<li>套茅，英科医疗</li>
<li>眼科，爱尔眼科</li>
<li>牙齿健康，通策医疗</li>
<li>机械，三一重工</li>
<li>空调，美的集团</li>
<li>养猪，牧原股份</li>
<li>水泥，海螺水泥</li>
<li>建筑，东方雨虹</li>
<li>旅游，中国中免</li>
<li>银行，招商银行</li>
<li>芯片，卓胜微</li>
<li> 5G，立讯精密</li>
<li>化学，万华化学</li>
<li>食用油，金龙鱼</li>
<li>软件，深信服</li>
<li>书写纸，中顺洁柔</li>
<li>券商，东方财富</li>
<li>快递，顺丰控股</li>
<li>金属，紫金矿业</li>
<li>安防，海康威视</li>
</ul>
</body></html>]]></content>
      <tags>
        <tag>基金</tag>
      </tags>
  </entry>
  <entry>
    <title>推荐系统杂谈</title>
    <url>/post/6de7497f.html</url>
    <content><![CDATA[<html><head><link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script></head><body><h2 id="召回策略分类" class="heading-control"><a href="#召回策略分类" class="headerlink" title="召回策略分类"></a>召回策略分类<a class="heading-anchor" href="#召回策略分类" aria-hidden="true"></a></h2><ol>
<li><p>实时行为召回：在线实时捕捉用户对商品的点击，收藏，加购，购买等反馈行为，并召回相似商品，迅速抓住用户的短期购物需求。</p>
</li>
<li><p>历史行为召回：离线分析用户对商品的历史点击，收藏，加购，购买等反馈行为，并召回相似商品，兼顾用户的长期购物需求。</p>
</li>
<li><p>profile 召回：从性别，年龄段，设备等多个维度，在线和离线同时对用户进行画像，并召回相对应的热门商品。不要小看这个召回，非常关键，往往新用户需要用这些静态信息和标签来做召回，往往可以快速圈定其圈层进行精准的探索和数据反馈，比如 5-6 线城市和北京西二旗的用户往往大概率兴趣差异较大。这层召回是全局热门召回的更精细化拆解。</p>
</li>
<li><p>热销 & 趋势召回：分析商品的长期和短期销量变化，召回爆款和近期热点商品。</p>
</li>
</ol>
<a id="more"></a>
<h2 id="用户兴趣标签" class="heading-control"><a href="#用户兴趣标签" class="headerlink" title="用户兴趣标签"></a>用户兴趣标签<a class="heading-anchor" href="#用户兴趣标签" aria-hidden="true"></a></h2><h3 id="基于统计的标签" class="heading-control"><a href="#基于统计的标签" class="headerlink" title="基于统计的标签"></a>基于统计的标签<a class="heading-anchor" href="#基于统计的标签" aria-hidden="true"></a></h3><p>基于统计的用户兴趣表现需考虑：</p>
<ul>
<li>相关行为：关注、点赞、评论、分享等</li>
<li>兴趣衰减：用户的兴趣是周期性的，会存在兴趣衰减的情况</li>
<li>内容热度：需考虑热门内容，大家都在看的内容</li>
<li>时间维度：分别为长期、短期和即时。</li>
</ul>
<p>用户偏好通过用户在不同属性的维度上行为次数的带衰减的线性加权求和，再进行归一化得到。<br>这里有两个关键点：</p>
<ul>
<li><p>第一个关键点是：不同行为的权重如何衡量。用户有着多种不同的行为，例如，在购物网站，用户可能发生浏览、收藏、加购物车、下单等行为，显然，下单的成本要比普通的浏览成本要高，即在不同行为上花费的成本是存在差异的，在数据上的反映是不同行为的权重差异很大，如何定义、衡量并验证不同行为的权重是一件并不容易的事情。我们采用的权重计算方法有：</p>
<ul>
<li>后验转化率的方法，转化率的倒数作为权重；</li>
<li>有监督的方法，bagging+LR 模型，可以将成交或者下单作为 label，模型得到的特征重要性作为权重；</li>
<li>通过贝叶斯模型计算权重。</li>
</ul>
</li>
<li><p>第二个关键点是：衰减系数的定义。用户的需求并不是持续稳定的，会随时间会发生变化和转移，这种需求的变化需要被偏好捕捉到，因此，距离当前越近的行为越能反映现在的需求。对于衰减形式，我们采取了指数衰减以及阶跃形式衰减。</p>
<ul>
<li>指数形式。用户行为对未来偏好的影响程度，随着时间的拉长呈指数型下降，对于 t 天前的行为，衰减因子为 λ 的 t 次方；</li>
<li>阶跃形式。将时间人为划分成若干不同的时间区间，同一个时间区间内的行为的衰减因子是相同的。</li>
</ul>
</li>
</ul>
<h3 id="标签推荐的问题" class="heading-control"><a href="#标签推荐的问题" class="headerlink" title="标签推荐的问题"></a>标签推荐的问题<a class="heading-anchor" href="#标签推荐的问题" aria-hidden="true"></a></h3><ol>
<li>非常依赖标签</li>
<li>推荐粒度较粗 <ul>
<li>如果用户兴趣单一的话，召回会不足。</li>
<li>不能很好的刻画用户兴趣。比如，有的用户只对英语感兴趣，如果把大量的教育相关的帖子推荐给他，用户体验会比较差。</li>
</ul>
</li>
<li>缺乏新颖性</li>
</ol>
<h2 id="推荐系统的多样性" class="heading-control"><a href="#推荐系统的多样性" class="headerlink" title="推荐系统的多样性"></a>推荐系统的多样性<a class="heading-anchor" href="#推荐系统的多样性" aria-hidden="true"></a></h2><h3 id="多样性分类" class="heading-control"><a href="#多样性分类" class="headerlink" title="多样性分类"></a>多样性分类<a class="heading-anchor" href="#多样性分类" aria-hidden="true"></a></h3><p>在多样性算法的研究中，通常把多样性分成两种：</p>
<ul>
<li><p>基于个体用户的多样性，旨在避免给单一用户推荐相似的物品，从而提高用户体验和增加用户满意度</p>
</li>
<li><p>基于全部用户的多样性，旨在优化长尾的物品分发效果</p>
</li>
</ul>
<h3 id="多样性算法落地的几个难点" class="heading-control"><a href="#多样性算法落地的几个难点" class="headerlink" title="多样性算法落地的几个难点"></a>多样性算法落地的几个难点<a class="heading-anchor" href="#多样性算法落地的几个难点" aria-hidden="true"></a></h3><ol>
<li>模型的优化目标模糊<br>众所周知，各种用户行为（点击、转化、停留、分享等等）都可以作为优化准确度的目标，我们可以明确的收集用户的行为作为模型的目标标签，从而设计模型并优化。因为多样性本身是一个集合统计量，很难找到直接的用户行为来作为模型优化的目标。</li>
<li>业务指标和多样性指标的冲突<br>业务关注的指标（转化率、停留时长等）和多样性指标并不是简单的正向或者负向的关系。如果单纯为了提高多样性指标而做多样性，反而会导致最终结果与业务目标偏离，使推荐的质量下降。</li>
</ol>
<h2 id="流量控制" class="heading-control"><a href="#流量控制" class="headerlink" title="流量控制"></a>流量控制<a class="heading-anchor" href="#流量控制" aria-hidden="true"></a></h2><p>头部效应不受控的话，海量匹配会被沉没，带来了双向匹配成功率的快速下降，而且占用了大量的曝光机会。不能大部分人没人喜欢，没有曝光，需要平衡。</p>
<ol>
<li><p>首先你得对内容生产者进行分层，将平台内的内容生产者进行区分，并根据对平台最终的贡献将他们分层，如下图。<br><a href="https://imgchr.com/i/se5Oit"><img src="https://s3.ax1x.com/2021/01/07/se5Oit.png" alt="se5Oit.png"></a></p>
</li>
<li><p>对平台内容生产者分层后，可以根据其流量配比进行调整，金字塔的底层需要被快速地识别，并将流量减少到可控范围内的最低；前 2 层需要被鼓励，特别是特色生产者需要流量倾斜，以保证其积极性，对于价值生产者所需流量不够的情况下，可以在非价值生产者内容流量中倾斜一部分。特色内容生产者可以类比第一个主题分享爆款种子内容筛选流程类似，可以通过部分种子特色内容生产者找到更多的特色内容生产者。</p>
</li>
</ol>
<p><a href="https://imgchr.com/i/seIion"><img src="https://s3.ax1x.com/2021/01/07/seIion.png" alt="seIion.png"></a></p>
<ol>
<li>流量如何控制呢，我们可以看下分配流程，当然这个是借鉴淘宝的商品流量分配模式，如上图所示。通过数据化和算法的方式先对整个流量体系进行拆解，将流量拆分成若干主要模块，并通过流量控制系统进行干预，可以实现用户时长、完播率、浏览深度不变的情况下，内容流量分布的调整 (至少电商中可以做到 gmv 不变的情况下，流量实现分配目标的 80%-90%)。</li>
</ol>
<h2 id="用户留存" class="heading-control"><a href="#用户留存" class="headerlink" title="用户留存"></a>用户留存<a class="heading-anchor" href="#用户留存" aria-hidden="true"></a></h2><h3 id="性别重要性平衡" class="heading-control"><a href="#性别重要性平衡" class="headerlink" title="性别重要性平衡"></a>性别重要性平衡<a class="heading-anchor" href="#性别重要性平衡" aria-hidden="true"></a></h3><p>男生对于陌生匹配的反感程度更低，耐受度更高，男生天然更开放，只要这里异性多，对男生而言就是最好的服务了。<strong>维持这种生态系统运作的基本机制，通常是对女性提供更加开放友好的环境，吸引她们入驻，再以此辐射男性群体。这中间需要以女性视角关注产品 (男生希望快速触达，女生希望更有安全感)，</strong>所以相互匹配才能交流，从这个角度来看是一个偏向于女性的功能。</p>
<h3 id="不同用户对于留存的价值不同" class="heading-control"><a href="#不同用户对于留存的价值不同" class="headerlink" title="不同用户对于留存的价值不同"></a>不同用户对于留存的价值不同<a class="heading-anchor" href="#不同用户对于留存的价值不同" aria-hidden="true"></a></h3><p>不同用户价值不同，留存的高低对系统影响也就应该区别对待：</p>
<ul>
<li>供小于需的那部分群体就是需要重要考虑和保护的</li>
<li>差体验用户 (卖货、不法交易) 需要被限制，这部分人的存在和留存高反而会严重拉低其它用户体验和留存；</li>
</ul>
<h3 id="交际带宽有限" class="heading-control"><a href="#交际带宽有限" class="headerlink" title="交际带宽有限"></a>交际带宽有限<a class="heading-anchor" href="#交际带宽有限" aria-hidden="true"></a></h3><p>用户的交际带宽也是有限的，无法做到人人有反馈。优质用户也只能提供有限的供给，这和书籍或者商品很不一样，并不是只要有库存就可以同时推荐给很多用户。美女帅哥在平台上从来不缺被喜欢，很容易成为产品的头部用户，他们也可以为产品吸引更多的用户进来；如果我们过度推荐这些用户可能会让这些用户收到到上万个喜欢的轰炸，但他们无法提供高的反馈率，比如下图中的头部用户拿到了几倍于普通用户的喜欢，但是回复率和匹配率却是颜值一般的人的五分之一水平。</p>
<h2 id="数据去噪" class="heading-control"><a href="#数据去噪" class="headerlink" title="数据去噪"></a>数据去噪<a class="heading-anchor" href="#数据去噪" aria-hidden="true"></a></h2><p>数据去燥和平滑：</p>
<ul>
<li>点击后停留 1 秒的为误点，移除</li>
<li>过度活跃的用户为无效用户，进行移除</li>
<li>频繁修改商品内容的进行移除</li>
</ul>
</body></html>]]></content>
      <tags>
        <tag>推荐系统</tag>
      </tags>
  </entry>
  <entry>
    <title>DIN 排序模型</title>
    <url>/post/aa639214.html</url>
    <content><![CDATA[<html><head><link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script></head><body><h2 id="论文" class="heading-control"><a href="#论文" class="headerlink" title="论文"></a>论文<a class="heading-anchor" href="#论文" aria-hidden="true"></a></h2><p><a href="https://arxiv.org/pdf/1706.06978.pdf">《Deep Interest Network for Click-Through Rate Prediction》</a></p>
<p>本文收录于 KDD18，来自于阿里妈妈的精准定向检索及基础算法团队。文章的创新点主要有三个：</p>
<ol>
<li>Deep Interest Network（DIN）—— 通过一个局部激活单元（local activation unit）来自适应地从用户历史行为中学习他对于某个广告的兴趣。</li>
<li>Mini-batch Aware Regularization —— 即一个针对 mini-batch SGD 进行优化的 L2 norm 正则项，通过近似减少了计算量。</li>
<li>一个数据自适应的激活函数，对 PReLU 的 indicator function 进行修改，并取名为 Dice。</li>
</ol>
<h2 id="背景" class="heading-control"><a href="#背景" class="headerlink" title="背景"></a>背景<a class="heading-anchor" href="#背景" aria-hidden="true"></a></h2><p>Deep Interest Network (DIN) 是盖坤大神领导的阿里妈妈的精准定向检索及基础算法团队，在 2017 年 6 月提出的。 它针对<strong>电子商务领域 (e-commerce industry)</strong> 的 CTR 预估，重点在于<strong>充分利用 / 挖掘用户历史行为数据中的信息</strong>。</p>
<ol>
<li><p><strong>数据特征：</strong> 针对互联网电子商务领域，数据特点：Diversity、Local Activation。</p>
</li>
<li><p><strong>针对问题：</strong>用户有多个兴趣爱好，访问了多个 good_id，shop_id。为了降低纬度并使得商品店铺间的算术运算有意义，我们先对其进行 Embedding 嵌入。那么我们如何对用户多种多样的兴趣建模那？使用 <strong>Pooling 对 Embedding Vector 求和或者求平均</strong>。同时这也解决了不同用户输入长度不同的问题，得到了一个固定长度的向量。这个向量就是用户表示，是用户兴趣的代表。但是，直接求 sum 或 average 损失了很多信息。所以稍加改进，针对不同的 behavior id 赋予不同的权重，这个权重是由当前 behavior id 和候选广告共同决定的。这就是 Attention 机制，实现了 Local Activation。</p>
</li>
<li><strong>DIN 的解决方案：</strong><ol>
<li>使用 <strong>用户兴趣分布 (Diversity)</strong> 来表示用户多种多样的兴趣爱好</li>
<li>使用 <strong>Attention 机制</strong> 来实现 Local Activation</li>
<li> 针对模型训练，提出了 <strong>Dice 激活函数，自适应正则 (Adaptive Regulation)</strong>，显著提升了模型性能与收敛速度</li>
</ol>
</li>
</ol>
<p><strong>Diversity：</strong> 用户在访问电商网站时会对多种商品都感兴趣。也就是用户的兴趣非常的广泛。</p>
<p><strong>Local Activation：</strong> 由于用户兴趣的多样性，只有部分历史数据会影响到当次推荐的物品是否被点击，而不是所有的历史记录。</p>
<p><strong>Diversity</strong> 体现在年轻的母亲的历史记录中体现的兴趣十分广泛，涵盖羊毛衫、手提袋、耳环、童装、运动装等等。而爱好游泳的人同样兴趣广泛，历史记录涉及浴装、旅游手册、踏水板、马铃薯、冰激凌、坚果等等。</p>
<p><strong>Local activation</strong> 体现在，当我们给爱好游泳的人推荐 google (护目镜) 时，跟他之前是否购买过薯片、书籍、冰激凌的关系就不大了，而跟他游泳相关的历史记录如游泳帽的关系就比较密切。</p>
<a id="more"></a>
<h2 id="模型结构" class="heading-control"><a href="#模型结构" class="headerlink" title="模型结构"></a>模型结构<a class="heading-anchor" href="#模型结构" aria-hidden="true"></a></h2><h3 id="Base模型" class="heading-control"><a href="#Base模型" class="headerlink" title="Base模型"></a>Base 模型<a class="heading-anchor" href="#Base模型" aria-hidden="true"></a></h3><p><img src="https://i.loli.net/2021/01/14/49yX1N2t8KdibPk.png" alt></p>
<p>Base Model 首先把 one-hot 或 multi-hot 特征转换为特定长度的 embedding，作为模型的输入，然后经过一个 DNN 得到最终的预估值。</p>
<p>特别地，针对 multi-hot 的特征，做了一次 element-wise + 的操作，这里其实就是 sum-pooling，这样，不管特征中有多少个非 0 值，经过转换之后的长度都是一样的。multi-hot 特征也称为多值离散特征，比如：用户在 YouTube 上看的视频和搜索过的视频。无论是看过的还是搜索过的，都不止一个，但是相对于所有的视频来说，看过和搜索过的数量都太小了 (非常稀疏)。 在电子商务上的例子就是：用户购买过的 good_id 有多个，购买过的 shop_id 也有多个，而这也直接导致了每个用户的历史行为 id 长度是不同的。</p>
<p>模型的基本过程如下：</p>
<ol>
<li>在输入上面加一层 embeding 层，把最原始高维度、稀疏的数据转换为低维度的实值表示上 (dense vector)。</li>
<li>增加多个全连接层，学习特征之间的非线性关系。 Sparse Features -> Embedding Vector -> MLPs -> Output</li>
</ol>
<p>从基准模型的结构图中可以看出，无论候选商品是什么，用户的 Embedding 值均不会发生改变。用户的历史行为中的商品 Embedding 数据对用户的 Embedding 的贡献力度是一样的，然而这与实际情况并不符合，因为每个用户的兴趣是多样性的。</p>
<p>举个例子：某用户购买过 “外套”、“手机”、“洗面奶”、“小说” 等，当用户计划购买 “耳机” 的时候，历史行为中的 “手机” 自然比其他商品对本次决策的贡献更大一些；当计划购买裤子的时候，历史行为中的 “外套” 自然比其他商品对本次决策的贡献更大一些。</p>
<p>在实际情况下，基准模型的效果存在待改进的空间，由此阿里提出了基于用户兴趣的深层网络（DIN 模型）。</p>
<h3 id="DIN模型" class="heading-control"><a href="#DIN模型" class="headerlink" title="DIN模型"></a>DIN 模型<a class="heading-anchor" href="#DIN模型" aria-hidden="true"></a></h3><p>DIN 的模型结构中增加了 Activation Unit 模块，该模块主要提取当前候选商品与历史行为中的商品的权重值。输入包括两个部分：</p>
<ol>
<li>一个是原始的用户行为 Embedding 向量、商品 Embedding 向量；</li>
<li>另外一个是两者 Embedding 向量经过外积计算后得到的向量，和两者 Embedding 向量差值得到的向量。</li>
</ol>
<p>外积 + embedding 拼接有点类似于 FM 的思想，构造所谓的 “一阶” 和 “二阶交叉” 特征，其实就是通过一种方式来在原始 embedding 之上构建一些行为和广告的交叉特征，再通过全连接层对信息进一步整合并得到对应的权重。</p>
<p><img src="https://i.loli.net/2021/01/14/EikCGSrjz1qDJ2u.png" alt></p>
<script type="math/tex; mode=display">
g(V_i, V_a)=PReLU([V_i, V_a, V_i \otimes V_a]) * W</script><p>DIN 模型在基准模型的基础上，增加了注意力机制，就是模型在对候选商品预测的时候，对用户不同行为的注意力是不一样的。“相关” 的行为历史看重一些，“不相关” 的历史甚至可以忽略。在 DIN 场景中，针对不同的候选广告需要自适应地调整 <code>User Representation</code>。也就是说：在 <code>Embedding Layer -> Pooling Layer</code> 得到用户兴趣表示的时候，依据给定 Ad，通过计算用户历史行为与该给定 Ad 的相关性，赋予不同的历史行为不同的权重，实现局部激活。从最终反向训练的角度来看，就是根据当前的候选广告，来反向的激活用户历史的兴趣爱好，赋予不同历史行为不同的权重。</p>
<p><img src="https://i.loli.net/2021/01/14/5YSyF4XvEUVBfwa.png" alt></p>
<p>上面这张图是是 DIN 的网络结构。左边是它整体的一个结构，右边是激活单元的一个详细说明（这里的激活单元就是上文中说的得到权重的方式）。我们先看左边的整体结构。最下面是 embedding 层，将高维稀疏的原始数据映射为低维稠密向量。embedding 后的特征分为四部分：<strong>用户画像特征，用户行为特征，广告特征和上下文特征</strong>，其中用户行为特征会通过激活单元以及 sum pooling 得到一个处理后的针对当前广告的总体兴趣向量（因为激活单元的输出是一个标量，所以这里其实就是对用户行为特征的加权求和）。将这四部分拼接后，通过两层全连接层和一层 softmax 就可以得到最后的概率值。</p>
<h2 id="训练技术" class="heading-control"><a href="#训练技术" class="headerlink" title="训练技术"></a>训练技术<a class="heading-anchor" href="#训练技术" aria-hidden="true"></a></h2><h3 id="Mini-batch-Aware-Regularization" class="heading-control"><a href="#Mini-batch-Aware-Regularization" class="headerlink" title="Mini-batch Aware Regularization"></a>Mini-batch Aware Regularization<a class="heading-anchor" href="#Mini-batch-Aware-Regularization" aria-hidden="true"></a></h3><p>CTR 中输入稀疏而且维度高，论文中举出 ID 类特征的维度为 0.6 billion，若是不添加任何正则的话，模型表现在一个 epoch 之后快速下降。通常的做法是加入 L1、L2 防止过拟合，但这种正则方式对于工业级 CTR 数据不适用，结合其稀疏性及上亿级的参数，以 L2 正则化为例，需要计算每个 mini-batch 下所有参数的 L2-norm，参数上升至亿级之后计算量太大，不可接受。</p>
<p>用户数据符合长尾定律 long-tail law，也就是说很多的 feature id 只出现了几次，而一小部分 feature id 出现很多次。这在训练过程中增加了很多噪声，并且加重了过拟合。</p>
<p>对于这个问题一个简单的处理办法就是：直接去掉出现次数比较少的 feature id。但是这样就人为的丢掉了一些信息，导致模型更加容易过拟合，同时阈值的设定作为一个新的超参数，也是需要大量的实验来选择的。</p>
<p>因此，阿里提出了<strong>自适应正则</strong>的做法，即：</p>
<ol>
<li>针对 feature id 出现的频率，来自适应的调整他们正则化的强度； </li>
<li>对于出现频率高的，给与较小的正则化强度； </li>
<li>对于出现频率低的，给予较大的正则化强度。</li>
</ol>
<p>提出 mini-batch aware regularizer（<strong>小批量感知正则化器</strong>），只计算出现在 mini-batch 中的稀疏特征参数的 L2-norm（即只计算 mini-batch 中非零项的 L2-norm）。它可以节省具有大量参数的深度网络上正则化的大量计算，并且有助于避免过度拟合。</p>
<h3 id="Dice-Data-Dependent-Activation-Function" class="heading-control"><a href="#Dice-Data-Dependent-Activation-Function" class="headerlink" title="Dice: Data Dependent Activation Function"></a>Dice: Data Dependent Activation Function<a class="heading-anchor" href="#Dice-Data-Dependent-Activation-Function" aria-hidden="true"></a></h3><p>本文设计了一种 data adaptive activation function，命名为 Dice：</p>
<script type="math/tex; mode=display">
p(s) = \frac{1}{1+e^{- \frac{s-E[s]}{\sqrt{Var[s] + \epsilon}}}} \label{eq1}</script><script type="math/tex; mode=display">
f(s)=  p(s) s + (1-p(s)) as</script><p>和 BN 类似，在训练时，$E [s]，<script type="math/tex">Var[s]$分别是每个mini-batch输入的均值和方差；在测试时，$E[s]，</script>Var [s]$ 随着数据进行移动求平均。$\epsilon$ 是一个小常数项，设定为 $10^{-8}$。</p>
<p>公式 $\eqref {eq1}$ 也可以进一步的用 BN 来表示：</p>
<script type="math/tex; mode=display">
p(s) = sigmoid(BN(s))</script><p>Dice 的代码实现如下：</p>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">Dice</span>(<span class="params">_x, axis=<span class="number">-1</span>, epsilon=<span class="number">0.000000001</span>, name=<span class="string">'dice'</span>, training=True</span>):</span></span><br><span class="line">    alphas = tf.get_variable(<span class="string">'alpha_'</span>+name, _x.get_shape()[<span class="number">-1</span>],</span><br><span class="line">            initializer=tf.constant_initializer(<span class="number">0.0</span>),</span><br><span class="line">            dtype=tf.float32)</span><br><span class="line">    inputs_normed = tf.layers.batch_normalization(</span><br><span class="line">            inputs=_x, </span><br><span class="line">            axis=axis, </span><br><span class="line">            epsilon=epsilon, </span><br><span class="line">            center=<span class="literal">False</span>, </span><br><span class="line">            scale=<span class="literal">False</span>, </span><br><span class="line">            training=training)</span><br><span class="line">    x_p = tf.sigmoid(inputs_normed)</span><br><span class="line">    <span class="keyword">return</span> alphas * (<span class="number">1.0</span> - x_p) * _x + x_p * _x</span><br></pre></td></tr></tbody></table></figure>
<p>优点：</p>
<ul>
<li>根据数据分布灵活调整阶跃变化点，具有 BN 的优点 (解决 Internal Covariate Shift)，原论文称效果好于 Parametric ReLU。</li>
</ul>
<p>缺点：</p>
<ul>
<li>具有 BN 的缺点，大大加大了计算复杂度。</li>
</ul>
<h2 id="评价指标GAUC" class="heading-control"><a href="#评价指标GAUC" class="headerlink" title="评价指标GAUC"></a>评价指标 GAUC<a class="heading-anchor" href="#评价指标GAUC" aria-hidden="true"></a></h2><p>因为推荐系统的排序是个性化的，不同用户的排序结果不太好比较，这可能导致全局 auc 并不能反映真实情况。论文采用的 GAUC 实现了用户级别的 AUC 计算，<strong>在单个用户 AUC 的基础上，按照点击次数或展示次数进行加权平均，消除了用户偏差对模型的影响</strong>，更准确的描述了模型的表现效果（论文里面叫 An variation of user weighted AUC， 用户加权 AUC）。</p>
<p><img src="https://i.loli.net/2021/01/15/5KCpLxXFI1HefYy.png" alt></p>
<p>其中 n 是用户数， $impression$ 和 $AUC_{i}$ 是第 $i$ 个用户的 impression 数和对应 AUC。<strong>一般计算时，会过滤掉单个用户全是正样本或负样本的情况。</strong></p>
<blockquote>
<p>impression：就是曝光数</p>
</blockquote>
<p>AUC 是要分用户看的，我们的模型的预测结果，只要能够保证对每个用户来说，他想要的结果排在前面就好了。假设有两个用户 A 和 B，每个用户都有 10 个商品，10 个商品中有 5 个是正样本，我们分别用 TA，TB，FA，FB 来表示两个用户的正样本和负样本。也就是说，20 个商品中有 10 个是正样本。假设模型预测的结果大小排序依次为 TA，FA，TB，FB。如果把两个用户的结果混起来看，AUC 并不是很高，因为有 5 个正样本排在了后面，但是分开看的话，每个用户的正样本都排在了负样本之前，AUC 应该是 1。显然，分开看更容易体现模型的效果，这样消除了用户本身的差异。</p>
<p>但是上文中所说的差异是在用户点击数即样本数相同的情况下说的。还有一种差异是用户的展示次数或者点击数，如果一个用户有 1 个正样本，10 个负样本，另一个用户有 5 个正样本，50 个负样本，这种差异同样需要消除。GAUC 的计算，不仅将每个用户的 AUC 分开计算，同时根据用户的展示数或者点击数来对每个用户的 AUC 进行加权处理，进一步消除了用户偏差对模型的影响。通过实验证明，GAUC 确实是一个更加合理的评价指标。</p>
<p><img src="https://i.loli.net/2021/01/15/kfqs59vXI8pNdHT.png" alt></p>
<div class="note warning">
            <p>复习一下 AUC 的计算：正例排在负例之前的概率。假设总共有（m+n）个样本，其中正样本 m 个，负样本 n 个，总共有 m <em> n 个样本对，计数，正样本预测为正样本的概率值大于负样本预测为正样本的概率值记为 1，累加计数，然后除以 m </em> n 就是 AUC 的值。</p>
          </div>
<p>AUC 的计算：</p>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">naive_auc</span>(<span class="params">labels,preds</span>):</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">　　　先排序，然后统计有多少正负样本对满足：正样本预测值>负样本预测值, 再除以总的正负样本对个数</span></span><br><span class="line"><span class="string">     复杂度 O(NlogN), N为样本数</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    n_pos = sum(labels)</span><br><span class="line">    n_neg = len(labels) - n_pos</span><br><span class="line">    total_pair = n_pos * n_neg</span><br><span class="line"> </span><br><span class="line">    labels_preds = zip(labels,preds)</span><br><span class="line">    labels_preds = sorted(labels_preds,key=<span class="keyword">lambda</span> x:x[<span class="number">1</span>])</span><br><span class="line">    accumulated_neg = <span class="number">0</span></span><br><span class="line">    satisfied_pair = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(len(labels_preds)):</span><br><span class="line">        <span class="keyword">if</span> labels_preds[i][<span class="number">0</span>] == <span class="number">1</span>:</span><br><span class="line">            satisfied_pair += accumulated_neg</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            accumulated_neg += <span class="number">1</span></span><br><span class="line"> </span><br><span class="line">    <span class="keyword">return</span> satisfied_pair / float(total_pair)</span><br></pre></td></tr></tbody></table></figure>
<p>GAUC 的计算：</p>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> defaultdict</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> roc_auc_score</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">cal_group_auc</span>(<span class="params">labels, preds, user_id_list</span>):</span></span><br><span class="line">    <span class="string">"""Calculate group auc"""</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> len(user_id_list) != len(labels):</span><br><span class="line">        <span class="keyword">raise</span> ValueError(</span><br><span class="line">            <span class="string">"impression id num should equal to the sample num,"</span> \</span><br><span class="line">            <span class="string">"impression id num is {0}"</span>.format(len(user_id_list)))</span><br><span class="line">    group_score = defaultdict(<span class="keyword">lambda</span>: [])</span><br><span class="line">    group_truth = defaultdict(<span class="keyword">lambda</span>: [])</span><br><span class="line">    <span class="keyword">for</span> idx, truth <span class="keyword">in</span> enumerate(labels):</span><br><span class="line">        user_id = user_id_list[idx]</span><br><span class="line">        score = preds[idx]</span><br><span class="line">        truth = labels[idx]</span><br><span class="line">        group_score[user_id].append(score)</span><br><span class="line">        group_truth[user_id].append(truth)</span><br><span class="line"></span><br><span class="line">    group_flag = defaultdict(<span class="keyword">lambda</span>: <span class="literal">False</span>)</span><br><span class="line">    <span class="keyword">for</span> user_id <span class="keyword">in</span> set(user_id_list):</span><br><span class="line">        truths = group_truth[user_id]</span><br><span class="line">        flag = <span class="literal">False</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(len(truths) - <span class="number">1</span>):</span><br><span class="line">            <span class="keyword">if</span> truths[i] != truths[i + <span class="number">1</span>]:</span><br><span class="line">                flag = <span class="literal">True</span></span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line">        group_flag[user_id] = flag</span><br><span class="line"></span><br><span class="line">    impression_total = <span class="number">0</span></span><br><span class="line">    total_auc = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> user_id <span class="keyword">in</span> group_flag:</span><br><span class="line">        <span class="keyword">if</span> group_flag[user_id]:</span><br><span class="line">            auc = roc_auc_score(np.asarray(group_truth[user_id]), np.asarray(group_score[user_id]))</span><br><span class="line">            total_auc += auc * len(group_truth[user_id])</span><br><span class="line">            impression_total += len(group_truth[user_id])</span><br><span class="line">    group_auc = float(total_auc) / impression_total</span><br><span class="line">    group_auc = round(group_auc, <span class="number">4</span>)</span><br><span class="line">    <span class="keyword">return</span> group_auc</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__==<span class="string">'__main__'</span>:</span><br><span class="line">     a=[<span class="number">1</span>,<span class="number">2</span>,<span class="number">1</span>,<span class="number">2</span>]</span><br><span class="line">     b=[<span class="number">0.6</span>,<span class="number">0.7</span>,<span class="number">0</span>,<span class="number">0</span>]</span><br><span class="line">     c=[<span class="number">1</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">0</span>]</span><br><span class="line">     d=np.array([[<span class="number">1</span>],[<span class="number">1</span>],[<span class="number">0</span>],[<span class="number">0</span>]])</span><br><span class="line">     print(d)</span><br><span class="line">     print(list(_flatten(d.tolist())))</span><br><span class="line">     print(cal_group_auc(list(_flatten(d.tolist())),b,a))</span><br></pre></td></tr></tbody></table></figure>
<h2 id="实验结果" class="heading-control"><a href="#实验结果" class="headerlink" title="实验结果"></a>实验结果<a class="heading-anchor" href="#实验结果" aria-hidden="true"></a></h2><p>文章在公开数据集上进行了大量且细致的离线实验用以证明 DIN 模型的效果，具体可以参考论文中的表述。这里主要关注的是 DIN 模型的线上实验表现，因为该模型最终是要部署到线上真实环境中的，所以作为相关领域的从业人员，我也是更加关注该模型在 A/B Test 中的表现。文章指出相较于 Base 模型，DIN 模型表现十分突出，<strong>线上 CTR 增长 %10，RPM 增长 3.8%</strong>，在 CTR 预估领域百分之零点几的 CTR 增长都会带来巨大的增长，所以足以见得 DIN 模型的效果还是非常出色的，该模型也成为了阿里妈妈新一代的 CTR 预估模型。</p>
<p><img src="https://i.loli.net/2021/01/15/UabXJFvHA64rVtR.png" alt></p>
<h2 id="需要注意的坑" class="heading-control"><a href="#需要注意的坑" class="headerlink" title="需要注意的坑"></a>需要注意的坑<a class="heading-anchor" href="#需要注意的坑" aria-hidden="true"></a></h2><ol>
<li><p><strong>Batch Normalization</strong> 的时候，训练的时候注意设置 traning 参数更新 BN 参数。</p>
</li>
<li><p>阿里的源码 <strong>Dice</strong> 激活函数在预测的时候实现的有问题。</p>
</li>
</ol>
<p>具体可参考文章：<a href="https://zhuanlan.zhihu.com/p/78829402?utm_source=wechat_timeline">深度学习中 Batch Normalization 和 Dice 激活函数</a></p>
<h2 id="DIN实现代码" class="heading-control"><a href="#DIN实现代码" class="headerlink" title="DIN实现代码"></a>DIN 实现代码<a class="heading-anchor" href="#DIN实现代码" aria-hidden="true"></a></h2><p><a href="https://github.com/ZiyaoGeng/Recommender-System-with-TF2.0">数据集处理</a></p>
<p><a href="https://github.com/ZiyaoGeng/Recommender-System-with-TF2.0/tree/master/DIN">代码</a></p>
<h2 id="参考" class="heading-control"><a href="#参考" class="headerlink" title="参考"></a>参考<a class="heading-anchor" href="#参考" aria-hidden="true"></a></h2><ol>
<li><a href="https://www.jianshu.com/p/73b6f5d00f46">推荐系统遇上深度学习 (十八)— 探秘阿里之深度兴趣网络 (DIN) 浅析及实现</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/42934748">CTR 论文精读 (八)—DIN for Click-Through Rate Prediction</a></li>
<li><a href="https://blog.csdn.net/zhongqiqianga/article/details/103718603">AUC 和 GAUC</a></li>
</ol>
</body></html>]]></content>
      <tags>
        <tag>排序模型</tag>
      </tags>
  </entry>
  <entry>
    <title>我对美国第 45 任总统唐纳德・特朗普的一些看法</title>
    <url>/post/b25618e1.html</url>
    <content><![CDATA[<html><head><link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script></head><body><h2 id="评价" class="heading-control"><a href="#评价" class="headerlink" title="评价"></a>评价<a class="heading-anchor" href="#评价" aria-hidden="true"></a></h2><p>　　不管怎么样他肯定会在历史上扮演一个比较重要的角色，一是他作为一个 “颠覆” 的角色出现，掀开了右倾民族主义的遮羞布；二是刚好遇上了百年不遇的新冠疫情，美国又恰好是最严重的国家。</p>
<p>　　特朗普以及他的团队其实是意识到美国出现了什么问题，他们幸运的找出了部分核心问题而且得到了很多民众的支持，但是很可惜海没有找到本质问题，也没找到解决办法，如果把美国看作一个得了感冒的病人，那么特朗普团队是找出了病因的医生，但是用了以毒攻毒的疗法，很有可能副作用会把人弄死。</p>
<p>　　附：唐纳德・特朗普就职和卸任演讲稿</p>
<a id="more"></a>
<h2 id="美国总统特朗普宣誓就职演讲词" class="heading-control"><a href="#美国总统特朗普宣誓就职演讲词" class="headerlink" title="美国总统特朗普宣誓就职演讲词"></a>美国总统特朗普宣誓就职演讲词<a class="heading-anchor" href="#美国总统特朗普宣誓就职演讲词" aria-hidden="true"></a></h2><p>​         大法官罗伯斯，卡特总统，克林顿总统，布什总统，奥巴马总统，美国人民们，全世界的人们：谢谢你们。</p>
<p>现在，我们美国公民们致力于重塑我们的国家以及兑现向全体人民作出的承诺。我们将携手决定美国以及世界接下来几年的命运。我们将面临挑战和困境，但是我们会做好分内之事。</p>
<p>　　我们每隔四年便齐聚一堂，以完成权力平稳交接之事宜。奥巴马夫妇为此事慷慨相助，我衷心感谢你们。今天的仪式有着非凡的意义，因为今天，权力不仅仅是两届政府或是两党之间的移交，而是华盛顿和你们，即人民之间的移交。</p>
<p>　　长期以来，一小撮人盘踞在首都通过政府攫取利益，而却要人民负担；华府兴旺发达，人民却未能分一杯羹；政客赚的盆满钵满，而工厂关闭，岗位流失。体制只会自保，而不会在乎民众；他们的胜利不是你的胜利；他们弹冠相庆，却不见全国上下苦苦挣扎的百姓。</p>
<p>　　就在此时此地，一切都将变化，因为这是你们的时刻，这是属于关注美国命运的全国人民的时刻，这是你们的庆典，因为美利坚合众国是你们的国家。真正重要的不是哪个党控制我们的政府，而是政府是不是被人民所掌控。2017 年 1 月 20 日将被历史牢记，这一天人民再次当家作主，曾被遗忘的男男女女将不会再被忘却。</p>
<p>　　所有人都在倾听你们的声音。你们跨过山和大海来见证历史，世上从未有之盛况。政府存在的理由即是服务它的人民。</p>
<p>　　美国人想让他们的孩子上好学校，想让他们的家庭住在安全的街区，想给自己谋个好工作，这些都是正派人民的正当需求。然而对于诸多国人来说，这样的要求都难被满足 —— 孤儿寡母困居内城；废弃工厂锈迹斑斑，如同墓碑，散布各地；教育体系为利益洪流损毁，学生风华正茂却难得学识。犯罪、帮派和毒品谋财害命，毁坏我国的潜力。此时此地，这些悲剧必须消失。我们身处一国，他们的痛苦就是我们的痛苦；他们的梦想和成功即是我们的梦想和成功。我们同呼吸，共命运。</p>
<p>　　我今天履职的宣誓即是对全体美国人的效忠。几十年来，我们损害自己工业成就了别国工业；强了他国的国防却弱了自己的军队；我们守了别国边境，却对自己的不闻不问；我们挥金如土，基础设施却年久失修；我们长了他人志气灭了自己威风。工厂一个个关门跑路，对留守的工人却不闻不问。我们中产阶级的财富凭空蒸发。当然，这些都是过去时了，我们现在着眼未来。</p>
<p>　　我们聚集此地，向每个城市、每个外国首都和每间权力的厅堂发声。从今日起，我们管理国家的新思路只有一个 —— 美国优先。从今日起，任何关于贸易、税收、移民、外交的政策都要保护美国工人和家庭的利益。我们必须守住边境，抵抗那些生产我们的商品、偷走我们公司和摧毁我们就业市场的蛮人。保护主义能使我们重归繁荣。我将不负众望，鞠躬尽瘁死而后已。</p>
<p>　　美国将再次走向成功，而且将取得史无前例的胜利。我们会带回就业和财富，巩固国境，重拾梦想。我们要在美丽祖国上兴建高速公路、桥梁、机场、隧道和铁路。我们会搞好人民福祉，用美国人民的双手重塑国家。我们有两个简单的原则：“买美国货” 和 “雇美国人”。我们要在国际上广交朋友，但我们也会尊重别国利益；我们不强求他国认同我们的生活方式，但我们要做文明的灯塔。我们要巩固旧盟友，交好新朋友，联合文明世界剿灭极端伊斯兰教恐怖主义。</p>
<p>　　我们所有政策的基础都是服务国家，通过对国家的忠诚，我们之间的信任也会重现。当你全身心地拥抱爱国主义，偏见就无处遁形。《圣经》告诉我们当上帝的子民和谐的生活在一起，是多么美好愉悦呀。君子和而不同，同求，但是存异。团结的美国是战无不胜的美国。我们不应胆怯，因为我们有军队和执法部门精英们的保护，他们一直在保护我们，而最重要的是，我们承蒙上帝恩荫。</p>
<p>　　我们要敢想，更要有梦想。在美国，我们知道勇者生存，国亦然。我们不再听信夸夸其谈而毫无作为的政客。空谈误国，实干兴邦。不要让别人说你不行，有志者事竟成，美国精神战无不胜，我国必将迎来伟大复兴的历史时刻。我们刚刚走进新的千禧年，太空的迷雾等待着我们探索，能源、工业和科技的桎梏亟需解锁。</p>
<p>　　民族自豪感充斥着我们心灵，治愈我们的裂痕；革命先烈的智慧振聋发聩，提醒我们即使肤色不同，但是血管里都流淌着爱国者的鲜血，我们都热爱自由，对星条旗顶礼。不管是出生在底特律城乡结合部还是狂风席卷的内布拉斯加州大平原的婴儿，他们都被同一位万能的造物主倾注生命的气息，他们仰望夜空，心中充斥的也都是同样的梦想。</p>
<p>　　我向所有美国人喊话 —— 住的近的或远的，住在大城市或小城市的，从群山到群山，从大洋到大洋的所有美国人，听吧，你们再也不会被忽视了，你们的声音、希望和梦想描绘着美国的命运，你们的勇气、善意和爱永远指引我们的道路。一起，我们使美国更强大，我们使美国更富裕，我们使美国更骄傲，我们使美国更安全，是的，我们会让美国再次伟大。</p>
<p>　　感谢诸位。上帝保佑你，天佑美利坚。</p>
<h2 id="川普总统卸任告别演说" class="heading-control"><a href="#川普总统卸任告别演说" class="headerlink" title="川普总统卸任告别演说"></a>川普总统卸任告别演说<a class="heading-anchor" href="#川普总统卸任告别演说" aria-hidden="true"></a></h2><p>　　美国同胞们，在 4 年之前，我们开启了一个伟大的全国性的运动，去重建我们的国家，去重振他的精神，也去恢复政府对它的公民的忠心耿耿。简而言之，我们开始了一项使命，去让美国再次的伟大，是为了所有的美国人。当我结束我作为第 45 任的美国总统任期之时，我站在你们的身边非常的自豪，为我们所共同达成的成就。我们做了我们来到这里要做的还有更多的更多，就在这一周，我们的新政府即将就职上任，我们为他祈祷，希望他成功，让美国和平和繁荣。</p>
<p>我们对它发出我们最诚挚的希望，我们也希望他们有幸运，这是个非常重要的词语。</p>
<p>　　首先我要感谢几个出类拔萃的人们，让我们的旅程得以实现，首先让我表达我巨大的感激，感激第一夫人给我的爱以及支持，我也想要表达我最深刻的感激，给到我的女儿伊万卡我的女婿库什娜以及 John Eric，还有 laura。我的二儿子他的儿媳，你们让我的世界充满了光明，充满了喜悦，我同时要感谢副总统彭斯以及他出类拔萃的妻子凯伦以及整个的彭斯家族，我要感谢我的参谋长梅多斯，以及整个白宫的尽职尽责的员工们，以及我的所有的内阁，以及我们政府中各层各面的人们，他们呕心沥血、鞠躬尽瘁的为美国而奋斗。</p>
<p>　　我同时也想用这个时间去感谢一个非常出类拔萃的团体，也就是美国的特勤局，我的家人和我，我们将永远的欠你们的。我巨大的感谢也要给到所有的白宫军队办公室的人们，还有我们 marine win，还有空军一号的所有的职员，还有所有的军队服务人员，以及给到州政府以及地方政府的官员，最重要的是我要感谢美国人，作为你们的总统是我无法用言语所描述的荣幸。感谢你们给我这个出类拔萃的尊荣，这是一个伟大的尊荣，巨大的荣幸，我们将永远不要忘记。</p>
<p>　　虽然说美国将永远都会有我们的分歧，但是我们是一个非常有信仰的热爱自由，热爱和平的公民的国家，我们都希望我们的国家能够繁荣，非常非常的成功，非常非常的良善。我们是一个非常伟大的国家，所有的美国人看到我们国会的暴力都感到非常的震惊，政治的暴力对我们美国人所真实的一切价值都是背道而驰的，这将永远不会受到容忍。现在最重要的是我们要围绕我们共同的价值团结一致，并且跨越党派之间的隔阂，创造我们共同的命运。</p>
<p>　　在 4 年之前，我作为一个唯一的真正的局外人，来到了白宫，第一个这样子的人赢得了总统，我以前不是一个政客，而是一个建造家，我看着开放的天际线并且有着无限的想象力。</p>
<p>我竞选总统是因为我知道我们美国人有着高耸入云的新高峰，正在等着我们去攀登，我也知道我们国家的潜力是无限的，只要我们把美国放在第一位，所以说我离开了我以前的生活，并且迈入了一个非常不同的领域，而这个领域却是有各种各样的潜能，只要我们做的对，美国给了我如此多，我也想将其回报有着，数百万的全国的新型的美国人，我们创造了有史以来最伟大的政治运动，我们也创造了有史以来最富最繁荣的经济，这是美国第一，因为我们都想要让美国再次的伟大，我们也重新建造了我们国家的立国之本，它是要去服务人民的。</p>
<p>　　我们的目标不是左右之分，也不是共和党或者民主党，而是关于我们国家的良善，也就是我们全国的利益。里面得到了美国人民的支持，还有祈祷我们达成了所有人想象的都要更多的成就，没有人能够想到我们能做到，我们也通过了有史来最大的减税，改变了最大的改革，同时也减少了很多扼杀工作岗位的政策上的繁文缛节，我们也解决了我们以前非常糟糕的贸易协议，同时也从巴黎气候协议中抽身而出。</p>
<p>　　我们也重新协调了南韩的协议，同时也用我们的美墨加贸易协议取代了原来的北美贸易条约与墨西哥和加拿大的协议非常的成功，同时非常重要的事，我们还实行了历史上标志性的对中国的关税，同时与中国达成了新的非常好的协议，但是当墨水还没有干的时候，我们以及整个世界被病毒而袭击，我们贸易的关系正在飞速的变化，有数十亿的美元正在涌入美国，但是这个病毒让我们不得不走另外一条道路，整个世界都在受苦受难，但是美国在经济上却领先了其他的国家，这是因为我们出类拔萃的经济，以及我们所建造起来的经济基础，就是说没有这些个基础的话，我们就不会如此了，也不会有我们有的有史以来最好的一些个数字了。</p>
<p>　　我们也解锁了开拓了我们能上的潜能，成为了世界上第一名的石油以及天然气生产最多的国家，我们也建造了全世界有史以来最繁荣的经济，我们重新点燃了美国的工作创造，同时也达到了有史以来最低的失业率，让西语裔非裔亚裔还有妇女，几乎所有人无论是什么人都达到了最低的失业率，收入也在上增，美国梦再次的得以实现，而数百万的人在极短的几年之中脱离了贫困，这是一个奇迹。</p>
<p>股市创了一个又一个的新高，在短短时间之中创了 148 次新高，同时我也重振了退休金，让那些个辛勤的美国人有了他们更好的退休金，401k 现在的程度是前所未见的，我们从来都没有看到过现在的数字，而这是在疫情之前，而且也是在疫情之后都是如此，我们也重新建造了美国的制造工业基地，我们开放了数以千计的新的工厂，同时也带回来了一个美妙的词语，叫做美国制造。为了让工人过得更好，我们签署了有史以来最大的一些个法案给到儿童的成长，同时我们也帮助私营企业让他们整整 1600 万个美国人受益，就是都是为了明天的工作岗位，当我们的国家受到一个非常糟糕病毒的袭击的时候，我们不仅是制造出来了一个而是两个疫苗是在破记录的时间中研发出来的，还有更多的还在后头，他们本来以为做不到的，但是我们做到了他们把它叫做医学上的奇迹，现在他们就是这么叫的，叫做医学上的奇迹。</p>
<p>　　如果是另一个政府的话，他们可能要花 3 年 4 年 5 年，甚至可能要花到 10 年才能够研发出来一个疫苗，但是我们在 9 个月就做成了，我们为每一个失去的生命而感到悲痛，我们也在他们的记忆中发誓要要永远的打败这个病毒，当这个病毒重击了全球的经济的时候，我们开创了最快的经济复苏。</p>
<p>　　这是我们国家前所未有的，我们也通过了整整 4 兆美元的经济援助，拯救并且帮助了这么多的工作，同时也减少了失业率，减少了一半，这些个数字是我们国家前所未见的，我们也创造了选择以及透明度，在医保系统之中与那些个大药厂对立，让那些个最惠国政策得以实施，它也会给我们在全世界最低的处方药价格，我们也通过了老兵选民法、选择法案、老兵责任法案、选择权法案以及非常有标志性的犯罪司法系统的改革，我们也任命了三名新的大法官，我们也任命了大概 300 多个联邦的法官，让他们能够白纸黑字的去解读我们的宪法。</p>
<p>　　好多年来美国的人民他们想要让华盛顿去保护我们的边境，我们终于回应了人们的诉求，并且达成了我们美国史上最安全的边境，我们给了我们勇敢的边境的工作人员们给了他们足够的资源和工具，让他们能够前所未有的更好的做好他们的工作，并且是执行我们的法律，让美国保证安全。我们也自豪的将最强壮的最坚固的边境安全留给下任政府，其中包括历史性的协议与墨西哥与危地马拉、洪多拉斯和萨尔瓦多。有超过整整 450 英里的非常有力的新的边境墙，我们重振了美国在本土的强力，同时也重振了美国在全世界的领导力。</p>
<p>　　现在全世界都再一次的尊敬了美国，请不要失去这份尊重，我们也重新获得了我们的主权，因为在联合国中我们为美国挺身而出，同时抽身而退出了这个一边性的从来都不为美国利益着想的一些个协议，而北约的国家他们现在比我刚刚就职的时候要付的钱多了许多，当时非常的不公平，我们在为全世界付钱，而现在全世界在帮我们了。</p>
<p>　　可能最重要的事情是我们有整整三兆美元重建了美国的军队，他们这些个器材装备都是在美国制造的，我们还开创了在超过 75 年来第一个新的美国军队的分支，也就是太空军。在去年的春天，我站在佛罗里达的航肯尼迪航天中心之中，看到了美国的宇航员回到地球上，他是坐在美国制造的火箭上，这是多年来都未见的。</p>
<p>　　我们也重振了我们的团结，并且让全世界的盟友让他们与我们一起前所未有的向中国而挺身而出，同时我们也终结了恐怖分子的生命，包括巴格达迪，同时我们也对抗了伊朗政权，杀死了全世界头号的恐怖分子，就是苏莱曼尼，我们也认可了耶路撒冷，他是以色列的首都，同时也认可了在戈兰高地以色列的主权，因为我们非常强有力的果敢的外交政策，我们达成了一系列的历史性的在中东的和平协议，没有人相信只能够发生。亚伯拉罕协议，打开了一扇大门，迎来和平以及和睦而不是血腥，这是一个新的中东的黎明，我们现在把士兵带回美国，我也非常的自豪，成为数十年来第一位总统，完全没有发动新的战争，最重要的是我们我们重新的肯定了一个神圣的理念，就是在美国，政府是要回答人民的，我们的北极星，我们追寻的光芒，我们坚定不移的决心就是我们要在这里去服务平凡的美国人们，我们的忠诚不是要给到那些特殊利益组织或者说是大企业，而是给到我们的子孙，我们的公民们，给到我们国家的本身，作为总统，我的第一个工作重点，我的一直以来的忧虑就是我们美国工人以及美国家人的他们的利益，我并没有走简单的那条路，而只是如今的确是非常艰难的，我也没有走那一条会受到最少批评的那条路，相反我担起了最强硬的战争，最艰难的战役，做了最艰难的选择，因为你们把我选上来就是让我这么做的，你们的需求，就是我第一个和最后一个绝对不会动摇的关注，这将会是一个伟大的遗产，共同我们将会让美国人重新掌握我们的国家，我们重振了自治，我们也重振了一个理念，其实是在美国没有人应该受到遗忘，因为每个人都是重要的，每个人都有他们的声音，我们也为这个价值而奋斗。</p>
<p>每一个的公民都应该受到公平的对待，公平的尊严，公平的权利，因为我们都是由神所平等的创造的，每个人都应该受到尊重的对待，应该他们的声音得到聆听，他们的政府也应该听取他们的意见，你们对我们的国家忠诚，而我们的政府也一直以来都对你们忠心耿耿，我们共同的努力建造一个国家，让所有的公民都能够找到一个好的工作，去支持他们出色的家庭，我们与社区站在一起，让每个人都能够是安全的，并且在这个学校中让每一个孩子都能够去学习，我们也推行了一个文化，让我们的法律得以捍卫，我们的英雄得以尊重，我们的历史得以维护，遵守法律的公民们，他们将珍视这一切，美国也应该对此感到非常的自豪。</p>
<p>　　看到我们所达成的一切成就，这是非凡的。</p>
<p>　　现在当我准备离开白宫之际，我也一直在反思那些个威胁着，我们都共同分享了珍贵财富的因素，作为全世界最伟大的国家，我们不停的在面临着来自外国的威胁和挑战，但是我们现在所面临的最大的一个威胁就是我们自己对自己的信心的失去，我们对我们为国家的伟大失去信心，这才是最大的威胁，我们要有个强大的精神才能够强壮，我们必须要对我们保持自豪。我们是的心中要有一个闪亮的信仰才能够振奋。</p>
<p>　　如果是个国家失去了对他自己的价值、历史还有英雄失去信心的话，这个国家就无法繁荣，这对我们的繁荣蓬勃来说是至关重要的，我们一定会克服难关，并且克服挑战，这是一个坚定不移的决心，坚信我们国家的珍贵，就是我们在历史上一个独特的使命，我们永远不要失去这一决心，我们也永远不要抛弃我们对美国的信念。达成国家伟大的关键，就是要我们持续的维持我们国家的一个身份，也就是要关注于我们所共同分享的一切，我们所共同分享的历史遗产，在历史财富的中心就是一个非常强硬的信仰，相信言论的自由，言论的表达以及公开的辩论。</p>
<p>　　如果说我们忘记了我们是谁，我们怎么到这里的，我们才会让政治的言论审查还有黑名单，在美国而发生。这想都不敢想，关闭了开放的辩论，这是与我们的价值所背道而驰的，也违反了我们的传统，我们的美国人不应该有这样子的情况出现，不应该有严格的言论审查和言论工具，我们不这么做，我们不是屈服灵魂的国家。不应该为听到对方的声音而感到害怕，这不是我们的本质。</p>
<p>　　在过去的 200 多年来，我们面对的每一个挑战的时候，每个人都一直的将我们无可比拟的勇气自信以及独立的精神展现的淋漓尽致。这些个奇迹般的特质让我们每天的平凡的公民们，让他们去开疆拓野，并且开创了在一个伟大的西方新的生活方式。正是这些巨大的爱，去这些个神所赐予的自由，让我们的士兵得以冲锋陷阵，并且让我们的宇航员得以上太空。</p>
<p>当我看到过去的 4 年，一个图像在我脑中浮现，如此的明确，无论我去到哪里，无论我的车队开到到哪里，都有数以千计的人们，他们拖家带口的出来，以至于他们能够在我们经过的时候站在一边，自豪的挥舞着美国的国旗，这让我深受感动。我知道他们不仅是出来去展示他们出来支持我的，他们是出来去给我看到他们对我们国家的支持和热爱，这是每一个自豪的美国公民，他们有着共同的决心和价值，他们都相信美国是史上最伟大的国家，我们一直是也必须是一个自由的光明的以及荣誉之国。</p>
<p>　　如此珍贵的历史财富，我们必须每一次都要坚定的捍卫。</p>
<p>　　在过去这 4 年我正是做了这一点，无论是在华沙还是在韩国，还是来到了联合国大会的主席台，或者说在北京的紫禁城，又来到了拉什莫尔山，我无论在何地，我都为你们而奋斗，为你们的家庭，为我们的国家而战，最重要的是我为美国而战，以及为美国所代表的一切价值而战，也就是安全、强壮、自由以及自豪。</p>
<p>　　现在我准备把权力交予给一个新的政府，就在星期三的中午，我希望你们知道我们所开启的这一项运动才刚刚开始，这是前所未有的，这个信念，国家必须要服务人民绝对不会消亡，相反他将会愈发的强壮。只要美国的人民能够在心中坚信，有着坚定的对我们国家的信仰和热爱，我们国家就没有任何达不到的事情，我们的社区将会繁荣，我们的人民将会非常的繁华，我们的传统我们的信仰都会非常的强壮，而我们的未来也会比以前任何一个时候的更加的光明。</p>
<p>　　从这个神圣的地方，我从这里走出来，有着一个喜悦的尊崇的心，并且有着巨大的信心，相信我们的国家，相信我们的孩子们，最好的还在前头，感谢你们，告别了。愿神保佑你们，愿神保佑美利坚合众国！</p>
</body></html>]]></content>
      <tags>
        <tag>时事</tag>
      </tags>
  </entry>
  <entry>
    <title>张小龙：微信十年的产品思考</title>
    <url>/post/3c85efb8.html</url>
    <content><![CDATA[<html><head><link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script></head><body><h3 id="开场" class="heading-control"><a href="#开场" class="headerlink" title="开场"></a>开场<a class="heading-anchor" href="#开场" aria-hidden="true"></a></h3><p>各位朋友，晚上好！</p>
<p>谢谢来到公开课现场的朋友们，让我感受到这是一个面对面的交流，而不是一个人面对屏幕的直播。</p>
<p>2020，对很多人来说都是很不容易的一年。包括我们的公开课，也改为线上进行了。虽然在几年前的一次公开课上，我说公开课应该线上开就好了，效率最高，但没有想到今天是因为疫情的原因被迫做到了。</p>
<p>去年这个时候我们也没有想到，这次我们已经通过视频号来进行直播了。</p>
<p>因为疫情，很多公司的年会都改线上了，所以这个时候，我的同事们正在努力给视频号直播加一个能力，就是只有白名单的人才能进入直播间的企业内直播，希望能给需要线上开年会的企业一些帮助吧。</p>
<p>回头看十年前，当时的想法只是，希望有一个适合自己的通讯工具来用。于是就开始了微信的第一版。但当时绝对没有想到，十年后的微信会是现在这个样子。对此，我自己感觉特别幸运，我想我一定是那个被上帝选中的人，因为光靠个人努力是做不到这一点的。</p>
<p>我分享一组数据吧，到今天，每天 ——</p>
<ul>
<li>有 10.9 亿用户打开微信，3.3 亿用户进行了视频通话；</li>
<li>有 7.8 亿用户进入朋友圈，1.2 亿用户发表朋友圈；</li>
<li>有 3.6 亿用户读公众号文章，4 亿用户使用小程序；</li>
</ul>
<p>还有很多，包括微信支付，企业微信，微信读书，搜索等，就不一一说了。如微信支付，它就像你以前的钱包一样，已经变成了生活常用品。而微信，也真的成为了 “一个生活方式”。</p>
<p>今天是公开课，应该有很多的创作者参与，所以，也在这里感谢微信平台的每一个创作者，公众号的，小程序的，视频号的创作者。因为你们的创作，让微信的生态充满活力。</p>
<p>大家知道视频号今年的变化特别大。这里也想分享一下视频号的一些想法。</p>
<a id="more"></a>
<h3 id="视频号的起源" class="heading-control"><a href="#视频号的起源" class="headerlink" title="视频号的起源"></a>视频号的起源<a class="heading-anchor" href="#视频号的起源" aria-hidden="true"></a></h3><p>可能在 2017 年吧，我跟公众号的团队说，我们现在公众号只适合少数人写长文章，但是大部分人写不了文章。我们应该在朋友圈下面加一个 “非朋友圈”，只能发短文或者照片视频。</p>
<p>但后来就不了了之了，确实是很大的工程。因为帐号体系可能都完全不同了，就完全是个新的比公众号还复杂的系统。</p>
<p>随着时间的推移，视频化表达其实越来越成为普通人的习惯。来看几个数据，最近 5 年，用户每天发送的视频消息数量上升 33 倍，朋友圈视频发表数上升 10 倍。这时候，我们再思考短内容的时候，就会想，不应该基于短文字来做，而是应该基于视频化内容来做了。</p>
<p>视频化表达应该是下一个十年的内容领域的一个主题。虽然我们并不清楚，文字还是视频才代表了人类文明的进步，但从个人表达，以及消费程度来说，时代正在往视频化表达方向发展。</p>
<p>于是在 2019 年，我们组织了一个特别小的小团队，开始了视频号的开发。</p>
<p>我们也没有问公司要什么资源专门去做，甚至没有在公司开会立项，就自己悄悄做了。我觉得这很微信风格啊，基本上微信做东西，都是成立小团队开始做起，而不是大规模的兵团作战。</p>
<p>并且我说，我们要做，就一定要做成做大。这并不是公司给的任务，因为完成任务是枯燥无味的，并且会因此动作变形。应该说是我们要给自己一些挑战性的目标，不然工作会显得很无聊。</p>
<h3 id="视频号是什么？" class="heading-control"><a href="#视频号是什么？" class="headerlink" title="视频号是什么？"></a>视频号是什么？<a class="heading-anchor" href="#视频号是什么？" aria-hidden="true"></a></h3><p>视频号是一个人人都可创作的短内容平台。</p>
<p>所以它是公开领域的内容平台，就不能基于微信号来创作了。</p>
<p>因此遇到的第一个问题是，需要有一种新的 ID（身份）。长期以来，微信的最大价值是每个人的微信 ID。比如微信支付能很顺畅，因为钱包跟着个人 ID 走，这是非常自然的。就像你现在只拿身份证也能取钱一样。但这个 ID 是通讯和社交领域的，因此是私密的。因此，微信的用户并不能公开对非好友说话。即便评论了，别人也无法联系你。这对于社交领域当然没有问题。但对于公开领域，需要新的身份。而在一个产品里，承担两个身份，其实是很有挑战的。</p>
<p>而这个新的 ID，还必须特别方便，不至于在各个场景里遇到身份的冲突。所以处理得不好，双 ID 会让系统变得非常复杂。比如你评论，就需要选择用哪个 ID 来评论。</p>
<p>但是这个 ID 的意义又特别大，一旦走出这一步，意味着微信不再局限于社交领域，而是进入到公开信息领域。</p>
<p>因此视频号的意义，与其说是视频，不如说是 “号”。因为有了一个公开的号，意味着每个人都有了一个公开发声的身份。</p>
<p>比如，直播，在视频号里做得很顺利。在视频号之前，我们是没法做直播的，最多做到群内直播，那还是属于群通信的范畴。但有了视频号这个 ID，每个人可以迅速开通自己的直播。这里，ID 才是基石。它可以承载视频内容，可以承载直播，可以承载小程序等。</p>
<p>我记得当时有个方案是，每个进视频号的人要创建一个视频号 ID，用这个 ID 来浏览和评论内容。我说不对，浏览者应该是微信身份，而不应该强迫每个人开一个新的身份才能看和评论。幸好当时选择了这样一条路径，不然就没有后来的社交推荐体系了。其实产品的迭代是由无数这样的选择组成的。</p>
<p>ID 还有一个重要的意义是针对机构的。</p>
<p>大家知道 PC 时代每个机构都有一个官方网站。其实微信一直在寻找 PC 时代的 “官方网站” 的替代物。做公众号的时候，我们希望公众号就是一个机构比如企业的官网。做小程序的时候，我们希望小程序就是官网。现在，我们希望视频号是每个机构的官网。这是合理的，官网是需要进化的。所以未来视频号会承接一个机构的很多服务内容，并不局限于视频。比如一个企业的服务，可以通过小程序的方式，展示在视频号下面。</p>
<p>所以我开玩笑说，如果有一天我们在每一个广告牌下面，都能看到广告主的视频号的二维码，那就说明视频号做成了想要的官网了。</p>
<p>第一个版本其实只是搭建了这样一个 ID 体系。和公众号的很类似，但是比公众号的门槛低很多，普通微信用户可以立即开通它。</p>
<p>内容表现上，只是一个简单的信息流，混合了关注的，朋友匿名点赞的，和系统推荐的内容在里面。</p>
<p>但这样的效果并不好。因为是灰度，量不大，因此也吸引不到大量的创作者来贡献内容，因此推荐的内容也一般般。</p>
<p>但即使如此，我们还是希望推荐的质量能够好起来。我们组建了三个做推荐算法的团队，每个团队十几个工程师。希望各自用不同方法去找到推荐的最优解。</p>
<p>应该说我们在算法领域沉淀应该还是很深的，搜一搜背后是个几百工程师的搜索技术团队，同时我们自己研发的语音识别和机器翻译，都是国内的一流水准。对了，外界一直有人说我们的语音识别用的是第三方的技术，其实我们从未用过第三方的，一直都是我们自己研发的。现在微信里面的语音识别每天翻译的语音条目在五亿条以上。</p>
<p>虽然搜索团队有很强的算法技术人员，但是，我还是把他们从搜索团队抽调出来进入到视频号团队来工作。因为闭环的小团队才能迅速迭代。</p>
<p>推荐团队很努力，但头几个月的滚动特别困难，似乎陷入了死结，就是内容不好看就没有浏览量，就导致没有人贡献内容，所以推荐系统也推不出好内容，然后继续没有好的内容看。</p>
<p>5 月份的时候，我们做了视频号最重大的一个改变。因为经过几个月的灰度，表明在现有的内容下，基于机器推荐是走不通的。对比朋友点赞的内容，虽然当时朋友点赞还是匿名的，和机器推荐的内容来对比，我发现，机器推荐的远不如人工（或者说朋友）推荐的精彩。既然这样，就应该以实名点赞的社交推荐为主，机器推荐为辅。</p>
<p>当时我给的理由是，我们所看的书，大部分是因为周围有人推荐而去看，而不是网上书店推荐的书。<strong>你少看几个机器推荐的内容不会觉得可惜，但错过了朋友们都在看的内容会觉得可惜。这是视频号能借助社交推荐起来的理由。</strong></p>
<p>于是五月份开始了变更最频繁的两周，几乎每两天就要更新一个版本。然后发布了基于朋友点赞的新的灰度版本，终于看到了上扬的数据，用户的留存非常高。</p>
<p>所以 6 月视频号的用户到了一个量级。数字其实不重要，但对于一个内容形态的产品来说，一定量级的用户意味着解决了生死问题，即流量的循环起来了。</p>
<p>这是一种典型的微信 style 的产品方法，即通过产品而非运营的方法，找到事情的撬动点，通过产品能力让事情运转起来。</p>
<p>有这个用户基数说明生存下来了，这时候就可以开始做基础功能的完善了，比如直播能力等。没有过生死线的话，做再多功能也是白搭。</p>
<p>在这里，是社交推荐发挥了作用，当时机器推荐的占比非常小，留存也非常低，我们也差点就放弃了机器推荐。但是，并不是说机器推荐没有用，而是要在内容丰富的情况下才能发挥作用。</p>
<p>插一个小故事，6 月份的时候，那时社交推荐的新版还在开发吧，我在黑板上写下一个断言：未来有一天，视频的播放量，关注，好友推荐，机器推荐的消耗比例，应该是 1:2:10。即，一个人应该平均看 10 个关注的视频，20 个朋友赞的视频，100 个系统推荐的视频这样的比例。</p>
<p>当时是这么解释的：</p>
<p>内容分两种，一种是你需要花脑力去理解的知识性信息，是学习；一种是不需要花脑力的思维舒适区的消费类的信息，是娱乐。朋友赞是朋友强迫你去获取你未必感兴趣的知识性信息，属于学习类的；机器推荐，是系统投其所好而让你很舒服的浏览你喜欢的消费性信息，属于娱乐类的。关注里面两种信息都有。</p>
<p>因为关注的东西你已经知道大概会是什么了，反而不会太有吸引力，因此是 1。朋友赞虽然看起来累，但是不能错过，所以是 2。而系统推荐，符合懒人原则，是大多数人都更容易消费且获得舒适感的信息，所以是 10。</p>
<p>但是我们现在的大盘数据，并不是这个比例。现在朋友赞产生的整体 vv，是机器推荐的 2 倍。</p>
<p>于是我让数据同事统计了一下，只拿有关注的用户来看。有关注的用户目前极少，属于活跃用户，所以代表了未来活跃用户的行为。前几天的数据是，有关注的用户，人均在三个 tab 产生的 vv，差不多是 1：2：9。拿到这个结果时我非常吃惊。它只是一种粗略的估计，并不是说预测特别准确，而是说我们做东西的习惯是，如果这样做，应该先推理出来一个结果，然后用数据去验证，才能检验方向是不是对的。</p>
<p>我估计未来这个 9 还会变得更大。因为这是和内容丰富度相关的。</p>
<p>说到这里，可能会有人说当机器推荐这个 9 变得越来越大，不是不符合用完即走吗。用完即走跟时间长短无关，跟效率有关。我们从来不会关注用户在微信里停留的时长，那不是我们的目标。当用户想要看内容的时候，不管是文章还是视频，如果他花了很多时间看，只能说明微信里面有很多值得看的内容，而不是要刻意去消耗他的时间。</p>
<h3 id="什么是视频" class="heading-control"><a href="#什么是视频" class="headerlink" title="什么是视频"></a>什么是视频<a class="heading-anchor" href="#什么是视频" aria-hidden="true"></a></h3><p>过程中还解决了另一个问题，即究竟什么是视频的问题。</p>
<p>说到视频，大家会想到手机相册里面的视频文件。就像朋友圈，只能上传相册的视频。我们也确实是通过这个方式，来希望朋友圈里的视频更多的是用户自己拍摄的视频。</p>
<p>但视频文件其实是会消失的。</p>
<p>从 Windows 转到苹果手机的用户，都会遇到一个问题，以前的文件和文件夹去哪里了。在 iOS 里，没有了文件的概念。文件被各个应用自己定义了。这是把文件应用化了，即文件不能脱离应用而存在，一旦脱离了，就是没有意义无法解释的数据。</p>
<p>这是一种很好的观念。</p>
<p>原始视频只是数据，它没法关联到其他信息，如创作者，观众数，评论等。它还需要存在本地，数据丢了就丢了。</p>
<p>因此未来的视频应该是一种结构化数据。它存在云端，有所有的创作者信息，有观众的互动信息，能够很方便的分享。</p>
<p>文字和视频等内容，存在的价值在于有人看到，也就是分享。而分享，如果还需要 copy 整个原始数据，是很落后的。分享应该只是一个链接的传递。</p>
<p>这会让我反思，朋友圈里面上传视频，以后会一直用这种原始方式吗？</p>
<p>所以在 6 月的时候，我们需要把视频号内容分享到朋友圈来，遇到一个问题，它应该长得像一个链接呢，还是像一个本地视频呢？其实是归类，它应该归类到文章链接，还是一个视频文件。我的答案是，云端化的结构化的视频，才是视频，本地的视频文件，反而是裸数据，是应该被淘汰的。所以你看到的朋友圈里的视频号的视频，和现在的本地视频的展现没什么区别。</p>
<p>在这里，视频号是结构化的视频内容的载体。我相信以后微信里面流通的视频，越来越多的会以视频号视频的形式存在，而不是视频文件的方式。</p>
<p>这种变化，其实在公众号体系里体现过一次。公众号是一个文章的载体。它让文章因为分享而变得有价值。并且，公众号定义了文章的展现形式，是所有的用户在阅读不同的文章时，能以一种相对一致的体验来阅读和互动。在我看来，这是对网页时代阅读体验的一次大的体验提升。</p>
<p>不管是文章还是视频，他们存在的价值在于被人看到，或者说被分享。显然，文章和视频需要一个载体来传播。</p>
<p>如果你能理解公众号对于文章分享的价值，那么，可以用同样的思路去理解视频号对于视频分享的价值。</p>
<p>载体的含义还体现在，我们自己不做内容，也不会去买内容。我们不关注具体的内容是什么。我们只做内容的承载和传递。</p>
<h3 id="长视频和短视频" class="heading-control"><a href="#长视频和短视频" class="headerlink" title="长视频和短视频"></a>长视频和短视频<a class="heading-anchor" href="#长视频和短视频" aria-hidden="true"></a></h3><p>我们也遇到了超过一分钟视频的问题。自然而然地，大家会认为长视频和短视频是两种东西，因此应该设计成两种不同的内容对象。</p>
<p>中间有个版本确实是视频号有专门的长视频这一栏的，甚至长视频和短视频的评论点赞还是分开的。</p>
<p>但如果仔细思考，在微信号体系里，是不应该做这种区分的。长短视频的区别只是消费的场景不一样。短视频适合碎片时间的连续消费，而长视频适合有一大段时间来看。</p>
<p>对视频号来说，简化这个问题的方法，是把一分钟以内的视频是为短视频，一分钟以上的视频的开头一分钟视为这个视频的摘要或简介。我把它称为封面。这样的话，视频号不区分长视频短视频，但是又能兼容短视频的体验。</p>
<p>关于长视频，我希望视频号逐渐积累越来越多的长视频，成为长视频的云端仓库。将来有一天，也许我们会提供一个检索或推荐入口，这样用户可以找到丰富的长视频内容。</p>
<p>这个其实也是未来非常有想象力的。</p>
<h3 id="视频号和个人的关系" class="heading-control"><a href="#视频号和个人的关系" class="headerlink" title="视频号和个人的关系"></a>视频号和个人的关系<a class="heading-anchor" href="#视频号和个人的关系" aria-hidden="true"></a></h3><p>视频号的初衷是让人人都能很容易通过视频化的方式去公开表达内容。但做产品的人都知道，让用户去发表内容去表达是最困难的。</p>
<p>现阶段我们也并没有做到让很多人在视频号去发表自己的日常。但我们有个举措，让我们能看到希望。我们上线了将自己的视频号内容关联到自己的微信名片的功能。我们发现结果比预料的要好很多，到现在已经有非常多人在名片展示了自己的视频号内容，并且还在持续增长。这是个很好的趋势。</p>
<p>这里有一个很有意思的话题，有的时候大家会觉得微信做东西特别保守。其实并不是保守，而是说很多东西是不对或不应该做的。举个例子，我们可以把视频号的内容挂在名片上，我们以前为什么不做一个类似这样的展示自己的一些精选的照片和视频的功能？我们内部讨论过好多次，因为很多人朋友圈设置了三天可见，越来越多了，我们打开名片有的时候几乎看不到东西。为什么不给他们提供一个可以把一些照片精选放在那里的功能，这样朋友进来至少可以看到一些。</p>
<p>之前我们不愿意做这个功能是因为，一旦这样做了，你可能只是把你历史上最好的照片放到那里，永远就不去修改它了。这次我们愿意这样做是因为，如果你关联到你的视频号的内容，那它就是活的，因为你会不停地更新你的视频号内容，而不是说我选几个历史上最好的照片作为精美的装饰就永远不变了。</p>
<p>毕竟，视频号希望的是人人都能表达，而不是只有网红和大 v 的表演。</p>
<h3 id="信息展现的方式" class="heading-control"><a href="#信息展现的方式" class="headerlink" title="信息展现的方式"></a>信息展现的方式<a class="heading-anchor" href="#信息展现的方式" aria-hidden="true"></a></h3><p>信息展现形式一直是互联网产品里的最基础部分，也是争议最大的。这里说的是指对信息列表的展现形式。</p>
<p>常见比如有瀑布流，通俗称呼的信息流，以及全屏。他们的区别是一屏里放多少条内容合适。全屏就是一屏只放一条内容。</p>
<p>以我自己的经验来说，我把这些式样的选择总结为一个粗略的规律，就是 ——</p>
<p>一屏里的内容条数，应当跟命中率成反比。</p>
<p>命中率是指用户可能感兴趣的内容条数的比例。比如 10 个邮件，只有一个是我想要看的，命中率是 10%。</p>
<p>以朋友圈举例，因为你并不是要看每一个朋友发的内容的，所以命中率并不高，如果改为全屏，就是灾难。同时，如果你添加的好友越来越多，命中率还会降低，因此就更不能增加每条内容的显示面积。如果我们要增大显示面积，就必须提高命中率。但朋友圈的命中率是很难提高的，因为朋友圈的命中率取决于朋友跟你的关系，而非他发的内容，而我们很难知道你对哪个朋友更感兴趣。</p>
<p>而往往关注内容越多的人，命中率就越低。所以公众号改版的时候，其实是一屏里的内容条数变少了，虽然带来了点击次数的减少，但关注多的人还是会抱怨，因为选择的难度增大了。但对于关注少的人，阅读量是上升了，因为只关注了几个号的话，命中率本来就高。后来我们在订阅号的顶部增加了常读号的展示，其实是提升了命中率。</p>
<p>视频号的上半年，平台的内容丰富度不够，命中率是很低的。所以当时半屏式的信息流是合适的，一屏显示超过一项内容，用户有选择的余地。那时候如果直接上全屏，可能死的很快。到下半年，内容开始丰富了，命中率开始提高了。并且全屏对于单个视频的展现效果当然也会比半屏要好，我们开始灰度的切换到全屏模式。</p>
<p>这里说个有意思的数据。我们把关注和机器推荐灰度切换到全屏，并且和没有灰度全屏的用户来对比观察。发现全屏后，关注 tab 的人均 vv（video view，视频播放量）下降了，推荐 tab 的上升了。这应该可以推导出来，关注 tab 的命中率不够高，以至于全屏后带来了轻微的选择困难。</p>
<p>我们在公众号里在给关注的号的内容做排序，以及在视频号里，也会通过算法对关注的内容做排序，也是为了提高命中率。特别是全屏之后，因为用户的选择余地是零了，更需要算法来做排序。</p>
<h3 id="直播" class="heading-control"><a href="#直播" class="headerlink" title="直播"></a>直播<a class="heading-anchor" href="#直播" aria-hidden="true"></a></h3><p>互联网历史上，个人在公开领域的表达方式一直在演变。最早的时候，需要你会写 HTML 来做网页。后来有了博客，博客之后是微博这样的短文字。现在是图片和短视频。演变的方向是往更能被普通人生产和消费的方向去走的。所以会体现为更短更碎片化。</p>
<p>所以我在想，还有什么内容形态是比短视频更能被更多人接受的。</p>
<p>我觉得直播有这个机会。直播比短视频的生产更容易，是因为拍一段短视频是需要有内容准备的。而直播，是不需要准备内容的，它就是日常聊天。这是一个非常巨大的差别，直接降低了直播的门槛。这是一种轻松的表达，普通人也能够去生产出来，朋友也更愿意去消费。</p>
<p>虽然直播已经发展了很多年，大家对直播的认知还是带货的领域，这是作为内容形态的方式来思考，就是个人表达的形态方面来思考的。</p>
<p>所以，直播在未来有可能会成为一种很多人在用的个人表达方式。</p>
<p>做一个未来的设想，很久以后，每个人的微信名片应该是活的，意思是，我打开你的名片，如果你刚好戴了一个可以直播的眼镜正在直播，那我就能直接看到你看到的东西。这可能是个人直播的终极形态。</p>
<p>前不久有一场流星雨的直播，有超过 100 万人观看了，有点超出我们的意料了。因为，我们并没有做任何中心化的流量分发去推它，它自然就吸引了 100 万人。在这里，是社交推荐在发生作用，通过朋友圈，群聊等进行了人群的扩散。当然，在视频号和直播的入口里面，我们还是会用机器推荐来给用户推荐适合的直播。当直播多了以后，除了你的朋友，我们也希望系统能告诉你哪个直播值得你看一下，这是我们的机器推荐有更大的考验。但社交推荐，仍然会是非常重要的传播途径。</p>
<p>其实我们现在还没有直播的入口，下一个版本可能就有了。我们现在有一个附近的直播和人，把它调一下，可能叫直播和附近。</p>
<p>我们也在丰富直播电商的能力，包括直播里可以挂接到第三方的小程序。</p>
<p>春节快到了，我们都习惯了在群里发红包抢红包来拜年了。但其实线下传统的拜年是走家串户面对面的行为。直播其实更能模拟出线下拜年这种传统方式。所以我们今年在直播这里也做了一点小小的东西，我们希望今年的春节能够有一些人通过直播的方式来拜年，那就特别好。</p>
<h3 id="关于创作者" class="heading-control"><a href="#关于创作者" class="headerlink" title="关于创作者"></a>关于创作者<a class="heading-anchor" href="#关于创作者" aria-hidden="true"></a></h3><p>很多人会关心平台会给创作者什么样的支持。</p>
<p>如上面提到的，我们更希望做视频的载体，并且让视频号成为个人和机构的官网。平台在这里的角色是连接，而不是做内容。但和以前的官网不一样的地方在于，微信体系里的官网，内容是能自己流通的。因此你不用太担心做了官网也没有人访问。我刚刚说到微信里集合了很多产品可能没法尝试的东西，比如说对于信息访问，我们可能会有关注关系可以获得，有搜索，有推荐，有系统推荐和社交传递这样一些方式，所以不用太担心自己的内容在这里没有人会看。</p>
<p>刚开始我们去邀请一些明星进来，明星会说有没有签约费。我们的回答是，我们希望你进来，因为你应该经营自己的粉丝，最终你会实现盈利，但不会平台出面来购买内容。</p>
<p>所以视频号这里，我们没有花一分钱去购买内容。将来也不想这么做。倒不是为了省钱，而是，当我们不花钱买内容的时候，创作者还愿意进来，才说明创作者能靠自己的努力获得回报，才说明我们建立了一个能自行运转起来的生态。同时，我相信普通人的创作力是巨大的，相反，购买的内容反而不一定能打动人。</p>
<p>微信的历史上，我们一直不强调强运营，也是这个原因。系统和规则会比运营的效率高太多了。就像我们现在看到微信支付，其实已经覆盖面非常大，但是我们微信支付的人数并不算多，对于支付这样一个需要跟线下接触的行业来说，我们每个行业微信支付里可能就一两个人在负责整个行业。</p>
<p>公众号的那一个 slogan 照样可以用在视频号上，再小的个体，也有自己的品牌。其实你现在放在视频号上也是很适用的。</p>
<h3 id="一些有趣的实验性项目" class="heading-control"><a href="#一些有趣的实验性项目" class="headerlink" title="一些有趣的实验性项目"></a>一些有趣的实验性项目<a class="heading-anchor" href="#一些有趣的实验性项目" aria-hidden="true"></a></h3><p>我们也有一些有趣好玩的实验性项目在进行中。</p>
<p>前面提到，做产品其实是个验证想法的过程。如果你脑袋里突然冒出一个想法，可能很不靠谱，但又似乎有意思。然后继续往深里去想，如果能经过很多次选择，最终能变为实现，就会体会到做产品的乐趣。</p>
<p>我就经常会有一些异想天开的想法。比如，如果你能拍一下一个人的头像会怎么样，如果你能朝跟你聊天的朋友扔一个炸弹在屏幕上炸开吓他一跳会怎么样，如果你在听一首歌的时候能看到其他听歌的人眼前的画面会怎么样，如果你失眠的时候也能看到其他的失眠的人然后大家一起数羊会怎么样。</p>
<p>甚至，如果给一个画布，每个人上去画一个点，如果有一千万人轮流去每人依次画一个点，到最后会不会形成一个图案？如果在没有组织的情况下，一千万人居然画出来一个图案，那又意味着什么？</p>
<p>所有这些都是很有趣的事情。所以做产品绝不是枯燥无味的。虽然大多数想法都会是行不通的，但有少数的能行得通，就非常好了。</p>
<p>这里，我就简单描述下微信新版本会有的几个功能。所有的功能在被用户实际验证之前，都不能说一定会受欢迎，但是只要思路的方向没有问题，就可以不断改进。有些功能也会经历灰度，完善了才放出来。所以不要抱以太高的期望。这里分享下这些好玩的功能的思考点。</p>
<h3 id="表情" class="heading-control"><a href="#表情" class="headerlink" title="表情"></a>表情<a class="heading-anchor" href="#表情" aria-hidden="true"></a></h3><p>一个是表情。<br>表情是表达方式中的一个基本元素。</p>
<p>说到表达方式的基本元素，这让我想起拍一拍。很多人会不喜欢被拍，还有很多人因为误触而拍错了人很尴尬。但仍然有 1.2 亿人设置了拍一拍的尾巴，每天几千万人在用拍一拍。拍一拍也是表达的一种基本元素，并且不同于其他所有方式，它是模拟人类的现实生活中的行为动作，用最简单的一个身体动作来完成了一次信息传递。有次内部开会我开玩笑说，未来人们的生活会越来越线上化，人们会怀念这种古老的人和人之间的交互方式的。</p>
<p>说回到表情。</p>
<p>人们的表情反映出情绪越来越强烈了。以至于必须经常 “裂开” 了。</p>
<p>我的想法可能比裂开更暴力。有一天我跟开发同学说，帮我做一个功能，我扔出一个炸弹，对方的屏幕就裂开来。当然，是动画效果的裂开，但要求很逼真。</p>
<p>实现是可以的，但是真的当作一个表情功能的时候，还是会遇到很多坎。</p>
<p>我说寻找基本元素，即这种表情必须是底层基础的，而不是一种特殊的。</p>
<p>最终我们做到了。</p>
<h3 id="状态" class="heading-control"><a href="#状态" class="headerlink" title="状态"></a>状态<a class="heading-anchor" href="#状态" aria-hidden="true"></a></h3><p>一个是状态。<br>现在大家打开一个朋友的微信名片，往往除了名字头像，什么也看不到。朋友圈也很多人设置了时效。</p>
<p>但事情不应该是这样的，每个名片，应该是活生生的才对。名片就是我们线上化生活的自己，它应该反映自己真实的状态。</p>
<p>我们之前尝试用视频动态表达一个人的状态，但视频化表达在这个地方其实挺困难的，因为确实拍个视频让所有的好友看到，这个压力还是挺大的，所以视频动态不算成功，每天大概有 100 多万的人在发视频动态，我们也会把它升级一下。升级以后的话，我们希望走到视频的另外一面。以前我说以前每个人发文字是很困难的，其实有一个前提，发一段让很多人都看的文字是很困难的，其实自己随便说一句话其实并不困难，状态就是随便说一句话这样一个东西。所以我们会走到视频的另外一面，通过你随便说一句话，随便写几个字来表达自己的状态。</p>
<p>并且，在某一时刻，一定还有其他的人跟你处在同一种状态里，你会希望看到他们。看到在打同一个游戏的人，同一个咖啡吧的人，同一个景点旅游的人等，甚至是，同一种心情的人。</p>
<p>我一直认为，社交的本质是找到同类。</p>
<p>状态，是用来给人看到的，最好还是给同类的人看到。</p>
<p>所以这一次，我们基于简单的文字来组织状态这样一个功能。</p>
<p>我不知道结果会怎么样。对于社交产品，因为它是群体互动来导致结果的，所以很难预料社交功能交给用户群体后的反应。但是，这样的尝试是应该的。因为，个人的状态表达的需求没有被满足。哪怕是简单的一句 “我今天很郁闷”，你不会发朋友圈，也不会跟朋友专门去说，那么，总需要一个地方可以说的。</p>
<h3 id="歌曲" class="heading-control"><a href="#歌曲" class="headerlink" title="歌曲"></a>歌曲<a class="heading-anchor" href="#歌曲" aria-hidden="true"></a></h3><p>还有一个新的尝试是关于听歌的，在座有一位听众跟我聊过怎样看见一首歌，歌不是用来听的，是用来看的。自从有了网络、移动互联网以后，我感觉是很多人听歌变得少了，只有在开车的时候才会听歌，因为在任何其他时候，你会宁愿去看视频了。微信其实是一个包含信息种类特别多的一个东西，但我一直不太满意的一点是在微信里面听歌的体验不太好，比如说我其实特别不理解为什么所有播放器都是一个电唱机在那里转，因为电唱机在我读中学的时候，我家里有一个，我还自己去买唱片，但是我想应该大部分用户不会经历过那个时代，那为什么他们要看不认识的物品，一个唱盘在那里转。</p>
<p>我们在听歌的时候应该看见什么？很多人说我们在听歌的时候不应该看见什么，而是应该听就好了，但我希望听歌的时候能够看到一点东西，因为听歌的时候有一点想象力，我们之所以希望在开车的时候听，是因为你的眼睛能看到很多的东西，让你的想象比平时更活跃了。如果这些东西，听同一首歌的人往往有很多人，举个例子，你可以想象你在这里听这首歌，另外一个人在另外的场景，还有很多类似的人，如果把他们听歌的眼前画面都连起来的话，总有一些人的画面跟你是非常类似的，他能够打动你的，所以从这个点上出发，我们就把听歌的体验做了一个视觉化的展现。</p>
<p>但这个难度其实特别大，因为技术还没有到那一步，我们的眼球都有一个摄像头实时传到云端，未来迟早会到那一步。所以目前只能通过别的产品方式才能做到这一步，就是说有一些热心的用户可能会愿意说，我能够把某一首歌变成一个制作得很精美的，类似 MV 这样一个东西，可以分享给更多的人看到。</p>
<h3 id="浮窗" class="heading-control"><a href="#浮窗" class="headerlink" title="浮窗"></a>浮窗<a class="heading-anchor" href="#浮窗" aria-hidden="true"></a></h3><p>我其实一直很不喜欢浮窗。因为它就像狗皮膏药。这也是 PC 时代大部分网页浏览的体验都不好的一个原因。</p>
<p>为了解决一篇文章要很久才看完，而中途要不断处理微信消息的需要，我们有了浮窗功能。但它并不完美。</p>
<p>很多时候，一篇文章，一个长视频，是要分很多次才看完的，如果每次都要先拖到浮窗，也是很繁琐的。</p>
<p>现在，微信提供了一个尚未看完的内容的列表，方便可以随时找回这些内容继续看完。尤其是对于长视频，更加需要随时可以切走，然后又能快速找到。直播也一样需要。</p>
<h3 id="输入法" class="heading-control"><a href="#输入法" class="headerlink" title="输入法"></a>输入法<a class="heading-anchor" href="#输入法" aria-hidden="true"></a></h3><p>还有一个可以提一下的新的研发中的产品，是团队正在研发的输入法。</p>
<p>我们会经常收到投诉，说刚刚在微信里聊到什么，就在其他 app 里看到这个东西的广告，是不是微信在出卖我的聊天记录给广告主。其实并不会。我们从来不会去分析用户的聊天记录，即便因此损失了很多广告收入。</p>
<p>所以当我们的技术团队，就是机器语义理解的团队，说我们自己做输入法可能会做的更好的时候，我当然很赞成。因为至少，在安全性方面，我们可以做的足够好。</p>
<p>我们的目标不是一下子获取多少用户。因为输入法是文字表达的入口，并且输入法必然越来越智能，可能出现新的输入形态，所以还是值得投入去做的。</p>
<h3 id="团队" class="heading-control"><a href="#团队" class="headerlink" title="团队"></a>团队<a class="heading-anchor" href="#团队" aria-hidden="true"></a></h3><p>很多人说视频号迭代速度特别快。事实上在微信的头两年，我们都是这个速度，后来有时快有时慢。其实我认为做产品就是应该快的。</p>
<p>我经常说的一句话是，如果一个问题，三天没有想出答案的话，那么三个月也想不出来，因此要么三天内找到解决方法，要么放弃，去寻找新的路径，而不是耗在那里。</p>
<p>孙子兵法说到，行军打仗应该要 “其徐如林，其疾如风”。做产品也是这样，要么没有想清楚，那不如什么都不做。如果要做，就要非常快速的迭代。</p>
<p>视频号团队到目前为止也就一两百人，其中还包括了三个算法团队，前后台开发，产品运营等。这很微信风格。互联网产品是关于创造力的，而不是拼人数。如果一个一百人的团队做不出来一个产品，给一千人也照样做不出来，甚至做的更差，因为一千人的内耗太大了。</p>
<h3 id="关于产品" class="heading-control"><a href="#关于产品" class="headerlink" title="关于产品"></a>关于产品<a class="heading-anchor" href="#关于产品" aria-hidden="true"></a></h3><p>微信十年，如果非要用两个词来描述微信，我想，一个是连接，一个是简单。</p>
<p>连接是很美的。因为世界的运行就是靠万事万物的连接而进行的。对产品来说，做连接，意味着做服务的底层设施，因为基于连接可以演变出来的结果是最丰富的。</p>
<p>很多的社交产品可能也做连接，但它止步于人，微信的连接范畴更大，公众号、小程序目标都是连接，连接人和内容、人和服务，包括微信支付也可以认为是一种货币的连接，视频号的目标也是连接。重心不是在做内容，而是在做底层的连接，这很重要。这也是为什么我们会提 “去中心化 “，因为连接和中心化是有些排斥的。</p>
<h3 id="简单" class="heading-control"><a href="#简单" class="headerlink" title="简单"></a>简单<a class="heading-anchor" href="#简单" aria-hidden="true"></a></h3><p>再说简单。</p>
<p>我用简单来作为美观，实用，合理，优雅的代名词。</p>
<p>简单是很美的。从一个物理公式到一个日常用品，往往是简单的是更好的。实现同样一个目标，有一千种方法，但只有最简单的方法是最美的。正是因为有一千种方法存在，所以要真正做到简单是很难的。</p>
<p>以前在饭否，看到很多产品越做越复杂，我吐槽说，“一个产品，要加多少功能，才能成为一个垃圾产品啊！” 不是说加功能会让产品不好，而是加了不必要的功能，或者加功能的方式不对。</p>
<p>十年来，微信加了很多功能。我很庆幸的是，现在的微信，还几乎和十年前的微信一样简单。虽然比十年前多了非常多功能，但这些功能，都已经是用的最简单的办法了，所以增加的复杂度会小。</p>
<p>简单才会好用。特别是一个产品有十亿人在用的时候。</p>
<p>有时候也会想，很多用户其实并不一定很在意产品是否简单。粗制滥造的产品，也可能照样会有很多人用的。但是我们还是会追求简单，因为总有部分人，会认同这种简单背后的美感。</p>
<h3 id="结束" class="heading-control"><a href="#结束" class="headerlink" title="结束"></a>结束<a class="heading-anchor" href="#结束" aria-hidden="true"></a></h3><p>微信虽然是这么大用户量的产品了，并且经历了 10 年之久了，但我还是希望，它能一直保持自己的风格，一直像一个小而美的产品一样，有自己的灵魂，有自己的审美，有自己的创意，有自己的观念。而不仅仅是数字的奴隶。这样的话，我和团队，才会为我们的工作而感到骄傲，并且觉得有意义，这是我对微信十年在今天的最后一个总结。</p>
<p>我今天的分享就到这里。</p>
<p>谢谢现场的朋友们，谢谢观看直播的每一个人，希望我没有浪费你的时间。再见。</p>
</body></html>]]></content>
      <tags>
        <tag>产品</tag>
      </tags>
  </entry>
  <entry>
    <title>Matlab 相关</title>
    <url>/post/cf3a540f.html</url>
    <content><![CDATA[<html><head><link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script></head><body><h2 id="Plot-Cheatsheet" class="heading-control"><a href="#Plot-Cheatsheet" class="headerlink" title="Plot Cheatsheet"></a>Plot Cheatsheet<a class="heading-anchor" href="#Plot-Cheatsheet" aria-hidden="true"></a></h2><p><img src="https://i.loli.net/2021/01/26/YBAivw8ShenR1kq.png" alt></p>
<a id="more"></a>
<h2 id="VScode-运行-Matlab" class="heading-control"><a href="#VScode-运行-Matlab" class="headerlink" title="VScode 运行 Matlab"></a>VScode 运行 Matlab<a class="heading-anchor" href="#VScode-运行-Matlab" aria-hidden="true"></a></h2><ol>
<li><p>电脑需要安装 VScode、Matlab 和 python</p>
</li>
<li><p>VScode 安装插件：MATLAB、Matlab Extension Pack、Matlab Interactive Terminal 以及 Matlab Snippets。</p>
</li>
<li><p>管理员权限打开命令行，进入 matlab (14b 以上版本) 目录：<code>matlab安装目录\extern\engines\python</code>，<code>python setup.py install</code></p>
</li>
<li><p>vscode 下，<code>ctrl+shift+p</code>：</p>
</li>
</ol>
<ul>
<li><code>Open a Matlab Terminal</code> which opens an interactive Matlab terminal in the VS Code integrated terminal, similar to the Matlab command line</li>
<li><code>Run current Matlab Script</code> which runs the currently opened Matlab script and then allows the user to interact with it through the opened terminal</li>
<li><code>Run current selection in Matlab</code> which runs the currently selected text in a Matlab terminal. If no text is selected, the current line is run instead</li>
</ul>
<h2 id="Matlab导出高DPI图像" class="heading-control"><a href="#Matlab导出高DPI图像" class="headerlink" title="Matlab导出高DPI图像"></a>Matlab 导出高 DPI 图像<a class="heading-anchor" href="#Matlab导出高DPI图像" aria-hidden="true"></a></h2><p>可参考文章：<a href="https://zhuanlan.zhihu.com/p/65116358">https://zhuanlan.zhihu.com/p/65116358</a></p>
<h3 id="文件-gt-导出设置" class="heading-control"><a href="#文件-gt-导出设置" class="headerlink" title="文件->导出设置"></a>文件 -> 导出设置<a class="heading-anchor" href="#文件-gt-导出设置" aria-hidden="true"></a></h3><p>点击文件》导出设置》就能打开导出设置窗口</p>
<p>我们需要设置:</p>
<ul>
<li>大小的单位（有时候需要自行设置宽和高），由于 dpi 是以 inch 为单位，这里将单位设置为英寸。</li>
<li>渲染的分辨率，设置为要求的大小。对于线图来说一般需要 600dpi：</li>
<li>最后点击导出，保存为需要的格式即可（包括 eps/tiff/jpeg 等）</li>
</ul>
<h3 id="matlab-的-print-函数" class="heading-control"><a href="#matlab-的-print-函数" class="headerlink" title="matlab 的 print 函数"></a>matlab 的 <a href="http://ww2.mathworks.cn/help/matlab/ref/print.html"><code>print</code></a> 函数<a class="heading-anchor" href="#matlab-的-print-函数" aria-hidden="true"></a></h3><p>可参考：<a href="http://ww2.mathworks.cn/help/matlab/ref/print.html">http://ww2.mathworks.cn/help/matlab/ref/print.html</a></p>
<figure class="highlight matlab"><table><tbody><tr><td class="code"><pre><span class="line">img =gcf;  <span class="comment">%获取当前画图的句柄</span></span><br><span class="line">print(img, <span class="string">'-dpng'</span>, <span class="string">'-r600'</span>, <span class="string">'./img.png'</span>)         <span class="comment">%即可得到对应格式和期望dpi的图像</span></span><br><span class="line">print(<span class="string">'-r600'</span>,<span class="string">'-dpdf'</span>, <span class="string">'-fillpage'</span>, <span class="string">'sphere1.pdf'</span>); <span class="comment">% 格式、分辨率</span></span><br><span class="line"><span class="comment">%第一个参数为fig的句柄，第二个-r后加对应的分辨率dpi，第二个为-d加对应的图像格式, 最后加上文件路径及名称字符串。</span></span><br></pre></td></tr></tbody></table></figure>
<h2 id="Matlab-3D-Plot" class="heading-control"><a href="#Matlab-3D-Plot" class="headerlink" title="Matlab 3D Plot"></a>Matlab 3D Plot<a class="heading-anchor" href="#Matlab-3D-Plot" aria-hidden="true"></a></h2><h3 id="meshgrid" class="heading-control"><a href="#meshgrid" class="headerlink" title="meshgrid"></a>meshgrid<a class="heading-anchor" href="#meshgrid" aria-hidden="true"></a></h3><figure class="highlight matlab"><table><tbody><tr><td class="code"><pre><span class="line">x = <span class="number">-2</span>:<span class="number">0.25</span>:<span class="number">2</span>;</span><br><span class="line">y = x;</span><br><span class="line">[X,Y] = meshgrid(x); # 使用均匀分布的 x 坐标和 y 坐标在区间 [-2,2] 内创建二维网格。</span><br><span class="line">F = X.*<span class="built_in">exp</span>(-X.^<span class="number">2</span>-Y.^<span class="number">2</span>);</span><br><span class="line">surf(X,Y,F)</span><br></pre></td></tr></tbody></table></figure>
<p><img src="https://i.loli.net/2021/01/28/CtSZFk28rN7YOAK.png" alt></p>
<h3 id="slice函数" class="heading-control"><a href="#slice函数" class="headerlink" title="slice函数"></a>slice 函数<a class="heading-anchor" href="#slice函数" aria-hidden="true"></a></h3><p>slice 函数用于对图像进行切面，调用格式：<code>slice（x,y,z,v，a,b,c）</code>，x,y,z, 作为坐标定义三维图像 v，a,b,c 作为矩阵，记录切面位置。比如 a=[1 2] 就是用 x=1,x=2 两个面去切 v。</p>
<figure class="highlight matlab"><table><tbody><tr><td class="code"><pre><span class="line">[x,y,z] = <span class="built_in">meshgrid</span>(<span class="number">-2</span>:<span class="number">.2</span>:<span class="number">2</span>,<span class="number">-2</span>:<span class="number">.25</span>:<span class="number">2</span>,<span class="number">-2</span>:<span class="number">.16</span>:<span class="number">2</span>);</span><br><span class="line">v = x.*<span class="built_in">exp</span>(-x.^<span class="number">2</span>-y.^<span class="number">2</span>-z.^<span class="number">2</span>);</span><br><span class="line">xslice = [<span class="number">-1.2</span>,<span class="number">.8</span>,<span class="number">2</span>]; yslice = <span class="number">2</span>; zslice = [<span class="number">-2</span>,<span class="number">0</span>];</span><br><span class="line">slice(x,y,z,v,xslice,yslice,zslice)</span><br><span class="line">set(get(gca, <span class="string">'XLabel'</span>), <span class="string">'String'</span>, <span class="string">'X'</span>);</span><br><span class="line">set(get(gca, <span class="string">'YLabel'</span>), <span class="string">'String'</span>, <span class="string">'Y'</span>);</span><br><span class="line">set(get(gca, <span class="string">'ZLabel'</span>), <span class="string">'String'</span>, <span class="string">'Z'</span>);</span><br><span class="line">colormap hsv</span><br></pre></td></tr></tbody></table></figure>
<p><img src="https://i.loli.net/2021/01/28/qTPzmHFiMBIQvNj.png" alt></p>
<h2 id="3D元胞自动机" class="heading-control"><a href="#3D元胞自动机" class="headerlink" title="3D元胞自动机"></a>3D 元胞自动机<a class="heading-anchor" href="#3D元胞自动机" aria-hidden="true"></a></h2><p>以 2016 年美赛 A 题为例：</p>
<figure class="highlight matlab"><table><tbody><tr><td class="code"><pre><span class="line"><span class="comment">%长方体浴缸液体三维元胞自动机模型</span></span><br><span class="line">clc, clear;</span><br><span class="line"><span class="keyword">global</span> tcell; <span class="comment">%本状态的元胞</span></span><br><span class="line"><span class="keyword">global</span> next_tcell; <span class="comment">%更新状态的元胞</span></span><br><span class="line"><span class="keyword">global</span> <span class="built_in">length</span>; <span class="keyword">global</span> width; <span class="keyword">global</span> height; <span class="comment">%元胞体的长宽高</span></span><br><span class="line"><span class="keyword">global</span> sum_cell; <span class="comment">%元胞的总个数</span></span><br><span class="line"><span class="keyword">global</span> tcell_type;</span><br><span class="line"><span class="comment">%元胞类型的判别矩阵</span></span><br><span class="line">tcell_type = <span class="built_in">zeros</span>(<span class="built_in">length</span>, width, height);</span><br><span class="line"></span><br><span class="line"><span class="comment">%元胞之间的距离</span></span><br><span class="line">dis = <span class="number">1</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">%时间间隔</span></span><br><span class="line">time = <span class="number">1500</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">%用切片函数构出长方体，构造长宽高</span></span><br><span class="line"><span class="built_in">length</span> = <span class="number">40</span>; width = <span class="number">60</span>; height = <span class="number">20</span>;</span><br><span class="line">[x, y, z] = <span class="built_in">meshgrid</span>(<span class="number">1</span>:dis:<span class="built_in">length</span> + <span class="number">1</span>, <span class="number">1</span>:dis:width + <span class="number">1</span>, <span class="number">1</span>:dis:height + <span class="number">1</span>);</span><br><span class="line">[m, n, p] = <span class="built_in">size</span>(x);</span><br><span class="line"><span class="built_in">length</span> = m - <span class="number">1</span>; width = n - <span class="number">1</span>; height = p - <span class="number">1</span>;</span><br><span class="line">sum_cell = <span class="built_in">length</span> * width * height;</span><br><span class="line"></span><br><span class="line"><span class="built_in">length</span> = m; width = n; height = p;</span><br><span class="line"></span><br><span class="line"><span class="comment">%设定温度的变化范围</span></span><br><span class="line">min_temperature = <span class="number">20</span>;</span><br><span class="line">max_temperature = <span class="number">45</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">% X = reshape(x, m*n*p, 1);</span></span><br><span class="line"><span class="comment">% Y = reshape(y, m*n*p, 1);</span></span><br><span class="line"><span class="comment">% Z = reshape(z, m*n*p, 1);</span></span><br><span class="line"><span class="comment">% scatter3(X, Y, Z, 'filled')</span></span><br><span class="line"></span><br><span class="line"><span class="comment">%测量周期</span></span><br><span class="line">t = <span class="number">35</span>;</span><br><span class="line"><span class="comment">%每周期的平均温度</span></span><br><span class="line">avg_t = <span class="built_in">zeros</span>(t, <span class="number">1</span>);</span><br><span class="line"><span class="comment">%设定初始温度</span></span><br><span class="line">tcell = <span class="built_in">zeros</span>(<span class="built_in">length</span>, width, height);</span><br><span class="line"><span class="comment">%初始化水温</span></span><br><span class="line"><span class="keyword">for</span> a = <span class="number">1</span>:<span class="built_in">length</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> b = <span class="number">1</span>:width</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> c = <span class="number">1</span>:height</span><br><span class="line">            tcell(a, b, c) = randi([<span class="number">20</span> <span class="number">45</span>]);</span><br><span class="line">        <span class="keyword">end</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">end</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"></span><br><span class="line">next_tcell = tcell;</span><br><span class="line"><span class="comment">%CA运行</span></span><br><span class="line"><span class="keyword">for</span> <span class="built_in">i</span> = <span class="number">1</span>:t</span><br><span class="line">    fprintf(<span class="string">'第%d时刻\n'</span>, <span class="built_in">i</span>);</span><br><span class="line">    slice(x, y, z, tcell, [<span class="number">3</span>], [], [], <span class="string">'cubic'</span>);</span><br><span class="line">    axis equal;</span><br><span class="line">    view(<span class="number">90</span>, <span class="number">10</span>);</span><br><span class="line">    shading flat;</span><br><span class="line">    caxis([min_temperature max_temperature]); <span class="comment">%控制水温与颜色映射关系</span></span><br><span class="line">    colormap jet<span class="comment">%标准颜色对照</span></span><br><span class="line">    colorbar</span><br><span class="line">    drawnow; <span class="comment">%当前立刻绘制</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">%液体内部热传递以及散热过程</span></span><br><span class="line">    <span class="keyword">for</span> x1 = <span class="number">2</span>:<span class="built_in">length</span> - <span class="number">1</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> y1 = <span class="number">2</span>:width - <span class="number">1</span></span><br><span class="line"></span><br><span class="line">            <span class="keyword">for</span> z1 = <span class="number">2</span>:height - <span class="number">1</span></span><br><span class="line"></span><br><span class="line">            <span class="keyword">end</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">end</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">end</span></span><br><span class="line"></span><br><span class="line">    tcell = next_tcell;</span><br><span class="line">    avg_t(<span class="built_in">i</span>) = <span class="number">1</span>; <span class="comment">%求平均温度</span></span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></tbody></table></figure>
<p><img src="https://i.loli.net/2021/01/28/zAlbIMs7ETFpBdH.png" alt></p>
</body></html>]]></content>
      <tags>
        <tag>Matlab</tag>
      </tags>
  </entry>
  <entry>
    <title>婚礼准备</title>
    <url>/post/fb3c7c8b.html</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p><img src="https://i.loli.net/2021/01/26/KLfdbTgQao64s9F.png" alt=""></p>
]]></content>
      <tags>
        <tag>婚礼</tag>
      </tags>
  </entry>
  <entry>
    <title>火影情结</title>
    <url>/post/8deb71f0.html</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p><img src="https://i.loli.net/2021/01/26/RBZw8U9cgHQq4Nd.gif" alt=""></p>
]]></content>
      <tags>
        <tag>火影</tag>
      </tags>
  </entry>
  <entry>
    <title>Shell 使用</title>
    <url>/post/d45370df.html</url>
    <content><![CDATA[<html><head><link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script></head><body><h2 id="初识shell" class="heading-control"><a href="#初识shell" class="headerlink" title="初识shell"></a>初识 shell<a class="heading-anchor" href="#初识shell" aria-hidden="true"></a></h2><p>脚本其实就是短小的、用来让计算机自动化完成一系列工作的程序，这类程序可以用文本编辑器修改，不需要编译，通常是解释运行的。</p>
<h3 id="第一个shell脚本" class="heading-control"><a href="#第一个shell脚本" class="headerlink" title="第一个shell脚本"></a>第一个 shell 脚本<a class="heading-anchor" href="#第一个shell脚本" aria-hidden="true"></a></h3><p>打开文本编辑器 (可以使用 vi/vim 命令来创建文件)，新建一个文件 test.sh，扩展名为 sh（sh 代表 shell）。<br></p><figure class="highlight shell"><table><tbody><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">!/bin/bash</span></span><br><span class="line">echo "Hello World !"</span><br></pre></td></tr></tbody></table></figure><br>1、<code>chmod +x file</code> 加上执行权限，否则会提示无执行权限。<br>2、注意执行脚本时候或者全目录，或者 <code>./file.sh</code> ，如果不加的话，linux 默认会从PATH 里去找该 file.sh。<br>3、脚本后缀名可以任意修改，仍然可以正常运行。<br><a id="more"></a><p></p>
<h3 id="运行shell脚本" class="heading-control"><a href="#运行shell脚本" class="headerlink" title="运行shell脚本"></a>运行 shell 脚本<a class="heading-anchor" href="#运行shell脚本" aria-hidden="true"></a></h3><p>运行 Shell 脚本有两种方法：<br>1、作为可执行程序<br></p><figure class="highlight shell"><table><tbody><tr><td class="code"><pre><span class="line">chmod +x ./test.sh  #使脚本具有执行权限</span><br><span class="line">./test.sh  #执行脚本</span><br></pre></td></tr></tbody></table></figure><br>2、作为解释器参数<br><figure class="highlight shell"><table><tbody><tr><td class="code"><pre><span class="line">/bin/sh test.sh</span><br></pre></td></tr></tbody></table></figure><p></p>
<h3 id="sh-bash-csh-Tcsh-ksh-pdksh等shell的区别" class="heading-control"><a href="#sh-bash-csh-Tcsh-ksh-pdksh等shell的区别" class="headerlink" title="sh/bash/csh/Tcsh/ksh/pdksh等shell的区别"></a>sh/bash/csh/Tcsh/ksh/pdksh 等 shell 的区别<a class="heading-anchor" href="#sh-bash-csh-Tcsh-ksh-pdksh等shell的区别" aria-hidden="true"></a></h3><ul>
<li><strong>sh (全称 Bourne Shell)</strong>: 是 UNIX 最初使用的 shell，而且在每种 UNIX 上都可以使用。Bourne Shell 在 shell 编程方面相当优秀，但在处理与用户的交互方面做得不如其他几种 shell。</li>
<li><strong>bash（全称 Bourne Again Shell）</strong>: LinuxOS 默认的，它是 Bourne Shell 的扩展。 与 Bourne Shell 完全兼容，并且在 Bourne Shell 的基础上增加了很多特性。可以提供命令补全，命令编辑和命令历史等功能。它还包含了很多 C Shell 和 Korn Shell 中的优点，有灵活和强大的编辑接口，同时又很友好的用户界面。</li>
<li><strong>csh (全称 C Shell)</strong>: 是一种比 Bourne Shell 更适合的变种 Shell，它的语法与 C 语言很相似。</li>
<li><strong>Tcsh</strong>: 是 Linux 提供的 C Shell 的一个扩展版本。Tcsh 包括命令行编辑，可编程单词补全，拼写校正，历史命令替换，作业控制和类似 C 语言的语法，他不仅和 Bash Shell 提示符兼容，而且还提供比 Bash Shell 更多的提示符参数。</li>
<li><strong>ksh (全称 Korn Shell)</strong>: 集合了 C Shell 和 Bourne Shell 的优点并且和 Bourne Shell 完全兼容。</li>
<li><strong>pdksh</strong>: 是 Linux 系统提供的 ksh 的扩展。pdksh 支持人物控制，可以在命令行上挂起，后台执行，唤醒或终止程序。</li>
</ul>
<h2 id="Shell-变量" class="heading-control"><a href="#Shell-变量" class="headerlink" title="Shell 变量"></a>Shell 变量<a class="heading-anchor" href="#Shell-变量" aria-hidden="true"></a></h2><h3 id="定义变量" class="heading-control"><a href="#定义变量" class="headerlink" title="定义变量"></a>定义变量<a class="heading-anchor" href="#定义变量" aria-hidden="true"></a></h3><figure class="highlight shell"><table><tbody><tr><td class="code"><pre><span class="line">your_name="runoob.com"</span><br></pre></td></tr></tbody></table></figure>
<p>注意，<strong>变量名和等号之间不能有空格</strong>。同时，变量名的命名须遵循如下规则：</p>
<ol>
<li>命名只能使用英文字母，数字和下划线，首个字符不能以数字开头。</li>
<li>中间不能有空格，可以使用下划线（_）。</li>
<li>不能使用标点符号。</li>
<li>不能使用 bash 里的关键字（可用 help 命令查看保留关键字）。</li>
</ol>
<h3 id="使用变量" class="heading-control"><a href="#使用变量" class="headerlink" title="使用变量"></a>使用变量<a class="heading-anchor" href="#使用变量" aria-hidden="true"></a></h3><p>使用一个定义过的变量，只要在变量名前面加美元符号即可，如：<br></p><figure class="highlight shell"><table><tbody><tr><td class="code"><pre><span class="line">your_name="qinjx"</span><br><span class="line">echo $your_name</span><br><span class="line">echo ${your_name}</span><br></pre></td></tr></tbody></table></figure><br>变量名外面的花括号是可选的，加不加都行，加花括号是为了帮助解释器识别变量的边界。推荐给所有变量加上花括号，这是个好的编程习惯。<p></p>
<h3 id="只读变量" class="heading-control"><a href="#只读变量" class="headerlink" title="只读变量"></a>只读变量<a class="heading-anchor" href="#只读变量" aria-hidden="true"></a></h3><p>使用 readonly 命令可以将变量定义为只读变量，只读变量的值不能被改变。<br></p><figure class="highlight shell"><table><tbody><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">!/bin/bash</span></span><br><span class="line">myUrl="https://www.google.com"</span><br><span class="line">readonly myUrl</span><br><span class="line">myUrl="https://www.runoob.com"</span><br></pre></td></tr></tbody></table></figure><br>上面的程序执行会报错 <code>/bin/sh: NAME: This variable is read only.</code>。<p></p>
<h3 id="删除变量" class="heading-control"><a href="#删除变量" class="headerlink" title="删除变量"></a>删除变量<a class="heading-anchor" href="#删除变量" aria-hidden="true"></a></h3><p>使用 unset 命令可以删除变量。语法：<br></p><figure class="highlight shell"><table><tbody><tr><td class="code"><pre><span class="line">unset variable_name</span><br></pre></td></tr></tbody></table></figure><br>变量被删除后不能再次使用。unset 命令不能删除只读变量。<p></p>
<h3 id="Shell-字符串" class="heading-control"><a href="#Shell-字符串" class="headerlink" title="Shell 字符串"></a>Shell 字符串<a class="heading-anchor" href="#Shell-字符串" aria-hidden="true"></a></h3><p>字符串是 shell 编程中最常用最有用的数据类型，字符串可以用单引号，也可以用双引号，也可以不用引号。</p>
</body></html>]]></content>
      <tags>
        <tag>shell</tag>
      </tags>
  </entry>
  <entry>
    <title>我在 BIGO 的这一年</title>
    <url>/post/e231005e.html</url>
    <content><![CDATA[<html><head><link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script></head><body><h2 id="从2020到2021" class="heading-control"><a href="#从2020到2021" class="headerlink" title="从2020到2021"></a>从 2020 到 2021<a class="heading-anchor" href="#从2020到2021" aria-hidden="true"></a></h2><p>2020 年 1 月 1 日，我正式和在知乎上相识几天的女朋友表白，并迅速在一起了。彼时我在武汉华科读研二，她在河北师范大学读大三。缘分这东西就是这样的奇妙，茫茫人海中一眼就能认出自己的有缘人。等到 1 月 15 日 放寒假的时候，我绕去石家庄回家，我们正式第一次见了面。19 号回到家中，23 日武汉爆发疫情。好在我平时出校门交际不多，并没有感染，回家也略早，没有滞留在武汉。接下来的几个月每天都很紧张，早上醒来第一件事就是看看武汉的疫情状况。回想起来，疫情那段时间主要做了几件事情：</p>
<ul>
<li>每天和女朋友视频，感情迅速升温，到了 5 月份好转一点的时候我们还溜出来见了几次。</li>
<li>远程写毕业论文，跟导师汇报和讨论进展，最后的答辩也是远程进行的。</li>
<li>自上大学起回家时间就很少，正好陪了一下父母，教会了我妈骑电动车。</li>
</ul>
<p>由于武汉是疫情中心，华科一直到 6 月 20 号才开学，和女朋友匆匆别过，去了华科收拾了行李，拿了毕业证书， 7 月 1 号正式入职秋招签约的公司 BIGO 广州总部。</p>
<p>我在公司附近租了一个带卫生间的主卧，房租每月 1300，走路到公司 15 分钟。入职的部门是应用算法部的技术体系，负责 BIGO Live 的贴吧 Feed 流内容推荐算法。刚进去的时候真是啥也不会，那段时间跟着师兄学习了 Hive Sql，学习了上线流程，学习了召回和排序算法的实现等等，受益良多。BIGO 的节奏是大小周，相当于每月有两个周六加班，周一到周五的工作节奏是早 10 晚 9。在学校的时候觉得这种加班挺容易的，毕竟研究生的时候也感觉自己挺能熬的。但是工作了后，才明白强度完全不在一个档次，单休的那周真的无比难受。2020 年的国庆节和春节，因为一来国家不提倡流动，二来广州离河北确实有点远，我就没有回家。工作的日子就这样一天天过去，直到 2021 年的 3 月。</p>
<a id="more"></a>
<p>2021 年的 3 月，公司发生了很大的架构调整，而我直接被公司放到资源池里面。我的小 Leader 直接让我简单交接后，两手准备，准备找工作。刚接到这个消息的时候，我还是很震惊的。后来想了一下，既然当初决定来这种小公司，当然也要承担这种不稳定的风险；另外我当时也一直在和女朋友说要转到北京那边工作（一来想找个大公司，二来见面也方便），对我来说只是提前了计划而已。之后 BIGO 提出解约，赔偿了 N+1。但公司的这种做法还是令我很不爽，这对应届生无疑是灾难一般，仅仅工作 9 月就跳槽，面试的时候肯定会被问原因的。</p>
<p>但是我也没办法，随后就开始刷题和复习，当时感觉自己推荐部分做的并不深，所以打算面老本行，NLP 方向的算法。陆续复习了半个多月，才开始面试。面过的公司包括，知乎、搜狗、搜狐、58 同城、平安科技、百度、美团、拼多多、微博、字节、阿里、微软等等。没想到面到最后 NLP 的一个没拿，倒是拿了一堆搜索和推荐的：百度搜索、美团搜索、拼多多推荐和搜狗搜索的 Offer。虽然结局是好的，但是也体验了一把小厂的动荡，现在想起来还有点后怕。</p>
<h2 id="写简历" class="heading-control"><a href="#写简历" class="headerlink" title="写简历"></a>写简历<a class="heading-anchor" href="#写简历" aria-hidden="true"></a></h2><p>我用的是这个简历模板 <a href="https://www.overleaf.com/read/tbjwnnsydqjz">链接</a>，需要 Latex 环境，TeXStudio+TeXLive。</p>
<h2 id="算法" class="heading-control"><a href="#算法" class="headerlink" title="算法"></a>算法<a class="heading-anchor" href="#算法" aria-hidden="true"></a></h2><p>刷题主要在剑指 offer，牛客题霸和 LeetCode，算法部分我主要刷了这些题目：</p>
<ul>
<li>排序算法相关：数组的快排，归并，无序数组求 TopK，链表的快排，归并，合并 K 个有序链表。</li>
<li>链表：判断链表是否有环，链表中环的入口节点</li>
<li>二分：搜索旋转排序数组，旋转数组最小值</li>
<li>树：树的非递归前中后序遍历，树的层次遍历，二叉树和为指定值的路径，二叉树的最大路径和，二叉树的镜像，二叉树最近公共祖先</li>
<li>动态规划：编辑距离，换硬币，矩阵从左上角到右下角的走法，子数组的最大累加和问题，最长上升子序列，股票交易</li>
</ul>
<h2 id="工作项目" class="heading-control"><a href="#工作项目" class="headerlink" title="工作项目"></a>工作项目<a class="heading-anchor" href="#工作项目" aria-hidden="true"></a></h2><p>我把这部分分为以下几个小部分：</p>
<ul>
<li>工作项目，我简历上的是图做召回算法，双塔做文本向量化召回，NLP 的部分包括一个问答系统和一个文本分类比赛。</li>
<li>基本知识：C++/Python 基础、机器学习基础、深度学习基础</li>
</ul>
<h3 id="工作项目-1" class="heading-control"><a href="#工作项目-1" class="headerlink" title="工作项目"></a>工作项目<a class="heading-anchor" href="#工作项目-1" aria-hidden="true"></a></h3><p>问的比较多的：</p>
<ol>
<li>召回怎么做离线评估和在线？</li>
<li>Faiss 的原理</li>
</ol>
<h3 id="基本知识" class="heading-control"><a href="#基本知识" class="headerlink" title="基本知识"></a>基本知识<a class="heading-anchor" href="#基本知识" aria-hidden="true"></a></h3><ol>
<li>C++ STL 容器的底层数据结构？</li>
<li>Python 的 GIL 锁？多进程和多线程？</li>
<li></li>
</ol>
<p>写于二零二一年五月八日，BIGO 公司</p>
</body></html>]]></content>
      <tags>
        <tag>总结</tag>
      </tags>
  </entry>
  <entry>
    <title>拓扑排序</title>
    <url>/post/fb40efc5.html</url>
    <content><![CDATA[<html><head><link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script></head><body><h2 id="AOV-网" class="heading-control"><a href="#AOV-网" class="headerlink" title="AOV-网"></a>AOV - 网<a class="heading-anchor" href="#AOV-网" aria-hidden="true"></a></h2><p>以顶点表示活动，有向边表示活动之间的先后关系的图称为 AOV 网 (Activity On Vertex Network，顶点表示活动的网)。AOV 网是一种有向无环图 (Directed Acyclic Graph, DAG)。</p>
<h2 id="拓扑排序" class="heading-control"><a href="#拓扑排序" class="headerlink" title="拓扑排序"></a>拓扑排序<a class="heading-anchor" href="#拓扑排序" aria-hidden="true"></a></h2><p>拓扑排序就是将 AOV 网中的所有顶点排列成一个线性序列，并且序列满足以下条件：在 AOV 网中，如果从顶点 A 到 B 存在一条路径，则在该线性序列中，顶点 A 一定出现在顶点 B 之前。因此拓扑排序的过程就是将 AOV 网中的各个活动组成一个可行的实施方案。此外拓扑排序也可以判断图中是否有环。拓扑排序并不唯一，有向无环图一定存在拓扑排序。<br><a id="more"></a><br>拓扑排序具体的算法步骤如下：</p>
<ul>
<li>选择一个入度为 0 的顶点并输出。</li>
<li>从 AOV 网中删除此顶点及以此顶点为起点的所有关联边。</li>
<li>重复上述两步，直到不存在入度为 0 的顶点为止。</li>
<li>AOV 网中还有剩余的顶点，则说明 AOV 网中存在回路，不是一个标准的 AOV 网。</li>
</ul>
<h2 id="代码实现" class="heading-control"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现<a class="heading-anchor" href="#代码实现" aria-hidden="true"></a></h2><p>需要维护一个入度为 0 的顶点的集合，每次从该集合中取出 (没有特殊的取出规则，随机取出也行，使用队列 / 栈也行，下同) 一个顶点，将该顶点放入保存结果中。<br>紧接着循环遍历由该顶点引出的所有边，从图中移除这条边，同时获取该边的另外一个顶点，如果该顶点的入度在减去本条边之后为 0，那么也将这个顶点放到入度为 0 的集合中。然后继续从集合中取出一个顶点。<br>当集合为空之后，检查图中是否还存在任何边，如果存在的话，说明图中至少存在一条环路。不存在的话则返回结果 List，此 List 中的顺序就是对图进行拓扑排序的结果。<br></p><figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">topoSort</span>(<span class="params">graph</span>):</span>     </span><br><span class="line">    in_degrees = dict((u,<span class="number">0</span>) <span class="keyword">for</span> u <span class="keyword">in</span> graph)   <span class="comment">#初始化所有顶点入度为0     </span></span><br><span class="line">    num = len(in_degrees)     </span><br><span class="line">    <span class="keyword">for</span> u <span class="keyword">in</span> graph:         </span><br><span class="line">        <span class="keyword">for</span> v <span class="keyword">in</span> graph[u]:             </span><br><span class="line">            in_degrees[v] += <span class="number">1</span>    <span class="comment">#计算每个顶点的入度     </span></span><br><span class="line">    Q = [u <span class="keyword">for</span> u <span class="keyword">in</span> in_degrees <span class="keyword">if</span> in_degrees[u] == <span class="number">0</span>]   <span class="comment"># 筛选入度为0的顶点     </span></span><br><span class="line">    Seq = []     </span><br><span class="line">    <span class="keyword">while</span> Q:         </span><br><span class="line">        u = Q.pop()       <span class="comment">#默认从最后一个删除         </span></span><br><span class="line">        Seq.append(u)         </span><br><span class="line">        <span class="keyword">for</span> v <span class="keyword">in</span> graph[u]:             </span><br><span class="line">            in_degrees[v] -= <span class="number">1</span>    <span class="comment">#移除其所有出边</span></span><br><span class="line">            <span class="keyword">if</span> in_degrees[v] == <span class="number">0</span>:        </span><br><span class="line">                Q.append(v)          <span class="comment">#再次筛选入度为0的顶点</span></span><br><span class="line">    <span class="keyword">if</span> len(Seq) == num:       <span class="comment">#输出的顶点数是否与图中的顶点数相等</span></span><br><span class="line">        <span class="keyword">return</span> Seq     </span><br><span class="line">    <span class="keyword">else</span>:         </span><br><span class="line">        <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">G = {</span><br><span class="line">    <span class="string">'a'</span>:<span class="string">'bf'</span>,</span><br><span class="line">    <span class="string">'b'</span>:<span class="string">'cdf'</span>,</span><br><span class="line">    <span class="string">'c'</span>:<span class="string">'d'</span>,</span><br><span class="line">    <span class="string">'d'</span>:<span class="string">'ef'</span>,</span><br><span class="line">    <span class="string">'e'</span>:<span class="string">'f'</span>,</span><br><span class="line">    <span class="string">'f'</span>:<span class="string">''</span></span><br><span class="line">}</span><br><span class="line">print(topoSort(G))</span><br></pre></td></tr></tbody></table></figure><p></p>
<h2 id="TensorFlow计算图" class="heading-control"><a href="#TensorFlow计算图" class="headerlink" title="TensorFlow计算图"></a>TensorFlow 计算图<a class="heading-anchor" href="#TensorFlow计算图" aria-hidden="true"></a></h2><p>TensorFlow 是一个使用数据流图 (Dataflow Graph) 表达数值计算的开源软件库。它使 用节点表示抽象的数学计算，并使用 OP 表达计算的逻辑；而边表示节点间传递的数据流， 并使用 Tensor 表达数据的表示。数据流图是一种有向无环图 (DAG)，当图中的 OP 按 照特定的 <strong>拓扑排序</strong> 依次被执行时，Tensor 在图中流动形成数据流，TensorFlow 因此而得名。</p>
<p>在分布式运行时，数据流图的被分裂为多个子图，并被有效地部署到集群中的多个机 器上并发执行。在一个机器内，注册的子图被二次分裂为更小的子图，它们被部署在本地 设备集上并发执行。TensorFlow 支持多种异构设备的分布式计算，包括 CPU, GPU, ASIC。 TensorFlow 跨平台的卓越表现，使得它能够灵活地部署在各种计算平台上，包括台式机、 服务器、移动终端。</p>
<p>TensorFlow 最初由 Google Brain 的研究员和工程师们开发出来，用于开展机器学习和 深度神经网络的研究，包括语言识别、计算机视觉、自然语言理解、机器人、信息检索。但 是，TensorFlow 系统架构的通用性和灵活性，使其广泛地用于其他科学领域的数值计算。</p>
</body></html>]]></content>
      <tags>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title>微软面试题</title>
    <url>/post/d4f879a5.html</url>
    <content><![CDATA[<html><head><link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script></head><body><p>面试的是微软 edge 浏览器的信息流推荐算法。</p>
<h2 id="完全二叉树的层次遍历反转" class="heading-control"><a href="#完全二叉树的层次遍历反转" class="headerlink" title="完全二叉树的层次遍历反转"></a>完全二叉树的层次遍历反转<a class="heading-anchor" href="#完全二叉树的层次遍历反转" aria-hidden="true"></a></h2><p>一面的算法题是给定一个数组，是一个完全二叉树的层次遍历结果，然后输出一个数组，是每层的逆序结果。<br><strong>思路：</strong> 首先，完全二叉树是可以计算每层节点的数量的，也就是可以在原数组中进行层的划分。之后需要处理的就是反转一个 list, 这个可以用双指针，左指针指向第一个位置，右指针指向最后一个位置，然后交换元素，直到左指针大于右指针。考虑特殊情况是，完全二叉树不满的情况，这种只出现在最后一层，需要计算右指针的位置。</p>
</body></html>]]></content>
      <tags>
        <tag>算法</tag>
      </tags>
  </entry>
</search>
